QUESTION,USERID,USERNAME,ANSWER
"<p>I've tried to measure the asymmetric memory access effects of NUMA, and failed.</p>

<h2>The Experiment</h2>

<p>Performed on an Intel Xeon X5570 @ 2.93GHz, 2 CPUs, 8 cores.</p>

<p>On a thread pinned to core 0, I allocate an array <strong><em>x</em></strong> of size 10,000,000 bytes on core 0's NUMA node with numa_alloc_local. 
Then I iterate over array <strong><em>x</em></strong> 50 times and read and write each byte in the array. Measure the elapsed time to do the 50 iterations. </p>

<p>Then, on each of the other cores in my server, I pin a new thread and again measure the elapsed time to do 50 iterations of reading and writing
to every byte in array <strong><em>x</em></strong>.</p>

<p>Array <strong><em>x</em></strong> is large to minimize cache effects. We want to measure the speed when the CPU has to go all the way to RAM to load and store, not when caches are helping.</p>

<p>There are two NUMA nodes in my server, so I would expect the cores that have affinity on the same node in which array <strong><em>x</em></strong> is allocated to have
faster read/write speed. I'm not seeing that. </p>

<p>Why?</p>

<p>Perhaps NUMA is only relevant on systems with > 8-12 cores, as I've seen suggested elsewhere?</p>

<p><a href=""http://lse.sourceforge.net/numa/faq/"">http://lse.sourceforge.net/numa/faq/</a></p>

<h2>numatest.cpp</h2>

<pre><code>#include &lt;numa.h&gt;
#include &lt;iostream&gt;
#include &lt;boost/thread/thread.hpp&gt;
#include &lt;boost/date_time/posix_time/posix_time.hpp&gt;
#include &lt;pthread.h&gt;

void pin_to_core(size_t core)
{
    cpu_set_t cpuset;
    CPU_ZERO(&amp;cpuset);
    CPU_SET(core, &amp;cpuset);
    pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &amp;cpuset);
}

std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const bitmask&amp; bm)
{
    for(size_t i=0;i&lt;bm.size;++i)
    {
        os &lt;&lt; numa_bitmask_isbitset(&amp;bm, i);
    }
    return os;
}

void* thread1(void** x, size_t core, size_t N, size_t M)
{
    pin_to_core(core);

    void* y = numa_alloc_local(N);

    boost::posix_time::ptime t1 = boost::posix_time::microsec_clock::universal_time();

    char c;
    for (size_t i(0);i&lt;M;++i)
        for(size_t j(0);j&lt;N;++j)
        {
            c = ((char*)y)[j];
            ((char*)y)[j] = c;
        }

    boost::posix_time::ptime t2 = boost::posix_time::microsec_clock::universal_time();

    std::cout &lt;&lt; ""Elapsed read/write by same thread that allocated on core "" &lt;&lt; core &lt;&lt; "": "" &lt;&lt; (t2 - t1) &lt;&lt; std::endl;

    *x = y;
}

void thread2(void* x, size_t core, size_t N, size_t M)
{
    pin_to_core(core);

    boost::posix_time::ptime t1 = boost::posix_time::microsec_clock::universal_time();

    char c;
    for (size_t i(0);i&lt;M;++i)
        for(size_t j(0);j&lt;N;++j)
        {
            c = ((char*)x)[j];
            ((char*)x)[j] = c;
        }

    boost::posix_time::ptime t2 = boost::posix_time::microsec_clock::universal_time();

    std::cout &lt;&lt; ""Elapsed read/write by thread on core "" &lt;&lt; core &lt;&lt; "": "" &lt;&lt; (t2 - t1) &lt;&lt; std::endl;
}

int main(int argc, const char **argv)
{
    int numcpus = numa_num_task_cpus();
    std::cout &lt;&lt; ""numa_available() "" &lt;&lt; numa_available() &lt;&lt; std::endl;
    numa_set_localalloc();

    bitmask* bm = numa_bitmask_alloc(numcpus);
    for (int i=0;i&lt;=numa_max_node();++i)
    {
        numa_node_to_cpus(i, bm);
        std::cout &lt;&lt; ""numa node "" &lt;&lt; i &lt;&lt; "" "" &lt;&lt; *bm &lt;&lt; "" "" &lt;&lt; numa_node_size(i, 0) &lt;&lt; std::endl;
    }
    numa_bitmask_free(bm);

    void* x;
    size_t N(10000000);
    size_t M(50);

    boost::thread t1(boost::bind(&amp;thread1, &amp;x, 0, N, M));
    t1.join();

    for (size_t i(0);i&lt;numcpus;++i)
    {
        boost::thread t2(boost::bind(&amp;thread2, x, i, N, M));
        t2.join();
    }

    numa_free(x, N);

    return 0;
}
</code></pre>

<h2>The Output</h2>

<pre><code>g++ -o numatest -pthread -lboost_thread -lnuma -O0 numatest.cpp

./numatest

numa_available() 0                    &lt;-- NUMA is available on this system
numa node 0 10101010 12884901888      &lt;-- cores 0,2,4,6 are on NUMA node 0, which is about 12 Gb
numa node 1 01010101 12874584064      &lt;-- cores 1,3,5,7 are on NUMA node 1, which is slightly smaller than node 0

Elapsed read/write by same thread that allocated on core 0: 00:00:01.767428
Elapsed read/write by thread on core 0: 00:00:01.760554
Elapsed read/write by thread on core 1: 00:00:01.719686
Elapsed read/write by thread on core 2: 00:00:01.708830
Elapsed read/write by thread on core 3: 00:00:01.691560
Elapsed read/write by thread on core 4: 00:00:01.686912
Elapsed read/write by thread on core 5: 00:00:01.691917
Elapsed read/write by thread on core 6: 00:00:01.686509
Elapsed read/write by thread on core 7: 00:00:01.689928
</code></pre>

<p>Doing 50 iterations reading and writing over array <strong><em>x</em></strong> takes about 1.7 seconds, no matter which core is doing the reading and writing.</p>

<h2>Update:</h2>

<p>The cache size on my CPUs is 8Mb, so maybe 10Mb array <strong><em>x</em></strong> is not big enough to eliminate cache effecs. I tried 100Mb array <strong><em>x</em></strong>, and
I've tried issuing a full memory fence with __sync_synchronize() inside my innermost loops. It still doesn't reveal any asymmetry between NUMA nodes.</p>

<h2>Update 2:</h2>

<p>I've tried reading and writing to array <strong><em>x</em></strong> with __sync_fetch_and_add(). Still nothing.</p>
","922184","","<p>The first thing I want to point out is that you might want to double-check which cores are on each node. I don't recall cores and nodes being interleaved like that.
Also, you should have 16 threads due to HT. (unless you disabled it)</p>

<p>Another thing:</p>

<p>The socket 1366 Xeon machines are only slightly NUMA. So it will be hard to see the difference. The NUMA effect is much more noticeable on the 4P Opterons.</p>

<p>On systems like yours, the node-to-node bandwidth is actually faster than the CPU-to-memory bandwidth. Since your access pattern is completely sequential, you are getting the full bandwidth regardless of whether or not the data is local. A better thing to measure is the latency. Try random accessing a block of 1 GB instead of streaming it sequentially.</p>

<p>Last thing:</p>

<p>Depending on how aggressively your compiler optimizes, your loop might be optimized out since it doesn't do anything:</p>

<pre><code>c = ((char*)x)[j];
((char*)x)[j] = c;
</code></pre>

<p>Something like this will guarantee that it won't be eliminated by the compiler:</p>

<pre><code>((char*)x)[j] += 1;
</code></pre>
"
"<p>I need an 1D Convolution against 2 big arrays. I'm using this code in C# but it takes a loooong time to run. </p>

<p>I know, i know! FFT convolutions is very fast. But in this project i CAN'T use it. 
It is a constraint of the project to not use FFT (please don't ask why :/).</p>

<p>This is my code in C# (ported from matlab, by the way): </p>

<pre><code>var result = new double[input.Length + filter.Length - 1];
for (var i = 0; i &lt; input.Length; i++)
{
    for (var j = 0; j &lt; filter.Length; j++)
    {
        result[i + j] += input[i] * filter[j];
    }
}
</code></pre>

<p>So, anyone knows any fast convolution algorithm widthout FFT? </p>
","922184","","<p>Convolution is numerically the same as a polynomial multiplication with an extra wrap-around step. Therefore, all the polynomial and large integer multiplication algorithms can be used to perform convolution.</p>

<p>FFT is the only way to get the fast O(n log(n)) run-time. But you can still get sub-quadratic run-time using the divide-and-conquer approaches like <a href=""http://en.wikipedia.org/wiki/Karatsuba_algorithm"" rel=""nofollow"">Karatsuba's algorithm</a>.</p>

<p>Karatsuba's algorithm is fairly easy to implement once you understand how it works. It runs in O(n^1.585), and will probably be faster than trying to super-optimize the classic O(n^2) approach.</p>
"
"<p>If I have the code:</p>

<pre><code>uint64_t a = 0x1111222233334444;
uint32_t b = 0;
b = a;
printf(""a is %llx "",a);
printf(""b is %x "",b);
</code></pre>

<p>and the output is :</p>

<pre><code> a is 1111222233334444 b is 33334444
</code></pre>

<p><strong>Questions</strong> : </p>

<ol>
<li><p>Will the behavior be same on big-endian machine?</p></li>
<li><p>If I assign a's value in b or do a typecast will the result be same in big endian?</p></li>
</ol>
","922184","","<p>The code you have there will work the same way. This is because the behavior of downcasting is defined by the C standard.</p>

<p>However, if you did this:</p>

<pre><code>uint64_t a = 0x0123456789abcdefull;
uint32_t b = *(uint32_t*)&amp;a;
printf(""b is %x"",b)
</code></pre>

<p>Then it will be endian-dependent.</p>

<p>EDIT:</p>

<p>Little Endian: b is 89abcdef</p>

<p>Big Endian   : b is 01234567</p>
"
"<p><strong>EDIT</strong>: The requirement was vague and instead of  calculating the n-th digit of pi they just wanted pi to the n-th digit not going beyond floats limitation so the brute force way worked for the requirements.</p>

<p>I need to calculate PI the the n-th digit and I wanted to try using the <a href=""http://en.wikipedia.org/wiki/Bailey%E2%80%93Borwein%E2%80%93Plouffe_formula"" rel=""nofollow"">BBP formula</a> but am having difficulties. The equation I typed up doesn't seem to be giving me PI correctly.</p>

<pre><code>(1 / pow(16,n))((4 / (8 * n + 1)) - (2 / (8 * n + 4)) - (1 / (8 * n + 5)) - (1 / (8 * n + 6)))
</code></pre>

<p>I was successful with the brute force way of finding PI but that is only so accurate and finding the nth number is difficult.</p>

<pre><code>(4 - (4/3) + (4/5) - (4/7)...)
</code></pre>

<p>I wanted to find out if anyone had a better idea of how to do this or maybe help with my BBP equation on what I messed up?</p>

<p>Thank you,<br>
LF4</p>

<p>Functional but not very accurate until a few iterations in and then you have to disreguard the last few.</p>

<pre><code>#include &lt;iostream&gt;

using namespace std;

int main()
{
    int loop_num = 0;
    cout &lt;&lt; ""How many digits of pi do you want?: "";
    cin  &gt;&gt; loop_num;

    double my_pi = 4.0;
    bool add_check = false;
    int den = 3;
    for (int i = 0; i &lt; loop_num; i++)
    {
        if (add_check)
        {
            my_pi += (4.0/den);
            add_check = false;
            den += 2;
        }
        else
        {
            my_pi -= (4.0/den);
            add_check = true;
            den += 2;
        }
    }
    cout &lt;&lt; ""Calculated PI is: "" &lt;&lt; my_pi &lt;&lt; endl;
    system(""pause"");

    return 0;
}
</code></pre>

<p>What I'm hoping would be a better program.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;cmath&gt;

using namespace std;

const double PI_BASE = 16.0;

int main()
{
    int loop_num = 0;
    cout &lt;&lt; ""How many digits of pi do you want?: "";
    cin  &gt;&gt; loop_num;

    double my_pi = 0.0;
    for (int i = 0; i &lt;= loop_num; i++)
    {
        my_pi += ( 1.0 / pow(PI_BASE,i) )( (4.0 / (8.0 * i + 1.0)) -
                                           (2.0 / (8.0 * i + 4.0)) -
                                           (1.0 / (8.0 * i + 5.0)) -
                                           (1.0 / (8.0 * i + 6.0)) );
    }
    cout &lt;&lt; ""Calculated PI is: "" &lt;&lt; my_pi &lt;&lt; endl;
    system(""pause"");

    return 0;
}
</code></pre>
","922184","","<p>Regardless of what formula you use, you will need arbitrary precision arithmetic to get more than 16 digits. (Since ""double"" only has 16 digits of precision).</p>

<p>The Chudnovsky Formula is the fastest known formula for computing Pi and converges at 14 digits per term. However, it is extremely difficult to implement efficiently.</p>

<p>Due to the complexity of this formula, there's no point in using to compute Pi to less than a few thousand digits. So don't use it unless you're ready to go all-out with arbitrary precision arithmetic.</p>

<p>A good open-sourced implementation of the Chudnovsky Formula using the GMP library is here: <a href=""http://gmplib.org/pi-with-gmp.html"" rel=""nofollow"">http://gmplib.org/pi-with-gmp.html</a></p>
"
"<p>I have noticed that sometimes MSVC 2010 doesn't reorder SSE instructions at all. I thought I didn't have to care about instruction order inside my loop since the compiler handles that best, which doesn't seem to be the case.</p>

<p>How should I think about this? What determines the best instruction order? I know some instruction have higher latency than others and that some instructions can run in parallel/async on cpu level. What metrics are relevant in the context? Where can I find them?</p>

<p>I know that I could <strong>avoid</strong> this question by profiling, however such profilers are expensive (VTune XE) and <strong>I would like to know the theory behind it</strong>, not just emperical results.</p>

<p>Also should I care about software prefetching (<code>_mm_prefetch</code>) or can I assume that the cpu will do a better job than me?</p>

<p>Lets say I have the following function. Should I interleave some of the instructions? Should I do the stores before the streams, do all the loads in order and then do calculations, etc...? Do I need to consider USWC vs non-USWC, and temporal vs non-temporal?</p>

<pre><code>            auto cur128     = reinterpret_cast&lt;__m128i*&gt;(cur);
            auto prev128    = reinterpret_cast&lt;const __m128i*&gt;(prev);
            auto dest128    = reinterpret_cast&lt;__m128i*&gt;(dest;
            auto end        = cur128 + count/16;

            while(cur128 != end)            
            {
                auto xmm0 = _mm_add_epi8(_mm_load_si128(cur128+0), _mm_load_si128(prev128+0));
                auto xmm1 = _mm_add_epi8(_mm_load_si128(cur128+1), _mm_load_si128(prev128+1));
                auto xmm2 = _mm_add_epi8(_mm_load_si128(cur128+2), _mm_load_si128(prev128+2));
                auto xmm3 = _mm_add_epi8(_mm_load_si128(cur128+3), _mm_load_si128(prev128+3));

                                    // dest128 is USWC memory
                _mm_stream_si128(dest128+0, xmm0);  
                _mm_stream_si128(dest128+1, xmm1);
                _mm_stream_si128(dest128+2, xmm2);;
                _mm_stream_si128(dest128+3, xmm3);

                                    // cur128 is temporal, and will be used next time, which is why I choose store over stream
                _mm_store_si128 (cur128+0, xmm0);               
                _mm_store_si128 (cur128+1, xmm1);                   
                _mm_store_si128 (cur128+2, xmm2);                   
                _mm_store_si128 (cur128+3, xmm3);

                cur128  += 4;
                dest128 += 4;
                prev128 += 4;
            }

           std::swap(cur, prev);
</code></pre>
","922184","","<p>I agree with everyone that testing and tweaking is the best approach. But there are some tricks to help it.</p>

<p>First of all, MSVC <strong>does</strong> re-order SSE instruction. Your example is probably too simple or already optimal.</p>

<p>Generally speaking, if you have enough registers to do so, full interleaving tends to give the best results. To take it a step further, unroll your loops enough to use all the registers, but not too much to spill.
In your example, the loop is completely bound by memory accesses, so there isn't much room to do any better.</p>

<p>In most cases, it isn't necessary to get the order of the instructions perfect to achieve optimal performance. As long as it's ""close enough"", either the compiler, or the hardware's out-of-order execution will fix it for you.</p>

<p>The method I use to determine if my code is optimal is critical-path and bottleneck analysis. After I write the loop, I look up what instructions use which resources. Using that information, I can calculate upper-bound on performance, which I then compare with the actual results to see how close/far I am from optimal.</p>

<p>For example, suppose I have a loop with 100 adds and 50 multiplies. On both Intel and AMD (pre-Bulldozer), each core can sustain one SSE/AVX add and one SSE/AVX multiply per cycle.
Since my loop has 100 adds, I know I cannot do any better than 100 cycles. Yes, the multiplier will be idle half the time, but the adder is the bottleneck.</p>

<p>Now I go and time my loop and I get 105 cycles per iteration. That means I'm pretty close to optimal and there's not much more to gain. But if I get 250 cycles, then that means something's wrong with the loop and it's worth tinkering with it more.</p>

<p>Critical-path analysis follows the same idea. Look up the latencies for all the instructions and find the cycle time of the critical path of the loop. If your actual performance is very close to it, you're already optimal.</p>

<p>Agner Fog has a great reference for the internal details of the current processors:
<a href=""http://www.agner.org/optimize/microarchitecture.pdf"">http://www.agner.org/optimize/microarchitecture.pdf</a></p>
"
"<p>I want to write some C code such that gcc using the <code>-msse4.1</code> flag can optimize it. Basically I want to check whether or not the compiler is taking advantage of SSE4.1 instructions. 
There are many SSE4.1 instructions (<a href=""http://en.wikipedia.org/wiki/SSE4#New_instructions"" rel=""nofollow"">http://en.wikipedia.org/wiki/SSE4#New_instructions</a>) but I am not able to write a fragment of C Code which is using any of those instructions in the generated assembly code.</p>

<p>Thanks in advance.</p>
","922184","","<p>From what I've seen, compilers rarely ever generate SSE4.1 instructions. I've seen a few cases where it will use the insert/extract instructions to pack data.</p>

<p>But for the most part, if you want to use the SSE4.1 instructions, you need to do them explicitly using intrinsics:</p>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_sse41.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_sse41.htm</a></p>
"
"<p>Just out of curiosity, why do C compilers specify <code>long</code> to be <code>32-bit</code> (same as <code>int</code>) and <code>long long</code> to be <code>64-bit</code>. Wouldn't it have made more sense to make long 64-bit and reserve long long until  128-bit numbers become a reality?</p>
","922184","","<p>Yes, it does make sense, but Microsoft had their own reasons for defining ""long"" as 32-bits.</p>

<p>As far as I know, of all the mainstream systems right now, Windows is the only OS where ""long"" is 32-bits. On Unix and Linux, it's 64-bit.</p>

<p>All compilers for Windows will compile ""long"" to 32-bits on Windows to maintain compatibility with Microsoft.</p>

<p>For this reason, I avoid using ""int"" and ""long"". Occasionally I'll use ""int"" for error codes and booleans (in C), but I never use them for any code that is dependent on the size of the type.</p>
"
"<p>I need some help understanding how 32 bit applications use memory on a 64 bit OS.</p>

<p>A 32 bit application can use 2 gb of memory on 64 bit OS, correct?
Does this mean that 3 32 bit applications running in parrallel could address 6 gb of memory...
Or do the 3 32 bit applications have to share the 2-4 gb of 32 bit memory that the os has?</p>

<p>Likewise, If I have a webservice that is compiled as 32 bits, running under IIS on a 64 bit machine. As long as a single request to that webservice always stays under 2gb of memory usage, is there any point in recompiling to 64 bit? My theory is that IIS creates a new process for each request, so the whole pool of processes will be able to make use of all the memory the 64bit machine has , 8 or 15 or 20 gig or whatever.</p>

<p>Let me know your thoughts, thanks</p>
","922184","","<p>Yes, the total usage of all the 32-bit programs can exceed 2 GB. So yes you can have a bunch of 32-bit processes using all the memory in a 64-bit machine.</p>

<p>Actually, there's a compiler option that lets 32-bit programs use up to 3GB in Windows.
If performance isn't important, then there isn't much of a reason to use 64-bit.</p>
"
"<p>I was playing around with high precision timers and one of my first tests was to use rdtsc to measure printf. Below is my test prpgram followed by its output. The thing I noticed is that the first time printf runs, it consistently takes about 25 times longer on the first print than it does on subsequent prints. Why is that?</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;

// Sample code grabbed from wikipedia
__inline__ uint64_t rdtsc(void)
{
    uint32_t lo, hi;
    __asm__ __volatile__ (
            ""xorl %%eax,%%eax \n        cpuid""
            ::: ""%rax"", ""%rbx"", ""%rcx"", ""%rdx"");
    __asm__ __volatile__ (""rdtsc"" : ""=a"" (lo), ""=d"" (hi));
    return (uint64_t)hi &lt;&lt; 32 | lo;
}

int main(int argc, const char *argv[])
{
    unsigned int i;
    uint64_t counter[10];
    uint64_t sum = 0;
    for (i = 0; i &lt; 10; i++)
    {
        counter[i] = rdtsc();
        printf(""Hello, world\n"");
        counter[i] = rdtsc() - counter[i];
    }

    for (i = 0; i &lt; 10; i++)
    {
        printf(""counter[%d] = %lld\n"", i, counter[i]);
        sum += counter[i];
    }
    printf(""avg = %lld\n"", sum/10);
    return 0;
}
</code></pre>

<p>And the output:</p>

<pre><code>Hello, world
Hello, world
Hello, world
Hello, world
Hello, world
Hello, world
Hello, world
Hello, world
Hello, world
Hello, world
counter[0] = 108165
counter[1] = 6375
counter[2] = 4388
counter[3] = 4388
counter[4] = 4380
counter[5] = 4545
counter[6] = 4215
counter[7] = 4290
counter[8] = 4237
counter[9] = 4320
avg = 14930
</code></pre>

<p>(For reference, this was compiled with gcc on OSX)</p>
","922184","","<p>My guess is that on the first call to printf, the stdout resources are not in cache and the call will need bring it into cache - hence it's slower.
For all subsequent calls, the cache is already warm.</p>

<p>A second possible explanation is that, if this is on Linux (may also apply to OSX, I'm not sure), the program needs to set the stream orientation. (ASCII vs. UNICODE) This is done on the first call to a function using that stream and is static until the stream closes.
I don't know what the overhead of setting this orientation is, but it's a one-time cost.</p>

<p>Please feel free to correct me if anyone thinks I'm completely wrong.</p>
"
"<p>To prevent false sharing, I want to align each element of an array to a cache line. So first I need to know the size of a cache line, so I assign each element that amount of bytes. Secondly I want the start of the array to be aligned to a cache line. </p>

<p>I am using Linux and 8-core x86 platform. First how do I find the cache line size. Secondly, how do I align to a cache line in C. I am using the gcc compiler. </p>

<p>So the structure would be following for example, assuming a cache line size of 64.</p>

<pre><code>element[0] occupies bytes 0-63
element[1] occupies bytes 64-127
element[2] occupies bytes 128-191
</code></pre>

<p>and so on, assuming of-course that 0-63 is aligned to a cache line.</p>
","922184","","<p>There's no completely portable way to get the cacheline size. But if you're on x86/64, you can call the <code>cpuid</code> instruction to get everything you need to know about the cache - including size, cacheline size, how many levels, etc...</p>

<p><a href=""http://softpixel.com/~cwright/programming/simd/cpuid.php"" rel=""nofollow"">http://softpixel.com/~cwright/programming/simd/cpuid.php</a></p>

<p>(scroll down a little bit, the page is about SIMD, but it has a section getting the cacheline.)</p>

<p>As for aligning your data structures, there's also no completely portable way to do it. GCC and VS10 have different ways to specify alignment of a struct.
One way to ""hack"" it is to pad your struct with unused variables until it matches the alignment you want.</p>

<p>To align your mallocs(), all the mainstream compilers also have aligned malloc functions for that purpose.</p>
"
"<p>Using only adding, subtracting, and bitshifting, how can I multiply an integer by a given number?</p>

<p>For example, I want to multiply an integer by 17.</p>

<p>I know that shifting left is multiplying by a multiple of 2 and shifting right is dividing by a power of 2 but I don’t know how to generalize that.</p>

<hr>

<p>What about negative numbers? Convert to two's complement and do the same procedure?</p>

<p>(<strong>EDIT:</strong> OK, I got this, nevermind. You convert to two's complement and then do you shifting according to the number from left to right instead of right to left.)</p>

<hr>

<p><strong>Now the tricky part comes in. We can only use 3 operators.</strong> </p>

<p>For example, multiplying by 60 I can accomplish by using this:</p>

<pre><code>(x &lt;&lt; 5) + (x &lt;&lt; 4) + (x &lt;&lt; 3) + (x &lt;&lt; 2)
</code></pre>

<p>Where <code>x</code> is the number I am multiplying. But that is 7 operators - how can I condense this to use only 3?</p>
","922184","","<p>It's called shift-and-add. Wikipedia has a good explanation of this:</p>

<p><a href=""http://en.wikipedia.org/wiki/Multiplication_algorithm#Shift_and_add"">http://en.wikipedia.org/wiki/Multiplication_algorithm#Shift_and_add</a></p>

<p>EDIT:
To answer your other question, yes converting to two's compliment will work. But you need to sign extend it long enough to hold the entire product. (assuming that's what you want)</p>

<p>EDIT2:
If both operands are negative, just two's compliment both of them from the start and you won't have to worry about this.</p>
"
"<p>I am porting inline assembler that use SSE commands to intrinsics. It takes much work to find appropriate intrinsic for assembler instruction. Somewhere on the Internet I saw a Python script that simplifies the job, but cannot find it now.</p>
","922184","","<p>I'm not aware of a script that will do exactly what you asking. A lot of cases will also have non-SSE instructions interleaved into the assembly, and not every assembly instruction can be mapped to an intrinsic or a primitive C operation.</p>

<p>I suppose you can probably hack you way through it with find-and-replace. (This actually might not be that bad. How much code are you trying port? Thousands of lines?)</p>

<p>Also, VC++ doesn't allow inline assembly at all on 64-bit. So everything needs to be done using intrinsics or a completely separate assembly file.</p>

<p>I won't go far to say that using intrinsics is completely inferior to assembly (assuming you know what you're doing), but writing good intrinsic code that compiles well and runs as fast as optimized assembly is a work of art on it's own. But it maintains two advantages: portability, and ease of use (no need to manually allocate registers).</p>
"
"<p>I want 2, 4, 6 to display... instead I think address numbers are displaying?  </p>

<p>What do I need to do to correct and why?
Thanks</p>

<p>(purpose... to demonstrate ability to change array space and still keep the base of the array) </p>

<pre><code>    int *line;

    line = new int;
    line[0] = 2;
    line = new int;
    line[1] = 4;
    line = new int;
    line[2] = 6;
    line = new int;
    printf(""%d  %d  %d"", line[0], line[1], line[2]);
</code></pre>
","922184","","<p>You're overwriting the pointer <code>line</code> at each <code>new int</code>. And you're leaking the memory from the one before it.</p>

<p>Also, since you're only allocating one int, only <code>line[0]</code> is defined.
Accessing <code>line[1]</code> and <code>line[2]</code> is undefined.</p>
"
"<p>I have seen many posts about using the clock() function to determine the amount of elapsed time in a program with code looking something like:</p>

<pre><code>start_time = clock();

//code to be timed
.
.
.

end_time = clock();
elapsed_time = (end_time - start_time) / CLOCKS_PER_SEC;
</code></pre>

<p>The value of CLOCKS_PER_SEC is almost surely not the actual number of clock ticks per second so I am a bit wary of the result. Without worrying about threading and I/O, is the output of the clock() function being scaled in some way so that this divison produces the correct wall clock time?</p>
","922184","","<p>The answer to your question is yes.</p>

<p><code>clock()</code> in this case refers to a wallclock rather than a CPU clock so it could be misleading at first glance. For all the machines and compilers I've seen, it returns the time in milliseconds since I've never seen a case where <code>CLOCKS_PER_SEC</code> isn't 1000. So the precision of <code>clock()</code> is limited to milliseconds and the accuracy is usually slightly less.</p>

<p>If you're interested in the actual cycles, this can be hard to obtain.
The <code>rdtsc</code> instruction will let you access the number ""pseudo""-cycles from when the CPU was booted. On older systems (like Intel Core 2), this number is usually the same as the actual CPU frequency. But on newer systems, it isn't.</p>

<p>To get a more accurate timer than <code>clock()</code>, you will need to use the hardware performance counters - which is specific to the OS. These are internally implemented using the 'rdtsc' instruction from the last paragraph.</p>
"
"<p>Is there a refactoring tool, either for C or Java that can simplify this type of redundant code. I believe this is called data propagation.</p>

<p>This is essentially what an optimizing compiler would do.</p>

<pre><code>public int foo() {
    int a = 3;
    int b = 4;
    int c = a + b;
    int d = c;
    System.out.println(c);
    return c;
}
</code></pre>

<p>into </p>

<pre><code>public int foo() {
    int c = 7;
    System.out.println(c);
    return c;
}
</code></pre>
","922184","","<p>One possible approach is to put it into a symbolic math program (like Mathematica or Maple) and have it do the simplification for you. It will do it regardless of whether they are constants or not.</p>

<p>The drawback is that you need to convert the code to a different language. (Though it could be mostly copy and paste if the syntax is similar.) Furthermore, it could be dangerous if you expect certain integer types to overflow at a specific size. Symbolic math programs don't care and will optimize it according to the ""math"". Same thing goes for floating-point round-off errors.</p>

<p>In your example, if you enter this into Mathematica:</p>

<pre><code>a = 3;
b = 4;
c = a + b;
d = c;
c
</code></pre>

<p>Will output this in Mathematica:</p>

<pre><code>7
</code></pre>

<p>Of course you can't just copy and paste because it's a different language and different syntax, but it's the best thing I have in mind for your question. I myself use Mathematica to simplify expressions and other math before I throw it into C/C++.</p>

<p>For a more complicated example involving unknowns:</p>

<p>Original C Code:</p>

<pre><code>int a = 3 + x*x;
int b = 4 + y*y;
int c = a + b - 7 + 2*x*y;
int d = c;
</code></pre>

<p>Enter this into Mathematica (which is still mostly copy+paste):</p>

<pre><code>a = 3 + x*x;
b = 4 + y*y;
c = a + b - 7 + 2*x*y;
d = c;
FullSimplify[c]
</code></pre>

<p>Output:</p>

<pre><code>(x + y)^2
</code></pre>

<p>Which transforms back into the following C-code:</p>

<pre><code>d = (x + y)
d = d * d;
</code></pre>

<p>This is obviously much more simple than the original code. In general, symbolic programs will even handle non-trivial expressions and will do just as well (or even better) than any compiler internal.</p>

<p>The final drawback is that symbolic math programs like Mathematica or Maple aren't free and are fairly expensive. SAGE is an open-sourced program, but I hear it is not as good as either Mathematica or Maple.</p>
"
"<p>I have this info from /proc/cpuinfo (shown below). My question is which core is hyperthreaded here. Secondly, which core lies on which processor, as there are two quad core processors here, as it is a dual socket system with 8 cores in total.</p>

<p>I interpret this as, core 0, 2, 4 and 6 are the 4 physical cores in processor 1, while core 1, 3, 5 and 7 are the 4 physical cores on processor 0. Cores 9-15 are the hyperthreaded ones. Is my interpretation correct?</p>

<pre><code>-bash-3.2$ cat /proc/cpuinfo | grep 'physical id'
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
physical id     : 1
physical id     : 0
-bash-3.2$ cat /proc/cpuinfo | grep 'core id'
core id         : 0
core id         : 0
core id         : 1
core id         : 1
core id         : 2
core id         : 2
core id         : 3
core id         : 3
core id         : 0
core id         : 0
core id         : 1
core id         : 1
core id         : 2
core id         : 2
core id         : 3
core id         : 3
-bash-3.2$ cat /proc/cpuinfo | grep 'processor'
processor       : 0
processor       : 1
processor       : 2
processor       : 3
processor       : 4
processor       : 5
processor       : 6
processor       : 7
processor       : 8
processor       : 9
processor       : 10
processor       : 11
processor       : 12
processor       : 13
processor       : 14
processor       : 15
</code></pre>
","922184","","<p>The best way to do it is just to benchmark it.</p>

<p>Write any trivial program that uses 2 threads. Then bind the threads to two cores.
If the performance drops significantly between a pair of cores versus another pair, then you know those two cores are on the same physical core.</p>

<p>I would trust a benchmark like this over whatever anything else tells you.</p>

<p>In Windows, the logical/physical cores are interleaved.
Cores 0,1 are on the same physical core.
Cores 2,3 are on the same...
Cores 4,5 are on the same... etc...</p>

<p>It may be different on Linux.</p>
"
"<p>I have a dual socket 8 core processor, that is, each processor has 4-cores in it. I haven't seen its specification completely, but I think that a separate memory bank is attached to each processor in a ccNUMA fashion and therefore accessing from memory bank of another processor is relatively slow. Also they have different L3 caches I suppose. </p>

<p>Now my question is what is the fastest way to share data between the two processors. Simple shared memory will have the problem due to ccNUMA and cache coherency. Is there any way which is very fast?</p>
","922184","","<p>That would depend highly on the nature of what you're trying to implement. From what I've seen, it's usually possible to do better with a very tightly managed shared memory approach than to resort to MPI. (because it's possible to do a lot more with shared-memory)</p>

<p>However, it's harder to go completely wrong with MPI since there's a lot less guess work to why X performs well or not.</p>

<p>Here are some common approaches using shared memory:</p>

<p>Read-Only data: If the data is small enough, it might be best to duplicate it across all the nodes.</p>

<p>If your memory access has extremely high spatial locality that doesn't ""migrate"" around, organize your data such that each ""group"" of spatial locality access is on the same node.</p>

<p>If your memory access pattern exhibits high temporal locality, but not enough spatial locality to fit into cache, then consider copying the data into a local buffer. Once the work is done, copy it back. This lets you keep the same structure of the program.</p>

<p>EDIT: Consider adding the ""NUMA"" tag to your question.</p>
"
"<p>Suppose we have a chunk of data that came from data transfer medium with the following properties:</p>

<ul>
<li>Total chunk size is <strong>8 bytes</strong>.</li>
<li>The data transfer is <strong>unreliable</strong>, so errors in a number of bits are possible.</li>
<li>The data transfer is cyclic and the beginning of the chunk is unknown. For example, the code <strong>0123456789ABCDEF</strong> is the same as <strong>3456789ABCDEF012</strong> (0123456789ABCDEF &lt;&lt; 12) and <strong>02468ACF13579BDE</strong> (0123456789ABCDEF &lt;&lt; 1). The receiver end should determine the beginning by the code itself.</li>
</ul>

<p><strong>What are the best error detection and error correction algorithms for this case?</strong> Of course, it's always a compromise between useful data amount per chunk and success validation (correction) probability.</p>
","922184","","<p>This is only a partial answer to the full question as I will not answer how to determine the start point. Refer to mcdowella's answer for that. I intended this to be a comment, but it's too long.</p>

<p>With a continuously transmitted message, there really is no need for any error-correction anymore. Even if a one bit-flip (or a bunch of them) occurs, it's unlikely it will affect every single instance of the same bit being transmitted - especially if it's being repeated forever. So in this sense, your redundancy factor is N where N approaches infinity as the broadcast goes on.</p>

<p>So reconstructing your 64-bits is now very easy since you have many samples to look at. Assuming the receiver knows the cycle length, you can just poll the stream and count how many occurrences of each bit for each of the 64 positions.</p>

<p>So say after 100 complete cycles, you get:</p>

<pre><code>Bit #    0s / 1s    Interpret bit as
Bit 0:  100 /   0        0
Bit 1:    0 / 100        1
Bit 2:   99 /   1        0
Bit 3:   98 /   2        0
Bit 4:    1 /  99        1
...
Bit 63:  96 /   4        0
</code></pre>

<p>Based on these samples, you can statistically figure out what the correct bit values are. The longer the receivers continues to receive the cycle, the stronger your bounds are. So you can tolerate an arbitrarily high error-rate if enough cycles are transferred.</p>

<p>Of course this applies to any cycle length - not just 64-bits. So combine this method with mcdowella's (and the data size will probably increase due to the index-foot-print).</p>

<p>If the cycle period isn't known to the receiver, there are two ways to figure it out:</p>

<ol>
<li><p>Guess the length and run the polling. Keep doing this for different lengths until you get a length with a very high correlation. (high confidence levels for each of the bits)</p></li>
<li><p>Perform a Fourier Transform on the received data. This will instantly reveal the period assuming the data isn't too ridiculously noisy.</p></li>
</ol>
"
"<p>I wish I could just use the preprocessor, but the input comes at runtime.. I tryed a conditional typedef, doesn't work. Or conditional declaration, doesn't work. Although I didn't really expect them to neither. And since all the code that follows is the exact same, I don't want to have to rewrite it twice.. once for each struct.</p>

<p>Is there a way to do this in C? Or different approach, with same result. All my google searches brought me to C++ templates. If I'm not being clear, maybe this will help:</p>

<pre><code>#include &lt;stdio.h&gt;

struct a32 {
    short bits;
    unsigned long val;
    // more values, not necessarily in the same order
};

struct a64 {
    short bits;
    unsigned long long val;
    // etc...
};

int main(void) {
    struct a32 mystruct;

    // read mystruct from somewhere

    if(mystruct.bits == 64) {
        // then I need mystruct to be a64
        // re-read mystruct
    }

    // exact same code for both structs

    printf(""%d\n"", sizeof(mystruct.val));
    return 0;
}
</code></pre>

<p>Any help would be appreciated.</p>
","922184","","<p>You can ""sorta"" do this using unions:</p>

<pre><code>struct{
    short bits;
    union{
        unsigned long a32;
        unsigned long long a64;
    };
} a_int;

int main(void) {
    a_int mystruct;

    // read mystruct from somewhere

    if(mystruct.bits == 64) {
        // then I need mystruct to be a64
        // re-read mystruct
    }

    // exact same code for both structs

    printf(""%d\n"", sizeof(mystruct.a32));
    return 0;
}
</code></pre>

<p>EDIT:
However, it's not possible to make the <code>printf()</code> work for both the 32-bit and 64-bit integers.</p>
"
"<p>Say I want to implement a software that uses hardware performance counters such as those for counting retired stores. Note that alternative solutions without the performance counters are possible but might be relatively a little inefficient. However, I can sacrifice performance a bit for portability and power efficiency. Also, note that the performance counters will be kept on the whole time.</p>

<p>How good hardware performance counters are in consuming power. Secondly, Are there popular platforms or processors, single or multicore, which don't have performance counters. If so, could you kindly name them.</p>
","922184","","<p>PAPI is a common profiler program that allows you to compile into the code and access the hardwrae counters. From my own experience, it doesn't have a noticable effect on performance.</p>

<p>Although I don't know for sure, I would assume that it will not increase power consumption because hardware counters are always enabled in the hardware. It's just a matter of reading them.</p>

<p>As far as I know, I'm not aware of any modern non-embedded processors that don't have performance counters. I may wrong. Someone care to correct me?</p>
"
"<p>I have this piece of code:</p>

<pre><code>// Returns the fibonacci range until the specified limit
int fibo(int** output, int limit)
{
    // Must be 1 or more
    if(limit &lt; 1) return 0;

    int* range = (int*)malloc(sizeof(int) * limit);
    assert(range);

    int i;

    // Calculate the range
    for(i = 0; i &lt; limit; i++)
    {
        int value;

        if(i == 0)  value = 0;
        if(i == 1)  value = 1;
        else        value = range[i - 2] + range[i - 1];

        range[i] = value;
    }

    *output = range;

    return 1;
}
</code></pre>

<p>Running it with limit 15 outputs</p>

<blockquote>
  <p>65, 1, 66, 67, 133, 200, 333, 533, 866, 1399, 2265, 3664, 5929, 9593, 15522</p>
</blockquote>

<p>which is not right at all. I suspect it's because I'm writing stuff like <code>range[i - 2]</code> when that's not what I should be doing. I tried using the size of int as the hop between each value and got segmentation errors. Am I using <code>[]</code> correctly? Can anyone think of any other reason why my output is weird?</p>

<p><a href=""http://pastebin.com/ziat5F7c"" rel=""nofollow"">Here's all the code for the program</a></p>
","922184","","<p>Change</p>

<pre><code>if(i == 1)  value = 1;
</code></pre>

<p>to</p>

<pre><code>else if(i == 1)  value = 1;
</code></pre>

<p>EDIT:
Just realized this was already answered in the comments.</p>
"
"<p>While reading a post, I came across the following code and output of this code according to post is an error saying:</p>

<blockquote>
  <p>Array element cannot be address of auto variable. It can be address of static or  external variables.               </p>
</blockquote>

<pre><code> #include&lt;stdio.h&gt;
 int main()
 {
 int a=5,b=10,c=15;
 int *arr[]={&amp;a,&amp;b,&amp;c};
 printf(""%d"",*arr[1]);
 return 0;
 }
</code></pre>

<p>But when run this code on MinGW and online compiler it works fine without any error.</p>

<p>So would like to know this is perfectly valid or not??</p>
","922184","","<p>It looks fine to me. I don't see anything wrong with it. If I had to nitpick, it'd be your formatting and indenting... But that's just about it.</p>

<p>EDIT:
I think what the post you were referring to meant is that you can't return the address of a local or auto variable. In this example, everything is in the same scope so it's perfectly fine.</p>

<p>EDIT 2:
Okay, going back to prior experience, I think I can find ""some"" weakness in the code. I've seen this on the Intel Compiler.</p>

<p>Since the variable is local, the compiler may promote it to a register. In that case addresses to it are invalid. However, modern compilers need to be able to trace this dependency and avoid putting that variable into a register.</p>

<p>In one case that I encountered a while back, I was accessing the address of the variable via inline assembly - something that the Intel Compiler could not trace. The compiler then promoted the variable to register and my inline assembly kept reading the old value on the stack rather than the register value.</p>

<p>Obviously it was something I shouldn't have done, but it would have been okay if the variable wasn't auto.</p>
"
"<p>I'm looking for a way to execute sections of code in parallel using multiple threads for each section. For example, if I have 16 threads and two tasks, I want 8 threads each to simultaneously execute those two tasks. OpenMP has several constructs (<code>section</code>, <code>task</code>) that execute general code in parallel, but they are single-threaded. In my scenario, using <code>section</code> or <code>task</code> would result in one thread executing each of the two tasks, while 14 threads sit idly by.</p>

<p>Is something like that even possible with OpenMP? If so, how do I do it, and if not, what can I use for that purpose?</p>

<p>Thanks for your time!</p>

<p><strong>edit 2:</strong></p>

<p>Let me expand on this question with an example code:</p>

<pre class=""lang-cpp prettyprint-override""><code>class some_class{
    void task(){
        cout&lt;&lt;""Entering the task method""&lt;&lt;endl;
        #pragma openmp parallel for
            for(int i=0; i &lt; large_matrix.rows(); i++){
                 perform_thread_safe_operation(large_matrix.getRow(i));
            }
    }

    matrix large_matrix;
};


void main(){
    //I have 16 cores, so I want to spawn 16 threads
     some_class o1;
     some_class o2;
    // I want 8 of the 16 threads to execute this line:
    o1.task();
    // and 8 remaining threads to execute this line:
    o2.task();
}
</code></pre>
","922184","","<p>You can do this using nested parallel regions.</p>

<pre><code>omp_set_nested(1);

#pragma omp parallel num_threads(2)
{
    if (omp_get_thread_num() == 0){
#pragma omp parallel num_threads(8)
        {

            //  Task 0

        }
    }else{
#pragma omp parallel num_threads(8)
        {

            //  Task 1

        }
    }
}
</code></pre>

<p>Alternatively, you could do it like this:</p>

<pre><code>#pragma omp parallel num_threads(16)
{
    if (omp_get_thread_num() &lt; 8){
        //  Task 0
    }else{
        //  Task 1
    }
}
</code></pre>

<p>Note, this code will not work if OpenMP decides to use fewer than 16 threads. You will have to insert your own cleanup code for that.</p>

<p>EDIT: In response to your update:</p>

<pre><code>class some_class{
    void task(){
        cout&lt;&lt;""Entering the task method""&lt;&lt;endl;

#pragma omp parallel for num_threads(8)
        for(int i=0; i &lt; large_matrix.rows(); i++){
            perform_thread_safe_operation(large_matrix.getRow(i));
        }
    }

    matrix large_matrix;
};


void main(){

    omp_set_nested(1);

    //I have 16 cores, so I want to spawn 16 threads
     some_class o1;
     some_class o2;

#pragma omp parallel num_threads(2)
   {
       if (omp_get_thread_num() == 0){
           // I want 8 of the 16 threads to execute this line:
           o1.task();
       }else{
           // and 8 remaining threads to execute this line:
           o2.task();
       }
   }
}
</code></pre>
"
"<p>I'm having a very strange problem. I'm using Visual Studio 2010 Ultimate on Windows 7 x64. I have this simple code:</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    fclose( fopen(""hakuna"", ""w"") );
    return 0;
}
</code></pre>

<p>It works very well when I compile it. When I go to the debug folder and double click on the exe it creates the file. But when I open the console and type in the destination of the exe and press ""Enter"" nothing happens. If there're some prinf-s they will appear, but the file is never created.
I'll be very grateful if someone is able to help me. I really have no idea why this's happening</p>
","922184","","<p>It's being created at your default directory - or wherever your cmdline active directory is.</p>

<p>For example, the cmdline will look like something like this.</p>

<pre><code>C:\Users\Akari&gt;
</code></pre>

<p>That's the directory where the file is being made.</p>
"
"<p>What is the usual/recommended way how to organize a multi-platform (Windows, Linux) <code>C/C++</code> library project?</p>

<p>How to name function and provide OS-dependent implementations, organize includes etc.? Please, constructive ideas only -- no pointers as ""Look at Linux."", <code>ideas strongly welcome</code>.</p>
","922184","","<p>The approach I use is to wrap all OS-specific functions into my own interface. Then I implement this interface for each different OS (mainly Windows and Linux).</p>

<p>At compile time, I use preprocessor to check which platform it is and then include the appropriate version.</p>

<p>I do this a lot with threads, disk I/O, and clocks/time.</p>

<p>For example:</p>

<pre><code>#ifdef _WIN32

#include &lt;windows.h&gt;
#include ""windows_code.h""

#elif __linux

#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include ""linux_code.h""

#else
#error ""Unrecognized Platform""
#endif
</code></pre>
"
"<p>Can anyone give an example or a link to an example which uses <code>__builtin_prefetch</code> in GCC (or just the asm instruction prefetcht0 in general) to gain a substantial performance advantage? In particular, I'd like the example to meet the following criteria:</p>

<ol>
<li>It is a simple, small, self-contained example.</li>
<li>Removing the <code>__builtin_prefetch</code> instruction results in performance degradation.</li>
<li>Replacing the <code>__builtin_prefetch</code> instruction with the corresponding memory access results in performance degradation.</li>
</ol>

<p>That is, I want the shortest example showing <code>__builtin_prefetch</code> performing an optimization that couldn't be managed without it.</p>
","922184","","<p>Here's an actual piece of code that I've pulled out of a larger project. (Sorry, it's the shortest one I can find that had a noticable speedup from prefetching.)
This code performs a very large data transpose.</p>

<p>This example uses the SSE prefetch instructions, which may be the same as the one that GCC emits.</p>

<p>To run this example, you will need to compile this for x64 and have more than 4GB of memory. You can run it with a smaller datasize, but it will be too fast to time.</p>

<pre><code>#include &lt;iostream&gt;
using std::cout;
using std::endl;

#include &lt;emmintrin.h&gt;
#include &lt;malloc.h&gt;
#include &lt;time.h&gt;
#include &lt;string.h&gt;

#define ENABLE_PREFETCH


#define f_vector    __m128d
#define i_ptr       size_t
inline void swap_block(f_vector *A,f_vector *B,i_ptr L){
    //  To be super-optimized later.

    f_vector *stop = A + L;

    do{
        f_vector tmpA = *A;
        f_vector tmpB = *B;
        *A++ = tmpB;
        *B++ = tmpA;
    }while (A &lt; stop);
}
void transpose_even(f_vector *T,i_ptr block,i_ptr x){
    //  Transposes T.
    //  T contains x columns and x rows.
    //  Each unit is of size (block * sizeof(f_vector)) bytes.

    //Conditions:
    //  - 0 &lt; block
    //  - 1 &lt; x

    i_ptr row_size = block * x;
    i_ptr iter_size = row_size + block;

    //  End of entire matrix.
    f_vector *stop_T = T + row_size * x;
    f_vector *end = stop_T - row_size;

    //  Iterate each row.
    f_vector *y_iter = T;
    do{
        //  Iterate each column.
        f_vector *ptr_x = y_iter + block;
        f_vector *ptr_y = y_iter + row_size;

        do{

#ifdef ENABLE_PREFETCH
            _mm_prefetch((char*)(ptr_y + row_size),_MM_HINT_T0);
#endif

            swap_block(ptr_x,ptr_y,block);

            ptr_x += block;
            ptr_y += row_size;
        }while (ptr_y &lt; stop_T);

        y_iter += iter_size;
    }while (y_iter &lt; end);
}
int main(){

    i_ptr dimension = 4096;
    i_ptr block = 16;

    i_ptr words = block * dimension * dimension;
    i_ptr bytes = words * sizeof(f_vector);

    cout &lt;&lt; ""bytes = "" &lt;&lt; bytes &lt;&lt; endl;
//    system(""pause"");

    f_vector *T = (f_vector*)_mm_malloc(bytes,16);
    if (T == NULL){
        cout &lt;&lt; ""Memory Allocation Failure"" &lt;&lt; endl;
        system(""pause"");
        exit(1);
    }
    memset(T,0,bytes);

    //  Perform in-place data transpose
    cout &lt;&lt; ""Starting Data Transpose...   "";
    clock_t start = clock();
    transpose_even(T,block,dimension);
    clock_t end = clock();

    cout &lt;&lt; ""Done"" &lt;&lt; endl;
    cout &lt;&lt; ""Time: "" &lt;&lt; (double)(end - start) / CLOCKS_PER_SEC &lt;&lt; "" seconds"" &lt;&lt; endl;

    _mm_free(T);
    system(""pause"");
}
</code></pre>

<p>When I run it with ENABLE_PREFETCH enabled, this is the output:</p>

<pre><code>bytes = 4294967296
Starting Data Transpose...   Done
Time: 0.725 seconds
Press any key to continue . . .
</code></pre>

<p>When I run it with ENABLE_PREFETCH disabled, this is the output:</p>

<pre><code>bytes = 4294967296
Starting Data Transpose...   Done
Time: 0.822 seconds
Press any key to continue . . .
</code></pre>

<p>So there's a 13% speedup from prefetching.</p>

<p>EDIT:</p>

<p>Here's some more results:</p>

<pre><code>Operating System: Windows 7 Professional/Ultimate
Compiler: Visual Studio 2010 SP1
Compile Mode: x64 Release

Intel Core i7 860 @ 2.8 GHz, 8 GB DDR3 @ 1333 MHz
Prefetch   : 0.868
No Prefetch: 0.960

Intel Core i7 920 @ 3.5 GHz, 12 GB DDR3 @ 1333 MHz
Prefetch   : 0.725
No Prefetch: 0.822

Intel Core i7 2600K @ 4.6 GHz, 16 GB DDR3 @ 1333 MHz
Prefetch   : 0.718
No Prefetch: 0.796

2 x Intel Xeon X5482 @ 3.2 GHz, 64 GB DDR2 @ 800 MHz
Prefetch   : 2.273
No Prefetch: 2.666
</code></pre>
"
"<p>I wrote a small code of C. </p>

<pre><code>#include&lt;stdio.h&gt;
int main()
{
    int a  = 0;
    printf(""Hello  World %llu is here %d\n"",a, 1);
    return 0;
}
</code></pre>

<p>It is printing the following ouput</p>

<blockquote>
  <p>Hello  World 4294967296 is here -1216225312</p>
</blockquote>

<p>With the following warning on compilation</p>

<blockquote>
  <p>prog.cpp: In function ‘int main()’: </p>
  
  <p>prog.cpp:5: warning: format ‘%llu’ expects type ‘long long unsigned int’, but argument 2 has type ‘int’</p>
</blockquote>

<p>I know i need to cast the int to long long unsigned int, but i could not understand the fact that why the later values got corrupted.</p>

<p>Thanks in advance</p>
","922184","","<p>%llu expects a 64-bit integer. But you only gave it a 32-bit integer.</p>

<p>The effect is that what printf is reading is ""shifted"" over by 32-bits with respect to what you've passed. Hence your ""1"" is not being read in the right location.</p>

<p>EDIT:</p>

<p>Now to explain the output:</p>

<p><code>a</code> and <code>1</code> are being stored 32-bits apart because they are both 32-bit integers.
However, printf expects the first argument to be a 64-bit integer. Hence it reads it as <code>a + 2^32 * 1</code> which is <code>4294967296</code> in your case. The second value that is printed is undefined because it is past the <code>1</code>.</p>
"
"<p>I want to use CPU and Mainboard serial number for licensing. please help me how can i implement this operation in QT</p>
","922184","","<p>In general, what you are trying to do is not possible for privacy reasons (at least on x86).</p>

<p>The only x86s CPUs to ever have a software-accessible serial number was the Pentium III. It was controversial, so Intel took it out of all later processors.</p>

<p><a href=""http://en.wikipedia.org/wiki/Pentium_III#Controversy_about_privacy_issues"" rel=""nofollow"">http://en.wikipedia.org/wiki/Pentium_III#Controversy_about_privacy_issues</a></p>

<p>It's sometimes possible to read motherboard serial #s, but in a lot of cases, they return meaningless (non-unique) numbers like 0123456789.</p>

<p>What you can do instead is to query the model numbers. For the CPU, you can do that via the <code>cpuid</code> instruction (<code>__cpuid()</code> and <code>__cpuidex()</code> intrinsics in Windows).
For the motherboard, I'm not sure.</p>
"
"<p>I have a function <code>compute()</code> that has parallelized matrix multiplication inside of it using OpenMP</p>

<pre><code>#pragma omp parallel for
</code></pre>

<p>This function is called many times in a loop - which I would like to run in parallel.
Will there be any issues in running parallel code inside other parallel code?</p>

<p>This is c++ compiled on Ubuntu.</p>
","922184","","<p>It will work fine, but you'll need to enable OpenMP nesting for it to work.</p>

<p>Call</p>

<pre><code>omp_set_nested(1);
</code></pre>

<p>at the start of the program and it will allow you to have nested parallel regions.</p>

<p>However: Be aware, that you could end up running many more threads than what you want. So you will want to limit the # of threads of both the top and inner parallel regions.</p>
"
"<p>I have been trying to understand floating point numbers in Assembly, but mention keeps being made of the mantissa and exponent.</p>

<p>I really have no idea what these two words mean or are referring to...could someone explain it to me in relation to floating point arithmetic, or point to an easy to understand explanation?</p>
","922184","","<p><a href=""http://en.wikipedia.org/wiki/Floating_point"" rel=""nofollow"">http://en.wikipedia.org/wiki/Floating_point</a></p>

<p>At the assembly language level, you usually don't need to worry about any of this unless you're actually doing bit-tricks with floating-point. The only case that could come up is performance degradation from denormals - which is also explained on wikipedia.</p>
"
"<p>Greetings and salutations,</p>

<p>I am looking for information regrading design patterns for working with a large number of functions in C99.</p>

<p><strong>Background:</strong><br>
I am working on a complete G-Code interpreter for my pet project, a desktop CNC mill.  Currently, commands are sent over a serial interface to an AVR microcontroller.  These commands are then parsed and executed to make the milling head move.  a typical example of a line might look like</p>

<pre><code>N01 F5.0 G90 M48 G1 X1 Y2 Z3
</code></pre>

<p>where G90, M48, and G1 are ""action"" codes and F5.0, X1, Y2, Z3 are parameters (N01 is the optional line number and is ignored). Currently the parsing is coming along swimmingly, but now it is time to make the machine actually move.</p>

<p>For each of the G and M codes, a specific action needs to be taken.  This ranges from controlled motion to coolant activation/deactivation, to performing canned cycles.  To this end, my current design features a function that uses a switch to select the proper function and return a pointer to that function which can then be used to call the individual code's function at the proper time.</p>

<p><strong>Questions:</strong><br>
1)  Is there a better way to resolve an arbitrary code to its respective function than a switch statement?  Note that this is being implemented on a microcontroller and memory is EXTREMELY tight (2K total).  I have considered a lookup table but, unfortunately, the code distribution is sparse leading to a lot of wasted space.  There are ~100 distinct codes and sub-codes.</p>

<p>2)  How does one go about function pointers in C when the names (and possibly signatures) may change?  If the function signatures are different, is this even possible?</p>

<p>3)  Assuming the functions have the same signature (which is where I am leaning), is there a way to typedef a generic type of that signature to be passed around and called from?</p>

<p>My apologies for the scattered questioning.  Thank you in advance for your assistance.</p>
","922184","","<p>I'm not an expert on embedded systems, but I have experience with VLSI. So sorry if I'm stating the obvious.</p>

<p>The function-pointer approach is probably the best way. But you'll need to either:</p>

<ol>
<li>Arrange all your action codes to be consecutive in address.</li>
<li>Implement an action code decoder similar to an opcode decoder in a normal processor.</li>
</ol>

<p>The first option is probably the better way (simple and small memory footprint). But if you can't control your action codes, you'll need to implement a decoder via <strike>another lookup table</strike>.</p>

<p>I'm not entirely sure on what you mean by ""function signature"". Function pointers should just be a number - which the compiler resolves.</p>

<p>EDIT:
Either way, I think two lookup tables (1 for function pointers, and one for decoder) is still going to be much smaller than a large switch statement. For varying parameters, use ""dummy"" parameters to make them all consistent. I'm not sure what the consequences of force casting everything to void-pointers to structs will be on an embedded processor.</p>

<p>EDIT 2:
Actually, a decoder can't be implementated with just a lookup table if the opcode space is too large. My mistake there. So 1 is really the only viable option.</p>
"
"<p>Using ONLY:</p>

<p>! ~ &amp; ^ | + &lt;&lt; >></p>

<p>NO LOOPS</p>

<p>I need to determine the sign of a 32 bit integer and I need to return 1 if positive, 0 if 0 and -1 if negative. </p>

<p>Any ideas? I first thought about shifting over 31 bits and then looking at that sign but that obviously wont work and now I am kind of stuck.</p>
","922184","","<p>Try this:</p>

<pre><code>(x &gt;&gt; 31) | (((0 - x) &gt;&gt; 31) &amp; 1)
</code></pre>

<p>How about this:</p>

<pre><code>(x &gt;&gt; 31) | (((~x + 1) &gt;&gt; 31) &amp; 1)
</code></pre>

<p>EDIT 2:</p>

<p>In response to issues (or rather nit-picking) raised in the comments...</p>

<p>Assumptions for these solutions to be valid:</p>

<ol>
<li>x is of type 32-bit signed integer.</li>
<li>On this system, signed 32-bit integers are two's complement. (right-shift is arithmetic)</li>
<li>Wrap-around on arithmetic overflow.</li>
<li>For the first solution, the literal <code>0</code> is the same type as x.</li>
</ol>
"
"<p>I am reading the source code for <code>glibc2.9</code>. Reading the source code for the <code>strcpy</code> function, the performance is not as good as I expect.</p>

<p>The following is the source code of <code>strcpy</code> in <code>glibc2.9</code>:</p>

<pre><code>   char * strcpy (char *dest, const char* src)
    {
        reg_char c;
        char *__unbounded s = (char *__unbounded) CHECK_BOUNDS_LOW (src);
        const ptrdiff_t off = CHECK_BOUNDS_LOW (dest) - s - 1;
        size_t n;

        do {
            c = *s++;
            s[off] = c;
        }
        while (c != '\0');

        n = s - src;
        (void) CHECK_BOUNDS_HIGH (src + n);
        (void) CHECK_BOUNDS_HIGH (dest + n);

        return dest;
    }
</code></pre>

<p>Because I don't know the reason for using the offset, I did some performance tests by comparing the above code with the following code:</p>

<pre><code>char* my_strcpy(char *dest, const char *src)
{
    char *d = dest;
    register char c;

    do {
        c = *src++;
        *d++ = c;
    } while ('\0' != c);

    return dest;
}
</code></pre>

<p>As a result, the performance of <code>strcpy</code> is worse during my tests. I have removed the codes about bound pointer.</p>

<p>Why does the <code>glibc</code> version use the offsets??</p>

<p>The following is the introduction about the tests.</p>

<ol>
<li>platform: x86(Intel(R) Pentium(R) 4), gcc version 4.4.2</li>
<li>compile flag: No flags, because I don't want any optimisation; The command is <code>gcc test.c</code>.</li>
</ol>

<p>The test code I used is the following:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

char* my_strcpy1(char *dest, const char *src)
{
    char *d = dest;
    register char c;

    do {
        c = *src++;
        *d++ = c;
    } while ('\0' != c);

    return dest;
}

/* Copy SRC to DEST. */
char *
my_strcpy2 (dest, src)
     char *dest;
     const char *src;
{
  register char c;
  char * s = (char *)src;
  const int off = dest - s - 1;

  do
    {
      c = *s++;
      s[off] = c;
    }
  while (c != '\0');

  return dest;
}

int main()
{
    const char str1[] = ""test1"";
    const char str2[] = ""test2"";
    char buf[100];

    int i;
    for (i = 0; i &lt; 10000000; ++i) {
        my_strcpy1(buf, str1);
        my_strcpy1(buf, str2);
    }

    return 0;
}
</code></pre>

<p>When using the <code>my_strcpy1</code> function, the outputs are:</p>

<pre><code>[root@Lnx99 test]#time ./a.out

real    0m0.519s
user    0m0.517s
sys     0m0.001s
[root@Lnx99 test]#time ./a.out

real    0m0.520s
user    0m0.520s
sys     0m0.001s
[root@Lnx99 test]#time ./a.out

real    0m0.519s
user    0m0.516s
sys     0m0.002s
</code></pre>

<p>When useing <code>my_strcpy2</code>, the output is:</p>

<pre><code>[root@Lnx99 test]#time ./a.out

real    0m0.647s
user    0m0.647s
sys     0m0.000s
[root@Lnx99 test]#time ./a.out

real    0m0.642s
user    0m0.638s
sys     0m0.001s
[root@Lnx99 test]#time ./a.out

real    0m0.639s
user    0m0.638s
sys     0m0.002s
</code></pre>

<p>I know it is not very accurate with the command <code>time</code>. But I could get the answer from the user time.</p>

<p><strong>Update:</strong></p>

<pre><code>To remove the cost used to calculate the offset, I removed some code and added a global variable.

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

char* my_strcpy1(char *dest, const char *src)
{
    char *d = dest;
    register char c;

    do {
        c = *src++;
        *d++ = c;
    } while ('\0' != c);

    return dest;
}


int off;

/* Copy SRC to DEST. */
char *
my_strcpy2 (dest, src)
     char *dest;
     const char *src;
{
  register char c;
  char * s = (char *)src;

  do
    {
      c = *s++;
      s[off] = c;
    }
  while (c != '\0');

  return dest;
}

int main()
{
    const char str1[] = ""test1test1test1test1test1test1test1test1"";
    char buf[100];

    off = buf-str1-1;

    int i;
    for (i = 0; i &lt; 10000000; ++i) {
        my_strcpy2(buf, str1);
    }

    return 0;
}
</code></pre>

<p>But the performance of <code>my_strcpy2</code> is still worse than <code>my_strcpy1</code>. Then I checked the assembled code but failed to get the answer too.</p>

<p>I also enlarged the size of string and the performance of <code>my_strcpy1</code> is still better than <code>my_strcpy2</code></p>
","922184","","<p>Based on what I'm seeing, I'm not at all surprised that your code is faster.</p>

<p>Look at the loop, both your loop and glibc's loop are virtually identical. But glibc's has a extra code before and after...</p>

<p>In general, simple offsets do not slow down performance because x86 allows a fairly complicated indirect-addressing scheme. So both loops here will probably run at identical speeds.</p>

<p>EDIT: Here's my update with the added info you gave.</p>

<p>Your string size is only 5 characters. Even though the offset method ""may"" be slightly faster in the long run, the fact that it needs several operations to compute the offset before starting the loop is slowing it down for short strings. Perhaps if you tried larger strings the gap will narrow and possibly vanish altogether.</p>
"
"<p>I squealed out loud.
This really makes you wonder.</p>

<p>I dread to think what would happen if I chose 'Favor size over speed'.</p>

<p>Setting: Visual Studio 2010</p>

<pre><code>&lt;Optimization&gt;MaxSpeed&lt;/Optimization&gt;
&lt;IntrinsicFunctions&gt;true&lt;/IntrinsicFunctions&gt;
&lt;FavorSizeOrSpeed&gt;Speed&lt;/FavorSizeOrSpeed&gt;
&lt;EnableEnhancedInstructionSet&gt;StreamingSIMDExtensions2&lt;/EnableEnhancedInstructionSet&gt;
&lt;FloatingPointModel&gt;Precise&lt;/FloatingPointModel&gt;
</code></pre>

<p>How does:</p>

<pre><code>for (i = 0; i &lt; some_num; i++)
{
    one += buf[i] * buf[i];     
    two += buf[i] * buf[off+i];
}
</code></pre>

<p>translate to this:</p>

<pre><code>131:    for (i = 0; i &lt; some_num; i++)
132:    {
133:        one += buf[i] * buf[i];
00404B40  movss       xmm0,dword ptr [eax-4]
00404B45  movss       xmm7,dword ptr [esp+18h]
00404B4B  movss       xmm2,dword ptr [eax]
00404B4F  cvtps2pd    xmm3,xmm2
00404B52  movss       xmm4,dword ptr [eax+4]
00404B57  cvtps2pd    xmm1,xmm0
00404B5A  mulsd       xmm3,xmm3
00404B5E  movss       xmm6,dword ptr [eax+8]
00404B63  mulsd       xmm1,xmm1
00404B67  cvtps2pd    xmm5,xmm4
00404B6A  mulsd       xmm5,xmm5
00404B6E  cvtps2pd    xmm7,xmm7
00404B71  addsd       xmm1,xmm7
00404B75  cvtpd2ps    xmm1,xmm1
00404B79  cvtss2sd    xmm1,xmm1
00404B7D  addsd       xmm1,xmm3
00404B81  xorps       xmm3,xmm3
00404B84  cvtpd2ps    xmm1,xmm1
00404B88  cvtss2sd    xmm1,xmm1
00404B8C  addsd       xmm1,xmm5
00404B90  cvtpd2ps    xmm1,xmm1
00404B94  cvtss2sd    xmm3,xmm1
   134:        two += buf[i] * buf[off+i];
00404B98  cvtps2pd    xmm0,xmm0
00404B9B  cvtps2pd    xmm2,xmm2
00404B9E  cvtps2pd    xmm1,xmm6
00404BA1  mulsd       xmm1,xmm1
00404BA5  addsd       xmm3,xmm1
00404BA9  xorps       xmm1,xmm1
00404BAC  cvtpd2ps    xmm1,xmm3
00404BB0  cvtps2pd    xmm5,xmm1
00404BB3  movss       xmm1,dword ptr [eax+0Ch]
00404BB8  cvtps2pd    xmm3,xmm1
00404BBB  mulsd       xmm3,xmm3
00404BBF  addsd       xmm5,xmm3
00404BC3  xorps       xmm3,xmm3
00404BC6  cvtpd2ps    xmm3,xmm5
00404BCA  cvtps2pd    xmm5,xmm3
00404BCD  movss       xmm3,dword ptr [eax+10h]
00404BD2  cvtps2pd    xmm3,xmm3
00404BD5  mulsd       xmm3,xmm3
00404BD9  addsd       xmm5,xmm3
00404BDD  xorps       xmm3,xmm3
00404BE0  cvtpd2ps    xmm3,xmm5
00404BE4  cvtps2pd    xmm5,xmm3
00404BE7  movss       xmm3,dword ptr [eax+14h]
00404BEC  cvtps2pd    xmm3,xmm3
00404BEF  mulsd       xmm3,xmm3
00404BF3  addsd       xmm5,xmm3
00404BF7  xorps       xmm3,xmm3
00404BFA  cvtpd2ps    xmm3,xmm5
00404BFE  cvtps2pd    xmm5,xmm3
00404C01  movss       xmm3,dword ptr [eax+18h]
00404C06  cvtps2pd    xmm3,xmm3
00404C09  mulsd       xmm3,xmm3
00404C0D  addsd       xmm5,xmm3
00404C11  xorps       xmm3,xmm3
00404C14  cvtpd2ps    xmm3,xmm5
00404C18  movss       dword ptr [esp+18h],xmm3
00404C1E  movss       xmm3,dword ptr [ecx-4]
00404C23  cvtps2pd    xmm3,xmm3
00404C26  mulsd       xmm3,xmm0
00404C2A  movss       xmm0,dword ptr [esp+10h]
00404C30  cvtps2pd    xmm0,xmm0
00404C33  addsd       xmm3,xmm0
00404C37  xorps       xmm0,xmm0
00404C3A  cvtpd2ps    xmm0,xmm3
00404C3E  movss       xmm3,dword ptr [ecx]
00404C42  cvtps2pd    xmm0,xmm0
00404C45  cvtps2pd    xmm3,xmm3
00404C48  mulsd       xmm2,xmm3
00404C4C  addsd       xmm0,xmm2
00404C50  movss       xmm2,dword ptr [ecx+4]
00404C55  cvtpd2ps    xmm0,xmm0
00404C59  cvtss2sd    xmm0,xmm0
00404C5D  cvtps2pd    xmm2,xmm2
00404C60  cvtps2pd    xmm3,xmm4
00404C63  mulsd       xmm2,xmm3
00404C67  addsd       xmm0,xmm2
00404C6B  movss       xmm2,dword ptr [ecx+8]
00404C70  cvtpd2ps    xmm0,xmm0
00404C74  cvtss2sd    xmm0,xmm0
00404C78  cvtps2pd    xmm2,xmm2
00404C7B  cvtps2pd    xmm1,xmm1
00404C7E  cvtps2pd    xmm3,xmm6
00404C81  mulsd       xmm2,xmm3
00404C85  addsd       xmm0,xmm2
00404C89  movss       xmm2,dword ptr [ecx+0Ch]
00404C8E  cvtpd2ps    xmm0,xmm0
00404C92  cvtss2sd    xmm0,xmm0
00404C96  cvtps2pd    xmm2,xmm2
00404C99  mulsd       xmm2,xmm1
00404C9D  addsd       xmm0,xmm2
00404CA1  cvtpd2ps    xmm0,xmm0
00404CA5  xorps       xmm1,xmm1
00404CA8  cvtss2sd    xmm1,xmm0
00404CAC  movss       xmm0,dword ptr [ecx+10h]
00404CB1  cvtps2pd    xmm2,xmm0
00404CB4  movss       xmm0,dword ptr [eax+10h]
00404CB9  cvtps2pd    xmm0,xmm0
00404CBC  mulsd       xmm2,xmm0
00404CC0  addsd       xmm1,xmm2
00404CC4  xorps       xmm0,xmm0
00404CC7  cvtpd2ps    xmm0,xmm1
00404CCB  add         eax,20h
00404CCE  add         ecx,20h
00404CD1  cvtps2pd    xmm1,xmm0
00404CD4  movss       xmm0,dword ptr [ecx-0Ch]
00404CD9  cvtps2pd    xmm2,xmm0
00404CDC  movss       xmm0,dword ptr [eax-0Ch]
00404CE1  cvtps2pd    xmm0,xmm0
00404CE4  mulsd       xmm2,xmm0
00404CE8  addsd       xmm1,xmm2
00404CEC  xorps       xmm0,xmm0
00404CEF  cvtpd2ps    xmm0,xmm1
00404CF3  xorps       xmm1,xmm1
00404CF6  cvtps2pd    xmm1,xmm0
00404CF9  movss       xmm0,dword ptr [ecx-8]
00404CFE  xorps       xmm2,xmm2
00404D01  cvtps2pd    xmm2,xmm0
00404D04  movss       xmm0,dword ptr [eax-8]
00404D09  cvtps2pd    xmm0,xmm0
00404D0C  mulsd       xmm2,xmm0
00404D10  addsd       xmm1,xmm2
00404D14  xorps       xmm0,xmm0
00404D17  cvtpd2ps    xmm0,xmm1
00404D1B  movss       dword ptr [esp+10h],xmm0
00404D21  cmp         eax,offset buf+84h (42D6A4h)
00404D26  jl          gem+290h (404B40h)
   135:    }
</code></pre>
","922184","","<p>The answer is yes. Visual Studio does not currently vectorize code. If you look at the assembly, those are all scalar SSE instructions. And your loop is clearly vectorizable.</p>

<p>You will have to use a vectorizing compiler to get better results. Or emit the vector-SSE instructions yourself using intrinsics.</p>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_intro.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_intro.htm</a></p>

<p>Another thing you could try is:</p>

<p>Change the floating-point mode to ""fast"" instead of ""precise"". The compiler is promoting the intermediates to double-precision and converting them back - which adds a lot of overhead.</p>
"
"<p>I see that binary translation is usually trace-based. Is it because one can not get the  boundaries of functions? Is there function label in binary code? </p>
","922184","","<p>There's no trivial answer to this. You could search for <code>ret</code> instructions, but they are no guarantee that they are function boundaries as you could return from the middle of a function.</p>

<p>Searching for stuff like</p>

<pre><code>mov   ebp, esp 
</code></pre>

<p>will work to some extent, but again, it's no guarantee.</p>

<p>Some compilers (most notably the Intel Compiler), will move branched blocks to <em>after</em> the function ends, and jump back into the function...</p>
"
"<p>I'm trying to compute the log of the mean of some very small values. For the current data set, the extreme points are</p>

<pre><code>log_a=-1.6430e+03;
log_b=-3.8278e+03;
</code></pre>

<p>So in effect I want to compute <code>(a+b) / 2</code>, or <code>log((a+b)/2)</code> since I know <code>(a+b)/2</code> is too small to store as a double.</p>

<p>I considered trying to pad everything by a constant, so that instead of storing <code>log_a</code> I'd store <code>log_a+c</code>, but it seems that <code>a</code>and <code>b</code> are far enough apart that in order to pad <code>log_b</code> enough to make <code>exp(log_b+c)</code> computable, I'd end up making <code>exp(log_a+c)</code> too large. </p>

<p>Am I missing some obvious way to go about this computation? As far as I know MATLAB won't let me use anything but double precision, so I'm stumped as to how I can do this simple computation.</p>

<p>EDIT: To clarify: I can compute the exact answer for these specific values. For other runs of the algorithm, the values will be different and might be closer together. So far there have been some good suggestions for approximations; if an exact solution isn't practical, are there any other approximations for more general numbers/magnitudes of values?</p>
","922184","","<p>Well, <code>exp(log_b)</code> is so much smaller than <code>exp(log_a)</code> that you can completely ignore that term and still get the correct answer with respect to double-precision:</p>

<pre><code>exp(log_a) = 2.845550077506*10^-714
exp(log_b) = 4.05118588390*10^-1663
</code></pre>

<p>If you are actually trying to compute <code>(exp(log_a) + exp(log_b)) / 2</code>, the answer would underflow to zero anyways. So it wouldn't really matter unless you're trying to take another logarithm at the end.</p>

<p>If you're trying compute:</p>

<pre><code>log((exp(log_a) + exp(log_b)) / 2)
</code></pre>

<p>Your best bet is to examine the difference between <code>log_a</code> and <code>log_b</code>. If the difference is large, then simply take the final value as equal to the larger term - log(2) since the smaller term will be small enough to completely vanish.</p>

<p>EDIT:</p>

<p>So your final algorithm could look like this:</p>

<ol>
<li>Check the magnitudes. If <code>abs(log_a - log_b) &gt; 800</code>. Return <code>max(log_a,log(b)) - log(2)</code>.</li>
<li>Check either magnitude (they will be close together at this point.). If it is much larger or smaller than 1, add/subtract a constant from both <code>log_a</code> and <code>log_b</code>.</li>
<li>Perform the calculation.</li>
<li>If the values were scaled in step 2. Scale the result back.</li>
</ol>

<p>EDIT 2:</p>

<p>Here's an even better solution:</p>

<pre><code>if (log_a &gt; log_b)
    return log_a + log(1 + exp(log_b - log_a)) - log(2)
else
    return log_b + log(1 + exp(log_a - log_b)) - log(2)
</code></pre>

<p>This will work if <code>log_a</code> and <code>log_b</code> are not too large or are negative.</p>
"
"<p>I am trying to measure the execution time taken by some functions in my C code.
I am ussing the difference of time using the clock() function, but I mostly get 0 as a result, since the value of CLOCKS_PER_SEC seems to be set at only 1000 on my implementation.</p>

<p>What are some other ways to measure accurately the execution time of a function? I am using Visual Studio 2010 </p>

<p>thanks</p>

<p>edit: I am looking for a time resolution of around 0.1ms, I don't really need more</p>
","922184","","<p>You can use performance counters:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms644904%28v=vs.85%29.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms644904%28v=vs.85%29.aspx</a></p>
"
"<p>I need to make an array of strings for a program in one of my CS classes.  We are to just assume that the length of all the strings is no more than 50 (this accounts for the null character).</p>

<p>I need use <code>malloc()</code> or <code>calloc()</code> to allocate the proper amount of memory for the array, but I am new to C and I don't really know how to use those functions.</p>

<p>The real question I guess is how much memory to I need do allocate for an array of x strings of 50 characters.</p>
","922184","","<p>Assuming type <code>char</code>, at minimum you will need <code>X * sizeof(char) * 50</code>.</p>

<p>If you are doing all of these allocations separately, there will be overhead for each allocation. So the total amount of memory in this case will be higher. </p>

<p>This overhead is unspecified and can be fairly large.</p>

<p>But I wouldn't worry about that for a homework assignment. I can't imagine the problem needing enough memory to possibly run your system out.</p>
"
"<p>I am trying to understand the for loop better. I have the following variables:</p>

<p>x = 1</p>

<p>y = 10</p>

<p>I want to increment x and double it ten times with a for loop to have the following output: 1, 2, 4, 8, 16, etc.</p>

<p>This is what I have, but it is not quite doing the trick:</p>

<pre><code>int x = 1;

int y = 10;

for (int i = 0; i &lt; y; i++)
{
    x *= 2;

}

printf(""%d\n"", x);
</code></pre>

<p>Do I need another variable to do this?</p>
","922184","","<p>It looks fine to me. If you want it to print at each iteration, you need to move the <code>printf</code> into the loop.</p>

<p>Also, your code will only work in C99 or with GCC's default extensions since you have <code>int i</code> inside the <code>for</code> loop.</p>
"
"<p>I have this binary file with showing the correct value when I opened the file using HexView.</p>

<p>4c 60 02 aa b4 c2 d1 e3 1a 01 00 00 8c 01 00 00
f5 01 00 00 52 02 00 00 bd 02 00 00 20 03 00 00
32 03 00 00 59 03 00 00</p>

<p>When I uses fread to read the 40 bytes data into a char buffer, it failed. From 9th byte data onwards, all the read back data is 0x00.</p>

<pre><code>int main()
{
    FILE *stream;
    char flag[40]={0};
    size_t numread = 0;
    UINT theme = 0;

    if ((stream = fopen(""alignment.bin"", ""r"")) != NULL)
    {
        numread = fread(&amp;flag, 1, 40, stream);

        fclose(stream);
    }
    else
    {
        cout &lt;&lt; ""File open failed"" &lt;&lt; endl;
    }
    system (""pause"");
    return 0;
}
</code></pre>
","922184","","<p>Try using <code>""rb""</code> instead of <code>""r""</code>. There might be some weird text formatting issues.</p>

<p>Specifying the <code>b</code> makes it read in pure binary with no formatting.</p>
"
"<p>I was asked this as interview question. Couldn't answer.  </p>

<blockquote>
  <p>Write a C program to find size of structure without using the <code>sizeof</code> operator.</p>
</blockquote>
","922184","","<p>Here's another approach. <strike>It also isn't completely defined but will still work on most systems.</strike></p>

<pre><code>typedef struct{
    //  stuff
} mystruct;

int main(){
    mystruct x;
    mystruct *p = &amp;x;

    int size = (char*)(p + 1) - (char*)p;
    printf(""Size = %d\n"",size);

    return 0;
}
</code></pre>
"
"<p>I have a code like the following which I am using to find prime numbers (using Eratosthenes sieve) within a range, and using OpenMP to parallelize. Before this, I have a preprocessing stage where I am flagging off all even numbers, and multiples of 3 and 5 so that I have to do less work in this stage. 
The shared L3 cache of the testbed is 12MB, and the physical memory is 32 GB. I am using 12 threads. The <code>flag</code> array is <code>unsigned char</code>.</p>

<pre><code>#pragma omp parallel for
for (i = 0; i &lt; range; i++)
{
     for (j = 5; j &lt; range; j+=2)
     {
         if( flag[i] == 1 &amp;&amp; i*j &lt; range )
             if ( flag[i*j] == 1 )
                 flag[i*j] = 0;
      }
 }
</code></pre>

<p>This program works well for ranges less than 1,000,000...but after that the execution time shoots up for larger ranges; eg, for <code>range = 10,000,000</code> this program takes around 70 mins (not fitting in cache?). I have modified the above program to incorporate loop tiling so that it could utilize the cache for any loop range, but even the blocking approach seems to be time consuming. Interchanging the loops also do not help for large ranges.</p>

<p>How do I modify the above code to tackle large ranges? And how could I rewrite the code to make it fully parallel (<code>range</code> and <code>flag</code> [since the <code>flag</code> array is quite large so I can't declare it private] is shared)? </p>
","922184","","<p>Actually, I just noticed a few easy speedups in your code. So I'll mention these before I get into the fast algorithm:</p>

<ol>
<li>Use a bit-field instead of a char array. You can save a factor of 8 in memory.</li>
<li>Your outer loop is running over all integers. Not just the primes. After each iteration, start from the first number that hasn't been crossed off yet. (that number will be prime)</li>
</ol>

<p>I'm suggesting this because you mentioned that it take 70 min. on a (pretty powerful) machine to run <code>N = 10,000,000</code>. That didn't look right, since my own trivial implementation can do <code>N = 2^32</code> in under 20 seconds on a laptop - single-threaded, no source-level optimizations. So then I noticed that you missed a few basic optimizations.</p>

<p>Here's the efficient solution. But it takes some work.</p>

<p>The key is to recognize that the Eratosthenes Sieve only needs to go up to sqrt(N) of your target size. In other words, you only need to run the sieve on all prime numbers up to sqrt(N) before you are done.</p>

<p>So the trick is to first run the algorithm on sqrt(N). Then dump all the primes into a dense data structure. By pre-computing all the needed primes, you break the dependency on the outer-loop.</p>

<p>Now, for the rest of the numbers from sqrt(N) - N, you can cross off all numbers that are divisible by any prime in your pre-computed table. Note that this is independent for all the remaining numbers. So the algorithm is now embarrassingly parallel.</p>

<p>To be efficient, this needs to be done using ""mini""-sieves on blocks that fit in cache. To be even more efficient, you should compute and cache the reciprocals of all the primes in the table. This will help you efficiently find the ""initial offsets"" of each prime when you fill out each ""mini-sieve"".</p>

<p>The initial step of running the algorithm sequential for sqrt(N) will be very fast since it's only sqrt(N). The rest of the work is completely parallelizable.</p>

<p>In the fully general case, this algorithm can be applied recursively on the initial sieve, but that's generally overkill.</p>
"
"<p>I have a friend who was working on a c example from a book and he did a code like </p>

<pre><code>#include&lt;stdio.h&gt;
#include&lt;math.h&gt;
#pragma warning(disable:4996)

int main()
{
    float numGrade;

    printf(""\n\nPlease enter your numerical grade: "");
    scanf(""%f"", &amp;numGrade);

    if (numGrade &gt;= 90)
        printf(""\nYou got an A.\n\n"");
    else if (90 &gt; numGrade &gt;= 80)
        printf(""\nYou got a B.\n\n"");
    else if (80 &gt; numGrade &gt;= 70)
        printf(""\nYou got a C.\n\n"");
    else if (70 &gt; numGrade &gt;= 60)
        printf(""\nYou got a D.\n\n"");
    else if (60 &gt; numGrade)
        printf(""\nYou got an F.\n\n"");
    else
        printf(""\nThis is an invalid grade!\n"");
}
</code></pre>

<p>Is there any problem with doing it like that or should he do it like :</p>

<pre><code>int main()
{
    float numGrade;

    printf(""\n\nPlease enter your numerical grade: "");
    scanf(""%f"", &amp;numGrade);

    if (numGrade &gt;= 90)
        printf(""\nYou got an A.\n\n"");
    else if (90 &gt; numGrade &amp;&amp; numGrade &gt;= 80)
        printf(""\nYou got a B.\n\n"");
    else if (80 &gt; numGrade &amp;&amp; numGrade &gt;= 70)
        printf(""\nYou got a C.\n\n"");
    else if (70 &gt; numGrade &amp;&amp; numGrade &gt;= 60)
        printf(""\nYou got a D.\n\n"");
    else if (60 &gt; numGrade)
        printf(""\nYou got an F.\n\n"");
    else
        printf(""\nThis is an invalid grade!\n"");
}
</code></pre>
","922184","","<p>That first example won't work at all.</p>

<p>The first comparison in each test will return either 0 or 1. So it will always fail the second.</p>

<p>EDIT:</p>

<p><strike>However, the program will probably still ""work"" the way it is desired, simply because the second comparison in each test is not needed.</strike></p>
"
"<p>I want to write a program to see if an integer is the power of another integer(true return 1 and false return 0). And the code is as follows:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;math.h&gt;

int cal_base_power(int);

int main()
{
int x,r;
printf(""Please input an integer\n"");
scanf(""%d\n"",&amp;x);
r=cal_base_power(x);
printf(""result is %d\n"",r);
}

int cal_base_power(int input)
{
int i=2;
double a=pow(input,(double)1/i);
while (a&gt;=2)
{
        if ((double)a==(int)a)

        return 1;               

        i++;
        a=pow(input,(double)1/i);

}

    return 0;


}
</code></pre>

<p>It is ok with 4,8,125 some cases like these. But failed when input 216 and 343. Also it will not automatically output 0 and 1. I must input some random characteristics before the result 0 or 1 comes out.
Can anyone help me? I know it is quite easy. But I really need your help</p>
","922184","","<p>You can't do equality comparisons on floating-point.</p>

<pre><code>(double)a==(int)a
</code></pre>

<p>Due to round-off error, <code>a</code> might not be exactly an integer even though it's supposed to be.</p>

<p>EDIT:</p>

<p>There's two ways to do this:</p>

<ol>
<li>Allow tolerance on the comparison: <code>fabs(a - (int)a) &lt; 0.0001</code> (or something like that, you'll need to tweak the threshold.)</li>
<li>Round <code>a</code> to the nearest integer and power it back up (using integers only) to see if it matches the input.</li>
</ol>
"
"<p>In C++ class today, we discussed the maximum possible length of identifiers, and how the compiler will eventually stop treating variables as different, after a certain length. (My professor seems to have implied that really long identifiers are truncated.) I <a href=""http://stackoverflow.com/questions/7392726/is-there-a-limit-to-the-length-of-identifier-names-in-c"">posted another question earlier, hoping to see if the limit is defined somewhere</a>. My question here is a little different. Suppose I wanted to test either a practical or enforced limit on identifier name lengths. How would I go about doing so? Here's what I'm thinking of doing, but somehow it seems to be too simple.</p>

<ul>
<li><strong>Step 1:</strong> Generate at least two variables with really long names and print them to the console. If the identifier names are really that unlimited, I am not going to waste time typing them. My code should do it for me. </li>
<li><strong>Step 2:</strong> Attempt to perform some operations with the variables, such as compare them, or any arithmetic. If the compiler stops differentiating, then in theory, certain arithmetic will break, such as <code>x/(reallyLongA-reallyLongB)</code>, since <code>reallyLongA</code> and <code>reallyLongB</code> will be so long that the compiler will just treat them as the same thing. At that point, the division operation will become a division-by-zero, which should crash and burn horribly. </li>
</ul>

<p>Am I approaching this correctly? Will I run out of memory before I ""break"" the compiler or ""runtime""?</p>
","922184","","<p>I would assume that if it still works after the length reaches some ridiculous size (like > 1MB), that the compiler probably is able to handle arbitrary sized identifiers.</p>

<p>Of course there's no sure way to tell as it is entirely possible for the identifier length limit to exceed the amount of memory you have. (a limit of 2^32 - 1 is entirely possible)</p>
"
"<p>Why declaration of two enums type with same values in same block is not allowed in C++?</p>

<pre><code>enum math_students {A,B,C};
enum comp_students {D,E,A}; // illegal
</code></pre>
","922184","","<p>The values in an enum are not scoped. The members of an enum are accessed directly by their names. So if multiple enums have members with the same name, there will be a naming comflict.</p>
"
"<p>I have a little story.</p>

<p>I wanted to calculate the machine epsilon (the largest epsilon > 0 satisfying condition 1.0 + epsilon = 1.0) in a C program compiled by MS Visual Studio 2008 (running on Windows 7 in a 64 bit PC). Since I know that double and float have different precision I wanted to see the answer for both. For that reason I constructed the following program:</p>

<pre><code>#include &lt;stdio.h&gt;
typedef double float_type;
int main()
{
  float_type eps = 1.0;
  while ((float_type) 1.0 + eps / (float_type) 2.0 &gt; (float_type) 1.0)
    eps = eps / (float_type) 2.0;
  printf(""%g\n"", eps);
  return 0;
}
</code></pre>

<p>I was quite surprised to see that it gave the same answer for both types double and float: 2.22045e-16. That was strange since double occupies twice more memory than float and should be more precise. After that I looked into <a href=""http://en.wikipedia.org/wiki/Machine_epsilon"" rel=""nofollow"">Wikipedia</a> and took a sample code from there:</p>

<pre><code>    #include &lt;stdio.h&gt;
    int main(int argc, char **argv)
    {
      float machEps = 1.0f;
      do {
        machEps /= 2.0f;
      } while ((float)(1.0 + (machEps/2.0)) != 1.0);
      printf( ""\nCalculated Machine epsilon: %G\n"", machEps );
      return 0;
   }
</code></pre>

<p>I was even more surprised when it worked correctly! After some attempts to understand the fundamental difference between the two programs I figured out the following fact: my program (the first one) starts to give the corrent answer for float (1.19209e-07) if I change the loop condition to</p>

<pre><code>  while ((float_type) (1.0 + eps / (float_type) 2.0) &gt; (float_type) 1.0)
</code></pre>

<p>Well, that is a mystery you'd say. Oh, the real mystery is the following. Compare:</p>

<pre><code>  while ((float) (1.0 + eps / 2.0f) &gt; 1.0f) 
</code></pre>

<p>which gave the correct answer (1.19209e-07) and</p>

<pre><code>  while ((float) (1.0f + eps / 2.0f) &gt; 1.0f)
</code></pre>

<p>which gave answer which is incorrect for float and correct for double (2.22045e-16).</p>

<p>In fact that is totally wrong, the result should have been opposite. That is because by default constants like 1.0 are treated as double by the compiler (according to the standard) and if it is present in an arithmetic expression then all other operands are promoted to double. Conversely, when I write 1.0f all operands are float and no promotion should take place. And yet I get a completely different result.</p>

<p>After all these tests I tried to compile run the programs on Linux using gcc. No surprise, it printed exactly what I expected (correct answers). So I now guess that this is Visual Studio bug. To make you all laugh (if there are any people who have read my post till that moment what is doubtful ^_^) I will give you another comparison:</p>

<pre><code>float c = 1.0;
while ((float) (c + eps / 2.0f) &gt; 1.0f)
</code></pre>

<p>This does not work properly in VS, but...</p>

<pre><code>const float c = 1.0;
</code></pre>

<p>gives the correct answer of 1.19209e-07.</p>

<p>Please somebody tell me if I am right that the root of the problem is a buggy VS 2008 compiler (can you confirm the bug on your machines?). I would be also  grateful if you tested the case in a newer version: MS VS 2010. Thanks.</p>
","922184","","<p>By default, Visual Studio's floating-point setting is set to ""precise"". This means that it will try to make the result as precise as possible. One of the side-effects of this is that intermediates are promoted to double precision.</p>

<p>While I haven't looked at every bit of code you posted, I suspect the problem is here:</p>

<pre><code>(float) (c + eps / 2.0f)
</code></pre>

<p>The <code>c + eps / 2.0f</code> is done using double-precision. Each of the 3 operands are promoted to double-precision and the entire expression is evaluated as such. It is only rounded down to a float when you cast it.</p>

<p>If you set the floating-point mode to ""strict"", it should work as you expect it to.</p>
"
"<p>Why does the following code output <code>1</code>, instead of <code>0</code>? <code>a || b</code> should give me <code>1</code> and <code>1 &amp;&amp; 0</code> is <code>0</code>, right? I don't think logical operations evaluated from right to left.</p>

<pre><code>int main()
{
    printf(""%d\n"", 1 || 1 &amp;&amp; 0);
    return 0;
}
</code></pre>
","922184","","<p><code>&amp;&amp;</code> has higher precedence than <code>||</code>. (Like how multiplication has higher precedence than addition.)</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/1151402/declaring-function-parameters-after-function-name"">Declaring function parameters after function name</a><br>
  <a href=""http://stackoverflow.com/questions/1585390/c-function-syntax-parameter-types-declared-after-parameter-list"">C function syntax, parameter types declared after parameter list</a>  </p>
</blockquote>



<p>I'm fairly new to C and was mucking around with timing and came across the following function.  I can get it to work by passing pointers to it.  I don't really understand whats happening here though. What does the third line do and how is the second line even legal?</p>

<pre><code>int 
timeval_subtract (result, x, y)
     struct timeval *result, *x, *y;
{
  ... (function code here)
}
</code></pre>
","922184","","<p>This is very old C syntax for function declaration. It is not recommended to use it.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/efx873ys.aspx"">http://msdn.microsoft.com/en-us/library/efx873ys.aspx</a></p>
"
"<p>Probably a stupid question but I am in the following situation:</p>

<p>our development machines are currently all 64-bit Intel-based systems, where we produce 32-bit and 64-bit versions of our applications. We also recommend our customers to use Intel-based systems (as opposed to AMD-based systems).</p>

<p>Now our IT-manager wants to buy some new development systems and to cut the costs he is looking into buying (64-bit) AMD-based systems.  Visual Studio (2010) probably doesn't care which processor it is running on, and the generated code is probably the same, but just to be sure: does it make any difference for the generated executable on which processor (AMD vs. Intel) it is built?</p>
","922184","","<p>It depends on how you configure it. I think by default, no it doesn't matter.</p>

<p>If you're using the Intel Compiler and you compile with <code>/QxHost</code> or <code>/fast</code>, then it will matter since it clearly looks at your system to see what it's capable of.</p>

<p>But if you specify <code>/arch:XXX</code> or whatever option, it will be independent of your machine. For GCC, I think by default it doesn't look at the host machine.</p>

<p>EDIT:</p>

<p>As as far as libraries like MKL go, the host machine will still have no effect on which version of the MKL is compiled. In general multiple code-paths of the MKL are put into the binary regardless and the CPU-dispatching is done at run-time.</p>
"
"<p>Intel helpfully provides a prefetch pragma; for example</p>

<pre><code>#pragma prefetch a
for(i=0; i&lt;m; i++)
  a[i]=b[i]+1;
</code></pre>

<p>will prefetch <code>a</code> a certain number of loop cycles ahead, as determined by the compiler.</p>

<p>But what if <code>a</code> is not an array but a class with <code>[]</code> overridden?  If <code>operator[]</code> does a simple array access, can prefetch still be used in this way?</p>

<p>(Presumably the question applies to <code>std::vectors</code> as well).</p>
","922184","","<p>One way to find out is to try it and look at the assembly. And if anything else, just benchmark it with and without the pragma. However, I'm not sure if the prefetch pragma is what you want:</p>

<blockquote>
  <p>The prefetch pragma is supported by Intel® Itanium® processors only.</p>
</blockquote>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/cref_cls/common/cppref_pragma_prefetch_noprefetch.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/cref_cls/common/cppref_pragma_prefetch_noprefetch.htm</a></p>

<p>Are you really writing this for an Itanium?</p>

<p>On x86/x64 systems, simple loops like that with sequential memory access are already well handled by the hardware prefetcher. So it may not help at all to do manual prefetching.</p>

<p>See here for a prefetching example: <a href=""http://stackoverflow.com/questions/7327994/prefetching-examples/7328195#7328195"">Prefetching Examples?</a></p>
"
"<p>I am guessing that even reading from shared data in openmp causes some parallel overheads, as depending on processor architecture (if different cores have their own cache...) it may be necessary to refresh the cache to ensure that no other cpu has modified the data before reading.</p>

<p>Am I right in thinking this?</p>

<p>If so, is there a way to tell openmp (on the intel compiler fwiw) that some of the shared data is constant, so such cache refreshing isn't necessary?</p>

<p>If the answer is c++ <code>const</code> is there an easy way to turn non-const data into const data, without actually reallocating the memory, once the program has passed a certain point at runtime?</p>

<p>UPDATE</p>

<p>Ah, ok.  I now remember where I got my impression that <code>const</code> was a good thing in this context:  <a href=""http://www.akkadia.org/drepper/cpumemory.pdf"" rel=""nofollow"">http://www.akkadia.org/drepper/cpumemory.pdf</a> , section 6.4.1.  It's to do with false sharing, where readonly variables which share cache lines with readwrite variables incur the penalty of the cache line being marked exclusive by the readwrite variable.  The linked document recommends, for example with gcc, to mark those vars as <code>__attribute__((section(something.else)))</code> to ensure they get stored elsewhere.</p>

<p>As it happens this is not relevant in my own situation - large arrays and stl containers of data in which the read/write granularity will span many cache lines and which are allocated from different memory pools in any case.  So these will naturally be located on different cache lines.  No problem!</p>
","922184","","<p>Sharing read-only data among multiple cores has no overhead. The same copy of the data will be in the cache for all the cores that are using it.</p>

<p>The only time you will incur overhead is when one of the cores writes to the shared data. In that situation, you will incur a (potentially large) overhead because the write will invalidate all the other copies of that cache line and force them to grab it from memory or from a different cache.</p>

<p>In other words, the cache is only ""refreshed"" when somebody changes the data. There's no periodic ""refreshing"".</p>

<p>So the answer to your question is: You do not have to do anything. There's no way to tell OpenMP or the hardware that the data is constant and <code>const</code> will have no effect aside from syntax.</p>
"
"<p>I'm trying to pass a mutex handle, to a child process trough command line, or any other way.</p>

<p>How can I do that? 
How do I acess the mutex from the child?</p>

<p>This is how I'm creating the child process:</p>

<pre><code>HANDLE ghMutex;

     if( !CreateProcess( _T(""C:\\Users\\Kumppler\\Documents\\Visual Studio 2010\\Projects\\teste3\\Debug\\teste3.exe""),   // No module name (use command line)
                aux2,                              // Command line
                NULL,                              // Process handle not inheritable
                NULL,                              // Thread handle not inheritable
                TRUE,                              // Set handle inheritance to TRUE
                STARTF_USESTDHANDLES,              // inherit the standard input, standard output, and standard error handles
                NULL,                              // Use parent's environment block
                NULL,                              // Use parent's starting directory 
                &amp;si[j],                            // Pointer to STARTUPINFO structure
                &amp;pi[j] )                           // Pointer to PROCESS_INFORMATION structure
            )                     
</code></pre>

<p>EDIT: </p>

<p>I need to use the mutex for more than one child process, is it ok?</p>

<p>So here is what I'm doing right now:</p>

<pre><code>HANDLE ghMutex;
int mutex;
char mutexstring[7];

mutex=(int)ghMutex;
itoa(mutexValue,mutexString,10);
</code></pre>

<p>I'll pass the mutexString trough command line, and then convert it back at child process:</p>

<pre><code>mutexValue=atoi(argv[2]);

Mutex=(HANDLE)mutexValue;
</code></pre>

<p>My question, is it okay to do the (HANDLE) casting??</p>
","922184","","<p>Mutexs and handles lie in the address space of the process that originally made it. So you can't just ""pass"" it into another process.</p>

<p>This page explains how to do inter-process synchronization:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms684123%28v=vs.85%29.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms684123%28v=vs.85%29.aspx</a></p>

<p>The idea is to create a mutex using object names.</p>
"
"<p>I understand that using this flag can greatly increase speed for float ops, and goes outside of IEEE standards, but I can't seem to find information on what is really happening when it's on. Can anyone please explain some of the details and maybe give a clear example of how something would change if the flag was on or off?</p>

<p>I did try digging through S.O. for similar questions but couldn't find anything explaining the workings of ffast-math.</p>
","922184","","<p>As you mentioned, it allows optimizations that do not preserve strict IEEE compliance.</p>

<p>An example is this:</p>

<pre><code>x = x*x*x*x*x*x*x*x;
</code></pre>

<p>to</p>

<pre><code>x *= x;
x *= x;
x *= x;
</code></pre>

<p>Because floating-point arithmetic is not associative, the ordering and factoring of the operations will affect results due to round-off. Therefore, this optimization is not done under strict FP behavior.</p>

<p>EDIT: I haven't actually checked to see if GCC actually does this particular optimization. But the idea is the same.</p>
"
"<p>I've read a few texts and threads showing how to convert from a decimal to IEEE 754 but I am still confused as to how I can convert the number without expanding the decimal (which is represented in scientific notation)</p>

<p>The number I am particularly working with is <code>9.07 * 10^23</code>, but any number would do; I will figure out how to do it for my particular example.</p>
","922184","","<p>Converting a number from a decimal string to binary IEEE is fairly straight-forward if you know how to do IEEE floating-point addition and multiplication. (or if you're using any basic programming language like C/C++)</p>

<p>There's a lot of different approaches to this, but the easiest is to evaluate <code>9.07 * 10^23</code> directly.</p>

<p>First, start with <code>9.07</code>:</p>

<pre><code>9.07 = 9 + 0 * 10^-1 + 7 * 10^-2
</code></pre>

<p>Now evaluate <code>10^23</code>. This can be done by starting with 10 and using any powering algorithm.</p>

<p>Then multiply the results together.</p>

<p>Here's a simple implementation in C/C++:</p>

<pre><code>double mantissa = 9;
mantissa += 0 / 10.;
mantissa += 7 / 100.;

double exp = 1;
for (int i = 0; i &lt; 23; i++){
    exp *= 10;
}

double result = mantissa * exp;
</code></pre>

<p>Now, going backwards (IEEE -> to decimal) is a lot harder.</p>

<p>Again, there's also a lot of different approaches. Here's the easiest one I can think of it.</p>

<p>I'll use <code>1.0011101b * 2^40</code> as the example. (the mantissa is in binary)</p>

<p>First, convert the mantissa to decimal: (this should be easy, since there's no exponent)</p>

<pre><code>1.0011101b * 2^40 = 1.22656 * 2^40
</code></pre>

<p>Now, ""scale"" the number such that the binary exponent vanishes. This is done by multiplying by an appropriate power of 10 to ""get rid"" of the binary exponent.</p>

<pre><code>1.22656 * 2^40 = 1.22656 * (2^40 * 10^-12) * 10^12
               = 1.22656 * (1.09951) * 10^12
               = 1.34861 * 10^12
</code></pre>

<p>So the answer is:</p>

<pre><code>1.0011101b * 2^40 = 1.34861 * 10^12
</code></pre>

<p>In this example, <code>10^12</code> was needed to ""scale away"" the <code>2^40</code>. Determining the power of 10 that is needed is simply equal to:</p>

<pre><code>power of 10 = (power of 2) * log(2)/log(10)
</code></pre>
"
"<p>I am writing code to enter a string and convert all its uppercase letters to lowercase and vice versa:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;string&gt;
using namespace std;
int main(){
     string s;
     cout&lt;&lt;""enter the string :""&lt;&lt;endl;
     cin&gt;&gt;s;

     for (int i=0;i&lt;s.length();i++){
        if ('a'&lt;=s[i] &amp;&amp; s[i]&lt;='z'){
           s[i]=char(((int)s[i])-32);
        }

        if ('A'&lt;=s[i] &amp;&amp; s[i]&lt;='Z'){
           s[i]=char(((int)s[i])+32);
        }
      }

     cout&lt;&lt;""modified string is  : ""&lt;&lt;s&lt;&lt;endl;
     return 0;
}
</code></pre>

<p>Problem is that it always returns string with all lower case letters and none of them is upper case. Why?</p>
","922184","","<p>You're converting all lower case to upper case in the first if-statement. However, the same letters that were changed to uppercase will immediately be changed to lower case again in the second if-statement.</p>

<p>What you want is an <code>else if</code>.</p>
"
"<p>My C application on windows is running a for loop in which it dumps numerous entries into some data structure and then saves the same in an xml. Now, i want to know the memory footprint it is taking to do the same. Are there any tools available?</p>
","922184","","<p>Task Manager is the way I do it. It's simple and easy.</p>

<p>But it only works if you're trying to measure very large memory footprints. But applications with large footprints are probably the only cases where you'd need to measure the usage anyway.</p>

<p>If you want to measure memory usage accurate to the byte, I would just build a simple wrapper around <code>malloc()</code> and <code>free()</code> that increments some global value. (if the app is threaded, a lock might also be needed)</p>
"
"<p>My question is whether is it a good idea to mix OpenMP with pthreads. Are there applications out there which combine these two. Is it a good practice to mix these two? Or typical applications normally just use one of the two. </p>
","922184","","<p>Typically it's better to just use one or the other. But for myself at least, I do regularly mix the two and it's safe if it's done correctly.</p>

<p>The most common case I do this is where I have a lower-level library that is threaded using pthreads, but I'm calling it in a user application that uses OpenMP.</p>

<p>There are some cases where it isn't safe. If for example, you kill a pthread before you exit all OpenMP regions in that thread.</p>
"
"<p>Is it safe to assume that the count returned from <a href=""http://msdn.microsoft.com/en-us/library/ms644904%28v=vs.85%29.aspx"" rel=""nofollow"">QueryPerformanceCounter</a> relates to the time since the last system boot? Or could it be reset while the system is running? The MSDN article itself doesn't guarantee this, however I've seen some 3rd party information (such as <a href=""http://www.decompile.com/cpp/faq/windows_timer_api.htm"" rel=""nofollow"">this</a>) that says that this is the case.</p>
","922184","","<p>It's meant to be used for relative times. But I don't think it can be used to measure time since boot.</p>

<p>From what I hear, it's implemented using the <code>rdtsc</code> instruction which measures ""pseudo"" CPU cycles since the CPU was powered on. In that case, yes, it probably does give the time since boot, but I don't think this is specified.</p>
"
"<p>There is such code:</p>

<pre><code>#include &lt;stdio.h&gt;

int main() {
  float d = 1.0;
  int i = 2;
  printf(""%d %d"", d, i);
  getchar();
  return 0;
}
</code></pre>

<p>And the output is: </p>

<pre><code>0 1072693248
</code></pre>

<p>I know that there is error in printf and first %d should be replaced with %f. But why variable i is printed wrong (1072693248 instead of 2)?</p>
","922184","","<p>Since you specified <code>%d</code> instead of <code>%f</code>, what you're really seeing is the binary representation of <code>d</code> as an integer.</p>

<p>Also, since the datatypes don't match, the code actually has undefined behavior.</p>

<p>EDIT:</p>

<p>Now to explain why you don't see the <code>2</code>:</p>

<p><code>float</code> gets promoted to <code>double</code> on the stack. Type <code>double</code> is (in this case) 8 bytes long. However, since your <code>printf</code> specifies two integers (both 4 bytes in this case), you are seeing the binary representations of <code>1.0</code> as a type <code>double</code>. The 2 isn't printed because it is beyond the 8 bytes that your <code>printf</code> expects.</p>
"
"<p>In the code below, <strong>why</strong> 1-byte <code>anUChar</code> is automatically converted into 4 bytes to produce the desired result 0x300 (instead of 0x0 if <code>anUChar</code> would remain 1 byte in size):</p>

<pre><code>unsigned char anUChar = 0xc0; // only the two most significant bits are set
int anInt = anUChar &lt;&lt; 2; // 0x300 (correct)
</code></pre>

<p><strong>But</strong> in this code, aimed at a 64-bit result, no automatic conversion into 8 bytes happens:</p>

<pre><code>unsigned int anUInt = 0xc0000000; // only the two most significant bits are set
long long aLongLong = anUInt &lt;&lt; 2; // 0x0 (wrong, means no conversion occurred)
</code></pre>

<p>And only placing an explicit type cast works:</p>

<pre><code>unsigned int anUInt = 0xc0000000;
long long aLongLong = (long long)anUInt &lt;&lt; 2; // 0x300000000 (correct)
</code></pre>

<p>And most importantly, <strong>would</strong> this behavior be the same in a program that targets 64-bit machines?</p>

<p>By the way, which of the two is most right and portable: <code>(type)var &lt;&lt; 1</code> or <code>((type)var) &lt;&lt; 1</code>?</p>
","922184","","<p><code>char</code> always gets promoted to <code>int</code> during arithmetic. I think this is specified behavior in the C standard.</p>

<p>However, <code>int</code> is not automatically promoted to <code>long long</code>.</p>

<p>Under <a href=""http://msdn.microsoft.com/en-us/library/ke55d167.aspx"" rel=""nofollow"">some situations</a>, some compilers (Visual Studio) will actually warn you about this if you try to left-shift a smaller integer and store it into a larger one.</p>

<blockquote>
  <p>By the way, which of the two is most right and portable: <code>(type)var &lt;&lt;
  1</code> or <code>((type)var) &lt;&lt; 1</code>?</p>
</blockquote>

<p>Both are fine and portable. Though I prefer the first one since it's shorter. Casting has higher precedence than shift.</p>
"
"<p>I have a read benchmark and between consecutive runs, I have to make sure that the data does not reside in memory to avoid effects seen due to caching. So far what I used to do is: run a program that writes a large file between consecutive runs of the read benchmark. Something like</p>

<pre><code>./read_benchmark
./write --size 64G --path /tmp/test.out
./read_benchmark
</code></pre>

<p>The write program simply writes an array of size 1G 64 times to file. Since the size of the main memory is 64G, I write a file that is approx. the same size. The problem is that writing takes a long time and I was wondering if there are better ways to do this, i.e. avoid effects seen when data is cached. </p>

<p>Also, what happens if I write data to /dev/null? </p>

<pre><code>./write --size 64G --path /dev/null
</code></pre>

<p>This way, the write program exits very fast, no I/O is actually performed, but I am not sure if it overwrites 64G of main memory, which is what I ultimately want. </p>

<p>Your input is greatly appreciated.</p>
","922184","","<p>One (crude) way that almost never fails is to simply occupy all that excess memory with another program.</p>

<p>Make a trivial program that allocates nearly all the free memory (while leaving enough for your benchmark app). Then <code>memset()</code> the memory to something to ensure that the OS will commit it to physical memory. Finally, do a <code>scanf()</code> to halt the program without terminating it.</p>

<p>By ""hogging"" all the excess memory, the OS won't be able to use it as cache. And this works in both Linux and Windows. Now you can proceed to do your I/O benchmark.</p>

<p>(Though this might not go well if you're sharing the machine with other users...)</p>
"
"<p>Suppose you have a static global variable in your header file, and you use this variable in your main.cpp.</p>

<pre><code>// header.h
static int variableOne = 100;

//main.cpp
   .
   .
   cout &lt;&lt; variableOne &lt;&lt; endl;
</code></pre>

<p>Will main.cpp get its own copy of <strong>variableOne</strong> (although the value is still 100...)? Or am I mixing this concept with extern (I know that extern tells the compiler that <strong>variableOne</strong> is defined elsewhere in the project...)</p>

<p>Thank you.</p>
","922184","","<p>In this case, each compilation module will get it's own copy of the variable.</p>

<p>If you use <code>extern</code>, there will only be one copy. But you are only allowed to initialize it in one module.</p>

<p>In other words, if you just replace <code>static</code> with <code>extern</code> in your example, it won't compile because it's being initialized in every module that includes that header.</p>
"
"<p>I am currently writing a small tool which should help me check whether my manually calculated fourier vectors are correct. Now i need the n-th Root of Unity specified by <code>omega = exp(2*pi*i / n)</code>. Can somebody explain me how to represent this <code>omega</code> as a <code>complex</code> in C++?</p>
","922184","","<p>Well, the real and imaginary parts of the twiddle factor omega is just:</p>

<pre><code>double angle = 2*pi/n;

double real = cos(angle);
double imaj = sin(angle);

complex&lt;double&gt; omega(real, imaj);
</code></pre>
"
"<p>I am looking for something which enables me to do something like a function in a function.
Here is an example to make it more obvious:</p>

<pre><code>class A{
 private: 
 int n;
 int c;
 public:
 void foo();
}
</code></pre>

<p>However foo is a function with is supposed to change c, but needs n for that. <code>foo</code> is somewhat complicated so I want to split it into different subfunctions.
Since <code>foo</code> needs <code>n</code> it is not simple doable through a friend function (without passing n (there are tons of variables in my real problem)</p>
","922184","","<p>Just put all those sub-functions inside the same class and make them private?</p>
"
"<p>I was just playing around with the Altivec extension on a power6 cluster we have.  I noticed that when I compiled the code below without any optimizations, my speedup was 4 as I was expecting.  However, when I compiled it again with the -O3 flag, I managed to obtain a speedup of 60!</p>

<p>Just wondering if anyone has more experience with this and is able to provide some insight into how the compiler is rearranging my code to perform such a speedup.  Is the only possible optimization through assembly and instruction pipelining here, or is there something else I am missing that I can include in my future work.</p>

<pre><code>int main(void) {
        const int m = 1000;

        __vector signed int va;
        __vector signed int vb;
        __vector signed int vc;
        __vector signed int vd;

        int a[m];
        int b[m];
        int c[m];

        for( int i=0 ; i &lt; m ; i++ ) {
                a[i] = i;
                b[i] = i;
                c[i] = 0;
        }

        for( int cnt = 0 ; cnt &lt; 10000000 ; cnt++ ) {
                vd = (__vector signed int){cnt,cnt,cnt,cnt};

                for( int i = 0 ; i &lt; m/4 ; i+=4 ) {
                        va = vec_ld(0, &amp;a[i]);
                        vb = vec_ld(0, &amp;b[i]);
                        vc = vec_add(vd, vec_add(va,vb));
                        vec_st(vc, 0, &amp;c[i]);
                }
        }

        std::cout &lt;&lt; c[0] &lt;&lt; "", "" &lt;&lt; c[1] &lt;&lt; "", "" &lt;&lt; c[2] &lt;&lt; "", "" &lt;&lt; c[3] &lt;&lt; ""\n"";

        return 0;
}
</code></pre>
","922184","","<p>I've done some stuff on Power 7, and I have seen very odd things with the XLC compiler. But not as odd as this! (not 60x at least...)</p>

<p>One thing to note about the PowerPC series (at least for Power6 and Power7), is that the instruction latencies are very long and the out-of-order execution is very weak compared to x86/x64.</p>

<p>Therefore, the inner loop (as written in your code) will get extremely low IPC.</p>

<p>Now, the only way I can imagine you getting 60x speedup is that the inner loop is <strong>completely unrolled under -O3</strong>. This is possible since the trip count of the inner loop can be statically determined to be 63.</p>

<p>Unrolling that inner loop will basically allow the entire pipeline to be filled.</p>

<p>Of course I'm just guessing. Your best bet is to look at the assembly.</p>

<p>Also, how are you timing this? A lot of the weird behavior I've seen on PowerPC is from the timers themselves...</p>

<p>EDIT:</p>

<p>Since your sample code is fairly simple, it should be very easy to spot (in the assembly) whether or not that inner loop is partially or completely unrolled.</p>
"
"<pre><code>#include&lt;stdio.h&gt;

int i;
int increment(int i)
{
    return ++i;
}

int main()
{
    for(i=0;i&lt;10;increment(i))
    {
        printf(""%d"",i);
    }
    return 0;
}
</code></pre>

<p>Here output is 000000.  i.e. infinite lopp occurs.</p>

<p>I want to know that is this occuring due to no-op as we have no variable to store the value of ++i (returned by increment function) or it is due to something else? .please explain.</p>
","922184","","<p>Yes, it's a no-op. The call to <code>increment</code> doesn't change anything since the value is passed by value.</p>

<p>The local definition of <code>i</code> shadows the global definition. Therefore, only the local definition of <code>i</code> is used and the global definition of <code>i</code> is not affected by the increment which is done on the local copy of the variable.</p>
"
"<p>I created simple ray tracer in Java as a hobby project, and well, it's slow. Not dramatically slow, but slow nevertheless. I wonder if I can get any performance gain using lower level language like C or C++ or will the difference be negligible and I should stick to improving ""my"" algorithm?</p>
","922184","","<p>It will depend. Using C/C++ will allow you access to things that you can't do in Java. (such as SIMD)</p>

<p>In other words, I'd say yes, it's <em>usually</em> possible do better in C/C++, but it will take some work. Do all your basic (mathematical/algorithmic) optimizations first. Then micro-optimize later.</p>
"
"<p>I keep receiving the following error and I have no idea whats wrong</p>

<pre><code>cc1plus: warnings being treated as errors
scene.cpp: In member function ‘Image* Scene::getpicture(int) const’:
scene.cpp:179: error: control reaches end of non-void function
</code></pre>

<p>Here is the part of the code that the error is in:</p>

<pre><code>Image* Scene::getpicture(int index) const {

    if(index&lt;0 || index &gt;maximum)
        cout &lt;&lt; ""invalid index"" &lt;&lt; endl;
    else {
        return images[index]; 
    }
}
</code></pre>
","922184","","<p>If the code does not enter the <code>else</code> statement, nothing gets returned. Therefore you need to insert a return either at the end or when you enter the if-statement.</p>
"
"<p>How do I determine the JVM heap size default values??</p>

<p>Note that I'm not interested in setting or modifying its initial, minimum, or maximum size before/while running my application. I just want to know what it is on a given machine if I do nothing!</p>
","922184","","<pre><code>Runtime.getRuntime().totalMemory();
</code></pre>
"
"<p>I am trying to benchmark how fast can Java do a simple task: read a huge file into memory and then perform some meaningless calculations on the data. All types of optimizations count. Whether it's rewriting the code differently or using a different JVM, tricking JIT ..</p>

<p>Input file is a 500 million long list of 32 bit integer pairs separated by a comma. Like this:</p>

<blockquote>
  <p>44439,5023<br />
  33140,22257<br />
  ...</p>
</blockquote>

<p>This file takes <strong>5.5GB</strong> on my machine. The program can't use more than <strong>8GB</strong> of RAM and can use only a <strong>single thread</strong>.</p>

<pre><code>package speedracer;

import java.io.FileInputStream;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;

public class Main
{
    public static void main(String[] args)
    {
        int[] list = new int[1000000000];

        long start1 = System.nanoTime();
        parse(list);
        long end1 = System.nanoTime();

        System.out.println(""Parsing took: "" + (end1 - start1) / 1000000000.0);

        int rs = 0;
        long start2 = System.nanoTime();

        for (int k = 0; k &lt; list.length; k++) {
            rs = calc(list[k++], list[k++], list[k++], list[k]);
        }

        long end2 = System.nanoTime();

        System.out.println(rs);
        System.out.println(""Calculations took: "" + (end2 - start2) / 1000000000.0);
    }

    public static int calc(final int a1, final int a2, final int b1, final int b2)
    {
        int c1 = (a1 + a2) ^ a2;
        int c2 = (b1 - b2) &lt;&lt; 4;

        for (int z = 0; z &lt; 100; z++) {
            c1 ^= z + c2;
        }

        return c1;
    }

    public static void parse(int[] list)
    {
        FileChannel fc = null;
        int i = 0;

        MappedByteBuffer byteBuffer;

        try {
            fc = new FileInputStream(""in.txt"").getChannel();

            long size = fc.size();
            long allocated = 0;
            long allocate = 0;

            while (size &gt; allocated) {

               if ((size - allocated) &gt; Integer.MAX_VALUE) {
                   allocate = Integer.MAX_VALUE;
               } else {
                   allocate = size - allocated;
               }

               byteBuffer = fc.map(FileChannel.MapMode.READ_ONLY, allocated, allocate);
               byteBuffer.clear();

               allocated += allocate;

               int number = 0;

               while (byteBuffer.hasRemaining()) {
                   char val = (char) byteBuffer.get();
                   if (val == '\n' || val == ',') {
                        list[i] = number;

                        number = 0;
                        i++;
                   } else {
                       number = number * 10 + (val - '0');
                   }
                }
            }

            fc.close();

        } catch (Exception e) {
            System.err.println(""Parsing error: "" + e);
        }
    }
}
</code></pre>

<p>I've tried all I could think of. Trying different readers, tried openjdk6, sunjdk6, sunjdk7. Tried different readers. Had to do some ugly parsing since MappedByteBuffer cannot map more than 2GB of memory at once. I'm running:</p>

<pre><code>   Linux AS292 2.6.38-11-generic #48-Ubuntu SMP 
   Fri Jul 29 19:02:55 UTC 2011 
   x86_64 GNU/Linux. Ubuntu 11.04. 
   CPU: is Intel(R) Core(TM) i5-2410M CPU @ 2.30GHz.
</code></pre>

<p>Currently, my results are for parsing: 26.50s, calculations: 11.27s. I'm competing against a similar C++ benchmark which does the IO in roughly the same time but the calculations take only 4.5s. My main objective is to reduce the calculation time in any means possible. Any ideas?</p>

<p><strong>Update:</strong> It seems the main speed improvement could come from what is called <a href=""http://cplusplus-soup.com/2009/02/12/auto-vectorization-and-c/"" rel=""nofollow"">Auto-Vectorization</a>. I was able to find some hints that the current Sun's JIT only does ""some vectorization"" however I can't really confirm it. It would be great to find some JVM or JIT that would have better auto-vectorization optimization support.</p>
","922184","","<p>First of all, <code>-O3</code> enables:</p>

<pre><code>-finline-functions
-ftree-vectorize
</code></pre>

<p>among others...</p>

<p>So it looks like it actually might be vectorizing.</p>

<p><strong>EDIT :
This has been been confirmed. (see comments)</strong> The C++ version is indeed being vectorized by the compiler. With vectorization disabled, the C++ version actually runs a bit slower than the Java version</p>

<p>Assuming the JIT does not vectorize the loop, <strong>it may be difficult/impossible for the Java version to match the speed of the C++ version.</strong></p>

<hr>

<p>Now, if I were a smart C/C++ compiler, here's how I would arrange that loop (on x64):</p>

<pre><code>int c1 = (a1 + a2) ^ a2;
int c2 = (b1 - b2) &lt;&lt; 4;

int tmp0 = c1;
int tmp1 = 0;
int tmp2 = 0;
int tmp3 = 0;

int z0 = 0;
int z1 = 1;
int z2 = 2;
int z3 = 3;

do{
    tmp0 ^= z0 + c2;
    tmp1 ^= z1 + c2;
    tmp2 ^= z2 + c2;
    tmp3 ^= z3 + c2;
    z0 += 4;
    z1 += 4;
    z2 += 4;
    z3 += 4;
}while (z0 &lt; 100);

tmp0 ^= tmp1;
tmp2 ^= tmp3;

tmp0 ^= tmp2;

return tmp0;
</code></pre>

<p>Note that this loop is completely vectorizable.</p>

<p>Even better, I would completely unroll this loop. These are things that a C/C++ compiler will do. But now the question, is will the JIT do it?</p>
"
"<p>I am learning C++ and I just read about dynamic arrays and how it lets you set the length of an array during runtime rather than during compile time. However, you don't need a dynamic array to do this. So what is the point of a dynamic array; when would you use it? I feel like I am missing something obvious so any insight is much appreciated. Thanks!</p>

<pre><code>// Static binding.
int size = 0;

cout &lt;&lt; ""Enter size of array:"" &lt;&lt; endl;
cin &gt;&gt; size;

int array[size];

int array_length = sizeof(array) / sizeof(int);
cout &lt;&lt; ""Number of elements in array: "" &lt;&lt; array_length &lt;&lt; endl;

// I just set the length of an array dynamically without using a dynamic array.
// So whats the point of a dynamic array then?
</code></pre>
","922184","","<p>I don't think you can do that in C++. Only C99 allows variable-length arrays.</p>

<p>Does this even compile? Were you talking about the <code>vector</code> class?</p>

<p>EDIT:</p>

<p>It does not compile in Visual Studio 2010:</p>

<pre><code>1&gt;..\main.c(207): error C2057: expected constant expression
1&gt;..\main.c(207): error C2466: cannot allocate an array of constant size 0
1&gt;..\main.c(207): error C2133: 'array' : unknown size
1&gt;..\main.c(209): error C2070: 'int []': illegal sizeof operand
</code></pre>
"
"<p>The only thing that I know about the mechanism of how C passes values is that it is done either through a register or the stack.</p>

<p>Register or Stack? Exactly how?</p>
","922184","","<p>Both. And the conventions will vary by platform.</p>

<p>On x86, values are usually passed by stack. On x64, passing by register is preferred.</p>

<p>In all cases, if you have too many parameters, some will have to be passed by stack.</p>

<p>Refer to <a href=""http://en.wikipedia.org/wiki/X86_calling_conventions"" rel=""nofollow"">x86 calling conventions</a></p>
"
"<p>When we we run this piece of code:</p>

<pre><code>char *someFun(){
    char *temp = ""string constant"";
    return temp;
}
int main(){
    puts(someFun());
}
</code></pre>

<p>it works normally and prints <code>""string constant""</code> on the screen.</p>

<p>But when we run the similar code as shown below:</p>

<pre><code>char *someFun1(){
    char temp[ ] = ""string"";
    return temp;
}
int main(){
    puts(someFun1());
}
</code></pre>

<p>it won't work and print some garbage on screen.</p>

<p>What is the reason behind it? Essentially both functions do similar things (i.e. return a ""string""), but still they behave differently. Why is that?</p>
","922184","","<p>In the first case, the pointer <code>temp</code> will point to a global constant storing <code>""string constant""</code>. Therefore, when you return the pointer, it's valid.</p>

<p>In the second case, '""string""' is just a char array on the stack - which dies after you return from the function.</p>
"
"<p>We know that
   sin(x)=x-x^3/3!+x^5/5!-x^7/7!+x^9/9! and so on. I have written this code:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;math.h&gt;
using namespace std;

const int m=19;

int factorial(int n) {

    if (n==0){ return 1;}
    return n*factorial(n-1);
}

int main() {
   float x;
   cin &gt;&gt; x;

   float sum=0;
   int k=1;
   for (int i=1;i&lt;=m;i+=2) {
      sum+=(k*(powf(x,i)/factorial(i)));
      k=k*(-1);
   }

   cout&lt;&lt;""series sum is equal :""&lt;&lt;sum&lt;&lt;endl;
   return 0;
}
</code></pre>

<p>One problem is that when I enter x=3 it gives me -10.9136, but I know that values range of sin(x) is [-1, 1] what is problem? Please help me.</p>
","922184","","<p>The problem is that you're running out of precision due to destructive cancellation.</p>

<p>You have an alternating series where some of the terms get very large. But those terms cancel each other out to a small result. Since <code>float</code> has limited precision, your round off error is larger than your final value.</p>

<p>You can ""reduce"" the problem by using double-precision. But it won't go away. Standard implementations of <code>sin/cos</code> involve taking the modulo of the argument by <code>2 pi</code> to make it small.</p>

<p><strong>EDIT :</strong></p>

<p><strong>I found the other problem.</strong> You have an integer overflow in your factorial function when <code>i = 19</code>.</p>
"
"<p>I am trying to generate Fibonacci series and provided the code for the same below. When I run this code for smaller values, it outputs correct results. However, when I try and calculate series for a number say '50', it out puts correct results upto the 47th number and result for 48,49 and 50th term are incorrect. I tried using unsigned long int as well but it did not correct the results. Can some please suggest what am I doing wrong here. 
Thanks.  </p>

<pre><code>#include&lt;stdio.h&gt;
unsigned long long int fibr(unsigned long long int);

int main(){
    unsigned long long  int n;
    printf(""Enter a number\n"");
    scanf(""%llu"",&amp;n);
    //res=fibr(n);
      while(n&gt;=0){
          printf(""%llu\n"",fibr(n));
          n--;
           }
     }
unsigned long long int fibr(unsigned long long int n){
     if((n==0)||(n==1))
         return n;
     else return fibr(n-1)+fibr(n-2);
     }
</code></pre>

<p>'After the suggestions , I incorporated unsigned long long int. Have modified the code above but now it gives a seg fault. Any hints please. I am not allowed to use any other library except the standards one available. '</p>
","922184","","<p>Here's the answer to your second question:</p>

<p>I think you had this problem from the beginning:</p>

<pre><code>while(n&gt;=0){
</code></pre>

<p>is an infinite loop since <code>n</code> is an unsigned integer. <code>n</code> will go negative due to the decrement. But since it's unsigned, it will wrap around and cause a stack-overflow in your recursion.</p>

<p>Also, your algorithm is probably slowest way to do this. It runs in exponential time. So it will take a very long time to run it when <code>n</code> is big.</p>

<p>A better way is just this:</p>

<pre><code>int n = 48;
return (unsigned long long)(pow(1.6180339887498948,n) * 0.44721359549995794 + 0.5);
</code></pre>

<p>This method will run in constant time. :)</p>
"
"<p>There is such code:</p>

<pre><code>#include &lt;iostream&gt;

class A{
    int a;
    int fun(){}
};

class B{
    int a;
    virtual int fun(){}
};

int main()
{
    std::cout &lt;&lt; sizeof(A) &lt;&lt; "" "" &lt;&lt; sizeof(B) &lt;&lt; std::endl;
    std::cin.get();
    return 0;
}
</code></pre>

<p>The output is:</p>

<pre><code>4 8
</code></pre>

<p>Why class B is 4 bytes bigger than class A?</p>
","922184","","<p>Any class with a virtual function needs a pointer to the vtable for that class. Therefore, there is a hidden member that's the size of the pointer.</p>

<p><a href=""http://en.wikipedia.org/wiki/Virtual_method_table"">http://en.wikipedia.org/wiki/Virtual_method_table</a></p>
"
"<p>Currently, I have all my objects managing their own memory, allocating with <code>new</code> in their constructors typically, and using <code>delete</code> in their destructors.  This works for now, but the number of classes I have that use arbitrary amounts of memory is growing.  The fact that <code>new</code> is essentially a ""request"" also bothers me, since these objects have no code within them to handle being told ""no"", and I don't want to rely on Exception Handling if I do not need to.  </p>

<ul>
<li><p>Is it beneficial in terms of performance to completely
shield all calls that allocate memory, to a single class that handles
every memory allocation on the heap, probably allocating large chunks
at a time and using placement new to deal out references?</p></li>
<li><p>Is the use of memory allocation in smaller classes a big enough concern to even bother with this?</p></li>
<li><p>Can I still use STL containers and force them to use the heap I
provide?</p></li>
</ul>

<p>Thank you in advance!</p>
","922184","","<p>I've done this before, and here's my experience:</p>

<ol>
<li><strong>It can get very messy very quickly.</strong> Especially since you now take memory allocation into your hands and you have to deal with stuff like fragmentation and re-entrancy.</li>
<li>However, I've seen performance boosts <strong>upwards of 20%</strong> due to being able to bypass the OS overheads.</li>
</ol>

<p>For your last question, I think there is a way to make them use a custom allocator, but I've never done it before. I do most of my coding in C.</p>

<p>EDIT:</p>

<p>Based on your comment, here's an update. You don't really have to deal with building an allocator. You can probably get away with just pointing all memory allocations to your custom class. Then your custom class will call <code>malloc()</code> or <code>new</code> and catch whatever NULL or exception is returned.</p>

<p>(Though it will take some work replacing every single <code>new</code> with your own <code>malloc()</code>.)</p>
"
"<p>I have two classes, one of which inherits the other:</p>

<pre><code>class baseClass
{
public:
    virtual void show();
};

void baseClass::show(){cout &lt;&lt; ""Base class"" &lt;&lt; endl;}


class derivedClass
{
public:
    void show();
};

void derivedClass::show(){cout &lt;&lt; ""Derived class"" &lt;&lt; endl;}
</code></pre>

<p>If I make a derivedClass object and called the show function, it correctly prints ""Derived class"". If I do the following:</p>

<pre><code>derivedClass b;
baseClass* b;
b=&amp;d;
b-&gt;show();
</code></pre>

<p>It again correctly prints out ""Derived class"".
However, if I make a list like so:</p>

<pre><code>list&lt;baseClass&gt; t;
list&lt;baseClass&gt;::iterator it;
baseClass b;
derivedClass d;
t.push_back(b);
t.push_back(d);
</code></pre>

<p>And try to call show on each item:</p>

<pre><code>it = t.begin();
it-&gt;show();
it++;
it-&gt;show();
</code></pre>

<p>The output for both b and d is ""Base class"".
My question is: why is it only using the baseClass version of show(), and how can I make it properly use the derived version for objects of derivedClass in the list?</p>

<p>Thanks in advance</p>
","922184","","<p>You have to declare the method <code>show()</code> as <code>virtual</code> to make polymorphism work:</p>

<pre><code>class baseClass
{
public:
    virtual void show();
};

void baseClass::show(){cout &lt;&lt; ""Base class"" &lt;&lt; endl;}


class derivedClass : public baseClass
{
public:
    virtual void show();
};

void derivedClass::show(){cout &lt;&lt; ""Derived class"" &lt;&lt; endl;}
</code></pre>

<p>You were also missing <code>class derivedClass : public baseClass</code>.</p>

<p>And the final problem. You need to use pointers.</p>

<pre><code>list&lt;baseClass*&gt; t;
list&lt;baseClass*&gt;::iterator it;
baseClass b;
derivedClass d;
t.push_back(&amp;b);
t.push_back(&amp;d);
</code></pre>

<p>and change to this:</p>

<pre><code>it = t.begin();
(*it)-&gt;show();
it++;
(*it)-&gt;show();
</code></pre>
"
"<p>The other day, the Wolfram Blog published an <a href=""http://blog.wolfram.com/2011/09/15/from-pi-to-puzzles/"" rel=""nofollow"">article</a> about a thirteen year old boy, Neil Bickford, who computed the first 458 million terms of the simple continued fraction representation of pi, beginning with <code>[3; 7, 15, 1, 292, ...]</code>. Bickford described his accomplishment <a href=""http://nbickford.wordpress.com/2010/10/22/pi/"" rel=""nofollow"">on his blog</a>, and even quoted <a href=""http://neilbickford.com/picf.htm"" rel=""nofollow"">Bill Gosper's algorithm</a>, but I haven't been able to work out the algorithm.</p>

<p>One thing I do know is how to convert the decimal representation of pi to a continued fraction, using the method given at the <a href=""http://en.wikipedia.org/wiki/Continued_fraction#Continued_fraction_expansions_of_.CF.80"" rel=""nofollow"">Wikipedia article</a> on continued fractions. But that requires a decimal representation of pi to a sufficient number of places, and certainly Bickford didn't have millions of digits of pi backing his calculation.</p>

<p>Can someone please explain -- in considerable detail -- the algorithm Bickford used to make his calculation?</p>
","922184","","<p>Actually he DID have millions of digits of Pi to start with. He probably used either Mathematica or another pi-program to get the initial digits.</p>

<p>Here's the link to his previous record:</p>

<p><a href=""http://neilbickford.com/picf.htm"" rel=""nofollow"">http://neilbickford.com/picf.htm</a></p>

<p>In this one, he said he used a program called <a href=""http://www.numberworld.org/misc_runs/pi-5t/details.html#program"" rel=""nofollow"">y-cruncher</a> to compute 500 million digits of Pi to start with.</p>

<p>EDIT:</p>

<p>As far as explaining exactly how the algorithm works: I'm not familiar with it myself. It's probably too localized for anyone on SO to be able to answer that.</p>
"
"<p>Ok, this might sound like a strange question but it is an interesting one. I am coding for iOS and have been told that it is always best to multiply rather than divide values as it is faster.</p>

<p>I know that processors these days probably make this a non issue but my curiosity has gotten the better of me and I am wondering if anyone might be able to shed some light on this for me.</p>

<p>SO..... My question is this - <br>
is:</p>

<pre><code>player.position = ccp(player.contentSize.width / 2, winSize.height / 2);
</code></pre>

<p>slower than:</p>

<pre><code>player.position = ccp(player.contentSize.width * 0.5, winSize.height * 0.5);
</code></pre>
","922184","","<p>Yes, division is usually <strong><em>much</em></strong> slower than multiplication.</p>

<p>However, when dividing by literals (or anything that can be determined to be a constant at compile-time), the compiler will usually optimize out the division.</p>
"
"<p>How can I convert a char to Int?</p>

<p>This is what I have done so far.</p>

<p>Thanks</p>

<pre><code>scanf(""%s"", str );

printf(""str: %s\n"", str);

int i;
if(isdigit(*str))
    i = (int) str;
else {
    i = 3;
}
</code></pre>

<p>test case</p>

<pre><code>7
str: 7
i: 1606415584  
</code></pre>
","922184","","<p>If you want to parse an integer from a string:</p>

<pre><code>i = atoi(str);
</code></pre>
"
"<p>Here is my program:</p>

<pre><code>#include &lt;stdio.h&gt;
int main()
{
    int a=0x09;
    int b=0x10;
    unsigned long long c=0x123456;
    printf(""%x %llx\n"",a,b,c);//in ""%llx"", l is lowercase of 'L', not digit 1
    return 0;
}
</code></pre>

<p>the output was:</p>

<pre><code>9 12345600000010
</code></pre>

<p>I want to know:</p>

<ol>
<li>how function printf() is executed? </li>
<li>what will happen if the number of arguments isn't equal to that of formats?</li>
</ol>

<p>please help me and use this program as an example to make an explanation.</p>
","922184","","<p>The problem is that your types don't match. This is undefined behavior.</p>

<p>Your second argument <code>b</code> does not match the type of the format. So what's happening is that <code>printf()</code> is reading past the 4 bytes holding b (<code>printf</code> is expecting an 8-byte operand, but <code>b</code> is only 4 bytes). Therefore you're getting junk. The 3rd argument isn't printed at all since your <code>printf()</code> only has 2 format codes.</p>

<p>Since the arguments are usually passed consecutively (and adjacent) in memory, the 4 extra bytes that <code>printf()</code> is reading are actually the lower 4 bytes of <code>c</code>.</p>

<p>So in the end, the second number that's being printed is equal to <code>b + ((c &amp; 0xffffffff) &lt;&lt; 32)</code>.</p>

<p>But I want to reiterate: <strong><em>this behavior is undefined</em></strong>. It's just that most systems today behave like this.</p>
"
"<p>Say I have some functions, each of about two simple lines of code, and they call each other like this: <code>A</code> calls <code>B</code> calls <code>C</code> calls <code>D</code> ... calls <code>K</code>. (So basically it's a long series of short function calls.) How deep will compilers usually go in the call tree to inline these functions?</p>
","922184","","<p>I've seen compilers inline more than 5 functions deep. But at some point, it basically becomes a space-efficiency trade-off that the compiler makes. Every compiler is different in this aspect. Visual Studio is very conservative with inlining. GCC (under -O3) and the Intel Compiler love to inline...</p>
"
"<p>I am testing my new image file format, which without going into unnecessary detail consists of the PPM RGB 24-bit per pixel format sent through zlib's compression stream, and an 8 byte header appended to the front. </p>

<p>While I was writing up tests to evaluate the performance of the corresponding code which implements this I had one test case which produced pretty terrible results. </p>

<pre><code>unsigned char *image = new unsigned char[3000*3000*3];
for(int i=0;i&lt;3000*3000;++i) {
    image[i*3] = i%255;
    image[i*3+1] = (i/2)%255;
    image[i*3+2] = (i*i*i)%255;
}
</code></pre>

<p>Now what I'm doing here is creating a 3000x3000 fully packed 3 byte per pixel image, which has red and green stripes increasing steadily, but the blue component is going to be varying quite a bit. </p>

<p>When I compressed this using the zlib stream for my <code>.ppmz</code> format, it was able to reduce the size from 27,000,049 bytes (the reason it is not an even 27 million is 49 bytes are in the headers) to 25,545,520 bytes. This compressed file is 94.6% the original size. </p>

<p>This got me rather flustered at first because I figured that even if the blue component was so chaotic it couldn't be helped much, at least the red and green components repeated themselves quite a bit. A smart enough compressor ought to be able to shrink to about 1/3 the size... </p>

<p>To test that, I took the original 27MB uncompressed file and RAR'd it, and it came out to 8,535,878 bytes. This is quite good, at 31.6%, even better than one-third! </p>

<p>Then I realized I made a mistake defining my test image. I was using mod 255 when I should be clamping to 255, which is mod 256: </p>

<pre><code>unsigned char *image = new unsigned char[3000*3000*3];
for(int i=0;i&lt;3000*3000;++i) {
    image[i*3] = i%256;
    image[i*3+1] = (i/2)%256;
    image[i*3+2] = (i*i*i)%256;
}
</code></pre>

<p>The thing is, there is now just one more value that my pixels can take, which I was skipping previously. But when I ran my code again, the <code>ppmz</code> became a measly 145797 byte file. WinRAR squeezed it into 62K. </p>

<p>Why would this tiny change account for this massive difference? Even mighty WinRAR couldn't get the original file under 8MB. What is it about repeating values every 256 steps that doing so every 255 steps completely changes? I get that with the <code>%255</code> it makes the first two color components' patterns slightly out of phase, but behavior is hardly random. And then there's just crazy modular arithmetic being dumped into the last channel. But I don't see how it could account for such a huge gap in performance. </p>

<p>I wonder if this is more of a math question than a programming question, but I really don't see how the original data could contain any more entropy than my newly modified data. I think the power of 2 dependence indicates something related to the algorithms.</p>

<p>Update: I've done another test: I switched the third line back to <code>(i*i*i)%255</code> but left the others at <code>%256</code>. <code>ppmz</code> compression ratio rose a tiny bit to 94.65% and RAR yielded a 30.9% ratio. So it appears as though they can handle the linearly increasing sequences just fine, even when they are out of sync, but there is something quite strange going on where arithmetic mod 2^8 is a hell of a lot more friendly to our compression algorithms than other values.</p>
","922184","","<p>Well, first of all, computers like powers of two. :)</p>

<p>Most of such compression algorithms use compression blocks that are typically aligned to large powers of two. When your cycle aligns perfectly with these blocks, there is only one ""unique sequence"" to compress. If your data is not aligned, your sequence will shift a little across each block and the algorithm may not be able to recognize it as one ""sequence"".</p>

<p>EDIT: (updated from comments)</p>

<p>The second reason is that there's an integer overflow on <code>i*i*i</code>. The result is a double modulus: one over <code>2^32</code> and then one over <code>255</code>. This double modulus greatly increases the length of the cycle making it close to random and difficult for the compression algorithm to find the ""pattern"".</p>
"
"<p>When viewing the assembly output of the following code (no optimizations, -O2 and -O3 produce very similar results):</p>

<pre><code>int main(int argc, char **argv)
{
    volatile float f1 = 1.0f;
    volatile float f2 = 2.0f;

    if(f1 &gt; f2)
    {
        puts(""+"");
    }
    else if(f1 &lt; f2)
    {
        puts(""-"");
    }

    return 0;
}
</code></pre>

<p>GCC does something that I have a hard time following:</p>

<pre><code>.LC2:
    .string ""+""
.LC3:
    .string ""-""
    .text
.globl main
    .type   main, @function
main:
.LFB2:
    pushq   %rbp
.LCFI0:
    movq    %rsp, %rbp
.LCFI1:
    subq    $32, %rsp
.LCFI2:
    movl    %edi, -20(%rbp)
    movq    %rsi, -32(%rbp)
    movl    $0x3f800000, %eax
    movl    %eax, -4(%rbp)
    movl    $0x40000000, %eax
    movl    %eax, -8(%rbp)
    movss   -4(%rbp), %xmm1
    movss   -8(%rbp), %xmm0
    ucomiss %xmm0, %xmm1
    jbe .L9
.L7:
    movl    $.LC2, %edi
    call    puts
    jmp .L4
.L9:
    movss   -4(%rbp), %xmm1
    movss   -8(%rbp), %xmm0
    ucomiss %xmm1, %xmm0
    jbe .L4
.L8:
    movl    $.LC3, %edi
    call    puts
.L4:
    movl    $0, %eax
    leave
    ret
</code></pre>

<p>Why does GCC move the the float values into xmm0 and xmm1 twice and also run ucomiss twice?</p>

<p>Wouldn't it be faster to do the following?</p>

<pre><code>.LC2:
    .string ""+""
.LC3:
    .string ""-""
    .text
.globl main
    .type   main, @function
main:
.LFB2:
    pushq   %rbp
.LCFI0:
    movq    %rsp, %rbp
.LCFI1:
    subq    $32, %rsp
.LCFI2:
    movl    %edi, -20(%rbp)
    movq    %rsi, -32(%rbp)
    movl    $0x3f800000, %eax
    movl    %eax, -4(%rbp)
    movl    $0x40000000, %eax
    movl    %eax, -8(%rbp)
    movss   -4(%rbp), %xmm1
    movss   -8(%rbp), %xmm0
    ucomiss %xmm0, %xmm1
    jb  .L8 # jump if less than
    je  .L4 # jump if equal
.L7:
    movl    $.LC2, %edi
    call    puts
    jmp .L4
.L8:
    movl    $.LC3, %edi
    call    puts
.L4:
    movl    $0, %eax
    leave
    ret
</code></pre>

<p>I'm not at all a real assembly programmer, but it just seemed odd to me to have duplicate instructions running. Is there a problem with my version of the code?</p>

<hr>

<p><strong>Update</strong></p>

<p>If you remove the volatile which I had originally and replace it with scanf(), you get the same results:</p>

<pre><code>int main(int argc, char **argv)
{
    float f1;
    float f2;

    scanf(""%f"", &amp;f1);
    scanf(""%f"", &amp;f2);

    if(f1 &gt; f2)
    {
        puts(""+"");
    }
    else if(f1 &lt; f2)
    {
        puts(""-"");
    }

    return 0;
}
</code></pre>

<p>And the corresponding assembler:</p>

<pre><code>.LCFI2:
    movl    %edi, -20(%rbp)
    movq    %rsi, -32(%rbp)
    leaq    -4(%rbp), %rsi
    movl    $.LC0, %edi
    movl    $0, %eax
    call    scanf
    leaq    -8(%rbp), %rsi
    movl    $.LC0, %edi
    movl    $0, %eax
    call    scanf
    movss   -4(%rbp), %xmm1
    movss   -8(%rbp), %xmm0
    ucomiss %xmm0, %xmm1
    jbe .L9
.L7:
    movl    $.LC1, %edi
    call    puts
    jmp .L4
.L9:
    movss   -4(%rbp), %xmm1
    movss   -8(%rbp), %xmm0
    ucomiss %xmm1, %xmm0
    jbe .L4
.L8:
    movl    $.LC2, %edi
    call    puts
.L4:
    movl    $0, %eax
    leave
    ret
</code></pre>

<hr>

<p><strong>Final Update</strong></p>

<p>After reviewing some of the follow up comments, it seems han (who commented under Jonathan Leffler's post) nailed this problem. GCC does not make the optimization not because it can't but because I hadn't told it to. It seems it all comes down to IEEE floating point rules and to handle the strict conditions GCC can't simply do a jump if above or jump if below after the first UCOMISS, because it needs to handle all the special conditions of floating point numbers. When using han's recommendation of the -ffast-math optimizer (none of the -Ox flags enable -ffast-math as it can break some programs) GCC does exactly what I was looking for:</p>

<p>The following assembly was produced using GCC 4.3.2 ""gcc -S -O3 -ffast-math test.c""</p>

<pre><code>.LC0:
    .string ""%f""
.LC1:
    .string ""+""
.LC2:
    .string ""-""
    .text
    .p2align 4,,15
.globl main
    .type   main, @function
main:
.LFB25:
    subq    $24, %rsp
.LCFI0:
    movl    $.LC0, %edi
    xorl    %eax, %eax
    leaq    20(%rsp), %rsi
    call    scanf
    leaq    16(%rsp), %rsi
    xorl    %eax, %eax
    movl    $.LC0, %edi
    call    scanf
    movss   20(%rsp), %xmm0
    comiss  16(%rsp), %xmm0
    ja  .L11
    jb  .L12
    xorl    %eax, %eax
    addq    $24, %rsp
    .p2align 4,,1
    .p2align 3
    ret
    .p2align 4,,10
    .p2align 3
.L12:
    movl    $.LC2, %edi
    call    puts
    xorl    %eax, %eax
    addq    $24, %rsp
    ret
    .p2align 4,,10
    .p2align 3
.L11:
    movl    $.LC1, %edi
    call    puts
    xorl    %eax, %eax
    addq    $24, %rsp
    ret
</code></pre>

<p>Notice the two UCOMISS instructions are now replaced with one COMISS directly followed by a JA (jump if above) and JB (jump if below). GCC is able to nail this optimization if you let it using -ffast-math!</p>

<p>UCOMISS vs COMISS (http://www.softeng.rl.ac.uk/st/archive/SoftEng/SESP/html/SoftwareTools/vtune/users_guide/mergedProjects/analyzer_ec/mergedProjects/reference_olh/mergedProjects/instructions/instruct32_hh/vc315.htm): ""The UCOMISS instruction differs from the COMISS instruction in that it signals an invalid SIMD floating-point exception only when a source operand is an SNaN. The COMISS instruction signals invalid if a source operand is either a QNaN or an SNaN.""</p>

<p>Thanks again everyone for the helpful discussion.</p>
","922184","","<p><strike>Here's another reason:
If you take a close look at it, it's NOT the same expression.</strike></p>

<p><strike>They are not complements of each other. Therefore, you have to do two comparisons anyway.</strike> <code>volatile</code> will force the values to be reloaded.</p>

<p>EDIT: (see comments, I forgot you can do that with the flags)</p>

<p>To answer the new question:</p>

<p>Combining the those two <code>ucomiss</code> is not a completely obvious optimization from the compiler's perspective.</p>

<p>In order to combine them, the compiler must:</p>

<ol>
<li>Recognize that <code>ucomiss %xmm0, %xmm1</code> is the ""same"" as <code>ucomiss %xmm1, %xmm0</code>.</li>
<li>Then it must do a common sub-expression elimination pass to pull it out.</li>
</ol>

<p>All of this needs to be done <em>after</em> the compiler does instruction selection. And most of the optimization passes are done before instruction selection.</p>

<p>What worries me more is why <code>f1</code> and <code>f2</code> aren't being kept in registers after you got rid of the <code>volatiles</code>. <code>-O3</code> is really giving you this?</p>
"
"<p>I would like to generate a text file containing all <a href=""http://en.wikipedia.org/wiki/Tic-tac-toe"" rel=""nofollow"">19,683</a> Tic-Tac-Toe board layouts in the structure of 0 = Blank, 1 = X, and 2 = O.  Unfortunately math is not my strong suit and I cannot seem to find any examples of this anywhere.</p>

<p>This isn't for homework I assure you.  I intend to run this data through a Minimax calculator in order to generate an image that contains RGB values representing the optimal move based on the board setup.  I am developing Tic-Tac-Toe for a platform that does not support functions (it's event-driven) so I will convert the board to a number in my game and then lookup the RGB of a pixel in an image which indicates what the best move is.  It's a cheeky workaround, but one that requires no more RAM than an 145x145 pixel image (145x145 = 21,025 so each pixel represents the recommended move based on the board effectively).  This also means I won't have to chew CPU time which is another plus.</p>
","922184","","<p>Since you want board layouts, there's only a small number of them (19683).</p>

<p>You can just brute-force generate all of these. Each box only has 3 possibilities. And there are 9 boxes, just run through all of them.</p>

<p>EDIT:</p>

<pre><code>int c = 0;
while (c &lt; 262144){
    bool valid = (c &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt;  2) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt;  4) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt;  6) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt;  8) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt; 10) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt; 12) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt; 14) &amp; 3) &lt; 3;
    valid &amp;= ((c &gt;&gt; 16) &amp; 3) &lt; 3;

    if (valid){
        int i = c;
        int j = 0;
        while (j &lt; 9){
            cout &lt;&lt; (i &amp; 3) &lt;&lt; "" "";
            i &gt;&gt;= 2;
            j++;
        }
        cout &lt;&lt; endl;
    }

    c++;
}
</code></pre>

<p>This will print out all 19,683 board layouts. I'm not sure what format you want, but it should be fairly easy to extract that from the output.</p>
"
"<p>can anyone explain the strage output of the program I know that the value has nothing to do with the value stored in the array but with the pointer thing but how is the second value coming to be 5:</p>

<pre><code>int main()
{
    int **h;
    int a[2][2]={1,2,3,4};
    h=(int **)a;
    int i,j;
    printf(""%d"",*h);
    (*h)++;
    printf(""\n%d"",*h);

    getch();
    return 0;
}
</code></pre>
","922184","","<p>What's happening is that <code>*h</code> is of type <code>int*</code> which is a pointer. </p>

<p>When you increment it will actually increment by 4 rather than 1. Therefore the number you print out in the end is <code>1 + 4 = 5</code>.</p>

<p>Here's your code with more prints:</p>

<pre><code>  int **h; 
  int a[2][2]={1,2,3,4}; 
  h=(int **)a; 

  cout &lt;&lt; h[0] &lt;&lt; endl;
  cout &lt;&lt; h[1] &lt;&lt; endl;
  cout &lt;&lt; h[2] &lt;&lt; endl;
  cout &lt;&lt; h[3] &lt;&lt; endl;

  int i,j; 
  printf(""%d"",*h); 
  (*h)++; 
  printf(""\n%d"",*h); 

  cout &lt;&lt; endl;
  cout &lt;&lt; h[0] &lt;&lt; endl;
  cout &lt;&lt; h[1] &lt;&lt; endl;
  cout &lt;&lt; h[2] &lt;&lt; endl;
  cout &lt;&lt; h[3] &lt;&lt; endl;
</code></pre>

<p>The output is:</p>

<pre><code>00000001
00000002
00000003
00000004
1
5
00000005
00000002
00000003
00000004
</code></pre>

<p>So you can see the first value, being incremented by 4. Because 4 is the size of the pointer when compiled for 32-bit.</p>
"
"<p>Given an array of unsinged integers(4 octets each), what's the optimal way of finding first element with atleast one '0' bit and it's index from LSB.</p>

<p>e.g: where n = 9</p>

<pre><code>unsinged int uIntArray[] = {
    0xffffffff,
    0xffffffff,
    0xffffffff,
    0xffffffff,
    0xffffff9f,
    0x00000000,
    0x00000000,
    0x00000000,
    0x00000000,
};
</code></pre>

<p>Ans: </p>

<pre><code>element's index = 4
bit's index = 4
</code></pre>

<p>I could only think of :</p>

<pre><code>int main (void)
{
    bool found_f = false;
    int n = 9;  //our test case value
    unsigned int uIntArray[] = {
        0xffffffff,
        0xffffffff,
        0xffffffff,
        0xffffffff,
        0xffffff8f,
        0x00000000,
        0x00000000,
        0x00000000,
        0x00000000,
    };  

    unsigned int uIntBits [32] = {
        1, 2, 4, 8, 16, 32, 64, 128,
            256, 512, 1024, 2048, 4096, 8192, 16384, 32768,
            65536, 131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608,
            16777216, 33554432, 67108864, 134217728, 268435456, 536870912, 1073741824, 2147483648
    };      

    unsigned int idx, jdx;
    int ele_idx = -1; 
    int bit_idx = -1;

    for (idx =0; idx &lt; n; idx ++) {
        if (uIntArray[idx] &lt; UINT_MAX) { /* our candidate */
            for (jdx =0; jdx &lt; 32; jdx ++)  {
                if ((uIntBits[jdx] &amp; uIntArray[idx])) {
                    ele_idx = idx; 
                    bit_idx = jdx;
                    found_f = true;
                    break;
                }   
            }   
        }   
        if(found_f) {
            break;
        }   
    }   
    fprintf (stderr, ""\nEleIdx[%d] BitIdx[%d]\n"", ele_idx, bit_idx);
    return 0;
}   
</code></pre>

<p>is there any better way to do it?</p>
","922184","","<p>You can make it faster by using larger datatypes. So instead of testing if each <code>int</code> is <code>0xffffffff</code>, you can go with 64-bit integers and test against <code>0xffffffffffffffff</code>.</p>

<p>If you're willing to vectorize, you can do 128-bits (SSE) or 256-bits (AVX) at a time.</p>

<p>In all cases, watch your data alignment. If you don't align, it either won't work, or will make it slower.</p>

<p>To take it one final step, you can actually unroll the loop and test multiple words/vectors at a time. This will give you better IPC. Only when you find any zero do you go through the mess of narrowing down which bit it is.</p>

<p>EDIT:</p>

<p>To illustrate this last point, you can do this: (I've omitted the cleanup code in case <code>idx % 4 != 0</code>)</p>

<pre><code>for (idx =0; idx &lt; n; idx += 4) {
    unsigned int test = uIntArray[idx];
    test &amp;= uIntArray[idx + 1];
    test &amp;= uIntArray[idx + 2];
    test &amp;= uIntArray[idx + 3];

    if (test &lt; UINT_MAX){
        //  Find which bit it is.

    }
}
</code></pre>

<p>Except you can do it on larger datatypes. (like SSE/AVX vectors)</p>

<p>This will make finding the region of the first 0 much faster, but narrowing on the exact bit will be a bit more expensive. So this approach is better if your datasize is large.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/88/is-gettimeofday-guaranteed-to-be-of-microsecond-resolution"">Is gettimeofday() guaranteed to be of microsecond resolution?</a>  </p>
</blockquote>



<p>So I find myself porting a game that was originally written for the Win32 API to Linux (well, porting the OS X port of the Win32 port to Linux), and have implemented QueryPerformanceCounter by giving the uSeconds since the process start up:    </p>

<pre><code>BOOL QueryPerformanceCounter(LARGE_INTEGER* performanceCount)
{
    gettimeofday(&amp;currentTimeVal, NULL);
    performanceCount-&gt;QuadPart = (currentTimeVal.tv_sec - startTimeVal.tv_sec);
    performanceCount-&gt;QuadPart *= (1000 * 1000);
    performanceCount-&gt;QuadPart += (currentTimeVal.tv_usec - startTimeVal.tv_usec);

    return true;
}
</code></pre>

<p>This, coupled with <code>QueryPerformanceFrequency()</code> giving a constant <code>1000000</code> as the frequency works well <b>on my machine</b>, giving me a 64 bit variable that contains uSeconds since the program's start up. So <em>is this portable?</em> I don't want to discover it works differently if the kernel was compiled in a certain way or anything like that. I am fine with it being non-portable to something other than Linux, however.</p>
","922184","","<p>There's two different terms here. Precision vs. Accuracy. If you mean ""resolution"" to be precision, then you're fine.</p>

<p>Precision means how precise the result is. ie. How many digits do you get.
Accuracy means how close to the true result is.</p>

<p>So while <code>gettimeofday()</code> is always <em>precise</em> to the millisecond, it may not always be <em>accurate</em> to the millisecond.</p>

<p>EDIT:</p>

<p>I would not count on <code>gettimeofday()</code> being as anywhere near as accurate as <code>QueryPerformanceCounter()</code>. If this matters, you may want to consider using the processor <code>rdtsc</code> clock.</p>
"
"<p>I've written a timer class. After starting the timer, I would like to know if 20 seconds has been passed or not, if it is, I would like to call a function or perform a block of code. That class doesn't work but I Don't know why .</p>

<p>EDIT:  By it doesn't work I mean that isTimeTout(seconds) always return true; I would like just to see if few seconds has been passed, and based on that do an action. 
    class timer {
        private:
            unsigned long begTime;
        public:
            void start() {
                begTime = clock();
            }</p>

<pre><code>        unsigned long elapsedTime() {
            return ((unsigned long) clock() - begTime) / CLOCKS_PER_SEC;
        }

        bool isTimeout(unsigned long seconds) {
            return seconds &gt;= elapsedTime();
        }
};
</code></pre>
","922184","","<p>Since you're on Windows, you can stick with using <code>clock()</code>.</p>

<p>The error is here:</p>

<pre><code>return seconds &gt;= elapsedTime();
</code></pre>

<p>it should be:</p>

<pre><code>return seconds &lt;= elapsedTime();
</code></pre>

<p>What you have right now will return <code>true</code> when <strong><em>less than</em></strong> 20 seconds has elapsed. Flipping the comparison should fix it.</p>
"
"<p>I'm using something like this to count how long does it takes my program from start to finish:</p>

<pre><code>int main(){
    clock_t startClock = clock();
    .... // many codes
    clock_t endClock = clock();
    printf(""%ld"", (endClock - startClock) / CLOCKS_PER_SEC);
}
</code></pre>

<p>And my question is, since there are multiple process running at the same time, say if for x amount of time my process is in <strong>idle</strong>, durning that time will clock tick within my program?</p>

<p>So basically my concern is, say there's 1000 clock cycle passed by, but my process only uses 500 of them, will I get 500 or 1000 from <code>(endClock - startClock)</code>?</p>

<p>Thanks.</p>
","922184","","<p>This depends on the OS. On Windows, <code>clock()</code> measures wall-time. On Linux/Posix, it measures the combined CPU time of all the threads.</p>

<p>If you want wall-time on Linux, you should use <code>gettimeofday()</code>.</p>

<p>If you want CPU-time on Windows, you should use <code>GetProcessTimes()</code>.</p>

<p>EDIT:</p>

<p>So if you're on Windows, <code>clock()</code> <strong><em>will</em></strong> measure idle time.</p>

<p>On Linux, <code>clock()</code> <strong><em>will not</em></strong> measure idle time.</p>
"
"<p>I'm writing a program in gcc that has asm language for performance-critical sections, and I want to ensure at run-time the program is running on the correct architecture.  In particular, I need to differentiate ia64 (Itanium) and x86_64 on Linux.</p>

<p>Do I just read /proc/cpuinfo?  Seems clunky, but I can't find an appropriate kernel call.</p>
","922184","","<p>The answer is already posted, but I'll add this:</p>

<p>If the machine is x86 or x64, you can get more detailed information through the <code>cpuid</code> instruction.</p>

<p><a href=""http://en.wikipedia.org/wiki/CPUID"" rel=""nofollow"">http://en.wikipedia.org/wiki/CPUID</a></p>
"
"<p>I wrote something to simulate the getopt.h library for a Windows application, and part of this is a global variable.  This worked fine when I compiled the program as a single application; however, when I split off the getopt library and linked against it, my program started getting segfaults. Investigating this, it seems that accessing the variable from outside the DLL doesn't work and returns an invalid pointer; is there anything I can do to fix this?</p>

<p>Edit:If I enter a function in the DLL in the debugger, the variable has the correct value - acessing it directly from the application gives a different value.</p>
","922184","","<p>What's probably happening is that you haven't setup the <code>dllexport/dllimport</code> correctly. The result is that you're ending up with different copies of the same variable. (one in the DLL and one outside)</p>

<p>Within the DLL, you need to compile with <code>dllexport</code> to expose the variable to the client application.</p>

<p>Then in the client application, you need to declare the same variable as <code>dllimport</code>. Then it will link against the one that's in the DLL.</p>

<p>This is slightly unfortunate because the same headers are usually used for the DLL and the client. So the usual work-around is this:</p>

<pre><code>#ifdef COMPILE_DLL
#define DLL_EXPORT  __declspec(dllexport)
#else
#define DLL_EXPORT  __declspec(dllimport)
#endif
</code></pre>

<p>EDIT:</p>

<p>Can you confirm whether or not you have two copies of the same variable? Try printing out the addresses from both inside the DLL and from outside.</p>
"
"<p>So I'm getting into Concurrent Programming, but for some reason I can't even get the basics to work. I have a file called fork.c, which contains a method main. In this method main I fork twice, into child processes 1 and 2. </p>

<p>In child 1, I print the character 'A' 50 times.</p>

<p>In child 2, I print the character 'B' 50 times.</p>

<p>When I run my code, I get the output AAAAA...AAAABBBBBB....BBBBBB. But never something like ABABABABABABAB.... In fact, sometimes I even get BBBBB....BBBBAAAA....AAAAA.</p>

<p>So why am I experiencing this behavior? Perhaps I'm going about it completely wrong. </p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

void my_char(char n) {
    write(1, &amp;n, 1);
}

int main() {
    int status;
    pid_t child1, child2;

    if (!(child1 = fork())) {
        // first childi
        int a;
        for (a = 0; a &lt; 50; a++) {
            my_char('A'); 
        }
        exit(0);
    } else if (!(child2 = fork())) {
        // second child
        int a;
        for (a = 0; a &lt; 50; a++) {
            my_char('B');
        }
        exit(0);
    } else {
        // parent
        wait(&amp;child1);
        wait(&amp;child2);
        my_char('\n');
    }

    return 0;
}   
</code></pre>
","922184","","<p>They <em>are</em> running concurrently, but the processes end almost immediately after being started. In other words, they're too short to actually get any real overlap.</p>

<p>EDIT:</p>

<p>The time needed to start another process is longer than the time it takes to run them. Therefore the chance of overlap is small. (there are also buffering issues which I'll omit)</p>

<p>You need each process to do more work than that. Try printing more than 50. Printing more than 10000 will probably be enough.</p>
"
"<p>How come on a calculator -1 mod 26 = 25, but in C or Java <code>-1 % 26 == -1</code>.  I need a program which solves it like the calculator. Is there a difference between the two?</p>
","922184","","<p>Both answers (25 and -1) are valid. It's just that different systems have different conventions.</p>

<p>The one I see the most common (in mathematics) is:</p>

<pre><code>quotient  = floor(x / y)
remainder = x - quotient * y
</code></pre>

<p>Where <code>floor()</code> is to round towards negative infinity.</p>

<p>This is the convention that your calculator is giving you. (Mathematica also uses this convention.)</p>

<p>The one I think most programming languages use is:</p>

<pre><code>quotient  = integerpart(x / y)
remainder = x - quotient * y
</code></pre>

<p>Where <code>integerpart()</code> is the same as a (float -> integer) cast. (round towards zero)</p>

<p>Some conventions like to keep the remainder the same sign as one of the operands.</p>

<p>The same thing applies to the sign of the divider. Different conventions are different.</p>
"
"<p>I have an assignment where I need to basically fill up main memory with allocated arrays in C. I am using VS2010 and kept on receiving stack overflow errors. Increasing the stack reserve past its default 1 MB helped, however now the array size I am working with is even larger and it seems no matter how much I increase the reserve, it now continually gives me a stack overflow error.
any help would be appreciated.
-thanks</p>
","922184","","<p>You're probably allocating your arrays on the stack. That's why you're getting stack overflows since your stack is never gonna be as large as your entire main memory.</p>

<p>You need to use <code>malloc()</code> to create arrays on the heap. That will allow you to use up all the main memory.</p>

<p>In other words, you can't do this:</p>

<pre><code>int array[1000000];
</code></pre>

<p>That will certainly blow your stack. You need to do this:</p>

<pre><code>int *array = malloc(1000000 * sizeof(int));
</code></pre>

<p>and you need to eventually free it like this:</p>

<pre><code>free(array);
</code></pre>

<p>Otherwise you will get a <a href=""http://en.wikipedia.org/wiki/Memory_leak"" rel=""nofollow"">memory leak</a>.</p>
"
"<p>I'm very new to this, so please bear with me.  For a coding C class, we're  to use a total of nine functions and a header file (we're calling it my.h) to collect the length and width of a room (ints), the percent discount (also an int), and the unit price of the carpet (a double).  We're to use the input to calculate the total cost to install the carpet.  I can get the length, width and area to print, but not the unit price.  It prints frin from the Read_Data.c and the Calc_Value.c functions, but not in Install_Price.c, which is called in Calc_Value.c.  unit_price is read at the same time as length and width, but somehow, its not passed correctly. I'm not sure why.  Maybe it does require a different pointer.  Any help would be immensely appreciated.  I've read my book and spoken to my professor and classmates, as well as searched the Internet, but I haven't found anything that helps.  The code for Install_Price is: </p>

<pre><code>/*This function calculates the cost of the carpet and the labor cost in order to    
calculate the installed price.*/

#include ""my.h""

void Install_Price (int length, int width, int unit_price, int* area, 
double* carpet_cost, double* labor_cost, double* installed_price)

{

printf(""\nThe unit price is %7.2f.\n"", *unit_price);

*area = length * width;
*carpet_cost = (*area) * unit_price;

printf(""The carpet cost is %7d x %7.2f = %7.2f.\n"", *area, unit_price, *carpet_cost);

*labor_cost = (*area) * LABOR_RATE;
*installed_price = (*carpet_cost) + (*labor_cost);

return;
}
</code></pre>

<p>Please note, the printf statements here are just to try and figure out where I went wrong with unit_price.  Below, I included the my.h header code, main.c, and the functions that it calls upto Install_Price.c.  Again, thanks for all your help!</p>

<p>my.h</p>

<pre><code>#include &lt;stdio.h&gt;
void Read_Data(int* length, int* width, int* percent_discount, double* 
unit_price);

void Calc_Values(int length, int width, int percent_discount, double 
unit_price, int* area, double* carpet_cost, double* labor_cost, double* 
installed_price, double* discount, double* subtotal, double* tax, 
double* total);

void Install_Price(int length, int width, int unit_price, int* area, double*      
carpet_cost, double* labor_cost, 
double* installed_price);

void Subtotal (int percent_discount, double installed_price, double* discount, 
double* subtotal);

void Total (double subtotal, double* tax, double* total);

void Print (int length, int width, int area, double unit_price, double carpet_cost,    
double labor_cost, double 
installed_price, int percent_discount, double discount, double subtotal, double tax,   
double total);

void Print_Measurements (int length, int width, int area);

void Print_Charges (double unit_price, double carpet_cost, double labor_cost, double   
installed_price, int percent_discount, double discount, double subtotal, double tax, 
double total);

#define LABOR_RATE 0.35
#define TAX_RATE 0.085
</code></pre>

<p>main.c</p>

<pre><code>/*  This function calls three subfuctions to calculate the costs of installing a    
carpet and prints an invoice.  */

#include ""my.h""

int main (void)

{
        int length;
        int width;
        int percent_discount;
        double unit_price;
        int area;
        double carpet_cost;
        double labor_cost;
        double installed_price;
        double discount;
        double subtotal;
        double tax;
        double total;

Read_Data(&amp;length, &amp;width, &amp;percent_discount, &amp;unit_price);

Calc_Values(length, width, percent_discount, unit_price, &amp;area, &amp;carpet_cost,  
&amp;labor_cost,&amp;installed_price, &amp;discount, &amp;subtotal, &amp;tax, &amp;total);

Print(length, width, area, unit_price, carpet_cost, labor_cost,
installed_price, percent_discount, discount, subtotal, tax, total);

return 0;
}
</code></pre>

<p>Read_Data.c</p>

<pre><code>/*This function asks the user for the length and width of a room to be carpeted, the  
percent discount and the unit price of the carpet. */

#include ""my.h""

void Read_Data (int* length, int* width, int* percent_discount, double* unit_price)

{
printf(""What is the length, in feet, of the room?\n"");
scanf(""%d"", length);

printf(""What is the width, in feet, of the room?\n""); 
scanf(""%d"", width);

printf(""What is the percent discount?\n"");
scanf(""%d"", percent_discount);

printf(""What is the unit price of the carpet?\n"");
scanf(""%lf"", unit_price);

printf(""\nThe length is %6d.\n"", *length);   //These printf statements work properly.
printf(""The width is %6d.\n"", *width);
printf(""The percent discount is %3d%.\n"", *percent_discount);
printf(""The unit price is $%7.2f.\n"", *unit_price);

return;
}
</code></pre>

<p>Calc_Value.c</p>

<pre><code>/*This function calls three subfuctions that calculate all required quantities.  */

#include ""my.h""

void Calc_Values (int length, int width, int percent_discount, double unit_price, 
int* area, double* carpet_cost, double* labor_cost, double* installed_price, double*  
discount, double* subtotal, double* tax, double* total)

{

printf(""\nUnit Price:  %7.2f.\n"", unit_price);  //This printf statement works properly.

Install_Price (length, width, unit_price, area, carpet_cost, labor_cost, 
installed_price);

Subtotal (percent_discount, *installed_price, discount, subtotal);

Total (*subtotal, tax, total);

return;
}
</code></pre>

<p>Install_Price.c  (repeating for user ease)</p>

<pre><code>/*This function calculates the cost of the carpet and the labor cost in order to    
calculate the installed price.*/

#include ""my.h""

void Install_Price (int length, int width, int unit_price, int* area, 
double* carpet_cost, double* labor_cost, double* installed_price)

{

printf(""\nThe unit price is %7.2f.\n"", *unit_price);  //THIS DOES NOT WORK

*area = length * width;
*carpet_cost = (*area) * unit_price;

printf(""The carpet cost is %7d x %7.2f = %7.2f.\n"", *area, unit_price, 
*carpet_cost);  //THIS DOES NOT WORK

*labor_cost = (*area) * LABOR_RATE;
*installed_price = (*carpet_cost) + (*labor_cost);

return;
}
</code></pre>
","922184","","<p>I didn't read the entire question but, I've already spotted an error here:</p>

<pre><code>printf(""\nThe unit price is %7.2f.\n"", *unit_price);
</code></pre>

<p>and</p>

<pre><code>printf(""The carpet cost is %7d x %7.2f = %7.2f.\n"", *area, unit_price, *carpet_cost);
</code></pre>

<p>The variable <code>unit_price</code> is of type <code>int</code>, but you're printing it out as a floating-point.</p>

<p>I'm guessing the first statement shouldn't even compile at all since <code>unit_price</code> isn't even dereferencable.</p>
"
"<p>Is the following code valid to check if a CPU supports the SSE3 instruction set?</p>

<p>Using the <code>IsProcessorFeaturePresent()</code> function apparently does not work on Windows XP (see <a href=""http://msdn.microsoft.com/en-us/library/ms724482(v=vs.85).aspx"">http://msdn.microsoft.com/en-us/library/ms724482(v=vs.85).aspx</a>).</p>

<pre><code>bool CheckSSE3()
{
    int CPUInfo[4] = {-1};

    //-- Get number of valid info ids
    __cpuid(CPUInfo, 0);
    int nIds = CPUInfo[0];

    //-- Get info for id ""1""
    if (nIds &gt;= 1)
    {
        __cpuid(CPUInfo, 1);
        bool bSSE3NewInstructions = (CPUInfo[2] &amp; 0x1) || false;
        return bSSE3NewInstructions;     
    }

    return false;      
}
</code></pre>
","922184","","<p>Here's a snippet from one of my CPU dispatchers.</p>

<p>First you need to access the CPUID instruction:</p>

<pre><code>#ifdef _WIN32

//  Windows
#define cpuid(info,x)    __cpuidex(info,x,0)

#else

//  GCC Inline Assembly
void cpuid(int CPUInfo[4],int InfoType){
    __asm__ __volatile__ (
        ""cpuid"":
        ""=a"" (CPUInfo[0]),
        ""=b"" (CPUInfo[1]),
        ""=c"" (CPUInfo[2]),
        ""=d"" (CPUInfo[3]) :
        ""a"" (InfoType), ""c"" (0)
    );
}

#endif
</code></pre>

<p>Then you can run the following code:</p>

<pre><code>//  Misc.
bool HW_MMX;
bool HW_x64;
bool HW_ABM;      // Advanced Bit Manipulation
bool HW_RDRAND;
bool HW_BMI1;
bool HW_BMI2;
bool HW_ADX;
bool HW_PREFETCHWT1;

//  SIMD: 128-bit
bool HW_SSE;
bool HW_SSE2;
bool HW_SSE3;
bool HW_SSSE3;
bool HW_SSE41;
bool HW_SSE42;
bool HW_SSE4a;
bool HW_AES;
bool HW_SHA;

//  SIMD: 256-bit
bool HW_AVX;
bool HW_XOP;
bool HW_FMA3;
bool HW_FMA4;
bool HW_AVX2;

//  SIMD: 512-bit
bool HW_AVX512F;    //  AVX512 Foundation
bool HW_AVX512CD;   //  AVX512 Conflict Detection
bool HW_AVX512PF;   //  AVX512 Prefetch
bool HW_AVX512ER;   //  AVX512 Exponential + Reciprocal
bool HW_AVX512VL;   //  AVX512 Vector Length Extensions
bool HW_AVX512BW;   //  AVX512 Byte + Word
bool HW_AVX512DQ;   //  AVX512 Doubleword + Quadword
bool HW_AVX512IFMA; //  AVX512 Integer 52-bit Fused Multiply-Add
bool HW_AVX512VBMI; //  AVX512 Vector Byte Manipulation Instructions

int info[4];
cpuid(info, 0);
int nIds = info[0];

cpuid(info, 0x80000000);
unsigned nExIds = info[0];

//  Detect Features
if (nIds &gt;= 0x00000001){
    cpuid(info,0x00000001);
    HW_MMX    = (info[3] &amp; ((int)1 &lt;&lt; 23)) != 0;
    HW_SSE    = (info[3] &amp; ((int)1 &lt;&lt; 25)) != 0;
    HW_SSE2   = (info[3] &amp; ((int)1 &lt;&lt; 26)) != 0;
    HW_SSE3   = (info[2] &amp; ((int)1 &lt;&lt;  0)) != 0;

    HW_SSSE3  = (info[2] &amp; ((int)1 &lt;&lt;  9)) != 0;
    HW_SSE41  = (info[2] &amp; ((int)1 &lt;&lt; 19)) != 0;
    HW_SSE42  = (info[2] &amp; ((int)1 &lt;&lt; 20)) != 0;
    HW_AES    = (info[2] &amp; ((int)1 &lt;&lt; 25)) != 0;

    HW_AVX    = (info[2] &amp; ((int)1 &lt;&lt; 28)) != 0;
    HW_FMA3   = (info[2] &amp; ((int)1 &lt;&lt; 12)) != 0;

    HW_RDRAND = (info[2] &amp; ((int)1 &lt;&lt; 30)) != 0;
}
if (nIds &gt;= 0x00000007){
    cpuid(info,0x00000007);
    HW_AVX2   = (info[1] &amp; ((int)1 &lt;&lt;  5)) != 0;

    HW_BMI1        = (info[1] &amp; ((int)1 &lt;&lt;  3)) != 0;
    HW_BMI2        = (info[1] &amp; ((int)1 &lt;&lt;  8)) != 0;
    HW_ADX         = (info[1] &amp; ((int)1 &lt;&lt; 19)) != 0;
    HW_SHA         = (info[1] &amp; ((int)1 &lt;&lt; 29)) != 0;
    HW_PREFETCHWT1 = (info[2] &amp; ((int)1 &lt;&lt;  0)) != 0;

    HW_AVX512F     = (info[1] &amp; ((int)1 &lt;&lt; 16)) != 0;
    HW_AVX512CD    = (info[1] &amp; ((int)1 &lt;&lt; 28)) != 0;
    HW_AVX512PF    = (info[1] &amp; ((int)1 &lt;&lt; 26)) != 0;
    HW_AVX512ER    = (info[1] &amp; ((int)1 &lt;&lt; 27)) != 0;
    HW_AVX512VL    = (info[1] &amp; ((int)1 &lt;&lt; 31)) != 0;
    HW_AVX512BW    = (info[1] &amp; ((int)1 &lt;&lt; 30)) != 0;
    HW_AVX512DQ    = (info[1] &amp; ((int)1 &lt;&lt; 17)) != 0;
    HW_AVX512IFMA  = (info[1] &amp; ((int)1 &lt;&lt; 21)) != 0;
    HW_AVX512VBMI  = (info[2] &amp; ((int)1 &lt;&lt;  1)) != 0;
}
if (nExIds &gt;= 0x80000001){
    cpuid(info,0x80000001);
    HW_x64   = (info[3] &amp; ((int)1 &lt;&lt; 29)) != 0;
    HW_ABM   = (info[2] &amp; ((int)1 &lt;&lt;  5)) != 0;
    HW_SSE4a = (info[2] &amp; ((int)1 &lt;&lt;  6)) != 0;
    HW_FMA4  = (info[2] &amp; ((int)1 &lt;&lt; 16)) != 0;
    HW_XOP   = (info[2] &amp; ((int)1 &lt;&lt; 11)) != 0;
}
</code></pre>

<hr>

<p>Note that this only detects whether the CPU supports the instructions. To actually run them, you also need to have operating system support.</p>

<p>Specifically, operating system support is required for:</p>

<ul>
<li>x64 instructions. (You need a 64-bit OS.)</li>
<li>Instructions that use the (AVX) 256-bit <code>ymm</code> registers. See <a href=""http://stackoverflow.com/a/22521619/922184"">Andy Lutomirski's answer</a> for how to detect this.</li>
<li>Instructions that use the (AVX512) 512-bit <code>zmm</code> and mask registers.</li>
</ul>
"
"<pre><code>#include &lt;iostream&gt;
#include &lt;windows.h&gt;
#include &lt;string&gt;
#include &lt;ctime&gt;
#include&lt;stdio.h&gt; 

using namespace std;

int main()
{
    HDC dc = GetDC(NULL); 
    COLORREF color = GetPixel(dc, 10, 10); 
    ReleaseDC(NULL, dc);
    cout &lt;&lt; color;

    return 0;
}
</code></pre>

<p>There's a error said :   </p>

<pre><code>[Linker error] undefined reference to `GetPixel@12'   
 ld returned 1 exit status    
[Build Error]  [Project1.exe] Error 1
</code></pre>

<p>I m using Dev-C++ complier</p>
","922184","","<p>You need to add <code>Gdi32.lib</code> to your dependency list. The <code>GetPixel()</code> function is not in the default libraries.</p>

<p>EDIT:</p>

<p>In Visual Studio, you can add dependencies like this:</p>

<p>Menu: Project -> Properties -> Configuration Properties -> Linker -> Input</p>

<p>The ""Additional Dependencies"" option will look like this:</p>

<p><code>kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</code></p>

<p>Add <code>Gdi32.lib</code> to it.</p>
"
"<p>I normalized a vector and length of it should be 1. But the result of length method is 0.99999982</p>

<p>I don't know it's right or wrong. But if I print it out, the result is 1. Not 0.99999982( printed by cout )</p>

<p>But how std::cout knows it's 1? [This is my first question]</p>

<p>And another question is why the result of comparing function is false.</p>

<p>I have a comparing method like below. And lhs is the length of a vector and the rhs is just 1.</p>

<p><code>
  return (fabsf(rhs-lhs) &lt;= FLT_EPSILON) ? true : false;
</code></p>

<p>Result of this method is false. </p>

<p>Is length of the normalized vector is already wrong to be considered normalized? or epsilon is too small?</p>

<p>What did I wrong? </p>
","922184","","<p>The epsilon is too small. That's because <strong><em>epsilon is the smallest as it can be</em></strong>. (by definition)</p>

<p>So you will need a larger tolerance.</p>
"
"<p>I'm trying to print out a wchar_t* string.
Code goes below:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;wchar.h&gt;

char *ascii_ = ""中日友好"";  //line-1
wchar_t *wchar_ = L""中日友好"";  //line-2

int main()
{
    printf(""ascii_: %s\n"", ascii_);  //line-3
    wprintf(L""wchar_: %s\n"", wchar_);  //line-4
    return 0;
}

//Output
ascii_: 中日友好
</code></pre>

<p><strong>Question:</strong></p>

<ol>
<li><p>Apparently I should not assign CJK characters to char* pointer in line-1, but I just did it, and the output of line-3 is correct, So why? How could printf() in line-3 give me the non-ascii characters? Does it know the encoding somehow?</p></li>
<li><p>I assume the code in line-2 and line-4 are correct, but why I didn't get any output of line-4?</p></li>
</ol>
","922184","","<p>First of all, it's usually not a good idea to use non-ascii characters in source code. What's probably happening is that the chinese characters are being encoded as UTF-8 which works with ascii.</p>

<p>Now, as for why the <code>wprintf()</code> isn't working. This has to do with stream orientation. Each stream can only be set to either normal or wide. Once set, it cannot be changed. It is set the first time it is used. (which is ascii due to the <code>printf</code>). After that the <code>wprintf</code> will not work due the incorrect orientation.</p>

<p>In other words, once you use <code>printf()</code> you need to keep on using <code>printf()</code>. Similarly, if you start with <code>wprintf()</code>, you need to keep using <code>wprintf()</code>.</p>

<p>You cannot intermix <code>printf()</code> and <code>wprintf()</code>. (except on Windows)</p>

<p>EDIT:</p>

<p>To answer the question about why the <code>wprintf</code> line doesn't work even by itself. It's probably because the code is being compiled so that the UTF-8 format of <code>中日友好</code> is stored into <code>wchar_</code>. However, <code>wchar_t</code> needs 4-byte unicode encoding. (2-bytes in Windows)</p>

<p>So there's two options that I can think of:</p>

<ol>
<li>Don't bother with <code>wchar_t</code>, and just stick with multi-byte <code>char</code>s. This is the easy way, but may break if the user's system is not set to the Chinese locale.</li>
<li>Use <code>wchar_t</code>, but you will need to encode the Chinese characters using unicode escape sequences. This will obviously make it unreadable in the source code, but it will work on any machine that can print Chinese character fonts regardless of the locale.</li>
</ol>
"
"<p>In multicore systems, such as 2, 4, 8 cores, we typically use mutexes and semaphores to access shared memory. However, I can foresee that these methods would induce a high overhead for future systems with many cores. Are there any alternative methods that would be better for future many core systems for accessing shared memories.</p>
","922184","","<p>I'm not sure how far in the future you want to go. But in the long-long run, shared memory as we know it right now (single address space accessible by any core) is not scalable. So the programming model will have to change at some point and make the lives of programmers harder as it did when we went to multi-core.</p>

<p>But for now (perhaps for another 10 years) you can get away with transactional memory and other hardware/software tricks.</p>

<p>The reason I say shared-memory is not scalable in the long run is simply due to physics. (similar to how single-core/high-frequency hit a barrier)</p>

<p>In short, transistors can't shrink to less than the size of an atom (barring new technology), and signals can't propagate faster than the speed of light. Therefore, memory will get slower and slower (with respect to the processor) and at some point, it becomes infeasible to share memory.</p>

<p>We can already see this effect right now with NUMA on the multi-socket systems. Large-scale supercomputers are neither shared-memory nor cache-coherent.</p>
"
"<p>I have to find is the number ""a"" a two-digit odd. Mistake comes on if</p>

<pre><code>#include &lt;stdio.h&gt;
main ()
{
    int a,k;
    int count=0;
    printf (""input number \n"", a);
    scanf (""%d"", &amp;a);
    k = a % 2;
    while (a)
    {
        a /= 10;
        count ++;
    }
    if (k = 1 &amp;&amp; count = 2)
        printf (""It is \n"");
    else
        printf (""It is not \n"");
    return (0);
}
</code></pre>
","922184","","<p>The error is here:</p>

<pre><code>if (k = 1 &amp;&amp; count = 2)
</code></pre>

<p>you probably meant:</p>

<pre><code>if (k == 1 &amp;&amp; count == 2)
</code></pre>

<p><code>=</code> is an assignment. <code>==</code> is a comparison for equality.</p>

<p>Also, the loop is not necessary. You can check if the number is two digits by checking if it's less than 100 and greater than or equal to 10.</p>
"
"<p>I am working on a programming assignment in which we are making our own BigNum class. One of the constructors needs to be set up so that it can take a number from a string (i.e. 342567) and reads it into an array. However if the number were 0000000342567 it would have to be able to skip over the 0s and just read 342567.</p>

<p>Where is what i have so far but am lost on trimming the 0s</p>

<pre><code>BigNum::BigNum(const char strin[])
{
    size_t size = strlen(strin);
    positive = true;
    capacity = size;
    digits = new size_t[capacity];
    used=0;

    while(used&lt;size)
    {
        if(strin[size - used -1] =='-')
        {
            positive = false;
            size --;
        }
        else if(strin[size - used -1] =='+')
        {
            size --;
        }
        else
        {
            digits[used] = strin[size - used -1] - '0';
            used++;
        }
    }
}
</code></pre>

<p>Here is the assignment description if it helps 
<a href=""http://csel.cs.colorado.edu/%7Eekwhite/CSCI2270Fall2011/hw2/Homework2.pdf"" rel=""nofollow"">http://csel.cs.colorado.edu/%7Eekwhite/CSCI2270Fall2011/hw2/Homework2.pdf</a></p>
","922184","","<p>Here's a hint:</p>

<p>Write a separate loop at the beginning that skips over all the zeros.</p>
"
"<p>I run the program and all I see is white space below Netbeans.</p>

<p>At first I thought it did not run then I ran four of the programs by accident and Netbeans crashed. So my first question: is it an infinite loop, and if so why? </p>

<p>From what I can see it is <code>int = 0</code>, <code>0</code> is <code>&gt;=0</code> So it should run  as <code>0 + 0</code>... wait if <code>int number</code> and <code>int sum</code> are both zero then does that mean the program can't proceed because it is stuck with looping zeros? But why wouldn't it show the output of 0 many times instead of being blank?</p>

<pre><code>public static void main(String[] args) {

    int number = 0;
    int sum = 0;
    while (number &gt;= 0 || number &lt;= 10) {
        sum += number;
        number += 3;
        System.out.print("" Sum is "" + sum);
    }
 }
</code></pre>
","922184","","<p>Yes, it's an infinite loop, you probably meant:</p>

<pre><code>while (number &gt;= 0 &amp;&amp; number &lt;= 10)
</code></pre>

<p>Otherwise, the number will always be greater than or equal zero, and will always loop again.</p>

<p>EDIT:</p>

<p>The <code>number &gt;= 0</code> isn't even necessary. It will work with just:</p>

<pre><code>while (number &lt;= 10)
</code></pre>
"
"<p>I have recently started learning C as a side project. I am working under OpenSuse with the latest NetBeans using the GCC as toolset for compiling.
One of the very first programs that I made was this:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;

/*
 * 
 */
int main(int argc, char** argv) {    
    double rad = 1;
    double result = 0;
    result = sin(rad);
    return (EXIT_SUCCESS);
}
</code></pre>

<p>This is a simple, no-brainer example that should have worked without a problem. However, I get a Build Error: Exit code 2(error in line 18, undefined reference to sin) when trying to compile. 
Interestingly enough, if I remove the assignment of the value of sin(rad) to result OR replace rad with a hard coded value, the program compiles just fine. 
What am I doing wrong here?</p>
","922184","","<p>In C, you need to link to the math library:</p>

<p>Add this to the command line options:</p>

<pre><code>-lm
</code></pre>
"
"<p>Here's the code:</p>

<pre><code>#include &lt;stdio.h&gt;

int main (void)
{
    int value[10];
    int index;

    value[0] = 197;
    value[2] = -100;
    value[5] = 350;
    value[3] = value[0] + value[5];
    value[9] = value[5] / 10;
    --value[2];

    for(index = 0; index &lt; 10; ++index)
        printf(""value[%i] = %i\n"", index, value[index]);
    return 0;
}
</code></pre>

<p>Here's the output when compile:</p>

<pre><code>value[0] = 197
value[1] = 0
value[2] = -101
value[3] = 547
value[4] = 0
value[5] = 350
value[6] = 0
value[7] = 0
value[8] = 1784505816
value[9] = 35
</code></pre>

<p>I don't understand why value[8] returns 1784505816? 
Isn't value[8] supposed be = value[6] = value[7] = 0? By the way, I compile the code via gcc under Mac OS X Lion.</p>
","922184","","<p><code>value[8]</code> was never initialized, therefore its contents are undefined and can be anything.</p>

<p>Same applies to <code>value[1]</code>, <code>value[4]</code>, <code>value[6]</code>, and <code>value[7]</code>. But they just happened to be zero.</p>
"
"<p>i'm trying to not use STL. i have this line in my code:</p>

<pre><code>std::copy(buffer_, buffer_ + size_ + 1, new_buffer)
</code></pre>

<p>if i want to NOT use copy, is this the right equivalent?</p>

<pre><code>for (int i = 0; i &lt; (size_ + 1); i++){
    new_buffer[i] = buffer[i];
}
</code></pre>

<p>or is that totally wrong? or is it off by one? or something else?</p>

<p>thanks!</p>
","922184","","<p>Okay, the two code-samples you have will give the same result.</p>

<p>However, you will have an off-by-one error if you use <code>size_ + 1</code>. Just <code>size_</code> is the correct value since it already points to one past the last element.</p>
"
"<p>What is the big-O complexity of the function (log n)<sup>k</sup> for any k?</p>
","922184","","<p>It will still be <code>(log(n))^2</code>. A logarithm raised to a power is already in the lowest/simplest form.</p>
"
"<p>I'm writing a unit test framework (see <a href=""http://stackoverflow.com/questions/7522954/how-can-we-apply-a-non-vararg-function-over-a-va-list"">SO</a> for more details). Or view the code at <a href=""https://github.com/mcandre/qc"" rel=""nofollow"">GitHub</a>.</p>

<p><a href=""http://www.safercode.com/blog/2008/11/25/generic-function-pointers-in-c-and-void.html"" rel=""nofollow"">Safer Code</a> describes a way to pass functions of arbitrary types.</p>

<p>But how do I call such a function without knowing its types beforehand? Assume <code>f</code> needs no input, so <code>f()</code> should work on its own.</p>

<p>Let's say I want to populate an array using an arbitrary generator function.</p>

<pre><code>void* gen_array(fp gen, size_t size) {
    int i, len = gen_int() % 100;

    void* arr = GC_MALLOC(len * size);

    for (i = 0; i &lt; len; i++) {
        arr[i] = gen(NULL);
    }

    return arr;
}
</code></pre>

<p>It should look something like this, but I get compiler errors:</p>

<pre><code>gcc -o example example.c qc.c qc.h -lgc
In file included from example.c:1:
qc.h:21: error: expected declaration specifiers or ‘...’ before ‘size_t’
In file included from qc.c:1:
qc.h:21: error: expected declaration specifiers or ‘...’ before ‘size_t’
qc.c:23: error: conflicting types for ‘gen_array’
qc.h:21: error: previous declaration of ‘gen_array’ was here
qc.c: In function ‘gen_array’:
qc.c:29: warning: dereferencing ‘void *’ pointer
qc.c:29: error: too many arguments to function ‘gen’
qc.c:29: error: invalid use of void expression
qc.h:21: error: expected declaration specifiers or ‘...’ before ‘size_t’
make: *** [example] Error 1
</code></pre>
","922184","","<p>That page suggests you make the function pointer take a <code>void*</code>. So in order for your code to compile, you must pass it a void pointer:</p>

<pre><code>typedef void* (*fp)(void*);

doit(fp f) {
   f(NULL);
}
</code></pre>

<p>And just make sure that the function that you're calling simply ignores the parameter.</p>

<p>Generally speaking, these generic function pointers are used for starting threads. The void pointer is simply a pointer to a struct that holds the actual parameters.</p>
"
"<p>on the line <code>*binSon[0].add(x);</code>, it give me an error, an expression must have a class type, what do i do?   </p>

<pre><code>struct Rectangle
{
    tName Name; //name of the rectangle
    struct Rectangle *binSon[NDIR_1D]; //left and right son
    int Center[NDIR_1D];
    int Length[NDIR_1D];

    void add(Rectangle x){
        if(strcmp(x.Name,Name)&lt;0)
        {
            if(binSon[0]==NULL)
                binSon[0]=&amp;x;
            else
                *binSon[0].add(x);

        }else{
            if(binSon[1]==NULL)
                binSon[1]=&amp;x;
            else
                *binSon[1].add(x);
        }
    }
};
</code></pre>
","922184","","<p>You have a small precedence issue. Either of the following should fix the problem:</p>

<pre><code>(*binSon[0]).add(x);
</code></pre>

<p>or</p>

<pre><code>binSon[0]-&gt;add(x);
</code></pre>

<p>Same applies to the other line.</p>
"
"<p>I have 2 classes:</p>

<pre><code>class Entity {
   void addChild(Entity* e);
};

class Control : public Entity {

};
</code></pre>

<p>What I want to do is to not allow adding a Control as a child of something that's not a Control. So, for example:</p>

<pre><code>Control c;
Entity e;
e.addChild(c); // This line would throw an error (at compile time if possible);
</code></pre>

<p>The first thing I thought of is adding this to Entity:</p>

<pre><code>void addChild(Control* c){
    assert(false);
};
</code></pre>

<p>NOTE: both Entity and Control are abstract classes but both has many subclasses.   </p>

<p>But is there any way to get an error at compile time?</p>
","922184","","<p>You can declare the function, but don't implement it. That will give a linker error if you try to use it.</p>
"
"<p>The same code ran in TURBO C.</p>

<pre><code>    struct details
    {
      char name[20];
      int year;
      float price;
    }my_str;

    details book1[10];
</code></pre>

<p>This error is produced. How can this be fixed?</p>

<pre><code>ram.c: In function ‘main’:
ram.c:11:1: error: ‘details’ undeclared (first use in this function)
ram.c:11:1: note: each undeclared identifier is reported only once for each function it appears in
</code></pre>
","922184","","<p>There are two ways to fix this:</p>

<p>Change second line to this:</p>

<pre><code>struct details book1[10];
</code></pre>

<p>Or you can change the declaration to:</p>

<pre><code>typedef struct{
    char name[20];
    int year;
    float price;
} details;
</code></pre>

<p>C is slightly different from C++, so you can't declare structs quite the same way.</p>
"
"<p>when i execute the below code, the compiler returns the message ""(.text+0x31): undefined reference to 'sqrt'"". but if i take away the q* the compiler correctly gives me 8.000000
i'm trying to get the program to multiply the INCREMENT by 1 (and eventually 2 and 3 when i write the loop in).</p>

<p>how come the below doesn't work? </p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;math.h&gt;

#define INCREMENT   64

int main () 
{
    int q = 1;
    printf(""%f"", sqrt(q*INCREMENT));
    return 0;
}    
</code></pre>
","922184","","<p>You probably need to link to the math library. (though I thought visual C++ does this automatically...)</p>

<p>The reason why it works without the <code>q</code> is because the compiler is optimizing out the <code>sqrt</code> since it's a constant.</p>
"
"<p>Recently I have been working on sockets in C++ and I have come across this:</p>

<pre><code>*(struct in_addr*)&amp;serv_addr.sin_addr.s_addr = *(struct in_addr *)server-&gt;h_addr;
</code></pre>

<p>While this does do what I want it to I am a little confused as to why I can't do this:</p>

<pre><code>(struct in_addr)serv_addr.sin_addr.s_addr = *(struct in_addr *)server-&gt;h_addr;
</code></pre>

<p>Since it becomes a pointer and then immediately is dereferenced shouldn't the second work as well as the first? I am still new to C++ and this is a little confusing to me. Any help would be greatly appreciated. Below is the code. All it does is takes the host name or IP and prints the IP to the screen.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;netdb.h&gt;
#include &lt;arpa/inet.h&gt;


using namespace std;

int main(){

    int socketfd, portno, rwResult; 
    struct sockaddr_in serv_addr; 
    struct hostent* server;     
    char inputName[50];

    //The next block gets the host name and port number and stores them in variables
    cout&lt;&lt;""Enter host(Max Size 50): "";
    cin&gt;&gt;inputName;
    cout&lt;&lt;endl&lt;&lt;""Enter port number: "";
    cin&gt;&gt;portno;
    cout&lt;&lt;endl;

    server = gethostbyname(inputName);
    serv_addr.sin_family = AF_INET;
    serv_addr.sin_port = htons(portno);

    *(struct in_addr*)&amp;serv_addr.sin_addr.s_addr = *(struct in_addr *)server-&gt;h_addr;
    //This is where I am confused
    //(struct in_addr)serv_addr.sin_addr.s_addr = *(struct in_addr *)server-&gt;h_addr;


    cout&lt;&lt; ""Server: ""&lt;&lt;inet_ntoa(*(struct in_addr *)server-&gt;h_addr_list[0])&lt;&lt;endl;

    cout&lt;&lt; ""Server: ""&lt;&lt;inet_ntoa(*(struct in_addr *)&amp;serv_addr.sin_addr.s_addr)&lt;&lt;endl;
    //The two cout's tell me if the address was copied correctly to serv_addr I believe.



    return 0;
}
</code></pre>
","922184","","<p>What the code is doing is trying to re-interpret <code>serv_addr.sin_addr.s_addr</code> as a type <code>in_addr</code>. However, this conversion is not compatible. Therefore, you get a compiler error in the second snippet if you try a direct cast.</p>

<p>In the first snippet, you're essentially using pointer casting to get around this type incompatibility.</p>
"
"<p>In C++ if I get and return the address of a variable and the caller then immediately dereferences it, will the compiler reliably optimize out the two operations?</p>

<p>The reason I ask is I have a data structure where I'm using an interface similar to std::map where find() returns a pointer (iterator) to a value, and returns NULL (there is no trivial .end() equivalent) to indicate that the value has not been found.</p>

<p>I happen to know that the variables being stored are pointers, so returning NULL works fine even if I returned the value directly, but it seems that returning a pointer to the value is more general.  Otherwise if someone tried to store an int there that was actually 0 the data structure would claim it isn't there.</p>

<p>However, I'm wondering if there's even any loss in efficiency here, seeing as the compiler should optimize away actions that just undo the effect of each other.  The problem is that the two are separated by a function return so maybe it wouldn't be able to detect that they just undo each other.</p>

<p>Lastly, what about having one private member function that just returns the value and an inline public member function that just takes the address of the value.  Then at least the address/dereference operations would take place together and have a better chance of being optimized out, while the whole body of the find() function is not inlined.</p>

<p><strike></p>

<pre>
private:
V _find(key) {
   ... // a few dozen lines...
}


public:
inline V* find(key) {
    return &_find(key);
}

std::cout &lt;&lt; *find(a_key);
</strike></pre>

<p>This would return a pointer to a temporary, which I didn't think about.  The only thing that can be done similar to this is to do a lot of processing in the _find() and do the last step and the return of the pointer in find() to minimize the amount of inlined code.</p>

<pre><code>
private:
W* _find(key) {
   ... // a few dozen lines...
}

public:
inline V* find(key) {
    return some_func(_find(key)); // last steps on W to get V*
}

std::cout &lt;&lt; *find(a_key);
</code></pre>

<p>Or as yet another responder mentioned, we could return a reference to V in the original version (again, not sure why we're all blind to the trivial stuff at first glance... see discussion.)</p>

<pre><code>
private:
V& _find(key) {
   ... // a few dozen lines...
}


public:
inline V* find(key) {
    return &_find(key);
}

std::cout &lt;&lt; *find(a_key);
</code></pre>
","922184","","<p>I've seen it go either way. It really depends on the compiler and the level optimization. Even when it does get inlined, I've seen cases where the compiler will not optimize this out.</p>

<p>The only way to see if it does get optimized out it is to actually look at the disassembly.</p>

<p>What you should probably do is to make a version where you manually inline them. Then benchmark it to see if you actually get a noticeable performance gain. If not, then this whole question is moot.</p>
"
"<p>please take a look at my codes below</p>

<pre><code>#include &lt;stdio.h&gt;

void printOut()
{
 static int i = 0;
 if (i &lt; 10)
 {
  printOut(i);
 }
}

int main(int argc, char *argv[])
{

  return 0;
}
</code></pre>

<p>i guess there should be an error due to my invoking the non-existed function prototype.Actually, the code compiles well with mingw5 compiler, which is weird for me, then i change to Borland Compiler, i get a warning message said that no printOut function prototype, is this only a warning ? What is more, the code executes well without any pop-up error windows.</p>
","922184","","<p>In C, a function without any parameters can still take parameters.</p>

<p>That's why it compiles. The way to specify that it doesn't take any parameters is:</p>

<pre><code>void printOut(void)
</code></pre>

<p>This is the proper way to do, but is less common especially for those from a C++ background.</p>
"
"<p>i have a question for you guys which is driving me nuts for 2 days already. Maybe its because i am missing the basics on bit shifting but somehow i don't get it into my head. What i want is a simple program which reads in 3 char or uint8_t's, stores them into one big int and then reads it out later again. </p>

<p>It is the first time that i experiment with bit shifting, and somehow i am stuck. </p>

<p>This is the code:</p>

<pre><code>int main (int argc, const char * argv[])
{
    u_int8_t insert1;
    u_int8_t insert2;
    u_int8_t insert3;
    int data;

    printf(""Please enter value1: "");
    scanf(""%d"", &amp;insert1);
    printf(""Please enter value2: "");
    scanf(""%d"", &amp;insert2);
    printf(""Please enter value3: "");
    scanf(""%d"", &amp;insert3);

    data |= insert3&lt;&lt;16 | insert2&lt;&lt;8 | insert1;

    printf(""\nValue1: %d\n"", data);
    printf(""Value2: %d\n"", data&gt;&gt;8);
    printf(""Value3: %d\n"", data&gt;&gt;16);
    return 0;
}
</code></pre>

<p>When i Enter</p>

<p>126
103
255</p>

<p>i get:</p>

<p>Value1: 16711680
Value2: 65280
Value3: 255</p>

<p>Which is completely wrong. I am pretty sure that the value is stored correctly stored into data but i don't know how to read out.</p>

<p>Thanks very much :-)</p>
","922184","","<p>You never initialized <code>data</code> and you're doing this:</p>

<pre><code>data |= 
</code></pre>

<p>Either initialize it to zero or change the line to this:</p>

<pre><code>data = insert3&lt;&lt;16 | insert2&lt;&lt;8 | insert1;
</code></pre>
"
"<p>I have recently migrated to a new laptop - HP dv6119tx (Intel Core i5, 4 GB RAM). It has Windows 7 Home Premium 64 bit installed. </p>

<p>I am trying to create an array of type <code>int</code> of length 10^6 in C++ (Dev C++), which I used to create comfortably on my last laptop (32 bit Windows 7 Ultimate/Ubuntu Linux, 2GB RAM) and every other environment I have programmed on (It should take around 3.5 MB of RAM). But with the current setup, I am getting a ""Segmentation Fault"" error in Debug Mode. </p>

<p><img src=""http://i.stack.imgur.com/pjMBp.png"" alt=""Screenshot when I am trying to create an array of length 10^5""></p>

<p><img src=""http://i.stack.imgur.com/IltRS.png"" alt=""Screenshot when I am trying to create an array of length 10^6""></p>

<p><strong>SCREENSHOTS (EDIT) :</strong><br>
The first screenshot shows 10^5 working on the current setup and 10^6 not. I do not have a screenshot for 10^6 working on my last machine but I have used it many times.</p>

<p><strong>EDIT:</strong><br>
The program would work just fine if I declared the array as <em>global</em> instead or created it dynamically on the heap as </p>

<pre><code>int* a = new int[MAX];  
</code></pre>

<p>But what I fail to understand is that when the local array is taking a meager 3.5 MB of memory on the stack (and was working fine on a 2 GB machine), why should this issue surface with a 4GB machine? Is this a user stack space issue? Can it be increased manually?   </p>

<p><strong>EDIT 2:</strong><br>
I am particularly asking this question because I have submitted numerous solutions on SPOJ with 10^6 sized arrays created on the stack. With my current setup, I feel crippled not being able to do that. I prefer stack over heap whenever possible because it has no memory leak issues;  and local variables over global variables because they are neat and do not mess up the namespace.  </p>
","922184","","<p>Arrays created like that are stored on the stack. However, the stack has very limited size, therefore you are hitting a stackoverflow and a crash.</p>

<p>The way to do it is to allocate it on the heap:</p>

<pre><code>int *a = (int*)malloc(MAX * sizeof(int));

//  Do what you need to do.

//  Free it when you're done using ""a"".
free(a);
</code></pre>
"
"<p>I suppose sizeof(char) is one byte. Then when I write following code, </p>

<pre><code>    #include&lt;stdio.h&gt;

    int main(void)
    {
       char x = 10;

       printf(""%d"", x&lt;&lt;5);
    }
</code></pre>

<p>The output is <code>320</code></p>

<p>My question is, if char is one byte long and value is 10, it should be:</p>

<pre><code>0000 1010
</code></pre>

<p>When I shift by 5, shouldn't it become:</p>

<pre><code>0100 0001
</code></pre>

<p>so why is output 320 and not 65?</p>

<p>I am using gcc on Linux and checked that <code>sizeof(char) = 1</code></p>
","922184","","<p>In C, all intermediates that are smaller than <code>int</code> are automatically promoted to <code>int</code>.
Therefore, your <code>char</code> is being promoted to larger than 8 bits.</p>

<p>So your <code>0000 1010</code> is being shifted up by 5 bits to get 320. (nothing is shifted off the top)</p>

<p>If you want to rotate, you need to do two shifts and a mask:</p>

<pre><code>unsigned char x = 10;

x = (x &lt;&lt; 5) | (x &gt;&gt; 3);
x &amp;= 0xff;

printf(""%d"", x);
</code></pre>

<p>It's possible to do it faster using inline assembly or if the compiler supports it, intrinsics.</p>
"
"<p>I was wondering whether there was a way to do the following, without writing a function or a for loop:</p>

<pre><code>int[] ma = (3,4,4,5,6,7);
ma += 5;
</code></pre>

<p>thus, adding 5 to all elements in the array.  Matlab allows for such a convenient shortcut.</p>
","922184","","<p>Short answer: No you can't. You need to write a loop to do it.</p>
"
"<p>Is there a C++ function that chops very small numerical values that appear due to approximations of the floating point numbers in the CPU to zero? I want to use this in complex number calculation, so it can appear in either the real or imaginary parts.</p>
","922184","","<p>No such function exists. The problem is that ""small"" is relative. If you're working on very large numbers, <code>1.0</code> can be considered small enough to chop. Similarly, if you're working with small numbers, <code>10^-30</code> could still be considered significant.</p>
"
"<p>I have faced an interview question related to embedded systems and C/C++. The question is:</p>

<blockquote>
  <p>If we multiply 2 signed (2's complement) 16-bit data, what should be the size of resultant data?</p>
</blockquote>

<p>I've started attempting it with an example of multiplying two signed 4-bit, so, if we multiply <code>+7</code> and <code>-7</code>, we end up with <code>-49</code>, which requires 7 bits. But, I could not formulate a general relation. </p>

<p>I think I need to understand binary multiply deeply to solve this question.</p>
","922184","","<p>This will depend on context. In C/C++, all intermediates smaller than <code>int</code> are promoted to <code>int</code>. So if <code>int</code> is larger than 16-bits, then the result will be a signed 32-bit integer.</p>

<p>However, if you assign it back to a 16-bit integer, it will truncate leaving only bottom 16 bits of the two's complement of the new number.</p>

<p>So if your definition of ""result"" is the intermediate immediately following the multiply, then the answer is the size of <code>int</code>. If you define the size as after you've stored it back to a 16-bit variable, then answer is the size of the 16-bit integer type.</p>
"
"<p>It struck me there must be a clever way to do this.  This isn't for homework, or work or anything.  I was just noodling around with a file format that has data interleaved.</p>

<p>So, in generic C/C++, (or whatever) given some array </p>

<pre><code>int x[] = ...
</code></pre>

<p>is there a clever way of splitting it into two short arrays</p>

<pre><code>short sa1[], sa2[]
</code></pre>

<p>such that the int array is split down the middle</p>

<pre><code>x[i] = 1111111111111111 1111111111111111
             sa1[i]         sa2[i]
</code></pre>

<p>Edit: Sorry if this is not phrased well. For each i-th element of the int array, the left-most 16 bits become the i-th element of one array, and the right-most 16bits become the i-th element of a 2nd array. </p>

<p>so given</p>

<pre><code>x[i] = 0001111111111111 1111111100011111
</code></pre>

<p>then</p>

<pre><code>sa1[i] = 0001111111111111
sa2[i] = 1111111100011111
</code></pre>

<p>I'm looking for non-obvious answers that do not loop over each element and shift and mask each element.  That's easy :)</p>
","922184","","<p>There's a lot of ways to do this:</p>

<p>Assumptions:</p>

<ol>
<li><code>short</code> is 16 bits.</li>
<li><code>int</code> is 32 bits.</li>
</ol>

<p>Method 1: (A simple loop)</p>

<pre><code>for (int i = 0; i &lt; size; i++){
    int tmp = x[i];
    sa1[i] = (tmp      ) &amp; 0xffff;
    sa2[i] = (tmp &gt;&gt; 16) &amp; 0xffff;
}
</code></pre>

<p>Method 2: SSE2</p>

<pre><code>for (int i = 0; i &lt; size / 8; i++){
    __m128i a0 = ((__m128i*)x)[2*i + 0];
    __m128i a1 = ((__m128i*)x)[2*i + 1];

    a0 = _mm_shufflelo_epi16(a0,216);
    a1 = _mm_shufflelo_epi16(a1,216);
    a0 = _mm_shufflehi_epi16(a0,216);
    a1 = _mm_shufflehi_epi16(a1,216);
    a0 = _mm_shuffle_epi32(a0,216);
    a1 = _mm_shuffle_epi32(a1,216);

    ((__m128i*)sa1)[i] = _mm_unpacklo_epi64(a0,a1);
    ((__m128i*)sa2)[i] = _mm_unpackhi_epi64(a0,a1);
}
</code></pre>

<p>This last example is very fast if the loop is further unrolled. I won't be surprised if this can beat all byte-manipulation libraries.</p>

<p>However, it has the following restrictions:</p>

<ol>
<li>The data must be aligned to 16 bytes.</li>
<li>The number of iterations must be divisible by 8.</li>
<li>It requires SSE2.</li>
</ol>

<p>The first two of these can be solved by cleanup code. It's messy, but if you really desire performance, it may be worth it.</p>

<p>EDIT:</p>

<p>Yes this violates strict-aliasing, but it's nearly impossible to use SSE intrinsics without doing so.</p>
"
"<pre><code>    for ( int iIdx = 0; iIdx &lt; argc; ++iIdx )
    _tprintf( TEXT( ""Arg %d: %s\n"" ), iIdx, argv[ iIdx ] );
_tprintf( TEXT( ""\n"" ) );
</code></pre>

<p>Is this valid in C? Because I get an error when I try to compile it, if I remove the int from the initializer section of the for loop, it compiles fine...</p>
","922184","","<p>It is not valid in C before C99.</p>

<p>In C89/90 and earlier, declarations need to be at the start of each block. You can't interleave declarations and normal code.</p>

<p>A declaration inside the <code>for</code> does not count as being at the start of a block.</p>
"
"<p>I am writing a C program which adds two nonzero integers which are given as fractions. The integers are input as n1 d1 n2 d2. There seems to be an error when certain negative numbers are input, such as in the following combination ( 1 2 -1 2). This should state that the numbers being added are 1/2 and -1/2, and then state that the sum is 0. Instead, the program just shows a blank line and does not accept any further input. The second problem I have is that when the sentinel value is input the program is supposed to display a termination message and then end, instead it displays ""floating point exception"".</p>

<pre><code> int
    main( void )
    {
int n1;
int d1;
int n2;
int d2;
int g;
int p;
int q;
int again;
int sumn;
int sumd;

again = 1;

while ( again == 1 ) {

  printf( ""Please enter 4 nonzero integers representing the fractions: "" );
  scanf( ""%d%d%d%d"", &amp;n1, &amp;d1, &amp;n2, &amp;d2 );

  if ( n1 == 0 &amp;&amp; n2 == 0 &amp;&amp; d1 == 0 &amp;&amp; d2 == 0 ) {
    again = 0;
  }
  else {
    again = 1;
  }
  if ( ( n1 == 0 || n2 == 0 || d1 == 0 || d2 == 0 ) &amp;&amp; ( n1 != 0 || n2 != 0 || d1 != 0 || d2 != 0 ) ) {
    printf( ""One or more of the integers is zero\n"" );
    again = 1;
  }
    else {

    g = gcd( d1, d2 );
    p = ( ( n1 * ( d2 / g ) ) + ( n2 * ( d1 / g ) ) );
    q = ( d1 * ( d2 / g ) );

    sumn = ( p / ( gcd( p, q ) ) );
    sumd = ( q / ( gcd( p, q ) ) );

    printf( ""The fractions are: %d/%d and %d/%d\n"", n1, d1, n2, d2 );

    if ( sumn == sumd ) {
      printf( ""Their sum is: 1\n"" );
    }
    else {
      if ( sumd == 1 ) {
        printf( ""Their sum is: %d\n"", sumn );
      }
      else {
        printf( ""Their sum is: %d/%d\n"", sumn, sumd );
      }
    }
  }
}
printf( ""***** Program Terminated *****\n"" );

return (EXIT_SUCCESS);
}

int gcd( int a, int b )
{
while ( a != b ) {
  if ( a &gt; b ) {
    a = ( a - b );
  }
  else {
    b = ( b - a );
  }
}
return a;
}
</code></pre>
","922184","","<p>You have an error in the <code>gcd</code> function. When <code>a</code> is negative, it's an infinite loop. Therefore the console hangs and won't take any more input.</p>

<pre><code>int gcd( int a, int b )
{
    while ( a != b ) {
       cout &lt;&lt; a &lt;&lt; ""  "" &lt;&lt; b &lt;&lt; endl;
       if ( a &gt; b ) {
          a = ( a - b );
       }
       else {
          b = ( b - a );
        }
    }
    return a;
}
</code></pre>

<p>Output: <code>gcd(-1,2)</code></p>

<pre><code>-1  2
-1  3
-1  4
-1  5
-1  6
-1  7
-1  8
-1  9
-1  10
-1  11
-1  12
-1  13
-1  14
...
</code></pre>

<p>p.s.
Yes I know the question is tagged C, but I'm just printing out data in C++.</p>

<p>EDIT:</p>

<p>The fix is to make <code>a</code> and <code>b</code> positive:</p>

<pre><code>int gcd( int a, int b )
{
    if (a &lt; 0)
        a = -a;
    if (b &lt; 0)
        b = -b;

    while ( a != b ){
       if ( a &gt; b ){
           a = ( a - b );
       }
       else{
           b = ( b - a );
       }
    }
    return a;
}
</code></pre>
"
"<p>Recently I had to modify a legacy code that was compiled with a very old version of GCC (somewhere around version 2.3). Within a function, variable had to be declared before being used. I believe this is done C89 standard. This limitation is later removed.</p>

<p>My question is: Back then, why did they enforce this ruling? Was there any concern that could jeopardise the integrity of the software?</p>
","922184","","<p>It was mainly to make compilers easier to write. If all the declarations were at the top of the function, it would be easy for the compiler to parse all the locals and determine how much stack is needed.</p>

<p>Of course now, compilers are a lot more mature than they were 30 years ago. So it makes sense to get rid of this restriction as it's become a nuisance to programmers.</p>
"
"<p>I have a recursive function which can be written like:</p>

<pre><code>void func(TypeName *dataStructure, LL_Node **accumulator) {
    func(datastructure-&gt;left, accumulator);
    func(datastructure-&gt;right, accumulator);

    {
        char buffer[1000];
        // do some stuff
    }

    return;
}        
</code></pre>

<p>I know that in reality the buffer is being allocated at the beginning of the function and putting the statement in a nested scope block <a href=""http://stackoverflow.com/questions/2759371/in-c-do-braces-act-as-a-stack-frame"">doesn't actually use a new stack frame</a>. But I don't want the compiler to allocate an exponential number of 1000-byte buffers at once, when they can be allocated and thrown away one at a time as each level returns.</p>

<p>Should I use outside global variables? A call to a helper function to force the buffer to be allocated after the recursive call? What I'm really fishing for here is advice on the cleanest, most C-idiomatic way of forcing this behavior.</p>

<p>Edit: One add-on question. If the exact same <code>accumulator</code> will be passed to every call of <code>func</code>, is it unheard of to leave the <code>accumulator</code> pointer in a global variable rather than pushing it onto the stack with every call?</p>
","922184","","<p>Since it's only used by one call at a time, you can just preallocate it and pass it into all the calls via an operand:</p>

<pre><code>void func(TypeName *dataStructure, LL_Node **accumulator, char *buffer) {
    func(datastructure-&gt;left, accumulator, buffer);
    func(datastructure-&gt;right, accumulator, buffer);

    {
        // do some stuff
    }

    return;
}  
</code></pre>
"
"<p>I know this will seem like a really stupid question, but I just don't get why this isn't working. This:</p>

<pre><code> System.out.println(5 % .10);
</code></pre>

<p>And it's returning:</p>

<pre><code>0.09999999999999973
</code></pre>

<p>I really have NO IDEA. I'm just learning Java, and I'm pretty good with C#, so I tried with C# to. C# seemed to return the same thing also.</p>
","922184","","<p>This is due to floating-point precision. <code>0.10</code> cannot be represented exactly in binary. Therefore the result is not exactly <code>0.10</code> and is hence not modded down to <code>0</code>.</p>

<p>This will work with <code>0.25</code> because <code>0.25</code> <strong>can</strong> be represented exactly in binary.</p>

<p>EDIT:</p>

<p>In general, any number that can be expressed as a fraction with a power-of-two in the denominator can be expressed exactly in IEEE floating-point. (provided it doesn't over/underflow)</p>
"
"<p>Ok so I've used function pointers for some time. I was trying to figure out if this was possible.</p>

<p>First. It IS possible to convert a function pointer into an array of bytes.</p>

<p>It is also possible to reconstruct that function with the bytes in that array.</p>

<p>I would like to save a function into an array of bytes, and lets say save it to a text file (func.dat). Then later read that text file and execute the particular function...
Is it possible? It seems it should be possible the only problem I run across is finding the size of the array that makes up the function.</p>

<p>Is there any way to do this?</p>

<pre><code>int func()
{
    return 1+1;
}

int main()
{
    int (*foo)() = func;

    char* data = (char*)func;

    // write all the data
    char* copyFunc = new char[sizeof(func)];
    for(int i = 0; i &lt; sizeof(func); i++)
        copyFunc[i] = data[i];

    int (*constructedFoo)() = (int (*)())copyFunc;

    return 0;
}
</code></pre>

<p>of course this code won't compile because sizeof does not work for functions, does anyone know how to get the size of a function? Or the size of the function header/footer.</p>

<p>I have tried things like</p>

<pre><code>int func()
{
    1+1;
    new char('}');
}
</code></pre>

<p>Then searched for the } char (as the end of the function) but that size doesn't work.</p>

<p>If your wondering why I need it, it could be used for lets say, sending a function to a remote computer to execute (thinking of parallel processing) Or even saving a function in a file like in my first example to later be used, this can be helpful.</p>

<p>Any help is greatly appreciated.</p>
","922184","","<p>What you're trying to do is not possible in C/C++. First of all, functions may not be contiguous in memory in the binary. So there's no definite ""size"".</p>

<p>Secondly, you can't just load it into another program and execute it because it will violate memory protection (among other things, like address space).</p>

<p>Lastly (if you managed to get this far), all non-relative jumps and references in the function will likely be broken.</p>

<p>EDIT:</p>

<p>The way to go about sending code to remote computers is to send entire (compiled) binaries. Then have the local and remote machines communicate.</p>
"
"<p>I need to find the ratio of one floating-point number to another, and the ratio needs to be two integers. For example:</p>

<ul>
<li>input: <code>1.5, 3.25</code></li>
<li>output: <code>""6:13""</code></li>
</ul>

<p>Does anyone know of one? Searching the internet, I found no such algorithm, nor an algorithm for the least common multiple or denominator of two floating-point numbers (just integers).</p>

<h2>Java implementation:</h2>

<hr>

<p>This is the final implementation that I will use:</p>

<pre class=""lang-java prettyprint-override""><code>public class RatioTest
{
  public static String getRatio(double d1, double d2)//1.5, 3.25
  {
    while(Math.max(d1,d2) &lt; Long.MAX_VALUE &amp;&amp; d1 != (long)d1 &amp;&amp; d2 != (long)d2)
    {
      d1 *= 10;//15 -&gt; 150
      d2 *= 10;//32.5 -&gt; 325
    }
    //d1 == 150.0
    //d2 == 325.0
    try
    {
      double gcd = getGCD(d1,d2);//gcd == 25
      return ((long)(d1 / gcd)) + "":"" + ((long)(d2 / gcd));//""6:13""
    }
    catch (StackOverflowError er)//in case getGDC (a recursively looping method) repeats too many times
    {
      throw new ArithmeticException(""Irrational ratio: "" + d1 + "" to "" + d2);
    }
  }

  public static double getGCD(double i1, double i2)//(150,325) -&gt; (150,175) -&gt; (150,25) -&gt; (125,25) -&gt; (100,25) -&gt; (75,25) -&gt; (50,25) -&gt; (25,25)
  {
    if (i1 == i2)
      return i1;//25
    if (i1 &gt; i2)
      return getGCD(i1 - i2, i2);//(125,25) -&gt; (100,25) -&gt; (75,25) -&gt; (50,25) -&gt; (25,25)
    return getGCD(i1, i2 - i1);//(150,175) -&gt; (150,25)
  }
}
</code></pre>

<ul>
<li><code>-&gt;</code> indicates the next stage in the loop or method call</li>
</ul>

<h2>Mystical's implementation as Java:</h2>

<hr>

<p>Though I did not end up using this, it more than deserves to be recognized, so I translated it to Java, so I could understand it:</p>

<pre class=""lang-java prettyprint-override""><code>import java.util.Stack;

public class RatioTest
{
    class Fraction{
        long num;
        long den;
        double val;
    };

    Fraction build_fraction(Stack&lt;long&gt; cf){
        long term = cf.size();
        long num = cf[term - 1];
        long den = 1;
        while (term-- &gt; 0){
            long tmp = cf[term];

            long new_num = tmp * num + den;
            long new_den = num;

            num = new_num;
            den = new_den;
        }

        Fraction f;
        f.num = num;
        f.den = den;
        f.val = (double)num / (double)den;

        return f;
    }

    void get_fraction(double x){
        System.out.println(""x = "" + x);

        //  Generate Continued Fraction
        System.out.print(""Continued Fraction: "");
        double t = Math.abs(x);
        double old_error = x;
        Stack&lt;long&gt; cf;
        Fraction f;
        do{
            //  Get next term.
            long tmp = (long)t;
            cf.push(tmp);

            //  Build the current convergent
            f = build_fraction(cf);

            //  Check error
            double new_error = Math.abs(f.val - x);
            if (tmp != 0 &amp;&amp; new_error &gt;= old_error){
                //  New error is bigger than old error.
                //  This means that the precision limit has been reached.
                //  Pop this (useless) term and break out.
                cf.pop();
                f = build_fraction(cf);
                break;
            }
            old_error = new_error;
            System.out.print(tmp + "", "");

            //  Error is zero. Break out.
            if (new_error == 0)
                break;

            t -= tmp;
            t = 1/t;
        }while (cf.size() &lt; 39); //  At most 39 terms are needed for double-precision.
        System.out.println();System.out.println();

        //  Print Results
        System.out.println(""The fraction is:   "" + f.num + "" / "" + f.den);
        System.out.println(""Target x = "" + x);
        System.out.println(""Fraction = "" + f.val);
        System.out.println(""Relative error is: "" + (Math.abs(f.val - x) / x));System.out.println();
        System.out.println();
    }
    public static void main(String[] args){
        get_fraction(15.38 / 12.3);
        get_fraction(0.3333333333333333333);    //  1 / 3
        get_fraction(0.4184397163120567376);    //  59 / 141
        get_fraction(0.8323518818409020299);    //  1513686 / 1818565
        get_fraction(3.1415926535897932385);    //  pi
    }
}
</code></pre>

<h2>One MORE thing:</h2>

<hr>

<p>The above mentioned implemented way of doing this works <strong>IN THEORY</strong>, however, due to floating-point rounding errors, this results in alot of unexpected exceptions, errors, and outputs. Below is a practical, robust, but a bit dirty implementation of a ratio-finding algorithm (Javadoc'd for your convenience):</p>

<pre class=""lang-java prettyprint-override""><code>public class RatioTest
{
  /** Represents the radix point */
  public static final char RAD_POI = '.';

  /**
   * Finds the ratio of the two inputs and returns that as a &lt;tt&gt;String&lt;/tt&gt;
   * &lt;h4&gt;Examples:&lt;/h4&gt;
   * &lt;ul&gt;
   * &lt;li&gt;&lt;tt&gt;getRatio(0.5, 12)&lt;/tt&gt;&lt;ul&gt;
     *   &lt;li&gt;returns ""&lt;tt&gt;24:1&lt;/tt&gt;""&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;getRatio(3, 82.0625)&lt;/tt&gt;&lt;ul&gt;
   *   &lt;li&gt;returns ""&lt;tt&gt;1313:48&lt;/tt&gt;""&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;/ul&gt;
   * @param d1 the first number of the ratio
   * @param d2 the second number of the ratio
   * @return the resulting ratio, in the format ""&lt;tt&gt;X:Y&lt;/tt&gt;""
   */
  public static strictfp String getRatio(double d1, double d2)
  {
    while(Math.max(d1,d2) &lt; Long.MAX_VALUE &amp;&amp; (!Numbers.isCloseTo(d1,(long)d1) || !Numbers.isCloseTo(d2,(long)d2)))
    {
      d1 *= 10;
      d2 *= 10;
    }
    long l1=(long)d1,l2=(long)d2;
    try
    {
      l1 = (long)teaseUp(d1); l2 = (long)teaseUp(d2);
      double gcd = getGCDRec(l1,l2);
      return ((long)(d1 / gcd)) + "":"" + ((long)(d2 / gcd));
    }
    catch(StackOverflowError er)
    {
      try
      {
        double gcd = getGCDItr(l1,l2);
        return ((long)(d1 / gcd)) + "":"" + ((long)(d2 / gcd));
      }
      catch (Throwable t)
      {
        return ""Irrational ratio: "" + l1 + "" to "" + l2;
      }
    }
  }


  /**
   * &lt;b&gt;Recursively&lt;/b&gt; finds the Greatest Common Denominator (GCD)
   * @param i1 the first number to be compared to find the GCD
   * @param i2 the second number to be compared to find the GCD
   * @return the greatest common denominator of these two numbers
   * @throws StackOverflowError if the method recurses to much
   */
  public static long getGCDRec(long i1, long i2)
  {
    if (i1 == i2)
      return i1;
    if (i1 &gt; i2)
      return getGCDRec(i1 - i2, i2);
    return getGCDRec(i1, i2 - i1);
  }

  /**
   * &lt;b&gt;Iteratively&lt;/b&gt; finds the Greatest Common Denominator (GCD)
   * @param i1 the first number to be compared to find the GCD
   * @param i2 the second number to be compared to find the GCD
   * @return the greatest common denominator of these two numbers
   */
  public static long getGCDItr(long i1, long i2)
  {
    for (short i=0; i &lt; Short.MAX_VALUE &amp;&amp;  i1 != i2; i++)
    {
      while (i1 &gt; i2)
        i1 = i1 - i2;
      while (i2 &gt; i1)
        i2 = i2 - i1;
    }
      return i1;
  }

  /**
   * Calculates and returns whether &lt;tt&gt;d1&lt;/tt&gt; is close to &lt;tt&gt;d2&lt;/tt&gt;
   * &lt;h4&gt;Examples:&lt;/h4&gt;
   * &lt;ul&gt;
   * &lt;li&gt;&lt;tt&gt;d1 == 5&lt;/tt&gt;, &lt;tt&gt;d2 == 5&lt;/tt&gt;
   *   &lt;ul&gt;&lt;li&gt;returns &lt;tt&gt;true&lt;/tt&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;d1 == 5.0001&lt;/tt&gt;, &lt;tt&gt;d2 == 5&lt;/tt&gt;
   *   &lt;ul&gt;&lt;li&gt;returns &lt;tt&gt;true&lt;/tt&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;d1 == 5&lt;/tt&gt;, &lt;tt&gt;d2 == 5.0001&lt;/tt&gt;
   *   &lt;ul&gt;&lt;li&gt;returns &lt;tt&gt;true&lt;/tt&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;d1 == 5.24999&lt;/tt&gt;, &lt;tt&gt;d2 == 5.25&lt;/tt&gt;
   *   &lt;ul&gt;&lt;li&gt;returns &lt;tt&gt;true&lt;/tt&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;d1 == 5.25&lt;/tt&gt;, &lt;tt&gt;d2 == 5.24999&lt;/tt&gt;
   *   &lt;ul&gt;&lt;li&gt;returns &lt;tt&gt;true&lt;/tt&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;d1 == 5&lt;/tt&gt;, &lt;tt&gt;d2 == 5.1&lt;/tt&gt;
   *   &lt;ul&gt;&lt;li&gt;returns &lt;tt&gt;false&lt;/tt&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;
   * &lt;/ul&gt;
   * @param d1 the first number to compare for closeness
   * @param d2 the second number to compare for closeness
   * @return &lt;tt&gt;true&lt;/tt&gt; if the two numbers are close, as judged by this method
   */
  public static boolean isCloseTo(double d1, double d2)
  {
    if (d1 == d2)
      return true;
    double t;
    String ds = Double.toString(d1);
    if ((t = teaseUp(d1-1)) == d2 || (t = teaseUp(d2-1)) == d1)
      return true;
    return false;
  }

  /**
   * continually increases the value of the last digit in &lt;tt&gt;d1&lt;/tt&gt; until the length of the double changes
   * @param d1
   * @return
   */
  public static double teaseUp(double d1)
  {
    String s = Double.toString(d1), o = s;
    byte b;
    for (byte c=0; Double.toString(extractDouble(s)).length() &gt;= o.length() &amp;&amp; c &lt; 100; c++)
      s = s.substring(0, s.length() - 1) + ((b = Byte.parseByte(Character.toString(s.charAt(s.length() - 1)))) == 9 ? 0 : b+1);
    return extractDouble(s);
  }

  /**
   * Works like Double.parseDouble, but ignores any extraneous characters. The first radix point (&lt;tt&gt;.&lt;/tt&gt;) is the only one treated as such.&lt;br/&gt;
   * &lt;h4&gt;Examples:&lt;/h4&gt;
   * &lt;li&gt;&lt;tt&gt;extractDouble(""123456.789"")&lt;/tt&gt; returns the double value of &lt;tt&gt;123456.789&lt;/tt&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;extractDouble(""1qw2e3rty4uiop[5a'6.p7u8&amp;9"")&lt;/tt&gt; returns the double value of &lt;tt&gt;123456.789&lt;/tt&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;extractDouble(""123,456.7.8.9"")&lt;/tt&gt; returns the double value of &lt;tt&gt;123456.789&lt;/tt&gt;&lt;/li&gt;
   * &lt;li&gt;&lt;tt&gt;extractDouble(""I have $9,862.39 in the bank."")&lt;/tt&gt; returns the double value of &lt;tt&gt;9862.39&lt;/tt&gt;&lt;/li&gt;
   * @param str The &lt;tt&gt;String&lt;/tt&gt; from which to extract a &lt;tt&gt;double&lt;/tt&gt;.
   * @return the &lt;tt&gt;double&lt;/tt&gt; that has been found within the string, if any.
   * @throws NumberFormatException if &lt;tt&gt;str&lt;/tt&gt; does not contain a digit between 0 and 9, inclusive.
   */
  public static double extractDouble(String str) throws NumberFormatException
  {
    try
    {
      return Double.parseDouble(str);
    }
    finally
    {
      boolean r = true;
      String d = """";
      for (int i=0; i &lt; str.length(); i++)
        if (Character.isDigit(str.charAt(i)) || (str.charAt(i) == RAD_POI &amp;&amp; r))
        {
          if (str.charAt(i) == RAD_POI &amp;&amp; r)
            r = false;
          d += str.charAt(i);
        }
      try
      {
        return Double.parseDouble(d);
      }
      catch (NumberFormatException ex)
      {
        throw new NumberFormatException(""The input string could not be parsed to a double: "" + str);
      }
    }
  }
}
</code></pre>
","922184","","<p>This is a fairly non-trivial task. The best approach I know that gives reliable results for any two floating-point is to use <a href=""http://en.wikipedia.org/wiki/Continued_fraction"" rel=""nofollow"">continued fractions</a>.</p>

<p>First, divide the two numbers to get the ratio in floating-point. Then run the continued fraction algorithm until it terminates. If it doesn't terminate, then it's irrational and there is no solution.</p>

<p>If it terminates, evaluate the resulting continued fraction back into a single fraction and that will be the answer.</p>

<p>Of course, there is no reliable way to determine if there is a solution or not since this becomes the halting problem. But for the purposes of limited precision floating-point, if the sequence doesn't terminate with a reasonable number of steps, then assume there's no answer.</p>

<p><strong>EDIT 2:
Here's an update to my original solution in C++. This version is much more robust and seems to work with any positive floating-point number except for <code>INF</code>, <code>NAN</code>, or extremely large or small values that would overflow an integer.</strong></p>

<pre><code>typedef unsigned long long  uint64;
struct Fraction{
    uint64 num;
    uint64 den;
    double val;
};
Fraction build_fraction(vector&lt;uint64&gt; &amp;cf){
    uint64 term = cf.size();
    uint64 num = cf[--term];
    uint64 den = 1;
    while (term-- &gt; 0){
        uint64 tmp = cf[term];

        uint64 new_num = tmp * num + den;
        uint64 new_den = num;

        num = new_num;
        den = new_den;
    }

    Fraction f;
    f.num = num;
    f.den = den;
    f.val = (double)num / den;

    return f;
}
void get_fraction(double x){
    printf(""x = %0.16f\n"",x);

    //  Generate Continued Fraction
    cout &lt;&lt; ""Continued Fraction: "";
    double t = abs(x);
    double old_error = x;
    vector&lt;uint64&gt; cf;
    Fraction f;
    do{
        //  Get next term.
        uint64 tmp = (uint64)t;
        cf.push_back(tmp);

        //  Build the current convergent
        f = build_fraction(cf);

        //  Check error
        double new_error = abs(f.val - x);
        if (tmp != 0 &amp;&amp; new_error &gt;= old_error){
            //  New error is bigger than old error.
            //  This means that the precision limit has been reached.
            //  Pop this (useless) term and break out.
            cf.pop_back();
            f = build_fraction(cf);
            break;
        }
        old_error = new_error;
        cout &lt;&lt; tmp &lt;&lt; "", "";

        //  Error is zero. Break out.
        if (new_error == 0)
            break;

        t -= tmp;
        t = 1/t;
    }while (cf.size() &lt; 39); //  At most 39 terms are needed for double-precision.
    cout &lt;&lt; endl &lt;&lt; endl;

    //  Print Results
    cout &lt;&lt; ""The fraction is:   "" &lt;&lt; f.num &lt;&lt; "" / "" &lt;&lt; f.den &lt;&lt; endl;
    printf(""Target x = %0.16f\n"",x);
    printf(""Fraction = %0.16f\n"",f.val);
    cout &lt;&lt; ""Relative error is: "" &lt;&lt; abs(f.val - x) / x &lt;&lt; endl &lt;&lt; endl;
    cout &lt;&lt; endl;
}
int main(){
    get_fraction(15.38 / 12.3);
    get_fraction(0.3333333333333333333);    //  1 / 3
    get_fraction(0.4184397163120567376);    //  59 / 141
    get_fraction(0.8323518818409020299);    //  1513686 / 1818565
    get_fraction(3.1415926535897932385);    //  pi
    system(""pause"");
}
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>x = 1.2504065040650407
Continued Fraction: 1, 3, 1, 152, 1,

The fraction is:   769 / 615
Target x = 1.2504065040650407
Fraction = 1.2504065040650407
Relative error is: 0


x = 0.3333333333333333
Continued Fraction: 0, 3,

The fraction is:   1 / 3
Target x = 0.3333333333333333
Fraction = 0.3333333333333333
Relative error is: 0


x = 0.4184397163120567
Continued Fraction: 0, 2, 2, 1, 1, 3, 3,

The fraction is:   59 / 141
Target x = 0.4184397163120567
Fraction = 0.4184397163120567
Relative error is: 0


x = 0.8323518818409020
Continued Fraction: 0, 1, 4, 1, 27, 2, 7, 1, 2, 13, 3, 5,

The fraction is:   1513686 / 1818565
Target x = 0.8323518818409020
Fraction = 0.8323518818409020
Relative error is: 0


x = 3.1415926535897931
Continued Fraction: 3, 7, 15, 1, 292, 1, 1, 1, 2, 1, 3, 1, 14, 3,

The fraction is:   245850922 / 78256779
Target x = 3.1415926535897931
Fraction = 3.1415926535897931
Relative error is: 0


Press any key to continue . . .
</code></pre>

<p>The thing to notice here is that it gives <code>245850922 / 78256779</code> for <code>pi</code>. Obviously, <strong>pi is irrational</strong>. But as far as double-precision allows, <code>245850922 / 78256779</code> isn't any different from <code>pi</code>.</p>

<p>Basically, any fraction with 8 - 9 digits in the numerator/denominator has enough entropy to cover nearly all DP floating-point values (barring corner cases like <code>INF</code>, <code>NAN</code>, or extremely large/small values).</p>
"
"<p>I'm doing a study assignment to measure memory access time on my machine.
To determine the clock cycles on our machines, we have been given the following C snippet:</p>

<pre><code>static inline void getcyclecount(uint64_t* cycles)
{
    __asm __volatile(
                     ""cpuid            # force all previous instruction to complete\n\t""
                     ""rdtsc            # TSC -&gt;  edx:eax \n\t""
                     ""movl %%edx, 4(0) # store edx\n\t""
                     ""movl %%eax, 0(0) # store eax\n\t""
                     : : ""r""(cycles) : ""eax"", ""ebx"", ""ecx"", ""edx"");
}
</code></pre>

<p>However, when I try to compile this (XCode 4, using ""Apple LLVM Compiler 2.1""), it results twice in the error ""Unexpected token in memory operand"" at the ""\t"" of the rdtsc resp. first movl instruction line. </p>

<p>I know basic assembler, but have no clue about the C inline assembler format.</p>

<p>Does anyone of you know what could be the issue with this code?</p>

<p>Thanks!</p>
","922184","","<p>Assuming this is GCC inline assembly syntax, you're missing a <code>%</code> in the memory operand:</p>

<pre><code>__asm __volatile(
                 ""cpuid            # force all previous instruction to complete\n\t""
                 ""rdtsc            # TSC -&gt;  edx:eax \n\t""
                 ""movl %%edx, 4(%0) # store edx\n\t""
                 ""movl %%eax, 0(%0) # store eax\n\t""
                 : : ""r""(cycles) : ""eax"", ""ebx"", ""ecx"", ""edx"");
</code></pre>
"
"<p>Ok, so I'm not really sure what is going on here.  I have a simple function, <code>int foo(char *filename)</code>, that takes <code>filename</code> and counts the words in a file.</p>

<pre><code>int foo(char *filename){

  FILE *inFile;
  int wordCount = 0;    

  printf(""foo\n""); // test printf() statement (currently prints)

  char word[50];
  inFile = (&amp;filename, ""r"");

  printf(""infile\n"");  // test printf() statement (currently prints)

  while (1){
    printf(""while"");   // test printf() statement (doesn't print)
    fscanf(inFile, ""%s"", word);
    if (feof(inFile))
        break;
    printf(""%d"", wordCount); //test printf() statement
    wordCount++;
  }
  fclose(inFile);
  return wordCount;

}
</code></pre>

<p>As you can see, I print ""infile"", but not ""while"". I get a segmentation fault. Does anyone have any idea why this doesn't work  Also, is my <code>inFile = (&amp;filename, ""r"");</code> statement correct? I'm not that great with pointers.</p>
","922184","","<p>I'm surprised this line actually compiles:</p>

<pre><code>inFile = (&amp;filename, ""r"");
</code></pre>

<p>If you're trying to open a file:</p>

<pre><code>inFile = fopen(filename, ""r"");
</code></pre>

<p>EDIT:</p>

<p>And as mentioned, you need to end your <code>printf</code>s with <code>\n</code> or call <code>fflush(stdout)</code> or it will get buffered and not print.</p>
"
"<p>for an assignment I have to write a program that will take in an 8 character string(hexadecimal) and then convert it to base 10. I am not allowed to use any outside classes to do this. I'm pretty sure I have it working properly... for positive numbers only. My problem is how to show negative numbers.
an example is that FFFFFFFA should print out as -6
This is my code so far</p>

<pre><code>package hexconverter;

import java.util.*;

/**
 *
 * @author Steven
 */
public class Main {

    Scanner scanner = new Scanner(System.in);

    public void doWork() {



        System.err.println(""Please enter the internal representation: "");
        String hex;
        hex = scanner.next();
        hex = hex.toUpperCase();

        long count = 1;
        long ans = 0;

        for (int i = 7; i &gt;= 0; i--) {
            Character c = hex.charAt(i);

            if (c != '1' &amp;&amp; c != '2' &amp;&amp; c != '3' &amp;&amp; c != '4' &amp;&amp; c != '5' &amp;&amp; c != '6' &amp;&amp; c != '7' &amp;&amp; c != '8' &amp;&amp; c != '9') {
                int num = fixLetters(c);
                ans = ans + (num * count);
                count = count * 16;
            } else {

                String s = c.toString(c);
                long num = Integer.parseInt(s);
                ans = ans + (num * count);
                count = count * 16;
            }
        }

       if (ans &gt; 2147483647) {
            System.out.println(""is negative"");


       } else {
            System.out.println(ans);
       }
    }

    public int fixLetters(Character c) {
        if (c.equals('A')) {
            return 10;
        } else if (c.equals('B')) {
            return 11;
        } else if (c.equals('C')) {
            return 12;
        } else if (c.equals('D')) {
            return 13;
        } else if (c.equals('E')) {
            return 14;
        } else if (c.equals('F')) {
            return 15;
        } else {
            return 0;
        }

    }

    public static void main(String[] args) {
        // TODO code application logic here
        Main a = new Main();
        a.doWork();
    }
}
</code></pre>

<p>I think my test for a negative integer is correct... since that is the highest value 32 bits can hold, anything over that will be an overflow so that means it should be negative.
From here I have no idea how to go about this. Any pointers or tips would be greatly appreciated. If there is no way to do it mathematically I feel like I am going to have to convert the hex into binary and then perform twos complements on it, but again I dont know where to start.</p>

<p>Thanks in advance</p>
","922184","","<p>If the number is negative (> 2147483647) in your code, just subtract <code>2^32</code> (4294967296) from it. Then print it out.</p>

<pre><code>if (ans &gt; 2147483647) {
        System.out.println(ans - 4294967296L);
   } else {
        System.out.println(ans);
   }
</code></pre>
"
"<pre><code>void main()
{
  char name[20];

  printf(""\n enter Your Name: "");
  gets(name);

  switch(name)
  {
    default : printf( ""Invalid"" );
  }

  getch();
}
</code></pre>

<p>So my question: is a char array OR Simple array valid in expression for switch and, if it is valid, then what are the case values?</p>
","922184","","<p>The <code>switch</code> statement is using the address of the character array as the parameter. So no it won't work as you expect it to.</p>

<p>It follows the same reason why you can't throw strings into a switch and expect it to work. (and same with string comparisons)</p>
"
"<p>In my application ,I am allocating memory to store ""volume data"" which read from stack of bitmap images.</p>

<p>I stored the data in a ""unsigned char"" and ,during allocation, first I try to allocate continuous memory-block for entire data.if that fails then tries for scattered allocation.(one small memory-block for each image).</p>

<pre><code>unsigned char *data;
</code></pre>

<p>here is my method to allocate memory,I call with ""tryContinouseBlock=true"".</p>

<pre><code> bool RzVolume::initVolumeData(int xsize, int ysize, int zsize, int bbpsize,bool tryContinouseBlock) {
        this-&gt;nx = xsize;
        this-&gt;ny = ysize;
        this-&gt;nz = zsize;
        this-&gt;bbp_type=bbpsize;

        bool succ = false;

        if (tryContinouseBlock) {
            succ = helper_allocContinouseVolume(xsize, ysize, zsize, bbpsize);
        }

        if (!succ) {
            succ = helper_allocScatteredVolume(xsize, ysize, zsize, bbpsize);
        } else {
            isContinousAlloc = true;
        }
        if (!succ) {
            qErrnoWarning(""Critical ERROR - Scattered allocation also failed!!!!"");
        }
        return succ;

    }



    bool RzVolume::helper_allocContinouseVolume(int xsize, int ysize, int zsize,
            int bbpsize) {
        try {
            data = new unsigned char*[1];
            int total=xsize*ysize*zsize*bbpsize;
            data[0] = new unsigned char[total];
            qDebug(""VoxelData allocated - Continouse! x=%d y=%d Z=%d bytes=%d"",xsize,ysize,zsize,xsize * ysize * zsize * bbpsize);
        } catch (std::bad_alloc e) {
            return false;
        }

        return true;

    }

bool RzVolume::helper_allocScatteredVolume(int xsize, int ysize, int zsize,
        int bbpsize) {
    data = new unsigned char*[zsize];
    //isContinousAlloc=false;
    int allocCount = 0;
    try { //Now try to allocate for each image
        for (int i = 0; i &lt; zsize; i++) {
            data[i] = new unsigned char[xsize * ysize];
            allocCount++;
        }
    } catch (std::bad_alloc ee) {
        //We failed to allocated either way.Failed!

        //deallocate any allocated memory;
        for (int i = 0; i &lt; allocCount; i++) {
            delete data[i];
        }
        delete data;
        data = NULL;
        return false;
    }
    qDebug(""VoxelData allocated - Scattered!"");
    return true;
}
</code></pre>

<p>I want this code to run in both 32bit and 64bit platforms.</p>

<p>Now the problem is, even in 64Bit environment (with 12Gb memory) ,<strong>helper_allocContinouseVolume()</strong> method fails when I load (1896*1816*1253) size of data (with bbpsize=1).
Its because of, I use ""int"" datatype for memory address access and the maxmum of ""int"" is 4294967295.</p>

<p>In both 32bit and 64bit environment following code gives the value ""19282112"".</p>

<pre><code> int sx=1896;
 int sy=1816;
 int sz=1253;
 printf(""%d"",sx*sy*sz);
</code></pre>

<p>where the correct value should be ""4314249408"".</p>

<p>So which datatype should I use for this ? I want to use the same code in 32bit and 64bit environments.</p>
","922184","","<p>I encounter the same problem very often when working on workstations with > 32GB of memory and large datasets.</p>

<p><code>size_t</code> is generally the right datatype to use for all indices in such situations as it ""usually"" matches the pointer size and stays compatible with <code>memcpy()</code> and other library functions.</p>

<p>The only problem is that on 32-bit, it may be hard to detect cases where it overflows. So it may be worthwhile to use a separate memory computation stage using the maximum integer size to see if it's even possible on 32-bit so that you can handle it gracefully.</p>
"
"<p>The numbers I'm trying to figure out are in this form (some examples):</p>

<p><code>2 ^ 7 - 1</code>, <code>2 ^ 31 - 1</code>, <code>2 ^ 127 - 1</code>, et cetera.</p>

<p>This is not a homework question I was just researching primes and a lot of the information is going a bit over my head (Fourier transformations). Originally I was just using a function like this:</p>

<pre><code>public static bool IsPrime(int candidate)
{
    if ((candidate &amp; 1) == 0)
    {
        return candidate == 2;
    }

    for (int i = 3; (i * i) &lt;= candidate; i += 2)
    {
        if ((candidate % i) == 0)
        {
            return false;
        }
    }

    return candidate != 1;
}
</code></pre>

<p>But that stopped working once the numbers got too big. I also looked in to the <a href=""http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"" rel=""nofollow"">Sieve of Eratosthenes</a> but apparently that only works for numbers of much smaller size.</p>

<p>To clarify, I'm not looking to write a program to <em>find</em> prime numbers, but rather, to determine if a given number is prime. I was looking in to the <a href=""http://msdn.microsoft.com/en-us/library/system.numerics.biginteger.aspx"" rel=""nofollow"">BigInteger</a> structure in the .NET Framework and it looks promising if I could just write an efficient enough algorithm (I'd settle for something that finished in days).</p>

<p>I'm not sure if a mathematical proof would be better in this circumstance but I do not have much knowledge in that area as opposed to programming but if there was a proof that specialized in these kinds of numbers, that'd definitely be worth looking in to.</p>

<p>Thanks.</p>
","922184","","<p>The numbers that you list: <code>2 ^ 7 - 1, 2 ^ 31 - 1, 2 ^ 127 - 1</code> are called <a href=""http://en.wikipedia.org/wiki/Mersenne_prime"" rel=""nofollow"">Mersenne Numbers</a>. There's already an entire distributed computing project to find those. It's called <a href=""http://en.wikipedia.org/wiki/Great_Internet_Mersenne_Prime_Search"" rel=""nofollow"">GIMPS</a>.</p>

<p>So the answer to your question is not trivial. All the currently existing known primes of that form are listed here:</p>

<p><a href=""http://en.wikipedia.org/wiki/Mersenne_prime#List_of_known_Mersenne_primes"" rel=""nofollow"">http://en.wikipedia.org/wiki/Mersenne_prime#List_of_known_Mersenne_primes</a></p>
"
"<p>So I'm seg faulting when I call printf in the following situation.  I just can't see what I'm doing wrong. Any ideas?  Thanks a million.  I've marked the spot in the code where i get the seg fault with a comment (in the first chunk of code).</p>

<pre><code>...
    char* command_to_run;
    if(is_command_built_in(exec_args, command_to_run)){
        //run built in command
        printf(""command_to_run = %s\n"", command_to_run); // &lt;--- this is where the problem is
        run_built_in_command(exec_args);
    }
...

int is_command_built_in(char** args, char* matched_command){
    char* built_in_commands[] = {""something"", ""quit"", ""hey""};
    int size_of_commands_arr = 3;
    int i;
    //char* command_to_execute;
    for(i = 0; i &lt; size_of_commands_arr; i++){
        int same = strcmp(args[0], built_in_commands[i]);
        if(same == 0){
            //they were the same
            matched_command = built_in_commands[i];
            return 1;
        }
    }
    return 0;
}
</code></pre>
","922184","","<p>You're passing the pointer <code>matched_command</code> by value. Therefore it isn't changed by the call to <code>is_command_built_in</code>. So it retains it's uninitialized value.</p>

<p>Try this:</p>

<pre><code>char* command_to_run;
if(is_command_built_in(exec_args, &amp;command_to_run)){   //  Changed this line.
    //run built in command
    printf(""command_to_run = %s\n"", command_to_run); // &lt;--- this is where the problem is
    run_built_in_command(exec_args);
}


int is_command_built_in(char** args, char** matched_command){   //  Changed this line.
    char* built_in_commands[] = {""something"", ""quit"", ""hey""};
    int size_of_commands_arr = 3;
    int i;
    //char* command_to_execute;
    for(i = 0; i &lt; size_of_commands_arr; i++){
        int same = strcmp(args[0], built_in_commands[i]);
        if(same == 0){
            //they were the same
            *matched_command = built_in_commands[i];   //  And changed this line.
            return 1;
        }
    }
    return 0;
}
</code></pre>
"
"<p>So I know functionally what I would like to happen, I just don't know the best way to make a computer do it... in C++...</p>

<p>I would like to implement a C++ function that maps a 10 bit sequence to a 6 bit sequence.</p>

<p>Nevermind what the bits stand for right now... There are 2^10 = 1024 possible inputs. There are 2^6 = 64 different outputs. Probably lots of patterns. Obviously lots of patterns. But it's complicated. It's s a known mapping, just a complicated mapping.</p>

<p>The output is just one of 64 possibilities.  Maybe they all don't get used.  They probably won't.  But assume they do.</p>

<p>Right now, I'm thinking a quadruple nested switch statement that just takes care of each of the 1024 cases and takes care of business inline, assigning appropriate values to whatever pointer to whatever structure I passed to this function. This seems to be naive and sort of slow. Not that I've implemented it, but that's why I want to ask you first.</p>

<p>This basic function (mapping) will have to be run at every statement node, often more than once, for as many statements this system wishes to support. I ask you, how do I map 10 bits to 6 bits as efficiently as possible in C++?</p>

<p>I know what the mapping is, I know which inputs of 10 bits go with what output of 6 bits... I could totally hard-code that ... somehow? Multi-switch is so ugly. How can I map my 10 bits to 6 bits?! Neural net? Memory muffin? What would you do?</p>

<p>Note to self:  So here is why I am not a fan of the lookup table.  Let's assume all inputs are equally likely (of course they are not, and could be ordered more effectively, but still) then it will take on average 512 memory advances of the array to retrieve the output values... It seems that if you make a (global, why not) binary tree 10 levels deep, you cover the 1024 inputs and can retrieve the output in an average of just 10 steps...  and maybe less if there are good patterns... given a deterministic function that is run so often, how best to retrieve known outputs from known inputs?</p>
","922184","","<p>I would use a lookup table of 1024 elements. So hard-code that and just access it by index.</p>

<p>This saves the need for a massive switch statement and will probably be much more readable.</p>
"
"<p>I am aware that there are a number of primality testing algorithms used in practice (Sieve of Eratosthenes, Fermat's test, Miller-Rabin, AKS, etc). However, they are either slow (e.g. sieve), probabalistic (Fermat and Miller-Rabin), or relatively difficult to implement (AKS).</p>

<p>What is the best deterministic solution to determine whether or not a number is prime?</p>

<p>Note that I am primarily (pun intended) interested in testing against numbers on the order of 32 (and maybe 64) bits. So a robust solution (applicable to larger numbers) is not necessary.</p>
","922184","","<p>Up to <code>~2^30</code> you could brute force with trial-division.</p>

<p>Up to <code>3.4*10^14</code>, <a href=""http://mathworld.wolfram.com/Rabin-MillerStrongPseudoprimeTest.html"">Rabin-Miller with the first 7 primes has been proven to be deterministic</a>.</p>

<p>Above that, you're on your own. There's no known sub-cubic deterministic algorithm.</p>

<p><strong>EDIT : I remembered this, but I didn't find the reference until now:</strong></p>

<p><a href=""http://reference.wolfram.com/legacy/v5_2/book/section-A.9.4"">http://reference.wolfram.com/legacy/v5_2/book/section-A.9.4</a></p>

<blockquote>
  <p>PrimeQ first tests for divisibility using small primes, then uses the
  Miller-Rabin strong pseudoprime test base 2 and base 3, and then uses
  a Lucas test.</p>
  
  <p>As of 1997, this procedure is known to be correct only for <code>n &lt; 10^16</code>,
  and it is conceivable that for larger <code>n</code> it could claim a composite
  number to be prime.</p>
</blockquote>

<p>So if you implement Rabin-Miller and Lucas, <strong>you're good up to 10^16</strong>.</p>
"
"<p>I have this code in linux kernel:</p>

<pre><code>#define task_cred_xxx(task, xxx)                        
({                                                      
    __typeof__(((struct cred *)NULL)-&gt;xxx) ___val;  
    rcu_read_lock();                               
    ___val = __task_cred((task))-&gt;xxx;              
    rcu_read_unlock();                              
    ___val;                                         
})
</code></pre>

<p>I never saw macro defined like this before, does that mean this is task_cred_xxx(task, xxx) returns ___val?</p>

<p>Thanks!</p>
","922184","","<p>Correct. It will return <code>___val</code>. However, block expressions like these are a GNU extension and isn't actually part of the C standard.</p>

<p><a href=""http://www.toofishes.net/blog/gcc-compound-statement-expressions/"" rel=""nofollow"">http://www.toofishes.net/blog/gcc-compound-statement-expressions/</a></p>
"
"<p>Attempting the following exponential integral:</p>

<pre><code>Integrate[  Exp[-2 A Sqrt[x^2 + a^2] + I ( x Subscript[k, x] + b )],
            {x, 0,   Infinity}
]
</code></pre>

<p>I get back something that is pretty printed, but not evaluated?  Does this mean that Mathematica could not perform the integral and gave up?  I don't see any messages saying that's what happened.</p>

<p>To provide context for this question, this is a stripped down to one dimension version of the integral I'd done with paper and pencil:</p>

<pre><code>\int d^3 r e^{ i \vec{k} \cdot \vec{r} } e^{ - 2 Z r/ a_0 }
</code></pre>

<p>The point of trying mathematica was to see if I could verify my result:</p>

<pre><code>16 \pi Z a_0^3/(4 Z^2 + k^2 a_0^2)^2
</code></pre>
","922184","","<p>Correct, when Mathematica spits the integral back out it usually means it doesn't know how to do it. Sometimes, it can only do the integral under certain assumptions (such as `a > 0' and real), but it will usually give the answer as a gigantic if-statement with those.</p>

<p>This particular integral you have is not trivial at all. And it doesn't fit the form of any of the special functions that I'm familiar with. So it's possible that it can't be expressed in closed form in terms of the special functions that Mathematica has.</p>

<p>Also, what's the point of the <code>Subscript[k, x]</code>? I tried removing it and Mathematica still can't do the integral.</p>
"
"<p>[Homework disclaimer]</p>

<p>I'm working on the <a href=""http://csapp.cs.cmu.edu/public/README-bomblab"" rel=""nofollow"">binary bomb lab</a>. Basically, I have to use the objdump of a ""bomb"" executable to find the right input strings to disarm the ""bomb."" Currently I've solved 5/7 phases and am working on the 6th phase which contains this assembly:</p>

<pre><code> 8048eb0:   39 18                   cmp    %ebx,(%eax)
 8048eb2:   74 05                   je     8048eb9 &lt;phase_6+0x49&gt;
 8048eb4:   e8 d0 0a 00 00          call   8049989 &lt;explode_bomb&gt;
</code></pre>

<p>To not explode the bomb, I need to set ebx and eax to same value so that <code>je</code> is called instead of the <code>explode_bomb</code> function. So, I found an input string that gives the same value of ebx and eax. However, when I reach this point in the program's execution, the <code>je</code> isn't called even though ebx and eax are the same value. In GDB:</p>

<pre><code>Good work!  On to the next...
134530284

Breakpoint 2, 0x08048e74 in phase_6 ()
Current language:  auto; currently asm
(gdb) break *0x8048eb0
Breakpoint 3 at 0x8048eb0
(gdb) c
Continuing.

Breakpoint 3, 0x08048eb0 in phase_6 ()
(gdb) print $ebx
$1 = 134530284
(gdb) print $eax
$2 = 134530284
(gdb) si
0x08048eb2 in phase_6 ()
(gdb) si
0x08048eb4 in phase_6 ()
(gdb) si
0x08049989 in explode_bomb ()
(gdb) 
</code></pre>

<p>Why is this not working? This is the first time this assignment where this issue has come up.</p>
","922184","","<p><code>(%eax)</code> is not the same as <code>%eax</code>.</p>

<p>(%eax) means load the value pointed to by <code>eax</code>, not <code>eax</code> itself.</p>
"
"<p>In the recent interview I got a question like this : </p>

<p><code>Given a string value, find out its 127th bit and reset it, do this in C language</code>
<code>Reset means if that particular bit is 0 change to 1 and vice versa</code></p>

<p>I didn't find out any algorithm for this, but I want to know about how one could solve this in <code>C</code> language. </p>

<h2>Edit:</h2>

<p>After getting the answer from few, I tried this : </p>

<pre><code>#include&lt;stdio.h&gt;
void main()
{
    char *str=""anto"";
    str[15] ^= 0x80;
    printf(""%s"",str);
}
</code></pre>

<p>I get the output as : <code>anto</code>. Now I got strike in my head that changing a bit doesn't change the output?</p>
","922184","","<p>Assuming <code>char</code> is 8 bits and the endian is little-endian:</p>

<pre><code>char *str = ...;

str[15] ^= 0x80;
</code></pre>

<p>This will flip the 127th bit.</p>

<p>EDIT:</p>

<p>If the bit-endian is big-endian, then use <code>0x01</code> instead.</p>

<p>The answer also depends on how the bits are numbered. If we start numbering from 0, the use <code>0x80</code>. If we index from 1, then we use <code>0x40</code>. (<code>0x01</code> and <code>0x02</code> for big-endian)</p>

<p><strong>EDIT 2 :
Here's the general case: (with the same assumptions)</strong></p>

<pre><code>char *str = ...;
int bit = 127;

int index = bit / 8;   //  Get the index
int chbit = bit % 8;   //  Get which bit in the char

int mask = 1 &lt;&lt; chbit; //  Build the mask

str[index] ^= mask;    //  XOR to flip the bit.
</code></pre>
"
"<p>I'm trying to run several instances of a piece of code (2000 instances or so) concurrently in a computing cluster.  The way it works is that I submit the jobs and the cluster will run them as nodes open up every so often, with several jobs per node.  This seems to produce the same values for a good number of the instances in their random number generation, which uses a time-seed.  </p>

<p>Is there a simple alternative I can use instead?  Reproducibility and security are not important, quick generation of unique seeds is.  What would be the simplest approach to this, and if possible a cross platform approach would be good.  </p>
","922184","","<p>The <code>rdtsc</code> instruction is a pretty reliable (and random) seed.</p>

<p>In Windows it's accessible via the <code>__rdtsc()</code> intrinsic.</p>

<p>In GNU C, it's accessible via:</p>

<pre><code>unsigned long long rdtsc(){
    unsigned int lo,hi;
    __asm__ __volatile__ (""rdtsc"" : ""=a"" (lo), ""=d"" (hi));
    return ((unsigned long long)hi &lt;&lt; 32) | lo;
}
</code></pre>

<p>The instruction measures the total pseudo-cycles since the processor was powered on. Given the high frequency of today's machines, it's extremely unlikely that two processors will return the same value even if they booted at the same time and are clocked at the same speed.</p>
"
"<p>Wow I thought I knew my C++ but this is weird</p>

<p>This function returns an unsigned int so I thought that means I will never get a negative number returned right?</p>

<p>The function determines how many hours ahead or behind of UTC you are. So for me I'm in Australia, Sydney so I am +10 GMT which means I am UTC = LocalTime + (-10). Therefore the GetTimeZoneInformation correctly determines I am -10.</p>

<p><strong>BUT my function returns an unsigned int so shouldn't it return 10 not -10?</strong></p>

<pre><code>unsigned int getTimeZoneBias()
{
    TIME_ZONE_INFORMATION tzInfo;
    DWORD res  = GetTimeZoneInformation( &amp;tzInfo );

    if ( res == TIME_ZONE_ID_INVALID )
    {
        return (INT_MAX/2); 
    }

    return (unsigned int(tzInfo.Bias / 60));  // convert from minutes to hours         
}

TCHAR ch[200];
_stprintf( ch, _T(""A: %d\n""), getTimeZoneBias()); // this prints out A: -10
debugLog += _T(""Bias: "") + tstring(ch) + _T(""\r\n"");
</code></pre>
","922184","","<p>Here's what I think is happening:</p>

<p>The value of <code>tzInfo.Bias</code> is actually -10. (<code>0xFFFFFFF6</code>)
On most systems, casting a signed integer to an unsigned integer of the same size does nothing to the representation.</p>

<p>So the function still returns <code>0xFFFFFFF6</code>.</p>

<p>But when you print it out, you're printing it back as a signed integer. So it prints<code>-10</code>. If you printed it as an unsigned integer, you'll probably get <code>4294967286</code>.</p>

<p>What you're probably trying to do is to get the absolute value of the time difference. So you want to convert this -10 into a 10. In which you should return <code>abs(tzInfo.Bias / 60)</code>.</p>
"
"<p>Is there a better agorithm to do the following?</p>

<p>I am trying to generate 50 random numbers that are divisible by 7. I then select one of those 50 at random &amp; return that number.</p>

<p><strong>Is there a more efficient/better way to randomly generate numbers that are divisible by 7? Is there a better way I could code/do this?</strong></p>

<pre><code>    unsigned int generateRandomNumberDivisibleByN( unsigned int n, unsigned int num=10 )
    {
        // Post: Generate many different random numbers that are divisible by n, then randomly select one of
        //       of those numbers to return.

        unsigned int potentialNums[num];

        for (int i=0, j=2; i&lt;num; i++, j=rand()%INT_MAX)
        {
            potentialNums[i] = j*n;
        }

        return potentialNums[ rand()%num ]; // should this be rand()%(num-1) so it never returns an invalid array index?
    }
</code></pre>
","922184","","<p>Why can't you just do this?</p>

<pre><code>return (rand() % MAX) * 7;
</code></pre>

<p>It does almost the same thing.</p>

<p>Where <code>MAX</code> is small enough to avoid overflow during the multiplication by 7. Which you can define as:</p>

<pre><code>const MAX = INT_MAX / 7;
</code></pre>

<p>Or if you want it to be fast, you can do something like:</p>

<pre><code>return (rand() &amp; 0xff) * 7;
</code></pre>
"
"<pre><code>(gdb) disas /m main
Dump of assembler code for function main():
2   {
   0x080483f4 &lt;+0&gt;: push   %ebp
   0x080483f5 &lt;+1&gt;: mov    %esp,%ebp
   0x080483f7 &lt;+3&gt;: sub    $0x10,%esp

3       int a = 1;
   0x080483fa &lt;+6&gt;: movl   $0x1,-0x4(%ebp)

4           int b = 10;
   0x08048401 &lt;+13&gt;:    movl   $0xa,-0x8(%ebp)

5           int c;
6           c = a + b;
   0x08048408 &lt;+20&gt;:    mov    -0x8(%ebp),%eax
   0x0804840b &lt;+23&gt;:    mov    -0x4(%ebp),%edx
   0x0804840e &lt;+26&gt;:    lea    (%edx,%eax,1),%eax
   0x08048411 &lt;+29&gt;:    mov    %eax,-0xc(%ebp)

7           return 0;
   0x08048414 &lt;+32&gt;:    mov    $0x0,%eax

8   }
   0x08048419 &lt;+37&gt;:    leave  
</code></pre>

<p>Notce the 3rd assembler instruction, it allocated 16 bytes instead of the expected 12 bytes. Why is that?  I thought the 3rd line is allocating automatic variables... </p>

<p>Even if I removed the assignment, the allocation is still 16 bytes. </p>

<p>Thanks.</p>

<hr>

<p>Edit</p>

<pre><code>// no header. nothing
int main()
{
        int a = 1;
        int b = 10;
        int c;
        c = a + b;
        return 0;
}
</code></pre>

<p>g++ -g -o demo demo.cpp</p>

<hr>

<p>Follow up...
I read a couple more threads on stack alignment (sorry, I am now studying computer arch and organization class...so I am not familiar with this at all)</p>

<p><a href=""http://stackoverflow.com/questions/1061818/stack-allocation-padding-and-alignment"">Stack Allocation Padding and Alignment</a></p>

<p>I am supposed it's the compiler's setting. So default, the minimum is 16-byte. </p>

<p>If we have </p>

<pre><code>int a = 1;
int b = 10;
int c = 10;
int d = 10;
// --
int e = 10;
</code></pre>

<p>Up to int d, we would have exactly 16-bytes, and the allocation is still 0x10. But when we give another delectation, int e = 10, esp is now allocated 32 bytes (0x20).</p>

<p>This shows me that esp, the stack pointer, is only used for automatic variables. </p>

<hr>

<p>Follow-up 2</p>

<p>Call stack and Stack frame</p>

<p>Each stack frame </p>

<blockquote>
<pre><code>Storage space for all the automatic variables for the newly called function.

The line number of the calling function to return to when the called function returns.

The arguments, or parameters, of the called function.
</code></pre>
</blockquote>

<p>But after we allocated int a through int d, it already took us 16 bytes. Main has no function parameters, so that's zero. But the line to return, where did this information go? </p>
","922184","","<p><strike>I although I haven't seen the source code for <code>main()</code> yet,</strike> I believe this is due to stack alignment.</p>

<p>Under your settings, the stack probably needs to be aligned to 8 bytes. Therefore <code>esp</code> is being incremented by 16 bytes rather than 12 bytes. (even though 12 bytes is enough to hold all the variables)</p>

<p>On other systems (with SSE or AVX), the stack will need to be aligned to 16 or 32 bytes.</p>
"
"<p>What would be the best way to generate a random 32-bit hexadecimal value in C? In my current implementation I am generating each bit separately but the output is not completely random ... many values are repeated several times. Is it better to generate the entire random number instead of generating each bit separately?</p>

<p>The random number should make use of the entire 32 bit address space (0x00000000 to 0xffffffff)</p>

<pre><code>file = fopen(tracefile,""wb""); // create file
for(numberofAddress = 0; numberofAddress&lt;10000; numberofAddress++){ //create 10000 address
    if(numberofAddress!=0)
        fprintf(file,""\n""); //start a new line, but not on the first one

    fprintf(file, ""0 "");
    int space;

    for(space = 0; space&lt;8; space++){ //remove any 0 from the left
        hexa_address = rand() % 16;
        if(hexa_address != 0){
            fprintf(file,""%x"", hexa_address);
            space++;
            break;
        }
        else if(hexa_address == 0 &amp;&amp; space == 7){ //in condition of 00000000
            fprintf(file,""%x"", ""0"");
            space++;
        }
    }

    for(space; space&lt;8; space++){ //continue generating the remaining address
        hexa_address = rand() % 16;
        fprintf(file,""%x"", hexa_address);
    }

}
</code></pre>
","922184","","<pre><code>x = rand() &amp; 0xff;
x |= (rand() &amp; 0xff) &lt;&lt; 8;
x |= (rand() &amp; 0xff) &lt;&lt; 16;
x |= (rand() &amp; 0xff) &lt;&lt; 24;

return x;
</code></pre>

<p><code>rand()</code> doesn't return a full random 32-bit integer. Last time I checked it returned between <code>0</code> and <code>2^15</code>. (I think it's implementation dependent.) So you'll have to call it multiple times and mask it.</p>
"
"<p>I have a problem when doing a prime calculation.
This is got to be done using the Sieve of Eratosthenes.
On the first part of my program user inputs the limit and the program creates an array from 2 two to that limit.</p>

<p>On the second part of the program, the program uses the Sieve of Eratosthenes to calculate the prime numbers. for the first run, program runs as described but after the second it gives me ArrayIndexOutOfBoundsException and I don't know how to solve it.</p>

<p>This is what I've done:</p>

<pre><code>primeCalc(matrix, 0);

public static void primeCalc(int[] matrixTemp, int run){
    int[] temp = new int[matrixTemp.length];
    int i = 0;
    int a = run + 1;
    int index = run + 1;
    int index2 =1;
    temp = matrixTemp;
    for (i = 1; i &lt; matrixTemp.length;i++){
        if ( matrixTemp[index] % matrixTemp[run] != 0){
            temp[a] = matrixTemp[index];
            a++;
            index2 += 1;
        }
        index++;

    }

    int[] temp2 = new int[index2];
    int k = 0;
    for (k = 0; k &lt; index2; k++){
        temp2[k] = temp[k];
    }
   run +=1;
   if (run &lt; 2){
       primeCalc(temp2, run);
   }

   System.out.println(Arrays.toString(temp2));
</code></pre>

<p>With run = 1 everything is ok but after that it does not work.
Problem is with  if ( matrixTemp[index] % matrixTemp[run] != 0)</p>

<p>Can you help me?</p>

<p>Thanks.</p>

<p>favolas</p>
","922184","","<p>The problem is here:</p>

<pre><code>matrixTemp[index]
</code></pre>

<p>Your <code>index</code> is set to <code>run + 1</code>. And it gets incremented with the each iteration. Since you pass in run = 1, <code>index</code> starts at 2. And always stays equal to <code>i + 1</code>.</p>

<p><code>i</code> gets iterated to the maximum length of <code>matrixTemp.length</code>. But <code>index</code> is equal to <code>i + 1</code>. Therefore your access at <code>matrixTemp[index]</code> overruns the array on the last iteration.</p>

<p>EDIT:</p>

<p>I'm not sure how to fix it since I can't quite figure what you're trying to do. Can you fill in on this?</p>

<p>EDIT2:</p>

<p>Try changing the loop to this:</p>

<pre><code>while (index &lt; matrixTemp.length){
</code></pre>

<p>That should get rid of the array-overrun.</p>
"
"<p>I've found some md5 code that consists of the following prototypes...</p>

<p>I've been trying to find out where I have to put the string I want to hash, what functions I need to call, and where to find the string once it has been hashed. I'm confused with regards to what the uint32 buf[4] and uint32 bits[2] are in the struct.</p>

<pre><code>struct MD5Context {
    uint32 buf[4];
    uint32 bits[2];
    unsigned char in[64];
};

/*
 * Start MD5 accumulation.  Set bit count to 0 and buffer to mysterious
 * initialization constants.
 */
void MD5Init(struct MD5Context *context);

/*
 * Update context to reflect the concatenation of another buffer full
 * of bytes.
 */
void MD5Update(struct MD5Context *context, unsigned char const *buf, unsigned len);

/*
 * Final wrapup - pad to 64-byte boundary with the bit pattern 
 * 1 0* (64-bit count of bits processed, MSB-first)
 */
void MD5Final(unsigned char digest[16], struct MD5Context *context);

/*
 * The core of the MD5 algorithm, this alters an existing MD5 hash to
 * reflect the addition of 16 longwords of new data.  MD5Update blocks
 * the data and converts bytes into longwords for this routine.
 */
void MD5Transform(uint32 buf[4], uint32 const in[16]);
</code></pre>
","922184","","<p>As other answers have mentioned, the following calls will compute the hash:</p>

<pre><code>MD5Context md5;
MD5Init(&amp;md5);
MD5Update(&amp;md5, data, datalen);
MD5Final(digest, &amp;md5);
</code></pre>

<p>The purpose of splitting it up into that many functions is to let you stream large datasets.</p>

<p>For example, if you're hashing a 10GB file and it doesn't fit into ram, here's how you would go about doing it. You would read the file in smaller chunks and call <code>MD5Update</code> on them.</p>

<pre><code>MD5Context md5;
MD5Init(&amp;md5);

fread(/* Read a block into data. */)
MD5Update(&amp;md5, data, datalen);

fread(/* Read the next block into data. */)
MD5Update(&amp;md5, data, datalen);

fread(/* Read the next block into data. */)
MD5Update(&amp;md5, data, datalen);

...

//  Now finish to get the final hash value.
MD5Final(digest, &amp;md5);
</code></pre>
"
"<p>I think the question speaks for itself, I'm writing a program in c++ and there is a part where the console asks the user which type of input they want to use</p>

<pre><code>while (loop == 5) {
  cout &lt;&lt; ""\nWould you like to enter a depoist or a check? ""; //asks for a choice
  cin &gt;&gt; choice;
  //determines whether or not to close the program
  if(choice == 0 || depo == 0 || check == 0) {
    return 0;          
  }//end close if
  //choses which type of input to make
  if( choice == 1) {
    cout &lt;&lt; ""\nPlease enter check amount: "";    
    cin &gt;&gt; check;
    check += check;
  } else if(choice == 2) {
    cout &lt;&lt; ""\nPlease enter deposit amount: "";
    cin &gt;&gt; depo;
    depo += depo;
  }//end if
}
</code></pre>

<p>but how do i keep track of how many times the if statement was true?</p>
","922184","","<p>You can add a counter and increment it every time you enter the if-statement's true block.</p>

<pre><code>int true_counts = 0;
while (loop == 5){

    ...

    if( choice == 1){
        true_counts++;

    ...
</code></pre>
"
"<p>I have a problem with OpenCL, which is that it executes the entire command queue, but it only reads only 1/4 of the input and writes only 1/4 of the result.
No matter how many iterations, always 1/4.</p>

<p>And also it sometimes randomly crashes..with debugging I dont get any information, since there is no debug symbols, where it crashes (0x4c4783f6 in ????, etc.)</p>

<p>Source code:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;cl/cl.h&gt;
#include &lt;cassert&gt;
#include &lt;cstring&gt;

const char *progsrc[] = {
""#pragma OPENCL EXTENSION cl_intel_printf : enable\n\
__kernel void add(__global const int *a, __global const int *b, __global int *out) \
{ \
    int tid = get_global_id(0);\
    out[tid] = tid/*a[tid]+b[tid]*/;\
    printf(\""krnl: %d = %d + %d \\n\"", out[tid], a[tid], b[tid]);\
}""};

const int iterations = 20;

#define CLCheck(a) \
do\
{\
    if(a != CL_SUCCESS)\
    {\
        std::cerr &lt;&lt; ""OpenCL Error("" &lt;&lt; a &lt;&lt; "") at "" &lt;&lt; __LINE__ &lt;&lt; std::endl;\
        return -1;\
    }\
} while(0)

int main()
{
    cl_int err = CL_SUCCESS;

    int *aH = NULL;
    int *bH = NULL;
    int *outH = NULL;

    cl_uint platnum, devnum;
    cl_device_id dev;
    cl_platform_id plat;
    err = clGetPlatformIDs(0, 0, &amp;platnum);
    CLCheck(err);
    cl_platform_id pfids[platnum];
    err = clGetPlatformIDs(platnum, pfids, &amp;platnum);
    CLCheck(err);

    if(!platnum)
    {
        std::cerr &lt;&lt; ""No platform found."" &lt;&lt; std::endl;
        return -1;
    }
    else
        std::cout &lt;&lt; platnum &lt;&lt; "" OpenCL platform(s) found.\n"" &lt;&lt; std::endl;

    for(unsigned int i = 0; i != platnum; i++)
    {
        char buf[4096];

        err = clGetDeviceIDs(pfids[i], CL_DEVICE_TYPE_ALL, 0, 0, &amp;devnum);
        CLCheck(err);
        cl_device_id devids[devnum];
        err = clGetDeviceIDs(pfids[i], CL_DEVICE_TYPE_ALL, devnum, devids, &amp;devnum);
        CLCheck(err);
        if(!devnum)
        {
            std::cerr &lt;&lt; ""No device found."" &lt;&lt; std::endl;
            return -1;
        }
        else
            std::cout &lt;&lt; "" "" &lt;&lt; devnum &lt;&lt; "" OpenCL device(s) found.\n"" &lt;&lt; std::endl;

        for(unsigned int i2 = 0; i2 != devnum; i2++)
        {
            char buf[1024];
            std::cout &lt;&lt; "": \n\tName: "" &lt;&lt; buf;
            err = clGetDeviceInfo(devids[i2], CL_DEVICE_VENDOR, 1024, buf, NULL);
            CLCheck(err);
            if(!strncmp(buf, ""Intel"", 5))
            {
                dev = devids[0];
                plat = pfids[i];
                std::cout &lt;&lt; ""\n\tFound Intel(R) OpenCL device."";
            }
        }
    }
    cl_context_properties ctxprop[3] = { CL_CONTEXT_PLATFORM, (cl_context_properties)plat, 0};
    cl_context ctx = clCreateContext(ctxprop, 1, &amp;dev, NULL, NULL, &amp;err);
    CLCheck(err);

    cl_program program = clCreateProgramWithSource(ctx, 1, progsrc, NULL, &amp;err);
    CLCheck(err);
    err = clBuildProgram(program, 1, &amp;dev, """", NULL, NULL);
    if(err != CL_SUCCESS)
    {
        size_t bufsz;
        err = clGetProgramBuildInfo(program, dev, CL_PROGRAM_BUILD_LOG, 0, 0, &amp;bufsz);
        char buf[bufsz];
        err = clGetProgramBuildInfo(program, dev, CL_PROGRAM_BUILD_LOG, bufsz, buf, &amp;bufsz);
        std::cerr &lt;&lt; ""OpenCL program building failed: "" &lt;&lt; buf &lt;&lt; std::endl;
        return -1;
    }
    err = clUnloadCompiler();
    CLCheck(err);

    aH = new int[iterations];
    bH = new int[iterations];
    outH = new int[iterations];
    memset(outH, 0, iterations*sizeof(int));
    for(int i = 0; i != iterations; i++)
    {
        aH[i] = i;
        bH[i] = i*2;
    }

    cl_mem aCL = clCreateBuffer(ctx, CL_MEM_READ_ONLY, iterations, NULL, &amp;err);
    cl_mem bCL = clCreateBuffer(ctx, CL_MEM_READ_ONLY, iterations, NULL, &amp;err);
    CLCheck(err);
    cl_mem outCL = clCreateBuffer(ctx, CL_MEM_WRITE_ONLY, iterations, NULL, &amp;err);
    CLCheck(err);

    cl_kernel krnl = clCreateKernel(program, ""add"", &amp;err);
    CLCheck(err);

    err = clSetKernelArg(krnl, 0, sizeof(aCL), &amp;aCL);
    CLCheck(err);
    err = clSetKernelArg(krnl, 1, sizeof(bCL), &amp;bCL);
    CLCheck(err);
    err = clSetKernelArg(krnl, 2, sizeof(outCL), &amp;outCL);
    CLCheck(err);

    cl_command_queue cmdqueue = clCreateCommandQueue(ctx, dev, 0, &amp;err);
    cl_event evt;
    size_t global_work_size[1] = { iterations };
    err = clEnqueueWriteBuffer(cmdqueue, aCL, CL_TRUE, 0, iterations, aH, 0, NULL, NULL);
    err = clEnqueueWriteBuffer(cmdqueue, bCL, CL_TRUE, 0, iterations, bH, 0, NULL, NULL);
    err = clEnqueueNDRangeKernel(cmdqueue, krnl, 1, NULL, global_work_size, NULL, 0, NULL, &amp;evt);
    err = clWaitForEvents(1, &amp;evt);
    err = clEnqueueReadBuffer(cmdqueue, outCL, CL_TRUE, 0, iterations, outH, 0, NULL, &amp;evt);

    for(int i = 0; i != iterations; i++)
    {
        std::cout &lt;&lt; outH[i] &lt;&lt; std::endl;
    }

    err = clReleaseEvent(evt);
    err = clReleaseCommandQueue(cmdqueue);
    err = clReleaseKernel(krnl);
    err = clReleaseMemObject(outCL);
    err = clReleaseMemObject(bCL);
    err = clReleaseMemObject(aCL);
    err = clReleaseProgram(program);
    err = clReleaseContext(ctx);

    if(aH)
        delete aH;
    if(bH)
        delete bH;
    if(outH)
        delete outH;
    return 0;
}
</code></pre>

<p>output:</p>

<pre><code>2 OpenCL platform(s) found.

Platform 0 :
        Name: NVIDIA CUDA
        Vendor: NVIDIA Corporation
        Profile: FULL_PROFILE
        Version: OpenCL 1.1 CUDA 4.0.1
        Extensions: cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing c
l_nv_d3d9_sharing cl_nv_d3d10_sharing cl_khr_d3d10_sharing cl_nv_d3d11_sharing c
l_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll

 1 OpenCL device(s) found.

  Device 0:
        Name: GeForce GT 425M
        Vendor: NVIDIA Corporation
        Profile: FULL_PROFILE
        Driver version: 280.26
        OpenCL version: OpenCL C 1.1
        Version: OpenCL 1.1 CUDA
        Extensions: cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing c
l_nv_d3d9_sharing cl_nv_d3d10_sharing cl_khr_d3d10_sharing cl_nv_d3d11_sharing c
l_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll  cl_khr_g
lobal_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32
_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64

Platform 1 :
        Name: Intel(R) OpenCL
        Vendor: Intel(R) Corporation
        Profile: FULL_PROFILE
        Version: OpenCL 1.1
        Extensions: cl_khr_fp64 cl_khr_global_int32_base_atomics cl_khr_global_i
nt32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extende
d_atomics cl_khr_byte_addressable_store cl_intel_printf cl_ext_device_fission cl
_intel_immediate_execution cl_khr_gl_sharing cl_khr_icd

 1 OpenCL device(s) found.

  Device 0:
        Name: Intel(R) Core(TM) i3 CPU       M 370  @ 2.40GHz
        Found Intel(R) OpenCL device.
        Vendor: Intel(R) Corporation
        Profile: FULL_PROFILE
        Driver version: 1.1
        OpenCL version: OpenCL C 1.1
        Version: OpenCL 1.1 (Build 15293.6650)
        Extensions: cl_khr_fp64 cl_khr_global_int32_base_atomics cl_khr_global_i
nt32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extende
d_atomics cl_khr_byte_addressable_store cl_intel_printf cl_ext_device_fission cl
_intel_immediate_execution cl_khr_gl_sharing

krnl: 0 = 0 + 0
krnl: 1 = 1 + 2
krnl: 2 = 2 + 4
krnl: 3 = 3 + 6
krnl: 4 = 4 + 8
krnl: 5 = 0 + 0
krnl: 6 = 0 + 0
krnl: 7 = 0 + 0
krnl: 16 = 0 + 492859489
krnl: 17 = 0 + -1042621749
krnl: 18 = 0 + 1310105771
krnl: 19 = 0 + 134230852
krnl: 8 = 0 + 0
krnl: 9 = 0 + 0
krnl: 10 = 0 + -1094462526
krnl: 11 = 0 + -1094462526
krnl: 12 = 0 + -1230120245
krnl: 13 = 0 + 500723958
krnl: 14 = 0 + 530164160
krnl: 15 = 0 + 492859489
0
1
2
3
4
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
</code></pre>

<p>Thanks :)</p>
","922184","","<p>I'm not familiar with openCL, but I think you're missing a few <code>sizeof</code>'s here:</p>

<pre><code>err = clEnqueueWriteBuffer(cmdqueue, aCL, CL_TRUE, 0, iterations, aH, 0, NULL, NULL);
</code></pre>

<p>should probably be:</p>

<pre><code>err = clEnqueueWriteBuffer(cmdqueue, aCL, CL_TRUE, 0, iterations * sizeof(int), aH, 0, NULL, NULL);
</code></pre>

<p>And same applies the similar code following this.</p>

<p>EDIT:</p>

<p>And here's another place you may have missed a few <code>sizeof()</code>s:</p>

<pre><code>cl_mem aCL = clCreateBuffer(ctx, CL_MEM_READ_ONLY, iterations, NULL, &amp;err);
cl_mem bCL = clCreateBuffer(ctx, CL_MEM_READ_ONLY, iterations, NULL, &amp;err);
CLCheck(err);
cl_mem outCL = clCreateBuffer(ctx, CL_MEM_WRITE_ONLY, iterations, NULL, &amp;err);
CLCheck(err);
</code></pre>
"
"<p>I have the following piece of code in C:</p>

<pre><code>char a[55] = ""hello"";
size_t length = strlen(a);
char b[length];
strncpy(b,a,length);
size_t length2 = strlen(b);
printf(""%d\n"", length);          // output = 5
printf(""%d\n"", length2);         // output = 8
</code></pre>

<p>Why is this the case?</p>
","922184","","<p>You never initialized <code>b</code> to anything. Therefore it's contents are undefined. The call to <code>strlen(b)</code> could read beyond the size of <code>b</code> and cause undefined behavior (such as a crash).</p>
"
"<p>In order to improve code readability, sometimes I use ""alias methods"". These are basically methods that all do the same thing (at least in the base class; derived classes may do it differently) with different names, that enhance code readability for the class user depending on the context. Consider the code below for an example:</p>

<pre><code>template &lt;typename T&gt;
class Foo {
public:

    T bar() { /* Lots of stuff here */ }

    inline T bar_alias1() { return this-&gt;bar(); }
    inline T bar_alias2() { return this-&gt;bar(); }
};
</code></pre>

<p>Of course, if <code>Foo::bar()</code> was a small function, one would simply duplicate the code in all the alias methods. However, since the code may be relatively large, code duplication should be avoided, hence why the alias methods are declared as inline. But I know that the compiler does not guarantee that any function declared as <code>inline</code> would actually end up being expanded at compile time.</p>

<p>So my question is, am I introducing any performance overhead by creating these alias methods? In the code below:</p>

<pre><code>Foo&lt;BIG_OBJECT&gt; foo;
BIG_OBJECT bo1 = foo.bar();
BIG_OBJECT bo2 = foo.bar_alias1();
</code></pre>

<p>Would calling <code>foo.bar()</code> be faster than calling <code>foo.bar_alias1()</code> assuming the object being passed is relatively large? Are there redundant copies of the object being made when <code>Foo::bar_alias1()</code> calls <code>Foo::bar()</code>?</p>

<p>I'm using Visual Studio 2010 as my compiler.</p>
","922184","","<p>Assuming the aliased functions are inlined - and they should given the size.
There shouldn't be any performance overhead. The code-size won't increase either if the compiler decides to omit the function code and inline all calls to it.</p>

<p>(I'm referring to the inlining of <code>bar_alias1()</code>, <code>bar()</code> itself won't necessarily be inlined if it's large.)</p>

<p>However, this doesn't apply if the functions are virtual.</p>

<p>In C, I would do this more directly with preprocessor, but I'm not sure how appropriate that is in C++.</p>
"
"<p>I'm getting this error and can't correct it. Any help is appreciated. Thanks.
error C2440: '=' : cannot convert from 'DWORD *' to 'unsigned int'
IntelliSense: a value of type ""DWORD *"" cannot be assigned to an entity of type ""unsigned int""</p>

<pre><code>using namespace std;
typedef vector&lt;WIN32_FIND_DATA&gt; tFoundFilesVector;
std::wstring LastWriteTime;  
int getFileList(wstring filespec, tFoundFilesVector &amp;foundFiles)
{
WIN32_FIND_DATA findData;
HANDLE h;
int validResult=true;

int numFoundFiles = 0;
h = FindFirstFile(filespec.c_str(), &amp;findData);

if (h == INVALID_HANDLE_VALUE)
    return 0;

while (validResult)
{
    numFoundFiles++;
    foundFiles.push_back(findData);
    validResult = FindNextFile(h, &amp;findData);
}
return numFoundFiles;
}

void showFileAge(tFoundFilesVector &amp;fileList)
{
    unsigned int fileTime,curTime, age;
    tFoundFilesVector::iterator iter;
FILETIME ftNow;
__int64 nFileSize;
    LARGE_INTEGER li;    
li.LowPart = ftNow.dwLowDateTime;
li.HighPart = ftNow.dwHighDateTime;

CoFileTimeNow(&amp;ftNow);
    curTime = ((_int64) &amp;ftNow.dwHighDateTime &lt;&lt; 32) + &amp;ftNow.dwLowDateTime;

    for (iter=fileList.begin(); iter&lt;fileList.end(); iter++)
    {
    fileTime = ((_int64)iter-&gt;ftLastWriteTime.dwHighDateTime &lt;&lt; 32) + iter-                       &gt;ftLastWriteTime.dwLowDateTime;

    age = curTime - fileTime;

    cout &lt;&lt; ""FILE: '"" &lt;&lt; iter-&gt;cFileName &lt;&lt; ""', AGE: "" &lt;&lt; (INT64)age/10000000UL &lt;&lt; "" seconds"" &lt;&lt;     endl;
    }
}

int main()
{
string fileSpec = ""*.*"";
tFoundFilesVector foundFiles;
tFoundFilesVector::iterator iter;

int foundCount = 0;

getFileList(L""*.c??"", foundFiles);
getFileList(L""*.h"", foundFiles);

foundCount = foundFiles.size();
if (foundCount)
{
    cout &lt;&lt; ""Found ""&lt;&lt;foundCount&lt;&lt;"" matching files.\n"";
    showFileAge(foundFiles);
}
return 0;
}
</code></pre>

<p>Its on this line.....</p>
","922184","","<p>The error is here:</p>

<pre><code>curTime = ((_int64) &amp;ftNow.dwHighDateTime &lt;&lt; 32) + &amp;ftNow.dwLowDateTime;
</code></pre>

<p><code>dwHighDateTime</code> and <code>dwLowDateTime</code> are already of type <code>int</code>. Yet you are taking the address of them.  Therefore the assignment to <code>curTime</code> becomes pointer to int.</p>

<p>What you want is this:</p>

<pre><code>curTime = ((_int64) ftNow.dwHighDateTime &lt;&lt; 32) + ftNow.dwLowDateTime;
</code></pre>

<p>Second Issue:</p>

<p><code>curTime</code> and <code>fileTime</code> are only 32-bits. You need to make them 64-bit integers.</p>
"
"<p>I have a unsigned char pointer which contains a structure.Now I want to do the following</p>

<pre><code>unsigned char buffer[24];

//code to fill the buffer with the relevant information.

int len = ntohs((record_t*)buffer-&gt;len);
</code></pre>

<p>where record_t structure contains a field called len.I am not able to do so and am getting the error.</p>

<pre><code>error: request for member ‘len’ in something not a structure or union.
</code></pre>

<p>Then I tried:</p>

<pre><code>int len = ntohs(((record_t*)buffer)-&gt;len);
</code></pre>

<p>so as to get the operator precedence right.that gave me the warning.
dereferencing type-punned pointer will break strict-aliasing rulesd.</p>

<p>then I declared </p>

<pre><code>record_t *rec = null;

rec = (record_t*)
</code></pre>

<p>what am I doing wrong here?</p>
","922184","","<p>You're getting that warning because you're breaking strict-aliasing by having two pointers of different types pointing to the same location.</p>

<p>One way to get around that is to use unions:</p>

<pre><code>union{
    unsigned char buffer[24];
    record_t record_part;
};

//code to fill the buffer with the relavent information.

int len = ntohs(record_part.len);
</code></pre>

<p>EDIT:</p>

<p>Strictly speaking, this isn't much safer than your original code, but it doesn't violate strict-aliasing.</p>
"
"<p>I was wondering if the compareTo method looks at just the length of the strings or if it looks at each character of the string?</p>

<p>and if it does just look at the length how would i be able to compare two elements in an array of strings to see which element is bigger.</p>

<p>What im trying to do is write a method that recursively looks at the right side of the array, the middle, and the left and returns the index of the longest string in the array.</p>

<p>i have it working fine, the only problem is when there are two strings of the same length, it returns the first one.</p>

<p>Just clarifying how the compareTo method looks at the strings would help me solve this problem i think</p>

<p>how do strings of numbers compare lexographically? would 17 be bigger than 15?</p>
","922184","","<p><code>compareTo</code> for strings is done lexicographically. (or alphabetically) It doesn't compare the lengths of the strings.</p>

<p>A is less than B if A is alphabetically before B.</p>

<p>If you want to compare the length of a string, you can get the length from the <code>.length()</code> method and compare it as an integer.</p>

<p>EDIT:</p>

<p>Lexicographically is done by the ASCII/UNICODE values.</p>

<p>So in your example, <code>17</code> is bigger than <code>15</code>. Because the <code>1</code> is the same (a tie), and <code>7</code> has a higher ASCII/UNICODE value than <code>5</code>.</p>
"
"<p>I am having a difficult time understanding what the fork() command does under different scenarios. Here is some sample code from my book:</p>

<pre><code>int main() {
    int a = 12;
    int b = 9;
    int fid = fork();

    if (fid == 0) {
        a++;
    }
    else {
        wait(NULL);
        b = b - 5;
    }

    printf(""program exit. a = %d, b = %d\n"", a, b);
    return 0;
}
</code></pre>

<p>Can someone walk me through what the fork() command is doing in this case and perhaps give some more examples to clarify?</p>
","922184","","<p>When you call <code>fork()</code>, the entire process including all memory/variables etc... are duplicated.</p>

<p>So after the <code>fork</code> call, each process has it's own copy of <code>a</code> and <code>b</code> which start as <code>12</code> and <code>9</code> respectively.</p>

<p>Process 0, will increment it's own copy of <code>a</code>. Process 1 will decrement (by 5) it's own copy of <code>b</code>.</p>

<p>So they should print:</p>

<pre><code>Process 0: a = 13, b = 9
Process 1: a = 12, b = 4
</code></pre>
"
"<p>I am working on a character string to signify a change in sign. I have had success with the character string that's commented out below, but would prefer a simple if-else statement using constant character arrays UP = ""up/0/0"" and DOWN = ""down"".</p>

<p>Does anyone know a simple way to declare such constant values?</p>

<pre><code>    char direction[5]; // declares char array to signify sign change    
    if (value - price1 &gt; - 0.005) { // adjusts for noise near 0
        direction = UP;
    }
    else direction = DOWN;

    // update price-change direction string
//      if (value - price1 &gt; - 0.005) { // adjusts for noise near 0
//          direction[0] = 'u';
//          direction[1] = 'p';
//          direction[2] = 00; // set character to null value
//          direction[3] = 00;
//      }
//      
//      int[4] var_name 
//      else {
//          direction[0] = 'd';
//          direction[1] = 'o';
//          direction[2] = 'w';
//          direction[3] = 'n';
//      }
</code></pre>
","922184","","<p>If you're not modifying the string later, you could do it like this:</p>

<pre><code>const char *direction:
if (value - price1 &gt; - 0.005) { // adjusts for noise near 0
    direction = UP;
}
else
    direction = DOWN;
</code></pre>
"
"<p>What are complexities of Java 7's methods <a href=""http://download.oracle.com/javase/7/docs/api/java/math/BigInteger.html#pow%28int%29"" rel=""nofollow""><code>pow</code></a> and <a href=""http://download.oracle.com/javase/7/docs/api/java/math/BigInteger.html#isProbablePrime%28int%29"" rel=""nofollow""><code>isProbablePrime</code></a> in the <a href=""http://download.oracle.com/javase/7/docs/api/java/math/BigInteger.html"" rel=""nofollow""><code>BigInteger</code></a> class?</p>

<p>I know that simple implementation of Rabin's test is of O(k(log(n))^3) complexity and that can be reduced by incorporating the <a href=""http://en.wikipedia.org/wiki/Sch%C3%B6nhage%E2%80%93Strassen_algorithm"" rel=""nofollow"">Schönhage-Strassen algorithm</a> for the fast multiplication of long integers. </p>
","922184","","<p>Assuming the standard algorithms, the complexities are:</p>

<pre><code>pow()             : O( M(n * exponent) )
IsProbablePrime() : O( M(n) * n )
</code></pre>

<p>where:</p>

<ul>
<li><code>n</code> is the number of digits in the operand.</li>
<li><code>exponent</code> is the exponent of the power function.</li>
<li><code>M(n)</code> is the run-time for an <code>n x n</code> digit multiplication. Which I believe is <code>O(n^2)</code> as of Java 6.</li>
</ul>

<p><strong>Explanation for <code>pow()</code>:</strong></p>

<p>For an input operand of n-digits long raised to a power of <code>exp</code>, the output is roughly <code>n * exp</code> digits long. This is done by binary-powering algorithm where the operand is squared at each iteration. So the complexity becomes:</p>

<pre><code>O( M(n) + M(2*n) + M(4*n) + ... M(n * exp/2) ) = O( M(n * exp) )
</code></pre>

<p>This is a geometric sum, so the sum becomes <code>O( M(n * exp) )</code>.</p>

<p><strong>Explanation for <code>IsProbablePrime()</code>:</strong></p>

<p>For a fixed number of Rabin-Miller iterations, each iteration has <code>O(n)</code> multiplications of size <code>n x n</code> digits. Therefore, the complexity becomes <code>O( n * M(n) )</code>.</p>
"
"<p>I want to read a file of 500 Mb with the help of 2 threads, so that reading the file will be much faster. Someone please give me some code for the task using core java concepts.</p>
","922184","","<p>Multi-threading is not likely to make the code faster at all. This because reading a file is an I/O-bound process. You will be limited by the speed of the disk rather than your processor.</p>
"
"<pre><code>#include &lt;iostream&gt;

using namespace std;
int main() {
  printf(""hello"");
  getchar();
  return 0;
}
</code></pre>

<p>Here, I used <code>&lt;iostream&gt;</code>. The <code>printf</code> function is working; <code>cout</code> is working, too. 
So, is it a C or C++ program?</p>
","922184","","<p>It's a C++ program. C doesn't have namespaces.</p>
"
"<p>Is there a list of the order of speed of instructions (this may be generally speaking at it will vary on the architecture)?  I was told years ago from my assembly professor that shift was the quickest.</p>

<p>How are +, -, *, / ordered?</p>
","922184","","<p>Agner Fog has a very nice list of instruction latencies and throughputs for x86 processors:</p>

<p><a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">http://www.agner.org/optimize/instruction_tables.pdf</a></p>

<p>EDIT:</p>

<p>That said, you really have to be at this level of HPC to be able to make use of this information to improve performance.</p>
"
"<p>Running visual c++ 2010 on 64bit win7, this line</p>

<pre><code>#include ""C:\Windows\SysWOW64\user32.dll""
</code></pre>

<p>its the correct path, the errors however include variations of </p>

<pre><code>1&gt;C:\Windows\SysWOW64\user32.dll(1): error C2018: unknown character '0x3'
1&gt;C:\Windows\SysWOW64\user32.dll(1): error C2018: unknown character '0x4'
1&gt;C:\Windows\SysWOW64\user32.dll(1): error C2018: unknown character '0x40'
1&gt;C:\Windows\SysWOW64\user32.dll(1): error C2146: syntax error : missing ';' before identifier 'ÿÿ¸'
1&gt;C:\Windows\SysWOW64\user32.dll(1): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int
</code></pre>

<p>I am using it to get keybd_event() working as msdn says User32.dll is a requirement. Thanks !
*Note: The errors are in a code format block because it wouldn't let me submit it otherwise</p>
","922184","","<p>That's not how you import libraries. You just tried to include a binary. This has nothing to do with 32/64 bits.</p>

<p>What you need to do it add <code>user32.lib</code> to your library path.</p>

<p>You can import a library in Visual Studio by:</p>

<pre><code>Project -&gt; Properties -&gt; Linker -&gt; Additional Dependencies
</code></pre>

<p>Add ""user32.lib"" to the list.</p>
"
"<p>I will be as specific as possible..
I have this code:</p>

<pre><code>// bintodec.cpp : Defines the entry point for the console application.

#include ""stdafx.h""
#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

int main(){
    string inp;
    int dec = 0;
    char base;
    cout &lt;&lt; ""Input a number: "";
    cin &gt;&gt; inp;
    cout &lt;&lt; ""Input the base your number is in: "";
    cin &gt;&gt; base;
    for (int i = inp.length()-1, j = 0; i &gt;= 0; i--, ++j)
        dec += (inp[i]-48) * pow((float)base-48, j);
    cout &lt;&lt; ""Your number in base 10 is: "" &lt;&lt; dec &lt;&lt;endl;
    system(""pause"");
    return 0;
}
</code></pre>

<p>I'm trying to REWRITE/SIMPLIFY IT..to:</p>

<pre><code>{
    int j=0,x;
    double dec,y;
    for(int i = inp.length()-1; i &gt;= 0; i--) 
    {
    x=(inp[i]-48);
    y=pow((float)base-48, j);
    dec=dec + x * y;
    ++j;
    }
}
</code></pre>

<p>I have:</p>

<pre><code>int j=0,x;
    double dec, y;
        char base, inp;

        cout &lt;&lt; ""Input a number: "";
    cin &gt;&gt; inp;
    cout &lt;&lt; ""Input the base your number is in: "";
    cin &gt;&gt; base;


        {
            for (int i = inp.length()-1; i&gt;=0; --i)
            x=(inp[i]-48);
            y=pow((float)base-48, j);
            dec=dec + (x*y)
                ++j;
            {
             return 0;
</code></pre>

<p>For some reason its not working..visual studio is reporting that:</p>

<ol>
<li>left of '.length' must have class/struct/union type is 'char'</li>
<li>subscript requires array or pointer type</li>
<li>'++' needs l-value</li>
<li>syntax error : missing ';' before identifier 'j'</li>
</ol>

<p>I want to rewrite and simplify it..help with errors please..thanks!</p>
","922184","","<p>1: You can't do <code>inp.length()</code> because you declared <code>inp</code> as a char. And a char isn't a string.</p>

<p>Try declaring <code>inp</code> as a <code>string</code>:</p>

<pre><code>string inp;
</code></pre>

<p>2: ""subscript requires array or pointer type""</p>

<p>Same reason as above. <code>inp</code> is a char and not an array or a string.</p>

<p>3/4: ""'++' needs l-value""</p>

<p>You're missing a semicolon after: <code>dec=dec + (x*y)</code></p>
"
"<p>Okay, I'm still fairly new to Java. We've been given an assisgnment to create a game where you have to guess a random integer that the computer had generated. The problem is that our lecturer is insisting that we use:</p>

<pre><code>double randNumber = Math.random();
</code></pre>

<p>And then translate that into an random integer that accepts 1 - 100 inclusive. I'm a bit at a loss. What I have so far is this:</p>

<pre><code>//Create random number 0 - 99
double randNumber = Math.random();
d = randNumber * 100;

//Type cast double to int
int randomInt = (int)d;
</code></pre>

<p>However, the random the lingering problem of the random double is that 0 is a possibility while 100 is not. I want to alter that so that 0 is not a possible answer and 100 is. Help? </p>
","922184","","<p>You're almost there. Just add 1 to the result:</p>

<pre><code>int randomInt = (int)d + 1;
</code></pre>

<p>This will ""shift"" your range to <code>1 - 100</code> instead of <code>0 - 99</code>.</p>
"
"<p>Just a simple algorithm to sort small integers, but it must be O(n).</p>
","922184","","<p>A <a href=""http://en.wikipedia.org/wiki/Radix_sort"" rel=""nofollow"">radix sort</a> is one approach that's <code>O(n)</code>. Since you're dealing with small integers, it shouldn't be too hard to implement.</p>
"
"<p>I am learning about <code>strcmp()</code> in C.  I understand that when two strings are equal, <code>strcmp</code> returns 0.</p>

<p>However, when the man pages state that <code>strcmp</code> returns less than 0 when the first string is less than the second string, is it referring to length, ASCII values, or something else?</p>
","922184","","<p>In this sense, ""less than"" for strings means lexicographic (alphabetical) order.</p>

<p>So <code>cat</code> is less than <code>dog</code> because <code>cat</code> is alphabetically before <code>dog</code>.</p>

<p>Lexicographic order is, in some sense, an extension of alphabetical order to all ASCII (and UNICODE) characters.</p>
"
"<p>I am having a struct defined like this:</p>

<pre><code>typedef struct stringd{
    char *y;
    char *x[32];
}stringd;
</code></pre>

<p>in the main program I am declaring a pointer to stringd as shown:</p>

<pre><code>stringd *d = malloc(sizeof(*d));
</code></pre>

<p>in the main function I am parsing an input string and then storing it in a two dimensional char array </p>

<pre><code>char *c[32];
</code></pre>

<p>Whenever I encounter a '|' character in my input string I copy the items of c to *x[32] in stringd structure. as shown below:</p>

<pre><code>if (c[i][0]=='\174')
    for(j=0;j&lt;=i;j++){
        d[k].x[j]=c[j]; 
        c[j]=NULL;
    }
k++;
</code></pre>

<p>once the last string from the input(Delimiter is the space) is fetched I do the final copy of array c to x in stringd as shown(token is the pointer to the input string);</p>

<pre><code>if(*token == '\0'||*token=='\n' 
    for(j=0;j&lt;=i;j++){
        d[k].x[j]=c[j];
    }
</code></pre>

<p>the problem here is the strings stored earlier in the struct char array x gets overwritten by junk characters upon the last operation. Where am I going wrong?</p>

<p>any help appreciated,</p>
","922184","","<p>Assuming the code you posted is run in that exact order, here's what I'm seeing:</p>

<p>You allocated only one <code>stringd</code> object. But then you increment <code>k</code> after your first loop. So in your final if-statement, you're accessing <code>d[k]</code> which is past what you allocated.</p>

<p>So if I'm reading this right, this is undefined behavior since you're writing into unallocated memory.</p>
"
"<p>I have a game on a USB drive called MyGame.jar. It is an executable jar file. I want to be able to put it on cd's and USB drives. I want the game to start up automatically when the cd or USB is put into the computer, how can i do this? The game will only be ran on Windows based computers(Windows Xp &amp; Windows 7).</p>
","922184","","<p>Here's how to automatically launch an application using autoplay:</p>

<p>Make a text file and save it as <code>autorun.inf</code>. Save it in the base path of the CD.</p>

<p>The contents of <code>autorun.inf</code> should look something like this:</p>

<pre><code>RUN=setup.exe
Icon=icon.ico
</code></pre>

<p>The <code>icon</code> field is optional.</p>

<p>Note that this only works if the user has autoplay enabled. If the user disabled it, it won't work.</p>
"
"<p>I am new to C and I am having trouble with a basic program that converts dollars to euros. When I print the final output both the dollar and euro amount is ""0.00"".
Here is my code:</p>

<pre><code>#include&lt;stdio.h&gt;

main()

{
    float usd = 0.00;
    float euro = 0.00;
    const float conversion = 0.75;

    printf(""Please enter the amount of USD you want to convert to Euros: "");
    scanf(""%f"", &amp;usd);

    euro = (usd * conversion);
    printf(""\n%.2f USD equals %.2f Euros."", &amp;usd, &amp;euro);


    getch();
    return 0;
}
</code></pre>

<p>Thanks in advance</p>
","922184","","<p>Change the <code>printf</code> line to this:</p>

<pre><code>printf(""\n%.2f USD equals %.2f Euros."", usd, euro);
</code></pre>

<p>You are passing the addresses of <code>usd</code> and <code>euro</code> rather than the values themselves.</p>
"
"<p>I know that there are ways to enforce thread/process effinity to bind a perticular thread/process to a cpu/core in various OSs. I am just wondering if there is a way to enforce the CPU Socket affinity. i.e. to enforce a thread/process to be bound to a CPU Socket which can house a multiprocessor chip.</p>

<p>The question arises due to the fact that multi-processors per chip are increasing day by day. </p>

<p>Regards,
-J</p>
","922184","","<p>The only way I know of doing this is to find out which thread IDs map to which socket (or NUMA node). Once you have this information, you can use the usual thread-binding methods to enforce it.</p>

<p>If you're on Linux, you can use the <a href=""http://linux.die.net/man/3/numa"" rel=""nofollow"">numactl.h</a> library to find out which hardware thread belongs on which NUMA node. Although a NUMA node isn't always one-to-one with a socket, it is the case for all post-Core 2 Xeons and all Opteron systems to date.</p>

<p>On Windows, you can use <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms683204%28v=vs.85%29.aspx"" rel=""nofollow"">GetNumaNodeProcessorMask</a> to figure out which hardware threads are on a node.</p>

<p>In the case where they don't map one-to-one (such as the Core 2 Xeons, where both sockets are on the same NUMA node), it probably won't matter anyway from a performance standpoint unless you're trying to micromanage the shared cache on each processor.</p>
"
"<p>I have some code that stuffs in parameters of various length (u8, u16, u32 ) into a u64 with the left shift operator. </p>

<p>Then at various places in the code i need to get back the original parameters from this big bloated parameter. </p>

<p>Just wondering how , in the code, should we ensure that its a logical right shift and not arithmatic one while getting back the original parameters. </p>

<p>So Question is are there any #defs or other ways to ensure and check whether the compiler will screw up. ? </p>

<p>Here's the C++ code :</p>

<p>while stuffing in </p>

<pre><code>u32 x , y ,z;
u64 uniqID = 0;

u64 uniqID = (s64) x &lt;&lt; 54  |     
             (s64)y &lt;&lt; 52 | 
            (s64)z &lt;&lt; 32 |  
            uniqID;  // the original uniqID value.
</code></pre>

<p>And later on while getting the values back : </p>

<pre><code>z= (u32 ) ((uniqID  &gt;&gt; 32 ) &amp; (0x0FFFFF));  //20 bits 
y= (u32) ( (uniqID &gt;&gt; (52 ) &amp; 0x03)) ; //2 bits
x=  (u32) ( (uniqID &gt;&gt; (54) &amp; 0x03F)) ;  //6 bits 
</code></pre>

<p>Regards,
-J</p>
","922184","","<p>This looks like C/C++, so just make sure <code>uniqID</code> is an unsigned integer type.</p>

<p>Alternatively, just cast it:</p>

<pre><code>z = (u32) ( ((unsigned long long)uniqID &gt;&gt; (32) &amp; (0x0FFFFF));  //20 bits 
y = (u32) ( ((unsigned long long)uniqID &gt;&gt; (52) &amp; 0x03)) ; //2 bits
x = (u32) ( ((unsigned long long)uniqID &gt;&gt; (54) &amp; 0x03F)) ;  //6 bits 
</code></pre>
"
"<p>I am having trouble understanding why in this code snippet the ""Hello"" statement is not
being printed. I thought that the condition statement in the for loop starts getting tested after only at the second iteration. </p>

<pre><code>  for ( count = 0; count &lt; 0; ++count)
    {
  cout&lt;&lt;""Hello!\n"";     
    }
</code></pre>
","922184","","<p>It never enters the loop at all because <code>for</code> loops are tested at the start.</p>

<p>You start with <code>count = 0</code>, but the loop condition is <code>count &lt; 0</code>. So it fails right away and skips the entire loop.</p>

<p><code>do-while</code> loops are the ones that are tested at the end of the iteration.</p>
"
"<p>Can anyone tell me why I get ""Access violation reading location "" with this code example? And how can i fix this?</p>

<pre><code>#include &lt;vector&gt;
using namespace std;
struct StructTest;
struct Struct1;
typedef struct Struct1{
    StructTest* test;
} Struct1;

typedef struct StructTest{
    vector&lt;Struct1*&gt; test123;
} StructTest;

static StructTest* abc;

int test(){
    abc = (StructTest*) malloc(sizeof(StructTest));;
    Struct1* a1 = (Struct1*) malloc(sizeof(Struct1));
    a1-&gt;test = abc;
    abc-&gt;test123.push_back(a1);
    return 0;
}

int main(){
    test();
    return 0;
}
</code></pre>
","922184","","<p>It's crashing on this line:</p>

<pre><code>abc-&gt;test123.push_back(a1);
</code></pre>

<p>The reason is because you allocate it two lines above using <code>malloc</code>. Therefore, the contents of <code>test123</code> are uninitialized. So it crashes when you call <code>push_back</code> on it.</p>
"
"<p>i am studing numerical analysis,and also  solving algorithms which is described in book;my problem is  about newtons method,in general if some function is given  and we have to find root,how can we determine  derivative of function in code?or even limit?because as  you know newtons method involves derivative and makes iteration like this .suppose some function <code>f(x)</code> and initial guess,<code>p0,</code>
then          <code>p(n)=p(n-1)+f(p(n-1))/f'(p(n-1))</code>
here f'  denotes derivative of f,how can i approximate it in code?thanks a lot</p>
","922184","","<p>If you want to use Newton's Method, you will need to know the derivative of the function and code it in.</p>

<p>Otherwise, you can go with the <a href=""http://en.wikipedia.org/wiki/Secant_method"" rel=""nofollow"">Secant Method</a> which doesn't require knowing the derivative. But it converges at a slower rate.</p>
"
"<p>The following is an in-lined(defined inside header file) static member function. Is the literal string ""MyClass"" always guaranteed to be in static memory? If not, will this not be returning a pointer in stack?</p>

<pre><code>const char * className()
{
return ""MyClass"";
}
</code></pre>

<p><em>Edit:</em></p>

<p>How about this?</p>

<pre><code>const RWCString&amp; className()
{
return ""MyClass"";
}
</code></pre>

<p><code>RWCString</code> is an string class which has a implicit constructor which takes a <code>const char*</code>.
<a href=""http://www.roguewave.com/portals/0/products/sourcepro/docs/11/html/toolsref/rwcstring.html"" rel=""nofollow"">http://www.roguewave.com/portals/0/products/sourcepro/docs/11/html/toolsref/rwcstring.html</a></p>
","922184","","<p>Nope. This is completely defined. The string isn't on the stack. It's in global memory. So the pointer it returns is valid. (even better: you declared it <code>const</code>)</p>
"
"<p>I have a loop that I'm trying to parallelize and in it I am filling a container, say an STL map. Consider then the simple pseudo code below where T1 and T2 are some arbitrary types, while f and g are some functions of integer argument, returning T1, T2 types respectively:</p>

<pre><code>#pragma omp parallel for schedule(static) private(i) shared(c)
for(i = 0; i &lt; N; ++i) {
   c.insert(std::make_pair&lt;T1,T2&gt;(f(i),g(i))
}
</code></pre>

<p>This looks rather straighforward and seems like it should be trivially parallelized but it doesn't speed up as I expected. On the contrary it leads to run-time errors in my code, due to unexpected values being filled in the container, likely due to race conditions. I've even tried putting barriers and what-not, but all to no-avail. The only thing that allows it to work is to use a <em>critical</em> directive as below:</p>

<pre><code>#pragma omp parallel for schedule(static) private(i) shared(c)
for(i = 0; i &lt; N; ++i) {
#pragma omp critical
   {
      c.insert(std::make_pair&lt;T1,T2&gt;(f(i),g(i))
   }
}
</code></pre>

<p>But this sort of renders useless the whole point of using omp in the above example, since only one thread at a time is executing the bulk of the loop (the container insert statement). What am I missing here? Short of changing the way the code is written, can somebody kindly explain?</p>
","922184","","<p>This particular example you have is not a good candidate for parallelism unless <code>f()</code> and <code>g()</code> are extremely expensive function calls.</p>

<ol>
<li><p>STL containers are not thread-safe. That's why you're getting the race conditions. So accessing them needs to be synchronized - which makes your insertion process inherently sequential.</p></li>
<li><p>As the other answer mentions, there's a LOT of overhead for parallelism. So unless <code>f()</code> and <code>g()</code> extremely expensive, your loop doesn't do enough work to offset the overhead of parallelism.</p></li>
</ol>

<p>Now assuming <code>f()</code> and <code>g()</code> are extremely expensive calls, then your loop can be parallelized like this:</p>

<pre><code>#pragma omp parallel for schedule(static) private(i) shared(c)
    for(i = 0; i &lt; N; ++i) {
        std::pair&lt;T1,T2&gt; p = std::make_pair&lt;T1,T2&gt;(f(i),g(i));

#pragma omp critical
       {
          c.insert(p);
       }
    }
</code></pre>
"
"<p>i have   posted a few hours ago question about   newtons method,i got answers and want to thanks everybody,now i   have tried to implement code itself</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;math.h&gt;
using namespace std;
#define h powf(10,-7)
#define PI 180
float funct(float x){

    return cos(x)-x;


}
float derivative (float x){
    return (( funct(x+h)-funct(x-h))/(2*h));

}
int main(){
    float tol=.001;
    int N=3;
    float p0=PI/4;
    float p=0;
    int i=1;
    while(i&lt;N){

        p=p0-(float)funct(p0)/derivative(p0);
        if ((p-p0)&lt;tol){
            cout&lt;&lt;p&lt;&lt;endl;
            break;

        }


        i=i+1;
        p0=p;


    if (i&gt;=N){
        cout&lt;&lt;""solution not found ""&lt;&lt;endl;
        break;
    }
    }



    return 0;
}
</code></pre>

<p>but i writes output ""solution not found"",in book after three iteration when  n=3  ,it finds solution like this <code>.7390851332</code>,so my question is how small i should change h  or how should i change my code such that,get correct answer?</p>
","922184","","<p>Several things:</p>

<ol>
<li>2 iterations is rarely going to be enough even in the best case.</li>
<li>You need to make sure your starting point is actually convergent.</li>
<li>Be aware of destructive cancellation in your <code>derivative</code> function. You are subtracting two numbers that are very close to each other so the difference will lose a lot of precision.</li>
</ol>

<p>To expand on the last point, the general method is to decrease <code>h</code> as the value converges. But as I mentioned in your previous question, this ""adjusting"" <code>h</code> method essentially (algebraically) reduces to the Secant Method.</p>
"
"<pre><code>#include&lt;stdio.h&gt;
#include&lt;conio.h&gt;
#define square(v) v*v
void main()
{
int p=3;
int s=square(++p);
printf(""%d %d"",s,p);
getch();
}
</code></pre>

<p>output 
25 5
Why 16 4 is not coming as output?
(Advance thanks) </p>
","922184","","<p>A macro is basically a text copy and paste. Therefore your <code>++</code> is being duplicated.</p>

<p>The macro is being expanded as:</p>

<pre><code>s = ++p * ++p;
</code></pre>

<p>That's the danger of macros. (in this case, it also invokes undefined behavior)</p>
"
"<p>I don't know the right name in english when you want to calculate a number with a upper small number besides. Like 1,5 with a small 3 besides (the calculation of 1,5 * 1,5 * 1,5)</p>

<p>Is there a simple and uncomplicated way to do this in java? I want to calculate the volume. I hope you understand my question.</p>

<p>Thanks.</p>
","922184","","<p>The term is called ""power"" or ""exponent"". In Java you can do it as:</p>

<pre><code>Math.pow(1.5,3);
</code></pre>
"
"<p>I was testing the use of sizeof operator in C/C++ with this code: </p>

<pre><code>#include &lt;ctype.h&gt;              /* Character types                       */
#include &lt;stdio.h&gt;              /* Standard buffered input/output        */
#include &lt;stdlib.h&gt;             /* Standard library functions            */
#include &lt;string.h&gt;             /* String operations                     */
#include &lt;sys/types.h&gt;          /* Data types                            */
#include &lt;sys/wait.h&gt;           /* Declarations for waiting              */
#include &lt;unistd.h&gt;   

void main()
{
  char a[100];
  char *des = malloc(100*sizeof(char));
  strcpy(des,""abcded\0"");
  printf(""%d\n"",sizeof(des));
  printf(""%d\n"",sizeof(a));
  free(des);
}
</code></pre>

<p>Why does this program output:</p>

<pre><code>4
100
</code></pre>

<p>As opposed to:</p>

<pre><code>100
100
</code></pre>
","922184","","<p><code>sizeof(des)</code> returns the size of the pointer - which is 4 on your system. It doesn't return the size of the allocated space it points to.</p>
"
"<p>I have a float that adds numbers and its not displaying all the decimal points i wish for example i have 1.25 add 1.25 as a float and it shows as 1.5. How can i have it display as 1.50 for example?</p>
","922184","","<p>In C++, you can do it like this:</p>

<pre><code>cout &lt;&lt; setprecision(2) &lt;&lt; f &lt;&lt; endl;
</code></pre>

<p>EDIT:</p>

<p>This answer isn't completely correct. See comments.</p>

<p>This sets the total precision to 2 digits. (Not digits after the decimal place.)</p>
"
"<p>The code I'm looking at is this:</p>

<pre><code>for (i = 0; i &lt; linesToFree; ++i ){
    printf(""Parsing line[%d]\n"", i);

    memset( &amp;line, 0x00, 65 );
    strcpy( line, lines[i] );

    //get Number of words:
    int numWords = 0;

    tok = strtok(line , "" \t"");
    while (tok != NULL) {
        ++numWords;
        printf(""Number of words is:  %d\n"", numWords);
        println(tok);

        tok = strtok(NULL, "" \t"");
    }
}
</code></pre>

<p>My question centers around the use of <code>numWords</code>.  Does the runtime system reuse this variable or does it allocate a new <code>int</code> every time it runs through the <code>for</code> loop?  If you're wondering why I'm asking this, I'm a Java  programmer by trade who wants to get into HPC and am therefore trying to learn C.  Typically I know you want to <em>avoid</em> code like this, so this question is really exploratory.  </p>

<p>I'm aware the answer is probably reliant upon the compiler... I'm looking for a deeper explanation than that.  Assume the compiler of your choice.  </p>
","922184","","<p>From a performance standpoint, it's not going to matter. (Variables map to registers or memory locations, so it has to be reused.)</p>

<p><strike>From a logical standpoint, yes, it will be reused because you declared it outside the loop.</strike></p>

<p>From a logical standpoint:</p>

<ul>
<li><code>numWords</code> <strong>will not</strong> be reused in the <strong>outer loop</strong> because it is declared inside it.</li>
<li><code>numWords</code> <strong>will</strong> be reused in the <strong>inner loop</strong> because it isn't declared inside.</li>
</ul>
"
"<p>GMP allows to print a mpz_t up to base 62, but I want to represent a number into any base N, and for this I first need to generate an array of integers (let us say I will limit myself to base 2 ^ 64), so an array of <code>unsigned long</code> might do it.</p>

<p>For example if I want to take any integer and convert it to base 792, I can't put it into a string directly, I have to make an array of integers first.</p>

<p>Is there existing code for this in GMP, like some math of some kind I need to learn about or should I start coding it ?</p>

<p>P.S.
I know it's totally irrelevant to employ the term 'base' while I could use 'linear vector space', so it makes the conversion pointless, but there a lot of symbols in unicode (95,221 in  unicode 3.2), so I could still find a way to represent those with single symbols.</p>
","922184","","<p>Internally, GMP's functions directly or indirectly call the <code>mpn</code> layer - which are documented here:</p>

<p><a href=""http://gmplib.org/manual/Low_002dlevel-Functions.html#Low_002dlevel-Functions"" rel=""nofollow"">http://gmplib.org/manual/Low_002dlevel-Functions.html#Low_002dlevel-Functions</a></p>

<p>The <code>mpn_get_str</code> only supports bases up to 256. So I don't think you can go higher unless you write your own base conversion (which is not trivial at all).</p>
"
"<p>In my program -- which uses the Eigen library -- I need to operate on 2D vectors.  In my inner loop I have the following function:</p>

<pre><code>static inline double eval(double x, double y, double xi, double yi)
{
    const double invlen2  = 1/(x*x + y*y);
    const double invlen4 = invlen2*invlen2;
    const double invlen6 = invlen4*invlen2;

    const double x2  = x*x,   y2  = y*y;
    const double x3  = x2*x,  y3  = y2*y;
    const double xi2 = xi*xi, yi2 = yi*yi;

    return x*invlen2 + invlen4*(x2*xi + 2*x*y*yi - xi*y2)
    + invlen6*(x3*xi2 + 3*x*y2*yi2 + 6*x2*y*xi*yi - 3*x*xi2*y2 - 2*y3*xi*yi - x3*yi2);
}

void f(Vector2d&amp; out, const Vector2d&amp; R, const Vector2d&amp; r)
{
    out.x() = eval(R.x(), R.y(), r.x(), r.y());
    out.y() = eval(R.y(), R.x(), r.y(), r.x());
}
</code></pre>

<p>This expression, although messy, seems like a prime candidate for vectorisation as both the <code>x()</code> and <code>y()</code> computations follow identical paths. My question is how to do it with Eigen without needing to manually drop down to assembly.</p>
","922184","","<p>This answer has nothing to do with Eigen, but since you mentioned manually dropping down to assembly, I'll add this.</p>

<p>You don't need to use assembly to vectorize code. There are compiler intrinsics that will let manually vectorize without assembly:</p>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_overview.htm#intref_overview"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_overview.htm#intref_overview</a></p>

<p>That said: It looks like Eigen already has internal support for vectorization, but it doesn't appear to be applicable in your example. So I can see why you want to do it manually.</p>
"
"<p>1 It's really strange that wprintf show 'Ω' as 3A9 (UTF16), but wctomb convert
wchar to CEA9 (UTF8), my locale is default en_US.utf8. As man-pages said,
they should comform to my locale, but wpritnf use UTF16, why?</p>

<p>excerpt from <a href=""http://www.fileformat.info/info/unicode/char/3a9/index.htm"" rel=""nofollow"">http://www.fileformat.info/info/unicode/char/3a9/index.htm</a></p>

<p>Ω in UTF</p>

<p>UTF-8 (hex) 0xCE 0xA9 (cea9)</p>

<p>UTF-16 (hex)    0x03A9 (03a9)</p>

<p>2 wprintf and printf just cannot be run in the same program, I have
to choose to use either wprintf or printf, why?</p>

<hr>

<p>See my program:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;wchar.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;locale.h&gt;

int main() {
  setlocale(LC_ALL,""""); // inherit locale setting from environment
  int r;
  char wc_char[4] = {0,0,0,0};
  wchar_t myChar1 = L'Ω'; //greek 

  // should comment out either wprintf or printf, they don't run together
  r = wprintf(L""char is %lc (%x)\n"", myChar1, myChar1);//On Linux, to UTF16

  r = wctomb(wc_char, myChar1); // On Linux, to UTF8
  r = printf(""r:%d, %x, %x, %x, %x\n"", r, wc_char[0], wc_char[1], wc_char[2], wc_char[3]);
}
</code></pre>
","922184","","<p>The answer to your second question has to do with <a href=""http://www.gnu.org/s/hello/manual/libc/Streams-and-I18N.html"" rel=""nofollow"">stream orientation</a>. You cannot mix <code>printf()</code> and <code>wprintf()</code> because they require different orientations.</p>

<p>When the process starts, the streams are not set yet. On the first call to a function that uses the stream, it gets set accordingly. <code>printf()</code> will set the orientation to normal, and <code>wprintf()</code> will set it to wide.</p>

<p>It is undefined behavior to call a function that requires a different orientation as the current setting.</p>
"
"<p>I've been searching everywhere for this, and I just can't seem to figure this out. This should be a simple answer but I just for the life of me can't get this.</p>

<p>Ok, so all I want to do is delete a char * array, which should be simple right? <code>char * = new char[length];</code> then use <code>delete[] char;</code>?</p>

<p>Also, I am <strong>unable to use <code>std::string</code></strong> for this exercise.</p>

<p>I'm getting this error:</p>

<pre><code>HEAP CORRUPTION DETECTED: after Normal block (#137) 0x00794B50.
CRT detected that the application wrote to memory after end of heap buffer.
</code></pre>

<p>Here is my code:</p>

<pre><code>class myClass
{
    char * myString;
    ...
public:
    myClass::myClass( const char * tempStr);
};

myClass::myClass( const char * tempStr)
{
    int length = strlen(tempStr);
    myString = new char(length + 1); //+1 for null char
    strcpy(myString, tempStr);
    myString[length] = '\0';
    delete[] myString; //error occurs here
}
</code></pre>

<p>Now, I know, this code is completely impractical, however it still throws the same error that I am trying to solve so if we can solve this then I should be merrily on my way. From what I've read this should be OK? I'll reiterate, for this exercise I cannot use <code>std::string</code>.</p>
","922184","","<p>You messed the brackets up. It should be:</p>

<pre><code>myString = new char[length + 1];
</code></pre>

<p>Square brackets will create an array. Normal brackets will allocate only one with whatever constructor takes that one operand.</p>
"
"<p>How does c store a double decimal in an 8 bit slot?</p>

<pre><code>#include ""stdio.h""

main(){
  double x = 123.456;
  printf(""\n %d - %e \n"",sizeof(x),x);
}
</code></pre>

<p>outputs:</p>

<pre><code>8 - 23.456
</code></pre>

<p>The value of x is correct being 123.456, but the supposedly it is only 8 bits.</p>
","922184","","<p>That's not 8 bits. It's 8 bytes. And each byte is at least 8 bits (and usually exactly 8 bits).</p>

<p>So it's probably 8 * 8 = 64-bits for a <code>double</code>.</p>

<p>EDIT:</p>

<p>The <code>sizeof()</code> operator yields the size of an object <em>in bytes</em>.</p>

<p>A ""byte"" is by definition the size of a <code>char</code>.  (That's how the C standard defines the word ""byte""; it may have different meanings in other contexts.)</p>

<p>The number of bits in a byte is specified by the macro <code>CHAR_BIT</code>, defined in <code>&lt;limits.h&gt;</code>.  Almost any system you're likely to encounter will have <code>CHAR_BIT == 8</code>, but I understand that some implementations for DSPs (Digital Signal Processors) have <code>CHAR_BIT</code> set to 16 or 32.</p>
"
"<p>In C++, I use the following code to work out the order of magnitude of the error due to the limited precision of float and double:</p>

<pre><code> float n=1;
 float dec  = 1;

 while(n!=(n-dec)) {
    dec = dec/10;
 }
 cout &lt;&lt; dec &lt;&lt; endl;
</code></pre>

<p>(in the double case all I do is exchange float with double in line 1 and 2)</p>

<p>Now when I compile and run this using g++ on a Unix system, the results are</p>

<pre><code>Float  10^-8
Double 10^-17
</code></pre>

<p>However, when I compile and run it using MinGW on Windows 7, the results are</p>

<pre><code>Float  10^-20
Double 10^-20
</code></pre>

<p>What is the reason for this?</p>
","922184","","<p>I guess I'll make my comment an answer and expand on it. <strong>This is my hypothesis, I may be wrong.</strong></p>

<p>MinGW on Windows is probably trying to preserve precision by promoting the intermediates of expressions to the full 80-bit precision of x86.</p>

<p>Therefore, both sides of the expression <code>n != (n-dec)</code> are evaluated to 64-bits of precision (80-bit FP has a 64-bit mantissa).</p>

<pre><code>2^-64 ~ 10^-20
</code></pre>

<p>So the numbers make sense.</p>

<p>Visual Studio also (by default), will promote intermediates. But only up to double-precision.</p>
"
"<p>Recently, i'm using a code to make unique <code>int</code> number for my classes.</p>

<p>I used <code>reinterpret_cast&lt;int&gt;(my_unique_name)</code> where <code>my_unique_name</code> is a <code>char []</code> variable with unique value. Something like below:</p>

<pre><code>const char my_unique_name[] = ""test1234"";

int generate_unique_id_from_string(const char *str)
{
  return reinterpret_cast&lt;int&gt;(str);
}
</code></pre>

<p>My question is, is the generated <code>int</code> really <strong>unique</strong> for all entry strings ?</p>
","922184","","<p>It would depend. Here's my interpretation of your question:</p>

<p>You're trying to assign a different number to each string. And identical strings from different sources will have different IDs.</p>

<p>Case 1:</p>

<p>If <code>str</code> happens to be a reusable buffer that you use to read in those strings from wherever. Then they'll all have the same base address. So no it <strong>will not</strong> be unique.</p>

<p>Case 2:</p>

<p><code>str</code> happens to be a heap-allocated string. Furthermore, all the strings that will be ID'ed have overlapping lifetimes. Then yes, the IDs will be unique because they all reside in memory at the same time at different addresses.</p>

<p>EDIT:</p>

<p>If you want to generate a unique ID, but you want identical strings to have the same ID, then look at Greg's answer for a hash function.</p>
"
"<pre><code>#include &lt;Windows.h&gt;
#include &lt;iostream&gt;

using namespace std;

int main(void)
{
    unsigned char* pFoo = new unsigned char[1000];

    pFoo = (unsigned char*)VirtualAlloc(NULL, 1000, MEM_COMMIT, PAGE_EXECUTE_READWRITE);

    VirtualFree(pFoo, 0, MEM_RELEASE);

    delete[] pFoo;

    cin.ignore();
    cin.get();

    return 0;
}
</code></pre>

<p>This crashes for me at</p>

<pre><code>delete[] pFoo;
</code></pre>

<p>I know this is crashing because of VirtualAlloc but I'm not sure how to fix this...</p>
","922184","","<p>You're using the same variable. So your first allocation gets leaked.</p>

<p>After you free it with <code>VirtualFree</code>, the pointer is invalid. So <code>delete</code> on it is undefined.</p>

<p>Furthermore:</p>

<p>You can't mix <code>VirtualAlloc</code> and <code>delete</code> for the same reason you can't mix <code>malloc</code> with <code>delete</code>.</p>
"
"<p>This would be part # 2 of my question about analysis of for loop running time</p>

<p><a href=""http://faculty.simpson.edu/lydia.sinapova/www/cmsc250/LN250_Weiss/L03-BigOhSolutions.htm#PR4"" rel=""nofollow"">http://faculty.simpson.edu/lydia.sinapova/www/cmsc250/LN250_Weiss/L03-BigOhSolutions.htm#PR4</a> contains solutions, and I have question about two particular ""for"" loops</p>

<p>Could someone explain to me how to figure out running time for both of them. Thanks !</p>

<p>1.</p>

<pre><code>sum = 0;
for( i = 0; i &lt; n; i++)
    for( j = 0; j &lt; i*i; j++)
        for( k = 0; k &lt; j; k++)
            sum++;  
</code></pre>

<p>2.</p>

<pre><code>sum = 0;
for( i = 0; i &lt; n; i++)
    for( j = 0; j &lt; i*i; j++)
        if (j % i ==0)
           for( k = 0; k &lt; j; k++)
               sum++;
</code></pre>
","922184","","<p><strong>The first snippet is <code>O(n^5)</code>.</strong></p>

<pre><code>Top Loop    = 0 - O(n)   = O(n)   iterations
Middle Loop = 0 - O(n^2) = O(n^2) iterations
Inner Loop  = 0 - O(n^2) = O(n^2) iterations

Total = O(n^5)
</code></pre>

<p><strong>Here's the closed-form solution of the first snippet:</strong> (computed via Mathematica)</p>

<pre><code>sum = -(1/10)*n + (1/4)*n^2 - (1/4)*n^4 + (1/10)*n^5
</code></pre>

<p>This is a 5th order polynomial, therefore it is: <code>O(n^5)</code></p>

<p><strong>The second snippet appears to be <code>O(n^4)</code>.</strong></p>

<pre><code>Top Loop    = 0 - O(n)   = O(n) iterations
Middle Loop = 0 - O(n^2) = O(n^2) iterations
If statement enters: O(1 / n) times
Inner Loop  = 0 - O(n^2) = O(n^2) iterations

Total = O(n^4)
</code></pre>

<p><strong>Here's the closed-form solution of the second snippet:</strong> (computed via Mathematica)</p>

<pre><code>sum = -(1/12)*n + (3/8)*n^2 - (5/12)*n^3 + (1/8)*n^4
</code></pre>

<p>This is a 4th order polynomial, therefore it is: <code>O(n^4)</code></p>

<p>Further explanation of the effect of the if-statement:</p>

<p>The middle loop iterates from 0 to <code>i*i</code>. The if-statement checks if <code>j</code> is divisible by <code>i</code>. But that is only possible when <code>j</code> is a multiple of <code>i</code>.</p>

<p>How many times is <code>j</code> a multiple of <code>i</code> if <code>0 &lt;= j &lt; i*i</code>? Exactly <code>i</code> times. Therefore only <code>1/i</code> of the iterations of the middle loop will fall through to the inner-most loop.</p>
"
"<p>For a char variable would i also set it to 0 as i would set and int or a float or any other variable?</p>

<p>Such as </p>

<pre><code>char test = 0 
</code></pre>

<p>would it be like that since </p>

<pre><code>int test = 0
</code></pre>

<p>would be like that?</p>
","922184","","<p>Which do you want? The character '0', or the ascii 0?</p>

<p>If you want to set it to the character '0', then you need:</p>

<pre><code>char test = '0';
</code></pre>

<p>If you want the ascii value 0, then it's fine the way it is. </p>
"
"<pre><code>// operator_overloading.cpp
// compile with: /EHsc
#include &lt;iostream&gt;
using namespace std;

struct Complex {
   Complex( double r, double i ) : re(r), im(i) {} // what is this syntax?
   Complex operator+( Complex &amp;other );
   void Display( ) {   cout &lt;&lt; re &lt;&lt; "", "" &lt;&lt; im &lt;&lt; endl; }
private:
   double re, im;
};

// Operator overloaded using a member function
Complex Complex::operator+( Complex &amp;other ) {
   return Complex( re + other.re, im + other.im );
}

int main() {
   Complex a = Complex( 1.2, 3.4 );
   Complex b = Complex( 5.6, 7.8 );
   Complex c = Complex( 0.0, 0.0 );

   c = a + b;
   c.Display();
}
</code></pre>
","922184","","<p>Those are member initializers. When the object is created with that constructor, the members are initialized according to those.</p>

<p>So <code>re</code> gets set to <code>r</code>. And <code>im</code> gets set to <code>i</code>.</p>
"
"<p>For unsigned int x, is it possible to calculate x % 255 (or 2^n - 1 in general) using only the following operators (plus no loop, branch or function call)?</p>

<p><code>!</code>, <code>~</code>, <code>&amp;</code>, <code>^</code>, <code>|</code>, <code>+</code>, <code>&lt;&lt;</code>, <code>&gt;&gt;</code>.</p>
","922184","","<p>Yes, it's possible. For 255, it can be done as follows:</p>

<pre><code>unsigned int x = 4023156861;

x = (x &amp; 255) + (x &gt;&gt; 8);
x = (x &amp; 255) + (x &gt;&gt; 8);
x = (x &amp; 255) + (x &gt;&gt; 8);
x = (x &amp; 255) + (x &gt;&gt; 8);

//  At this point, x will be in the range: 0 &lt;= x &lt; 256.
//  If the answer 0, x could potentially be 255 which is not fully reduced.

//  Here's an ugly way of implementing: if (x == 255) x -= 255;
//  (See comments for a simpler version by Paul R.)
unsigned int t = (x + 1) &gt;&gt; 8;
t = !t + 0xffffffff;
t &amp;= 255;
x += ~t + 1;

// x = 186
</code></pre>

<p>This will work if <code>unsigned int</code> is a 32-bit integer.</p>

<p>EDIT: The pattern should be obvious enough to see how this can be generalized to <code>2^n - 1</code>. You just have to figure out how many iterations are needed. For <code>n = 8</code> and a 32-bit integer, 4 iterations should be enough.</p>

<p>EDIT 2:</p>

<p>Here's a slightly more optimized version combined with Paul R.'s conditional subtract code:</p>

<pre><code>unsigned int x = 4023156861;

x = (x &amp; 65535) + (x &gt;&gt; 16);     //  Reduce to 17 bits
x = (x &amp; 255) + (x &gt;&gt; 8);        //  Reduce to 9 bits
x = (x &amp; 255) + (x &gt;&gt; 8);        //  Reduce to 8 bits
x = (x + ((x + 1) &gt;&gt; 8)) &amp; 255;  //  Reduce to &lt; 255
</code></pre>
"
"<p>let's say I have the following loops:</p>

<pre><code>for(int i=left; i &lt; right; i++) {
    for(int j=top; j &lt; bottom; j++) {
        if(tilesMap[i][j])
            (tilesMap[i][j])-&gt;Draw(window) ;
    }
}
</code></pre>

<p>and</p>

<pre><code>for(int i=left; i &lt; right; i++) {
    for(int j=top; j &lt; bottom; j++) {
        (tilesMap[i][j])-&gt;Draw(window) ;
    }
}
</code></pre>

<p>Is there any way I can make this ""generic"", ie if some boolean is true, I will call the first code segment, if not I'll call the second code segment.
I obviously could do a test before the loop and branch on the right loop, but then I have to duplicate the loop ""header"" and the instruction inside too, and change it twice every time I change the code inside the loop. The other solution is to do a test inside the lopp at every iteration, but this would make way too many tests at runtime.
Is there any other way I can do this? thanks</p>

<p>EDIT: this is just a question for my knowledge, I'm perfectly fine with duplicating my code for such small amount</p>
","922184","","<p>IMO, this code is small enough to just duplicate the loop. I'd be okay with a tiny bit of code-duplication if it makes it more readable and helps performance.</p>

<p>I would say that putting a test inside the loop could make it harder to read since it increases the nesting depth.</p>
"
"<pre><code>char buffer[1000] = {0};
</code></pre>

<p>This initializes all 1000 elements to 0. Is this constant time? If not, why?</p>

<p>It seems like the compiler could optimize this to O(1) based on the following facts:</p>

<ol>
<li>The array is of fixed size and known at compile time</li>
<li>The array is located on the stack, which means that presumably the executable could contain this data in the data segment of the executable (on Windows) as a chunk of data that is already filled with 0's.</li>
</ol>

<p>Note that answers can be general to any compiler, but I'm specifically interested in answers tested on the MSVC compiler (any version) on Windows.</p>

<p>Bonus Points: Links to any articles, white papers, etc. on the details of this would be greatly appreciated.</p>
","922184","","<p>If it's inside a function, no, it's not constant time.</p>

<p>Your second assumption isn't correct:</p>

<p>""The array is located on the stack, which means that presumably the executable could contain this data in the data segment of the executable (on Windows) as a chunk of data that is already filled with 0's.""</p>

<p>The stack isn't already filled with zeros. It's filled with junk leftover from previous function calls.</p>

<p>So it's not possible to do it in <code>O(1)</code> because it will have to zero it.</p>
"
"<p>I have been reading a lot of articles lately about programming practice, design and so forth and was curious about the real performance gains from implementing multiplication as bit shifting.</p>

<p>The example I was reading about was encouraging implementing x*320 as (x&lt;&lt;8 + x&lt;&lt;6) for a commonly used routine.</p>

<p>How relevant is this in modern compilers? If there are significant performance gains, can compilers not automatically convert these ""easy multiplications"" to bit-shifts as necessary?</p>

<p>Has anyone had to resort to bit-shifting in this way in their projects to achieve faster multiplication? What performance gains can you expect?</p>
","922184","","<p>Yes, compilers will do most of these for you. They're pretty aggressive with it too. So there's rarely a need to do it yourself. (especially at the cost of readability)</p>

<p>However, on modern machines now, multiplication isn't ""that"" much slower than shifts. So any number that needs more than like 2 shifts are better done using multiplication. The compilers know this and will choose accordingly.</p>

<p>EDIT:</p>

<p>From my experience, I've never been able to outdo a compiler in this area unless the code was vectorized via SSE intrinsics (which the compilers don't really try to optimize).</p>
"
"<p>This program is giving me a full screen of errors when i try to compile it with g++ but i didnt even start the hard part. Just printing instructions. What is wrong here?</p>

<pre><code>/* Samuel LaManna
CSC 135 Lisa Frye
Program 2 Functions (Shipping Charges)
Calculate the shipping and total charge
for shipping spools of wire
*/

#include &lt;iostream&gt;

using namespace std;

void instruct();     //Function Declaration for instruction function

int main()
{
  instruct();     // Function to print instructions to user

  return 0;
}


/********************************************/
// Name: Instruct                            /
// Description: Print instructions to user   /
// Parameters: N/A                           /
// Reture Value: N/A                         /
/********************************************/

void instruct()
{
  cout &lt;&lt; ""This program will calculate the shipping information ""
       &lt;&lt; ""for a batch of wire spools. "" &lt;&lt; endl &lt; endl;

  return;
}
</code></pre>
","922184","","<p>Here's one problem:</p>

<pre><code>&lt;&lt; endl &lt; endl;
</code></pre>

<p>It should be:</p>

<pre><code>&lt;&lt; endl &lt;&lt; endl;
</code></pre>
"
"<p>I'm using two different variable to divide in the calculation with the variable from <code>int</code> and <code>double</code>. These work fine when I use something like:</p>

<pre><code>int cost
cost = 40;
cost = (cost / 400) * 20 * 2;
</code></pre>

<p>For this the method works fine and I get the right result which is <code>4</code>, but when I use the variable <code>cost</code> and put it in the header instead, like:</p>

<pre><code>#define cost 40
int total_cost;
total_cost = (cost / 400) * 20 * 2;
</code></pre>

<p>this always results in <code>0</code> for me and I don't know why. Even if I use <code>printf</code> with <code>%d</code> or <code>%f</code> this still gives me a result of <code>0</code>.</p>
","922184","","<p>You are doing integer division - which rounds down.</p>

<p>Therefore:</p>

<pre><code>cost / 400
</code></pre>

<p>is returning zero because <code>cost = 40</code> and <code>40 / 400</code> rounds down to zero.</p>

<p>What you should do is use a floating-point type like <code>double</code>.</p>

<p>EDIT:</p>

<pre><code>double cost
cost = 40;
cost = (cost / 400) * 20 * 2;
</code></pre>

<p>and</p>

<pre><code>#define cost 40
double total_cost;
total_cost = ((double)cost / 400) * 20 * 2;
</code></pre>
"
"<p>it says there is a problem with this function. It should get input from the user for number of spools to be ordered and then output the input it recieved. (thinking of adding a confirmation dialog if there is time).</p>

<pre><code>/********************************************/
// Name: inspools                            /
// Description: Ask for and get number of    /
// spools                                    /
// Parameters: N/A                           /
// Reture Value: spoolnum                    /
/********************************************/
int spoolnum()
{
  int spoolnum;

  cout &lt;&lt; ""Number of spools to be shipped: "" &lt;&lt; endl;
  cin &gt;&gt; spoolnum;
  cout &gt;&gt; spoolnum &gt;&gt; "" spool(s) of wire will be shipped"" &gt;&gt; endl;

  return;
}
</code></pre>
","922184","","<p>You have your arrows backwards in this line:</p>

<pre><code>cout &gt;&gt; spoolnum &gt;&gt; "" spool(s) of wire will be shipped"" &gt;&gt; endl;
</code></pre>

<p>it should be:</p>

<pre><code>cout &lt;&lt; spoolnum &lt;&lt; "" spool(s) of wire will be shipped"" &lt;&lt; endl;
</code></pre>

<p>And your <code>return</code> statement needs to return something:</p>

<pre><code>return spoolnum;
</code></pre>
"
"<p>In the software I'm writing, I'm doing millions of multiplication or division by 2 (or powers of 2) of my values. I would really like these values to be <code>int</code> so that I could access the bitshift operators </p>

<pre><code>int a = 1;
int b = a&lt;&lt;24
</code></pre>

<p>However, I cannot, and I have to stick with doubles. </p>

<p>My question is : <strong>as there is a standard representation of doubles (sign, exponent, mantissa), is there a way to play with the exponent to get fast multiplications/divisions by a power of 2</strong>?</p>

<p>I can even assume that the number of bits is going to be fixed (the software will work on machines that will always have 64 bits long doubles)</p>

<p>P.S : And yes, the algorithm mostly does these operations only. This is the bottleneck (it's already multithreaded).</p>

<p>Edit : Or am I completely mistaken and clever compilers already optimize things for me?</p>

<hr>

<p>Temporary results (with Qt to measure time, overkill, but I don't care): </p>

<pre><code>#include &lt;QtCore/QCoreApplication&gt;
#include &lt;QtCore/QElapsedTimer&gt;
#include &lt;QtCore/QDebug&gt;

#include &lt;iostream&gt;
#include &lt;math.h&gt;

using namespace std;

int main(int argc, char *argv[])
{
QCoreApplication a(argc, argv);

while(true)
{
    QElapsedTimer timer;
    timer.start();

    int n=100000000;
    volatile double d=12.4;
    volatile double D;
    for(unsigned int i=0; i&lt;n; ++i)
    {
        //D = d*32;      // 200 ms
        //D = d*(1&lt;&lt;5);  // 200 ms
        D = ldexp (d,5); // 6000 ms
    }

    qDebug() &lt;&lt; ""The operation took"" &lt;&lt; timer.elapsed() &lt;&lt; ""milliseconds"";
}

return a.exec();
}
</code></pre>

<p>Runs suggest that <code>D = d*(1&lt;&lt;5);</code> and <code>D = d*32;</code> run in the same time (200 ms) whereas <code>D = ldexp (d,5);</code> is much slower (6000 ms). I <strong>know</strong> that this is a micro benchmark, and that suddenly, my RAM has exploded because Chrome has suddenly asked to compute Pi in my back every single time I run <code>ldexp()</code>, so this benchmark is worth nothing. But I'll keep it nevertheless.</p>

<p>On the other had, I'm having trouble doing <code>reinterpret_cast&lt;uint64_t *&gt;</code> because there's a <code>const</code> violation (seems the <code>volatile</code> keyword interferes)</p>
","922184","","<p>This is one of those highly-application specific things. It may help in some cases and not in others. (In the vast majority of cases, a straight-forward multiplication is still best.)</p>

<p>The ""intuitive"" way of doing this is just to extract the bits into a 64-bit integer and add the shift value directly into the exponent. (this will work as long as you don't hit NAN or INF)</p>

<p>So something like this:</p>

<pre><code>union{
    uint64 i;
    double f;
};

f = 123.;
i += 0x0010000000000000ull;

//  Check for zero. And if it matters, denormals as well.
</code></pre>

<p><strong>Note that this code is not C-compliant in any way, and is shown just to illustrate the idea. Any attempt to implement this should be done directly in assembly or SSE intrinsics.</strong></p>

<p>However, in <strong><em>most</em></strong> cases the overhead of moving the data from the FP unit to the integer unit (and back) will cost much more than just doing a multiplication outright. This is especially the case for pre-SSE era where the value needs to be stored from the x87 FPU into memory and then read back into the integer registers.</p>

<p>In the SSE era, the Integer SSE and FP SSE use the same ISA registers (though they still have separate register files). According the <a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">Agner Fog</a>, there's a 1 to 2 cycle penalty for moving data between the Integer SSE and FP SSE execution units. So the cost is much better than the x87 era, but it's still there.</p>

<p>All-in-all, it will depend on what else you have on your pipeline. But in most cases, multiplying will still be faster. I've run into this exact same problem before so I'm speaking from first-hand experience.</p>

<p>Now with 256-bit AVX instructions that only support FP instructions, there's even less of an incentive to play tricks like this.</p>
"
"<p>In the following assembly code I am trying to implement a multiplication method using bitwise shifts etc but I am getting two errors over and over, ""too many memory references for 'mov'"" as well as ""ambiguous operand size for 'cmp/and/mov/shl/shr'"". Any ideas?</p>

<p>Thanks guys. The associated errors are below, as requested.</p>

<pre><code>    .intel_syntax
    .data

    .globl x
x:  .long 0

    .globl y
y:  .long 0
    .text

    .globl multiply
multiply:
    push    ebp #These two statements are necessary
    mov ebp,esp

    mov eax,0
    mov ebx,x
    mov edx,y

LOOP:
    cmp ebx,0
    je  DONE

    mov ecx,ebx
    and ecx,1
    cmp ecx,1
    jne LOOPC   #jump to continued loop if low_bit(x) not 1

    add eax,edx

LOOPC:
    shr ebx,1
    shl edx,1
    jmp LOOP

DONE:
    pop ebp #Necessary statement
    ret     #return
</code></pre>

<p>Error messages:</p>

<pre><code>multiply.s: Assembler messages:
multiply.s:0: Warning: end of file in comment; newline inserted
multiply.s:15: Error: too many memory references for `mov'
multiply.s:17: Error: ambiguous operand size for `mov'
multiply.s:18: Error: too many memory references for `mov'
multiply.s:19: Error: too many memory references for `mov'
multiply.s:22: Error: ambiguous operand size for `cmp'
multiply.s:25: Error: too many memory references for `mov'
multiply.s:26: Error: ambiguous operand size for `and'
multiply.s:27: Error: ambiguous operand size for `cmp'
multiply.s:30: Error: too many memory references for `add'
multiply.s:33: Error: ambiguous operand size for `shr'
multiply.s:34: Error: ambiguous operand size for `shl'
</code></pre>
","922184","","<p>You are missing <code>%</code> in front of all your register names:</p>

<p>So it should be:</p>

<pre><code>mov %eax,0
mov %ebx,x
mov %edx,y
</code></pre>

<p>As it is, it is parsing them as variables to memory locations. (without the <code>%</code>, they'd be the same as <code>x</code> and <code>y</code> which <strong>are</strong> memory references.)</p>

<p>EDIT:</p>

<p>Ah... Looks like ughoavgfhw already pointed this out in the comments.</p>
"
"<p>I know the syntax for writing a case break statement, but I'm wondering if this is allowed:</p>

<p>CODE:</p>

<pre><code>    case 'p':
    {
    printf(""Give number: "");
    scanf(""%d, &amp;int_1);
    if int_1=5;{
    printf(""Played: you win"");
    }
    break;
    }
</code></pre>

<p>Basically I'm just wondering if this is something that's possible to do, I know the code is incomplete but I don't want anyone to think I'm trying to elicit specific answers. I simply seek a better understanding of applying conditionals to my programs. Thank you.</p>

<p>EDIT: Other than in the tags, I didn't specify so just in case this isn't clear, this is in C.</p>
","922184","","<p>Yes it's allowed. But you also forgot the <code>(</code>parentheses<code>)</code> around your <code>if</code>:</p>

<pre><code>if int_1=5;{
</code></pre>

<p>should be:</p>

<pre><code>if (int_1 == 5){
</code></pre>

<p>So if it wasn't compiling, this is the reason.</p>
"
"<p>I am creating a menu that needs to take in an three inputs from the users.</p>

<pre><code>    char *fullname;
    char *date;
    float sal;
    printf(""\nEnter full name: "");
</code></pre>

<p>line92  </p>

<pre><code>scanf(""%s"", &amp;fullname);

printf(""\nEnter hire date: "");
</code></pre>

<p>Line 94</p>

<pre><code>scanf(""%s"", &amp;date);

printf(""\nEnter salary: "");
</code></pre>

<p>Line 96</p>

<pre><code>scanf(""%d"", &amp;sal);
</code></pre>

<p>These are the error I am recieving</p>

<pre><code>    Employee.c:92: warning: format ‘%s’ expects type ‘char *’, but argument 2 has type ‘char **’
    Employee.c:94: warning: format ‘%s’ expects type ‘char *’, but argument 2 has type ‘char **’
    Employee.c:96: warning: format ‘%d’ expects type ‘int *’, but argument 2 has type ‘float *’
</code></pre>

<p>Can I get an explanation of what is causing these issues?</p>
","922184","","<p>There are several problems:</p>

<p>First:</p>

<p>When you use <code>scanf</code> for strings you do not use the <code>&amp;</code>. So just <code>scanf(""%s"", fullname);</code>.</p>

<p>Second:</p>

<p>Your pointers aren't initialized. Try this instead:</p>

<pre><code>char fullname[256];
char date[256];
</code></pre>

<p>This will work as long as you input at most 255 characters.</p>

<p>Third:</p>

<p>Your typing for the last <code>scanf</code> doesn't match. You're passing in a <code>float</code> when you've specified an <code>int</code> in the format string. Try this:</p>

<pre><code>scanf(""%f"", &amp;sal);
</code></pre>
"
"<p>I've added OpenMP to an existing code base in order to parallelize a for loop.  Several variables are created inside the scope of the <code>parallel for</code> region, including a pointer:</p>

<pre><code>#pragma omp parallel for
for (int i = 0; i &lt; n; i++){
    [....]
    Model *lm;
    lm-&gt;myfunc();
    lm-&gt;anotherfunc();
    [....]
}
</code></pre>

<p>In the resulting output files I noticed inconsistencies, presumably caused by a race condition.  I ultimately resolved the race condition by using an <code>omp critical</code>.  My question remains, though:  is <code>lm</code> private to each thread, or is it shared?</p>
","922184","","<p>Yes, all variables declared inside the OpenMP region are private. This includes pointers.</p>

<p>Each thread will have it's own copy of the pointer.</p>

<p>EDIT:</p>

<p>So it lets you do stuff like this:</p>

<pre><code>int threads = 8;
int size_per_thread = 10000000;

int *ptr = new int[size_per_thread * threads];

#pragma omp parallel num_threads(threads)
    {
        int id = omp_get_thread_num();
        int *my_ptr = ptr + size_per_thread * id;

        //  Do work on ""my_ptr"".
    }
</code></pre>
"
"<p>GCC warns me that the following piece of code contains an implicit conversion that may change a value:</p>

<pre><code>#include &lt;stdlib.h&gt;
float square = rand();
</code></pre>

<p>However, the following does not yield any warning:</p>

<pre><code>float square = 100;
</code></pre>

<p>The warning given by GCC is a follows:</p>

<pre><code>tests/ChemTests.cpp:17:23: error: conversion to ‘float’ from ‘int’ may alter its value
</code></pre>

<p>I don't understand why the former would give a warning, since <code>rand()</code> is properly declared and returns an <code>int</code>, just as the <code>100</code> integer literal.</p>

<p><strong>Why does the first line give a compiler warning but not the second, even though both have an implicit conversion from <code>int</code>to <code>float</code>?</strong></p>
","922184","","<p>GCC emits this warning when a loss of precision may result from the cast. (in other words, the value may be ""altered"")</p>

<p>In the first case, <code>rand()</code> returns an <code>int</code>. Since not all values that can be stored in an <code>int</code> are representable as a <code>float</code>, it will emit this warning.</p>

<p>In the second case, 100 can be safely casted to a <code>float</code> without any precision loss.</p>
"
"<p>I have a issue with basic typecasting.</p>

<pre><code>#include&lt;stdio.h&gt;

int main()
{
     printf(""%.22f"",0.30);
     return 1;
}
</code></pre>

<p>The output I am getting is 0.2999999999999999888978</p>

<p>Why is 0.3 converted to a lesser value</p>

<p>Any help much appreciated</p>

<p>Nandish</p>
","922184","","<p>This is because <code>0.30</code> cannot be exactly represented in binary floating-point.
Internally, only an approximation to <code>0.30</code> can be stored. Therefore, when you print it all out, you'll get a slightly different number.</p>

<p><a href=""http://en.wikipedia.org/wiki/Floating_point"" rel=""nofollow"">http://en.wikipedia.org/wiki/Floating_point</a></p>
"
"<p>My random numbers that output, output in the same sequence every time I run my game. Why is this happening?</p>

<p>I have </p>

<pre><code>#include &lt;cstdlib&gt; 
</code></pre>

<p>and am using this to generate the random numbers </p>

<pre><code>randomDiceRollComputer = 1 + rand() % 6;
</code></pre>
","922184","","<p>You need to seed your random number generator:</p>

<p>Try putting this at the beginning of the program:</p>

<pre><code>srand ( time(NULL) );
</code></pre>

<p>Note that you will need to <code>#include &lt;ctime&gt;</code>.</p>

<p>The idea here is to seed the RNG with a different number each time you launch the program. By using time as the seed, you get a different number each time you launch the program.</p>
"
"<p>I got:</p>

<pre><code>int number = 1255; -&gt; //It could also be 125(1€25Cent) or 10(10Cent) or 5(5Cent)

public double toMoney(int number)
{
...
}
</code></pre>

<p>as return, I want the double number: <strong>12.55</strong> or if input: 10 then: <strong>00.10</strong> </p>

<p>I know that I can do with Modulo something like this:</p>

<p>1255 % 100.. to get 55.. But how to do it for 12 and at the end, how to 
form it as a double?</p>
","922184","","<p>If I'm understanding your question correctly, you're probably trying to just do this:</p>

<pre><code>return (double)number / 100.;
</code></pre>

<p><strong>Though a word of warning:</strong> <em>You shouldn't be using floating-point for money due to round-off issues.</em></p>

<p>If you just want to print the number in money format, here's a 100% safe method:</p>

<pre><code>System.out.print((number / 100) + ""."");
int cents = number % 100;
if (cents &lt; 10)
    System.out.print(""0"");
System.out.println(cents);
</code></pre>

<p>This can probably be simplified a lot better... Of course you can go with BigDecimal, but IMO that's smashing an ant with a sledgehammer.</p>
"
"<p>For a program, I would like to make an array copy of the arguments sent in by command line using malloc().</p>

<p>So for example if I do ./a.out one two three
I want an array with {a.out, one, two, three} in it. </p>

<p>However, I have some issues getting my program to work. Here's what I have:</p>

<pre><code>static char** duplicateArgv(int argc, char **argv)                                                                                                                                                         
{                                                                                                                                                                                                                                                                                                                                                                                       
    char *array;                                                                                                                                                                                                                                                                                                                                                               
    int j = 0;                                                                                                                                                                                        

    // First allocate overall array with each element of char*                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
    array = malloc(sizeof(char*) * argc);                                                                                                                                                       
    int i;                  

    // For each element allocate the amount of space for the number of chars in each      argument                                                                                                                                                              
    for(i = 1; i &lt; (argc + 1); i++){                                                                                                                                                                      
        array[i] = malloc(strlen(*(argv + i)) * sizeof(char));                                                                                                                                        
        int j;       

        // Cycle through all the chars and copy them in one by one                                                                                                                                                                                 
        for(j = 0; j &lt; strlen(*(argv + i)); j++){                                                                                                                                                     
            array[i][j] = *(argv + i)[j];                                                                                                                                                                                                                                                                                                                                                       
        }                                                                                                                                                                                             

    }                                                                                                                                                                                                 

    return array;

}
</code></pre>

<p>As you might imagine, this doesn't work. I apologize ahead of time if this somehow totally doesn't make sense, as I just started learning about pointers. Also, I'm not quite sure how to write code to free up every element in the *array after I do what I need to the copy. </p>

<p>Could anyone give me some tips on what I should look into to make it do what I want?</p>

<p>Thanks for any help! </p>
","922184","","<p>You're not allocating or copying the terminating NULL characters:</p>

<p>This line needs to be changed to this for the NULL.</p>

<pre><code>array[i] = malloc((strlen(*(argv + i)) + 1) * sizeof(char));   
</code></pre>

<p>And the loop should be changed to this:</p>

<pre><code>for(j = 0; j &lt;= strlen(*(argv + i)); j++){ 
</code></pre>

<p>Also, the code can be better optimized if you saved the result of the <code>strlen()</code> call since you call it in so many places.</p>

<p>Try the loop as this:</p>

<pre><code>// For each element allocate the amount of space for the number of chars in each argument
for(i = 0; i &lt; argc; i++){

    int length = strlen(argv[i]);

    array[i] = malloc((length + 1) * sizeof(char));
    int j;

    // Cycle through all the chars and copy them in one by one
    for(j = 0; j &lt;= length; j++){
        array[i][j] = argv[i][j];
    }

}
</code></pre>
"
"<p>I have made available a static lib to third party. they are one of the only people who dont want to use the lib in this form and are trying to use a dll with that. however, in order to do that would i just need to change those functions which will need exporting by placing 
__declspec(dllexport) in the .h and .cpp files?</p>
","922184","","<p>It's a little more complicated than that:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms235636%28v=vs.80%29.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms235636%28v=vs.80%29.aspx</a></p>

<p>Not only do you have to declare all your API functions as <code>__declspec(dllexport)</code>, but you also have to configure the compiler to compile to a <code>.dll</code>.</p>

<p>If you're also exporting global variables, you'll need to use deal with <code>__declspec(dllimport)</code> as well.</p>
"
"<p>let a A.java file be :</p>

<pre><code>    class B {static int i; }

    class A {
        public static void main(String[] args) {
            B a=new B();
            B b=new B(); 
            a.i=10;
            b.i=5; 

            System.out.println(a.i);
        }
    }
</code></pre>

<p>Why is the result 5 and not 10 ?</p>

<p>Thanks.</p>
","922184","","<p>It's because you declared <code>i</code> to be static. <strike>Therefore, all instances of <code>B</code> share the same value and memory location.</strike> (Therefore, there <code>B</code> is associated with the type rather than the instance.)</p>

<p>So when you do this:</p>

<pre><code>a.i=10;
b.i=5;
</code></pre>

<p>You are actually writing to the value variable. Hence why <code>5</code> gets printed out instead of <code>10</code>.</p>
"
"<p>I was looking into some C++ tutorial and encountered a function declaration inside the class</p>

<pre><code>class CRectangle {
    int x, y;
public:
    int area (void)  {return x*y;}
};
</code></pre>

<p>Now I am wondering what is the use of <code>void</code> after int area?</p>
","922184","","<p><code>void</code> in this case means that the function doesn't take any parameters.</p>

<p>Also - syntax error, you probably meant <code>{}</code> brackets and you had the semicolon in the wrong place.</p>

<pre><code>int area (void){ return (x*y); }
</code></pre>
"
"<p>When I use the operator % in my Java programs, I keep getting negative answers. Example: -1%100 gives -1. While this is mathematically correct, I want to get the normal mathematical solution, or 99. In other words, I want to get the smallest positive integer solution. Is there any simple solution for this in Java (perhaps something I overlooked in Math? -- I can't find it)?</p>

<p>Thanks!</p>

<p>EDIT: I also want to clarify that if there is something in the API that does this, a link would be awesome.</p>
","922184","","<p>You can just do this?</p>

<pre><code>int d = 100;

int x = -1 % d;
if (x &lt; 0)
    x += d;
</code></pre>

<p>This should work for any positive <code>d</code>.</p>
"
"<p>I'd like to make object of class not copyable so I put copy constructor and operator= in private section. However one class is friend of this class so it has access to private methods. Is it good idea to put throw exception in copy constructor and operator= to be sure that object will not be copied?</p>
","922184","","<p>One approach to make it not copyable is just to declare the copy constructor, but don't implement it at all. That will force a linker error at compile time if anyone tries to use it.</p>

<pre><code>class foo
{
private:
    foo(const foo&amp;); // not defined
    foo&amp; operator=(const foo&amp;); // not defined
};
</code></pre>
"
"<p>i have to make a java program (an artichoke cipher) well...  please help lol</p>

<p>it keeps giving me an error - </p>

<pre><code> ""
    java.lang.StringIndexOutOfBoundsException: String index out of range: 11
    at java.lang.String.charAt(String.java:686)
    at ArtichokeCipher.main(ArtichokeCipher.java:29)
    ""
</code></pre>

<p>this is the actual artichoke cipher program..i obtain the data file from the user then ask them for the key to be used to shift the letters from the data inside the text file.  From there i turn the cipher key into a char to be used as a shift number but im just really lost as to why i get this error.</p>

<pre><code>//PROGRAM
import java.util.Scanner;
import java.io.*;

public class ArtichokeCipher {
public static void main(String[] args) throws IOException {
    Scanner scan1 = new Scanner (System.in);

    System.out.println(""Welcome to Artichoke Cipher!"");
    System.out.println(""Please name input file to be processed: "");
    String filei = scan1.next();
    Scanner scan = new Scanner (new File (filei));

    System.out.println(""Please enter the word to be used as the cipher key: "");
    String shift = scan1.next();
    String lowcase = shift.toLowerCase();


    while (scan.hasNext()) {
    String word = scan.nextLine();
    String answer = """";
    for (int i = 0; i &lt; word.length(); i++)
    {
       char curChar = word.charAt(i);
       char key = lowcase.charAt(i);
       char newChar = (char)(curChar + key);
       if (curChar &gt;= 'A' &amp;&amp; curChar &lt;= 'Z'){
           if (newChar &gt; 'Z')
           newChar = (char)(newChar-26);
        }
        else if (curChar &gt;= 'a' &amp;&amp; curChar &lt;= 'z') {
            if (newChar &gt; 'z')
            newChar = (char)(newChar - 26);
    }
}
            System.out.println(""Encoded: "" + answer);
}
}
}
</code></pre>

<p>any help is appreciated thanks</p>
","922184","","<p>You are potentially overrunning a string on this line:</p>

<pre><code>char key = lowcase.charAt(i);
</code></pre>

<p>The reason is that the index <code>i</code> is valid for <code>word</code>, but may be beyond the length of <code>lowcase</code>. In which case, you will can an Out of Bounds exception when <code>word</code> is longer than <code>lowcase</code>. </p>
"
"<pre><code>char *recvmsg(){
    char buffer[1024];
    return buffer;
}

int main(){
    char *reply = recvmsg();
    .....
}
</code></pre>

<p>I get a warning
warning C4172: returning address of local variable or temporary</p>
","922184","","<p>The warning message is correct. You're returning the address of a local array which disappears after the function returns.</p>

<p>You can do this using dynamic memory allocation:</p>

<pre><code>char *recvmsg(){
    char *buffer = (char*)malloc(1024);
    return buffer;
}
</code></pre>

<p>The catch is that you need to make sure you <code>free()</code> the pointer later on to avoid a memory leak.</p>

<p>Alternatively, you can pass the buffer into the function.</p>

<pre><code>void recvmsg(char *buffer,int buffer_size){
    //  write to buffer
}

void main(){
    char buffer[1024];
    recvmsg(buffer,1024);
}
</code></pre>

<p>This avoids the need for a memory allocation. This is actually the preferred way to do it.</p>
"
"<p>Say I have a class I defined called 'MyClass'. My 'main' method takes as arguments a list of filenames. Each filename is a config file for MyClass, but the program user can have as many objects of MyClass as they want. If they type in, say, 2 filenames as arguments to my main method, I would like to have 2 objects.</p>

<p>If I knew the user was limited to 2 objects, I could just use:</p>

<pre><code>MyClass myclass1;
MyClass myclass2;
</code></pre>

<p>However this wouldn't work if the user had say inputted 3 or 4 filenames instead. Can anyone help me and suggest a method I could use to create a number of insantiations of a class depending on the number of arguments my program is given?</p>

<p>Thanks</p>
","922184","","<p>For this, you should use arrays or vectors:</p>

<pre><code>vector&lt;MyClass&gt; myclass;

myclass.push_back( ... );  // Make your objects, push them into the vector.
myclass.push_back( ... );
myclass.push_back( ... );
</code></pre>

<p>And then you can access them like:</p>

<pre><code>myclass[0];
myclass[1];

...
</code></pre>

<p>See wikipedia for more info and examples:</p>

<p><a href=""http://en.wikipedia.org/wiki/Vector_%28C%2B%2B%29#Usage_example"" rel=""nofollow"">http://en.wikipedia.org/wiki/Vector_%28C%2B%2B%29#Usage_example</a></p>
"
"<p>I am a bit stuck right now. I have a base class called BaseBond. ZeroCouponBond and CouponBond inherit from that class. I am looking to create an array that contains both types of bonds. Here is my code:</p>

<pre><code>...
BaseBond port[12];

for (int i=0; i &lt; recordCount; i++)
{
    if (bonds[i].CouponRate == 0.0)
        port[i] = new ZeroCouponBond(bonds[i]);
    else
        port[i] = new CouponBond(bonds[i]);
}
</code></pre>

<p>Here is the error I am getting:
error: no match for ‘operator=’ in ‘port[i]</p>

<p>I know this is probably a simple fix and has to do with when I can declare objects in an array, but I'm relatively new to C++ and don't know all the rules. </p>

<p>Thanks in advance for the help!</p>
","922184","","<p>You need to do this using pointers:</p>

<p>Change the declaration to this:</p>

<pre><code>BaseBond *port[12];
</code></pre>

<p>In your original code, you were trying to assign a pointer to <code>BaseBond</code>. So it won't compile.</p>

<p>Furthermore, when you use inheritance like this, you have to do it using pointers anyway to prevent object slicing.</p>
"
"<p>Here is the source code:</p>

<pre><code>int main() {
    int secondsInYear = 366*24*60*60; // Equals 31,622,400
    short int data[secondsInYear];
    FILE * pFile;
    pFile = fopen (""stat"", ""r"");
    fread(data, sizeof(short int), secondsInYear, pFile);
    fclose(pFile);
}
</code></pre>

<p>on line <code>fopen(""stat"", ""r"")</code> it gives me the segmentation fault error! If I read <code>secondsInYear/10</code> characters it will execute without any problem, So what seems to be the problem? And what's the solution?</p>
","922184","","<p>You're creating a massive array on the stack. So you are hitting a stackoverflow. :)</p>

<p>You should dynamically allocate that array instead.</p>

<pre><code>short int *data = new short int[secondsInYear];
</code></pre>

<p>and be sure to delete it later:</p>

<pre><code>delete[] data;
</code></pre>
"
"<p>How do I set the size of a file in c ? Would I do this after I fopen?</p>
","922184","","<p>There's a bunch of ways to do this:</p>

<p>1 . C/C++ only</p>

<p>You can move the file pointer (using <code>fseek()</code>) to the size you want, and write anything. This will set the size of the file to the location of the file pointer.</p>

<p>However, this approach only lets you increase the size of a file. It doesn't not let you shrink it.</p>

<p>2 . (Windows)</p>

<p>You can make the file using <code>CreateFile()</code>, then set the file pointer location and use <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/aa365531%28v=vs.85%29.aspx"" rel=""nofollow""><code>SetEndOfFile()</code></a> to set the actual size.</p>

<p>This method in Windows can also be used to shrink the size of a file.</p>

<p>3 . (Linux)</p>

<p>I'm not sure here, but there's probably something in posix that will do it other than just <code>fseek</code> + <code>fwrite</code>.</p>
"
"<p>It's surprising for me to see that even when the value can be converted, an int to float conversion <em>always</em> give a warning.  Why is this?</p>

<pre><code>int i = 0;
float f = 0; // warning here

// I thought this was an implicit conversion,
// meaning it is convertible with no warnings.
f = i;      // another warning here
</code></pre>

<p>The warning is:</p>

<pre><code>warning C4244: '=' : conversion from 'int' to 'float', possible loss of data
</code></pre>
","922184","","<p>I answered a similar question here:</p>

<p><a href=""http://stackoverflow.com/questions/7735383/why-does-gcc-warn-against-this-implicit-conversion/7735395#7735395"">Why does GCC warn against this implicit conversion?</a></p>

<p>The reason is that an <code>int</code> needs to be rounded when it is casted into a <code>float</code> because <code>float</code> cannot contain all the precision of an <code>int</code> in this case.</p>

<p>In your case, a <code>float</code> only has about 24 bits of precision. While an <code>int</code> has 32 bits of precision, therefore, some precision is loss by this cast, hence the warning.</p>
"
"<p>I have two threads with a parallel for but this one does not break up into threads:</p>

<pre><code>#pragma omp parallel sections
  {
#pragma omp section
    {
      for(int i=0;i&lt;4;++i)
        printf(""Loop A %d %d\n"", omp_get_thread_num(),2);
    }
#pragma omp section
    {
      for(int i=0;i&lt;4;++i)
        printf(""Loop B %d %d\n"", omp_get_thread_num(),3);
    }           
  }
</code></pre>

<p>Output:</p>

<p>Running…</p>

<pre><code>Loop A 0 2
Loop A 0 2
Loop A 0 2
Loop A 0 2
Loop B 0 3
Loop B 0 3
Loop B 0 3
Loop B 0 3
</code></pre>
","922184","","<p>This can happen for a number of reasons. I'll list the possible ones I know:</p>

<p>1: Make sure you actually have a multi-core machine. If it's a single core machine (no HT), it'll only run with one thread.</p>

<p>2: If this is on Visual Studio, you need to enable OpenMP support. Just including the header is not enough:</p>

<pre><code>Project -&gt; Properties -&gt; Configuration Properties -&gt; C/C++ -&gt; Language -&gt; Open MP Support
</code></pre>

<p>change it to <code>Yes (/openmp)</code>, and it should be enabled.</p>

<p>I ran your code with OpenMP setup properly and I get this:</p>

<pre><code>Loop A 0 2
Loop B 2 3
Loop B 2 3
Loop B 2 3
Loop B 2 3
Loop A 0 2
Loop A 0 2
Loop A 0 2
</code></pre>

<p>So I think your code is correct.</p>
"
"<p>I'm having an issue with inserting an entry into a Map.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;vector&gt;
#include &lt;stack&gt;
#include &lt;map&gt;

using namespace std;

class Nodo
{
public:
    vector&lt;Nodo&gt; Relaciones;
    int Valor;
    bool Visitado;

    Nodo(int V)
    {
        Valor = V;
        Visitado = false;
    }
};

class Grafo
{
public:
    Nodo *Raiz;
    map&lt;int, Nodo&gt; Nodos;

    Grafo(int V)
    {
        Raiz = new Nodo(V);
        //Getting http://msdn.microsoft.com/en-us/library/s5b150wd(v=VS.100).aspx here
        Nodos.insert(pair&lt;int, Nodo&gt;(V, Raiz));
    }
};
</code></pre>
","922184","","<p>You have a type mismatch. You're passing a <code>Nodo*</code> into the <code>pair</code> constructor while it expects a <code>Nodo</code> object.</p>

<p>You declare:</p>

<pre><code>Nodo *Raiz;
</code></pre>

<p>and then you try to call:</p>

<pre><code>pair&lt;int, Nodo&gt;(V, Raiz)
</code></pre>

<p>which expects an <code>int</code> and a <code>Nodo</code>. But you passed it <code>int</code> and <code>Nodo*</code>.</p>

<p>What you probably want is this:</p>

<pre><code>class Grafo
{
    public:
        Nodo *Raiz;
        map&lt;int, Nodo*&gt; Nodos;    //  change to pointer

        Grafo(int V)
        {
            Raiz = new Nodo(V);
            //Getting http://msdn.microsoft.com/en-us/library/s5b150wd(v=VS.100).aspx here
            Nodos.insert(pair&lt;int, Nodo*&gt;(V, Raiz));   // change to pointer
        }
};
</code></pre>
"
"<p>So I'm trying to make a program where it averages out your golf scores. I edited a standard averaging calculator to make it work:</p>

<pre><code>import java.util.Scanner;
public class Test {
public static void main(String args[]){
    Scanner input = new Scanner(System.in);
    int total = 0;
    int score;
    int average;
    int counter = 0;

    while (counter &gt;= 0){
    score = input.nextInt();
    total = total + score;
    counter++;
    }
    average= total/10;
    System.out.println(""Your average score is ""+ average);
}
}
</code></pre>

<p>But when I enter scores, I can keep entering infinite scores and it never averages them. It just keeps expecting another score. I know it has something to do with this line:</p>

<pre><code>while (counter &gt;= 0){
</code></pre>

<p>but I'm not sure what to do so it works right.</p>
","922184","","<p>You never find a way to break out of the loop:</p>

<pre><code>while (counter &gt;= 0){
    score = input.nextInt();
    total = total + score;
    counter++;
}
</code></pre>

<p>will loop <strong><em>2 billion</em></strong> times (no I'm not exaggerating) since you don't have another way to break out.</p>

<p>What you probably want is to change your loop condition to this:</p>

<pre><code>int score = 0;

while (score &gt;= 0){
</code></pre>

<p>This will break out when a negative score is entered.</p>

<p>Also, you have an integer division at the end. You want to make floating-point, so change the declaration to this:</p>

<pre><code>double average;
</code></pre>

<p>and change this line to this:</p>

<pre><code>average = (double)total / 10.;
</code></pre>
"
"<p>I am using native function in my java class.</p>

<p>I have written C++ function for XML parsing.</p>

<p>My problem is that after parsing XML, i have to store node names into string array, but i dont want to fix its size.</p>

<p>Like java, C++ have any collection ?</p>
","922184","","<p>Are you looking for just this?</p>

<pre><code>vector&lt;string&gt; var;
</code></pre>

<p><a href=""http://en.wikipedia.org/wiki/Vector_%28C%2B%2B%29"" rel=""nofollow"">http://en.wikipedia.org/wiki/Vector_%28C%2B%2B%29</a></p>

<p>It's used pretty much the same way but with different method names.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/1518711/c-programming-how-does-free-know-how-much-to-free"">C programming : How does free know how much to free?</a>  </p>
</blockquote>



<p>In C the function malloc takes an argument, specifiying how many bytes to alloacte.
How ever the function free doesn't take any arguments but a pointer.
How does free know how many bytes it has to free?</p>
","922184","","<p>This information such as the size of the allocation is kept within the memory allocator itself.</p>

<p>Internally, there's some data-structure that keeps a list of all the active memory allocations, their sizes, and their addresses. Exactly how it works is fairly complicated as there are lot of different memory allocation algorithms suited for different purposes and allocation sizes.</p>

<p>Often times, the size is stored as a fixed offset just below the address returned by <code>malloc()</code>, but that's just an implementation detail.</p>
"
"<p>how does most compilers implement operations on 64 bit operands (e.g long int) in 32 bit environments ? in other words, is there a way to implement these operations in a single step or we need to access multiple memory locations to implement these operations ?</p>
","922184","","<p>They use two registers to hold a 64-bit value. One for the lower 32-bits and one for the upper 32-bits.</p>

<p>For x86, 64-bit Addition/subtraction is done using add-with-carry and subtract-with-borrow instructions:</p>

<pre><code>add   %eax, (lower 32-bits of operand)
adc   %edx, (upper 32-bits of operand)
</code></pre>

<p>64-bit multiplication is much more complicated, but also done using a combination of 32-bit multiplies and 32-bit add-with-carry instructions. (in a way similar to long-multiplication with 2 digits)</p>

<p>For loads and stores, yes, two 32-bit values need to be loaded/stored into/from two registers.</p>

<p>Similarly, 128-bit integers can be implemented on 64-bit hardware. GCC supports this as an extension.</p>
"
"<p>Have a simple while loop and trying to make it to a for loop</p>

<pre><code>i=1
while(i&lt;=128)
{     printf(""%d"",i);
   i*=2;
}
</code></pre>

<p>Here is my for loop</p>

<pre><code>for (i=1;i&lt;=128;i++)
{ 
   printf(""%d"",i);
   i*=2;
}
</code></pre>

<p>How come it does not give the same output? The first one would print <code>1248163264128</code>, the for loop print <code>137153163127</code>?</p>
","922184","","<p>Because you're also incrementing <code>i</code> in the for-loop. In your original while-loop, <code>i</code> is never incremented.</p>

<p>Try this:</p>

<pre><code>for (i=1; i&lt;=128; i*=2)  //  Remove i++, move the i*=2 here.
{
    printf(""%d"",i);
}
</code></pre>
"
"<p>When I compile this code, I get an output of 10 when it should be 0.</p>

<pre><code>#include &lt;iostream&gt;

struct player
{
    int hp;
    int dmg;
};

void dealdamage(player x, player y)
{
    y.hp = y.hp - x.dmg;
}

int main()
{
player p1, p2;
p1.hp = 10, p1.dmg = 10;
p2.hp = 10, p2.dmg = 10;
dealdamage(p1, p2);
std::cout &lt;&lt; p2.hp &lt;&lt; std::endl;
return 0;
}
</code></pre>

<p>Can anyone explain why?</p>
","922184","","<p>That's because you're passing the <code>player</code> structs in by value.</p>

<p>When the parameter is passed by value, a copy is made into the called function. So whatever changes you make in the function won't affect the original.</p>

<p>So your statement:</p>

<pre><code>y.hp = y.hp - x.dmg;
</code></pre>

<p>Only affects the local copy of <code>x</code> and <code>y</code>. Which falls out of scope and is thrown away after the function ends.</p>

<p>The solution is to pass by reference like this:</p>

<pre><code>void dealdamage(player &amp;x, player &amp;y){
</code></pre>

<p>In this case, then changes made to <code>x</code> and <code>y</code> will be affect the originals.</p>
"
"<p>The question is very straight: is it fastest to access a byte than a bit? If I store 8 booleans in a byte will it be slower when I have to compare them than if I used 8 bytes? Why?</p>
","922184","","<p>Chances are no. The smallest addressable unit of memory in most machines today is a byte. In most cases, you can't address or access by bit.</p>

<p>In fact, accessing a specific bit might be even more expensive because you have to build a mask and use some logic.</p>

<p>EDIT:</p>

<p>Your question mentions ""compare"", I'm not sure exactly what you mean by that. But in some cases, you perform logic very efficiently on multiple booleans using bitwise operators if your booleans are densely packed into larger integer types.</p>

<p><strong>As for which to use:</strong> array of bytes (with one boolean per byte), or a densely packed structure with one boolean per bit is a <strong>space-effiicency trade-off</strong>. For some applications that need to store a massive amount of bools, dense packing is better since it saves memory.</p>
"
"<p>I dont know whats wrong with me right now. I dont know if im tired or something but what's wrong with this code</p>

<pre><code>        message = scanner.nextLine();

    while ((!message.equalsIgnoreCase(""exit"")) || (!message.equalsIgnoreCase(""read"")))
    {
        System.out.println(""WTF"");
        Encrypt(message, salt);
        message = scanner.nextLine();
    }
</code></pre>

<p>for some reason, even though i for message i write read or exit the program still goes through the loop once ...</p>
","922184","","<p>You probably meant to use <code>&amp;&amp;</code>:</p>

<pre><code>while ((!message.equalsIgnoreCase(""exit"")) &amp;&amp; (!message.equalsIgnoreCase(""read"")))
</code></pre>

<p>As it is right now, of course the message will not equal one of them. So it loops forever.</p>
"
"<p>I'm currently writing a file loader for an ipad program and I'm getting strange EXC_BAD_ACCESS exceptions. Here is a short snipped of code that I think is the reason for the error:</p>

<pre><code>float testFloat() {
    char mem[32];
    char *charPtr = &amp;mem[0];
    float *floatPtr = (float*)(charPtr + 1);
    float f = *floatPtr; //EXC_BAD_ACCESS
    return f;
}
</code></pre>

<p>The error happens only if the offset of charPtr is not divisible by 4, so I guess it could have something to do with pointer alignment on ARM CPUs.</p>
","922184","","<p>You are correct, this is due to pointer alignment. On many RISC systems, the alignment needs to be at least as large as the data-type itself. (ARM falls into this category.)</p>

<p>In this case, <code>float</code> is 4 bytes, so the address needs to be aligned to 4 bytes. (divisible by 4)</p>

<p><strike>Furthermore, this type of type-punning violates strict-aliasing.</strike></p>

<p>On x86 systems, memory accesses do not always have to be aligned - but there will usually be a performance penalty on a misaligned access.</p>
"
"<p>I am getting the following error when running my program. </p>

<p>Debug Assertion Failed!<br>
File: f:\dd\vctools\crt_bld\self_x86\crt\src\dbgheap.c<br>
Line: 1322<br>
Expression: _CrtIsValidHeapPointer(pUserData)</p>

<p>So I debugged my program and found out that the problem occurred when the following function was called the second time, more specifically the free statement at the end.</p>

<pre><code>int writeToLog(char* str, enum LOGLEVEL logLevel) {
    if(logFile &amp;&amp; logLevel &gt;= level) {
        FILE* log;
        char *now = (char *)malloc(sizeof(char)*1024);
        time_t timer = time(NULL);
        if(*now == NULL) {
            return -1;
        }       
        now = ctime(&amp;timer);
        if(now[strlen(now) - 1] == '\n') {
            now[strlen(now) - 1] = '\0';
        }
        log = fopen(logFile, ""a+"");
        if (log == NULL)
            return -1;
        fprintf(log, ""%s%s\n"", now, str);
        fclose(log);
        free(now); //fails here on the second function call
    }
    return 0;
}
</code></pre>

<p>Now I would love to just make <code>now</code> a constant char array but visual studio isn't letting me do that because of the return type of ctime. Can anyone help?<br>
Cheers.</p>
","922184","","<p>You are replacing the pointer <code>now</code> with a different one returned by <code>ctime</code>. Then you are trying to free it. So you end up freeing the pointer returned by <code>ctime</code>, and not the pointer you allocated yourself.</p>

<p>You are not supposed to modify the pointer returned by <code>ctime</code>.</p>

<p>For your purposes, you don't even need to allocate any memory at all. You can just use the pointer returned by <code>ctime</code> directly.</p>

<p>So this should work just fine:</p>

<pre><code>int writeToLog(char* str, enum LOGLEVEL logLevel) {
    if(logFile &amp;&amp; logLevel &gt;= level) {
        FILE* log;
        time_t timer = time(NULL);

        const char *now = ctime(&amp;timer);

        size_t length = strlen(now);
        if(now[length - 1] == '\n') {
            now[length - 1] = '\0';
        }
        log = fopen(logFile, ""a+"");
        if (log == NULL)
            return -1;
        fprintf(log, ""%s%s\n"", now, str);
        fclose(log);
    }
    return 0;
}
</code></pre>

<p>Also note that you make two calls to <code>strlen(now)</code>. You should call it once and save the result.</p>
"
"<p>Having a problem when assigning a value to an array. I have a class I created called <code>Treasury</code>. I created another class called <code>TradingBook</code> which I want to contain a global array of <code>Treasury</code> that can be accessed from all methods in <code>TradingBook</code>. Here is my header files for TradingBook and Treasury:</p>

<pre><code>class Treasury{
public:
    Treasury(SBB_instrument_fields bond);
    Treasury();
    double yieldRate;
    short periods;
};


class TradingBook
{
public:
    TradingBook(const char* yieldCurvePath, const char* bondPath);
    double getBenchmarkYield(short bPeriods) const;
    void quickSort(int arr[], int left, int right, double index[]);

    BaseBond** tradingBook;
    int treasuryCount;
    Treasury* yieldCurve;
    int bondCount;
    void runAnalytics(int i);
};
</code></pre>

<p>And here is my main code where I'm getting the error:</p>

<pre><code>TradingBook::TradingBook(const char* yieldCurvePath, const char* bondPath)
{
    //Loading Yield Curve
    // ...
    yieldCurve = new Treasury[treasuryCount];

    int periods[treasuryCount];
    double yields[treasuryCount];
    for (int i=0; i &lt; treasuryCount; i++)
    {
        yieldCurve[i] = new Treasury(treasuries[i]);
        //^^^^^^^^^^^^^^^^LINE WITH ERROR^^^^^^^^^^^^^^
    }
}
</code></pre>

<p>I am getting the error:</p>

<blockquote>
  <p>No match for <code>'operator='</code> on the line <code>'yieldCurve[i] = new Treasury(treasuries[i]);'</code></p>
</blockquote>

<p>Any advice?</p>
","922184","","<p>That's because <code>yieldCurve[i]</code> is of type <code>Treasury</code>, and <code>new Treasury(treasuries[i]);</code> is a pointer to a <code>Treasury</code> object. So you have a type mismatch.</p>

<p>Try changing this line:</p>

<pre><code>yieldCurve[i] = new Treasury(treasuries[i]);
</code></pre>

<p>to this:</p>

<pre><code>yieldCurve[i] = Treasury(treasuries[i]);
</code></pre>
"
"<p>I'm working on a string class that employs pointers and I'm just having some difficulty in understanding how my <code>print</code> function works here.  Specifically, why does <code>cout &lt;&lt; pString</code> output the string and not the memory address of the dynamic array that it's pointing to?  My understanding was that the variable pString was a pointer.</p>

<pre><code>class MyString
{
    public:
        MyString(const char *inString);
        void print();
    private:
        char *pString;
};


MyString::MyString(const char *inString)
{
    pString = new char[strlen(inString) + 1];
    strcpy(pString, inString);
}

void MyString::print()
{
    cout &lt;&lt; pString;
}

int main( )
{
    MyString stringy = MyString(""hello"");
    stringy.print();
    return 0;
}
</code></pre>
","922184","","<p>This is because the <code>&lt;&lt;</code> operator has been overloaded to handle the case of a <code>char*</code> and print it out as a string. As opposed to the address (which is the case with other pointers).</p>

<p>I think it's safe to say that this is done for convenience - to make it easy to print out strings.</p>

<p>EDIT:</p>

<p>So if you want to print out the address, you should cast the pointer to a <code>void*</code>.</p>
"
"<p>I'm currently developing a C-module for a Java-application that needs some performance improvements (see <a href=""http://stackoverflow.com/questions/7737488/improving-performance-of-network-coding-encoding"">Improving performance of network coding-encoding</a> for a background). I've tried to optimize the code using SSE-intrinsics and it executes somewhat faster than the Java-version (~20%). However, it's still not fast enough. </p>

<p>Unfortunately my experience with optimizing C-code is somewhat limited. I therefore would love to get some ideas on how to improve the current implementation. </p>

<p>The inner loop that constitutes the hot-spot looks like this:</p>

<pre><code>for (i = 0; i &lt; numberOfGFVectorsInFragment; i++)   {

        // Load the 4 GF-elements from the message-fragment and add the log of the coefficeint to them.
        __m128i currentMessageFragmentVector = _mm_load_si128 (currentMessageFragmentPtr);
        __m128i currentEncodedResult = _mm_load_si128(encodedFragmentResultArray);

        __m128i logSumVector = _mm_add_epi32(coefficientLogValueVector, currentMessageFragmentVector);

        __m128i updatedResultVector = _mm_xor_si128(currentEncodedResult, valuesToXor);
        _mm_store_si128(encodedFragmentResultArray, updatedResultVector);

        encodedFragmentResultArray++;
        currentMessageFragmentPtr++;
    }
</code></pre>
","922184","","<p>Even without looking at the assembly, I can tell right away that the bottleneck is from the 4-element gather memory access and from the <code>_mm_set_epi32</code> packing operations. Internally, <code>_mm_set_epi32</code>, in your case will probably be implemented as a series of <code>unpacklo/hi</code> instructions.</p>

<p>Most of the ""work"" in this loop is from packing these 4 memory accesses. In the absence of SSE4.1, I would go so far to say that the loop could be faster non-vectorized, but unrolled.</p>

<p>If you're willing to use SSE4.1, you can try this. It might be faster, it might not:</p>

<pre><code>    int* logSumArray = (int*)(&amp;logSumVector);

    __m128i valuesToXor = _mm_cvtsi32_si128(expTable[*(logSumArray++)]);
    valuesToXor = _mm_insert_epi32(valuesToXor, expTable[*(logSumArray++)], 1);
    valuesToXor = _mm_insert_epi32(valuesToXor, expTable[*(logSumArray++)], 2);
    valuesToXor = _mm_insert_epi32(valuesToXor, expTable[*(logSumArray++)], 3);
</code></pre>

<p>I suggest unrolling the loop at least 4 iterations and interleaving all the instructions to give this code any chance of performing well.</p>

<p>What you really need is Intel's AVX2 gather/scatter instructions. But that's a few years down the road...</p>
"
"<p>Okay so the problem is, NetBeans is saying the second one is already defined. These three are my constructors  at the top, The whole program is listed in case a set or get method is the error of it. So to be clear i am talking about</p>

<p>public Dog(String initialName)
public Dog(String initialBreed)
public Dog(double initialWeight)</p>

<p>The error shows up on public Dog(String initialBreed). Did i misuse the Overload method? Also i must use the overload method it is mandatory.</p>

<pre><code>package dog;


import java.util.*;
public class Dog 
{

// instance variables
private String name;
private String breed;
private double weight;

 public Dog( )
{
name = ""no name"";
breed = ""no breed"";
weight = 0.0;
}

public Dog(String initialName)
{
name = initialName;
breed = ""no breed"";
weight = 0.0;
     }

public Dog(String initialBreed){
   name = ""no name"";
   breed = initialBreed;
   weight = 0.0;
 }
public Dog(double initialWeight){
    name = ""no name"";
    breed = ""no breed"";
    weight = initialWeight;
     }


  public void SetDog(String newName, String newBreed, double newWeight) 
  {
   name = newName;
   breed = newBreed;
   if (newWeight &lt;= 0)
      System.out.println(""Error: Negative weight."");
   else
       weight = newWeight;
    }
public void setName(String newName){
    name = newName;
}
public void setBreed(String newBreed){
    breed = newBreed;
}
public void setWeight(double newWeight){
    weight = newWeight;
}

public double getWeight(){
     return weight;
}
public String getName(){
     return name;
}
public String getBreed(){
    return breed;
}
</code></pre>

<p>}</p>
","922184","","<p>The problem is that two of your constructors take the same argument:</p>

<pre><code>public Dog(String initialName)

public Dog(String initialBreed){
</code></pre>

<p>They both take <code>string</code>. You can't have two methods with the exact same name and parameters.</p>

<p>Based on what I think you are trying to do, you might want a single constructor that takes all 3 of those parameters:</p>

<pre><code>public Dog(String initialName, String initialBreed, double initialWeight){
</code></pre>
"
"<p>I'm an idiot:</p>

<p>My code is the code below. I ran the code, and input 4 as my answer. However, the program still tells me the answer is incorrect. What did I do wrong? Thank you so much for the help.</p>

<pre><code>import java.io.*;

class class1 {

  public static void main (String[] args) throws IOException { 
    BufferedReader input = new BufferedReader (new InputStreamReader(System.in));
    System.out.println(""What is the answer to 2 + 2"");
    String answer;

    answer = input.readLine();

    if ( answer == ""4""){
      System.out.println(""Correct"");
    } else System.out.println(""Incorrect"");

    }
  }
}
</code></pre>
","922184","","<p>You can't compare strings using <code>==</code>. You need to do it like this:</p>

<pre><code>answer.equals(""4"");
</code></pre>

<p>The reason is because <code>==</code> only works if both sides are the exact same object (the same instance). What you really need is to check if both strings have identical content.</p>

<p>More specifically, <code>==</code> in your example compares to see if <code>answer</code> points to the same object as <code>""4""</code>, which it doesn't.</p>

<p>More technical detail: <a href=""http://leepoint.net/notes-java/data/expressions/22compareobjects.html"" rel=""nofollow"">http://leepoint.net/notes-java/data/expressions/22compareobjects.html</a></p>
"
"<p>I'm currently writing a linked list and trying to free up memory allocations when I delete a node. However, after hours of trying to do this, I can't seem to get a clean valgrind output. </p>

<pre><code>void * pop(struct List *list)
{
    if(list-&gt;head == 0){
        return 0;
    }

    struct Node * tempNode = list-&gt;head-&gt;next;                                                                                                            
    free(list-&gt;head);
    list-&gt;head = tempNode;
    ...
}
</code></pre>

<p>I'm allocating the space by saying:</p>

<pre><code>addNode(struct List *list, void *element){
    struct Node *node;
    node = (struct Node *)malloc(sizeof(node));
    ....
}
</code></pre>

<p>Basically in the pop function I want to take out the head of the list and make the head's next node the new head. I want to deallocate the memory that was given to head. </p>

<p>Thanks for any help</p>
","922184","","<p>Woah, your <code>malloc</code> isn't correct. You have:</p>

<pre><code>(struct Node *)malloc(sizeof(node));
</code></pre>

<p>What you need is:</p>

<pre><code>(struct Node *)malloc(sizeof(struct Node));
</code></pre>

<p>In your original code, you are only allocating enough for a pointer. But you are trying allocate a <code>Node</code> object.</p>
"
"<p>I am doing a sample application where I have declared a struct:</p>

<pre><code> // common.h
 typedef struct MyStruct
 {
   int a;
 }

  //sample.h
  #include ""common.h""
  int main()
  {
     MyStruct st;// getting error here
  }
</code></pre>

<blockquote>
  <p>C2146: syntax error : missing ';' before identifier</p>
</blockquote>

<p>What are the possible reasons for this?</p>
","922184","","<p>Two things:</p>

<p>First, you're missing a semi-colon after the struct definition:</p>

<pre><code> // common.h
 typedef struct MyStruct
 {
     int a;
 };
  ^
</code></pre>

<p>Not that this is still wrong. You will need to fix the other error.</p>

<p>Second, you should define the struct like this:</p>

<pre><code> // common.h
 typedef struct
 {
     int a;
 } MyStruct;
</code></pre>

<p>Alternatively, you can define it like this:</p>

<pre><code> // common.h
 struct MyStruct
 {
     int a;
 };
</code></pre>
"
"<pre><code>#include &lt;stdio.h&gt;
#include &lt;iostream&gt;
using namespace std;

float cost, total;
bool loop(char item){
        switch (toupper(item)) {
            case 'A':
                cost = 4.25;        
                return true;
            case 'B':
                cost = 5.57;
                return true;
            case 'C':
                cost = 5.25;
                return true;
            case 'D':
                cost = 3.75;
                return true;
            case 'T':
                return false;
        }
        return true;
}

int main(){
        char item;
        do {
            printf(""\nEnter Item Ordered [A/B/C/D] or T to calculate total:"");
            scanf(""%c"", &amp;item);
            total = total + cost;
        } while (loop(item)); 
        printf(""Total Cost: $%f\n"", total);
}
</code></pre>

<p>Let me output the process:</p>

<pre><code>$ ./Case3.o 

Enter Item Ordered [A/B/C/D] or T to calculate total:a

Enter Item Ordered [A/B/C/D] or T to calculate total:
Enter Item Ordered [A/B/C/D] or T to calculate total:b

Enter Item Ordered [A/B/C/D] or T to calculate total:
Enter Item Ordered [A/B/C/D] or T to calculate total:a

Enter Item Ordered [A/B/C/D] or T to calculate total:
Enter Item Ordered [A/B/C/D] or T to calculate total:t
Total Cost: $28.139999
</code></pre>

<p>Why is it after the first printf its printing the <code>printf</code> twice but skipping me from input the first time. then how is it calculating 5.24+5.57+5.24 to equal 28.14?</p>
","922184","","<p>Since the <code>newline</code> has been mentioned, I'll answer the other question of why <code>28.14</code>.</p>

<p>Notice that in your switch, the default is just return. <code>cost</code> is never set. Therefore, when it reads in the <code>newline</code> it skips the switch block and leaves cost untouched.</p>

<p>So the result is this:</p>

<pre><code>total = 0;  // It's actually undefined since you didn't initialize, but it probably started as zero.

total += 4.25;    //  For a
total += 4.25;    //  For '\n' after the 'a'

total += 5.57;    //  For b
total += 5.57;    //  For '\n' after the 'b'

total += 4.25;    //  For a
total += 4.25;    //  For '\n' after the 'a'
</code></pre>

<p>Final answer: <code>28.14</code></p>

<p>The <code>t</code> that is entered last doesn't get added to <code>total</code>.</p>
"
"<p>I am trying to malloc and free a small array/table of single letter strings.  I know that this can be done in an array, but I want to try and do this with a malloc and free.</p>

<p>I have this right now:</p>

<pre><code>char **letters = (char**) malloc(5 * sizeof(char*));
int i =0;
for(i=0; i &lt; NUMLETTERS ; ++i )
{
    letters[i] = (char*) malloc(2*sizeof(char)); //2 is for the letter and null terminator
}

letters[0] = ""a"";
letters[1] = ""b"";
letters[2] = ""c"";
letters[3] = ""d"";
letters[4] = ""e"";

//Do stuff here

int i =0;
for(i=0; i &lt; 5; ++i )
{
    free(letters[i]);
}


free(letters);
</code></pre>

<p>The above code compiles fine and my code in between also works and runs fine, but at runtime it gets an error during the free parts.  Also, after using valgrind..it says that the <em>free(letters[i]);</em> is invalid.</p>

<p>Any help?</p>
","922184","","<p>The problem is here:</p>

<pre><code>letters[0] = ""a"";
letters[1] = ""b"";
letters[2] = ""c"";
letters[3] = ""d"";
letters[4] = ""e"";
</code></pre>

<p>You are overwriting each of your malloc'ed pointers with string literals. Then you free them in the final loop. Since you are effectively freeing the string literals, it fails.</p>

<p>There are two ways to solve this:</p>

<p>1: You don't need the inner allocation if you are just assigning string literals to them. So get rid of both loops.</p>

<p>2: <code>strcpy</code> each of the string literals instead.</p>
"
"<p>I cannot understand why the results of my division appear rounded down?</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdio.h&gt;
using namespace std;

int rVote, oVote, dVote;
int rTotal, oTotal, dTotal, total;
int rPercent, dPercent, oPercent;

bool loop(char vote){
        switch(toupper(vote)){
                case 'D':
                    dVote = 1;
                    dTotal = dTotal + dVote;
                    return true;
                case 'R':
                    rVote = 1;
                    rTotal = rTotal + rVote;
                    return true;
                case 'O':
                    oVote = 1;
                    oTotal = oTotal + oVote;
                    return true;
                case 'Q':
                    return false;
        }
        return true;
}
int main(){
        char vote;
        do{
                printf(""Enter Vote [D/R/O] or Q to quit: "");
                scanf(""%c%*c"", &amp;vote);
        } while (loop(vote));
        total = dTotal + rTotal + oTotal;
        rPercent = ((rTotal/total)*100);
        dPercent = ((dTotal/total)*100);
        oPercent = ((oTotal/total)*100);
        printf(""Democrate total vote %d: %d%%\n"", dTotal, dPercent);

        printf(""Republican total vote %d: %d%%\n"", rTotal, rPercent);

        printf(""Other total vote %d: %d%%\n"", oTotal, oPercent);
}
</code></pre>

<p>Great I am being really dumb....
Why is it that any of my <code>*Percent</code>'s not printing the % value in this c/c++ program?</p>

<p>Thanks.</p>
","922184","","<p>It's because you're doing integer division. Integer division in C/C++ rounds down. So your following code:</p>

<pre><code>    rPercent = ((rTotal/total)*100);
    dPercent = ((dTotal/total)*100);
    oPercent = ((oTotal/total)*100);
</code></pre>

<p>is all rounding down to 0.</p>

<p>To fix this, you should cast to a floating-point type:</p>

<pre><code>    rPercent = (int)((double)rTotal/total*100);
    dPercent = (int)((double)dTotal/total*100);
    oPercent = (int)((double)oTotal/total*100);
</code></pre>

<p>EDIT:</p>

<p>The code above could give some weird results due to rounding behavior. Perhaps something like this might be more appropriate since it rounds to the nearest %:</p>

<pre><code>    rPercent = (int)((double)rTotal/total*100 + 0.5);
    dPercent = (int)((double)dTotal/total*100 + 0.5);
    oPercent = (int)((double)oTotal/total*100 + 0.5);
</code></pre>
"
"<p>I'm doing an integration program with Riemann sums for my Calculus class. I've decided to use C when computing my integrals, and I noticed a huge error in my program that derives from this problem.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;

int main(int argc, char** argv) {

double x = 2.0/20.0;
printf(""%1.50f \n"", x);


return (EXIT_SUCCESS);
}    
</code></pre>

<p>The program gives me : 0.10000000000000000555111512312578270211815834045410. My question: Why does this happen? And how can I fix this? Or at least round off to ~15 decimal places?</p>

<p>Thanks for the help.</p>
","922184","","<p>The basics of floating-point:</p>

<p><a href=""http://en.wikipedia.org/wiki/Floating_point"" rel=""nofollow"">http://en.wikipedia.org/wiki/Floating_point</a></p>

<p>The answer in your case <code>0.10</code> is not exactly representable in binary floating-point. Therefore, it's only accurate to about 16 digits. Yet you are trying to print it out to 50 decimal places.</p>
"
"<p>In C, when we use structures, when would it be inappropriate to use <strong>#pragma pack</strong> directive..?</p>

<p>an addition to the question.....</p>

<p>Can someone please explain more on how might the accessing of unaligned data specially with a pointer fail?  </p>
","922184","","<p>I would say that you shouldn't pack unless there's a really good reason to do so.</p>

<p>When pack is specified, all the padding is stripped out. Therefore the struct members could be unaligned - which could have performance consequences.</p>
"
"<p>I can't figure out why I keep getting the result 1.#INF from <code>my_exp()</code> when I give it 1 as input. Here is the code:</p>

<pre><code>double factorial(const int k)
{
    int prod = 1;
    for(int i=1; i&lt;=k; i++)
        prod = i * prod;
    return prod;
}

double power(const double base, const int exponent)
{
    double result = 1;
    for(int i=1; i&lt;=exponent; i++)
        result = result * base;
    return result;
}

double my_exp(double x)
{
    double sum = 1 + x;
    for(int k=2; k&lt;50; k++)
        sum = sum + power(x,k) / factorial(k);
    return sum;
}
</code></pre>
","922184","","<p>You have an integer overflow in your <code>factorial</code> function. This causes it to output zero. <code>49!</code> is divisible by <code>2^32</code>, so your <code>factorial</code> function will return zero.</p>

<p>Then you divide by it causing it to go infinity. So the solution is to change <code>prod</code> to <code>double</code>:</p>

<pre><code>double prod = 1;
</code></pre>
"
"<p>I have 2 variables one has a value of 5 the other has a value of 0. if i have:</p>

<pre><code>cout &lt;&lt; var1;      //the one with a value of 5
cout &lt;&lt; var2;      //the one with a value of 0
</code></pre>

<p>is there a way to make the second variable not print anything if its value is 0 at that point in the code?</p>
","922184","","<p>Just use an if-statement:</p>

<pre><code>cout &lt;&lt; var1;
if (var2 != 0)
     cout &lt;&lt; var2;
</code></pre>
"
"<p>I am using DevC++ 4.9, running on WinXP SP3 (32bit), here is the code:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

main(int argc, char *argv[])
{
    double value;

    int i;

    printf(""Enter double: "");
    scanf(""%lf"", &amp;value);
    i = value*100;
    printf(""double: %lf\n"", value);
    printf(""int: %d\n"", i);

  system(""PAUSE"");  
}
</code></pre>

<p>I have entered different values and here are the results:</p>

<p>Test 1:</p>

<p><img src=""http://i.stack.imgur.com/cKIpU.png"" alt=""enter image description here""></p>

<p>Test 2:</p>

<p><img src=""http://i.stack.imgur.com/3yykh.png"" alt=""enter image description here""></p>

<p>Test 3:</p>

<p><img src=""http://i.stack.imgur.com/WYwde.png"" alt=""enter image description here""></p>

<p>Why Test 1 and Test 2 displayed different results??</p>
","922184","","<p>This is due to floating-point round-off:</p>

<p>What Every Computer Scientist Should Know About Floating-Point Arithmetic:
 <a href=""http://download.oracle.com/docs/cd/E19957-01/806-3568/ncg_goldberg.html"" rel=""nofollow"">http://download.oracle.com/docs/cd/E19957-01/806-3568/ncg_goldberg.html</a></p>

<p><code>3.07</code> cannot be exactly represented in binary. In your case, it's being rounded to slightly less than <code>3.07</code>, therefore <code>100 * 3.07</code> is evaluating to <code>306.9999999...</code>, which is truncated to 306.</p>

<p>Same applies to <code>3.05</code>. But <code>3.06</code>, is rounded slightly up. So <code>100 * 3.06</code> correctly shows up as 306.</p>
"
"<p>I am trying to solve this recurrence</p>

<p>T(n) = 3 T(n/2) + n lg n ..</p>

<p>I have come to the solution that it belongs to masters theorem case 2 since n lg n  is O(n^2)</p>

<p>but after referring to the solution manual i noticed this solution that they have</p>

<p><img src=""http://i.stack.imgur.com/GRtZd.jpg"" alt=""enter image description here""></p>

<p>The soluttion  says that n lg n = O ( n ^(lg 3 - e)) for e between 0 and 0.58</p>

<p>so this means n lg n is O(n) .. is this right? Am i missing something here?</p>

<p>Isn't nlgn O(n^2) ?</p>
","922184","","<p><code>n*log(n)</code> is not <code>O(n^2)</code>. It's known as quasi-linear and it grows much slower than <code>O(n^2)</code>. In fact <code>n*log(n)</code> is less than polynomial.</p>

<p>In other words:</p>

<pre><code>O(n*log(n)) &lt; O(n^k)
</code></pre>

<p>where <code>k &gt; 1</code></p>

<p>In your example:</p>

<pre><code>3*T(2n) -&gt; O(n^1.585)
</code></pre>

<p>Since <code>O(n^1.585)</code> is polynomial and dominates <code>O(n*log(n))</code>, the latter term drops off so the final complexity is just <code>O(n^1.585)</code>.</p>
"
"<p>When I try to compile this file by issuing the command, ""g++ qr.cpp -o qr"" The system hangs. I haven't seen this kind of an error anywhere else.</p>

<pre><code>#include&lt;iostream&gt;

using namespace std;

bool win[1000000001];
bool know[1000000001];

int sixes[] = {6, 36, 216, 1296, 7776, 46656, 279936, 1679616, 10077696, 60466176, 362797056};

bool check(int n){
   cout &lt;&lt; n &lt;&lt; endl;
   if(!know[n]){
      bool b = check(n-1);
      for(int i=0; i&lt;11; i++){
         if(n &gt; sixes[i]){
            b = b &amp; check(n-sixes[i]);
         }
      }
      win[n] = !b;
   }
   return win[n];
}

int main(){
   win[1] = know[1] = true;
   for(int j=0; j&lt;11; j++){
      win[sixes[j]] = know[sixes[j]] = true;
   }
   int n = 1; 
   cin &gt;&gt; n;
   int i = 0;
   while(n != 0){
      i++;
      win[n] = check(n);
      cout &lt;&lt; i &lt;&lt; (win[n]?""-Heckle"":""-Jeckle"");
      cin &gt;&gt; n;
      if(n!=0) cout &lt;&lt; endl;
   }
   return 0;
}
</code></pre>

<p>My compiler version information is given below.</p>

<pre><code>yasith@vostro:~/Dropbox/Shared$ g++ -v
Using built-in specs.
COLLECT_GCC=g++
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.6.1/lto-wrapper
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu/Linaro 4.6.1-9ubuntu3' --with-bugurl=file:///usr/share/doc/gcc-4.6/README.Bugs --enable-languages=c,c++,fortran,objc,obj-c++,go --prefix=/usr --program-suffix=-4.6 --enable-shared --enable-linker-build-id --with-system-zlib --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.6 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-plugin --enable-objc-gc --disable-werror --with-arch-32=i686 --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 4.6.1 (Ubuntu/Linaro 4.6.1-9ubuntu3) 
</code></pre>
","922184","","<p>Do you realize how big these are?</p>

<pre><code>bool win[1000000001];
bool know[1000000001];
</code></pre>

<p>Those are at least 1GB each!!! You're gonna want to allocate them dynamically...</p>
"
"<p>My C++ code uses SSE and now I want to improve it to support AVX when it is available. So I detect when AVX is available and call a function that uses AVX commands. I use Win7 SP1 + VS2010 SP1 and a CPU with AVX.</p>

<p>To use AVX, it is necessary to include this:</p>

<pre><code>#include ""immintrin.h""
</code></pre>

<p>and then you can use intrinsics AVX functions like <code>_mm256_mul_ps</code>, <code>_mm256_add_ps</code> etc.
The problem is that by default, VS2010 produces code that works very slowly and shows the warning:</p>

<blockquote>
  <p>warning C4752: found Intel(R) Advanced Vector Extensions; consider
  using /arch:AVX</p>
</blockquote>

<p>It seems VS2010 actually does not use AVX instructions, but instead, emulates them. I added <code>/arch:AVX</code> to the compiler options and got good results. But this option tells the compiler to use AVX commands everywhere when possible. So my code may crash on CPU that does not support AVX! </p>

<p>So the question is how to make VS2010 compiler to produce AVX code but only when I specify AVX intrinsics directly. For SSE it works, I just use SSE intrinsics functions and it produce SSE code without any compiler options like <code>/arch:SSE</code>. But for AVX it does not work for some reason.</p>
","922184","","<p>The behavior that you are seeing is the result of expensive state-switching.</p>

<p>See page 102 of Agner Fog's manual:</p>

<p><a href=""http://www.agner.org/optimize/microarchitecture.pdf"">http://www.agner.org/optimize/microarchitecture.pdf</a></p>

<p>Every time you improperly switch back and forth between SSE and AVX instructions, you will pay an extremely high (~70) cycle penalty.</p>

<p>When you compile without <code>/arch:AVX</code>, VS2010 will generate SSE instructions, but will still use AVX wherever you have AVX intrinsics. Therefore, you'll get code that has both SSE and AVX instructions - which will have those state-switching penalties. (VS2010 knows this, so it emits that warning you're seeing.)</p>

<p>Therefore, you should use either all SSE, or all AVX. Specifying <code>/arch:AVX</code> tells the compiler to use all AVX.</p>

<p>It sounds like you're trying to make multiple code paths: one for SSE, and one for AVX.
For this, I suggest you separate your SSE and AVX code into two different compilation units. (one compiled with <code>/arch:AVX</code> and one without) Then link them together and make a dispatcher to choose based on the what hardware it's running on.</p>

<p>If you <strong><em>need</em></strong> to mix SSE and AVX, be sure to use <code>_mm256_zeroupper()</code> or <code>_mm256_zeroall()</code> appropriately to avoid the state-switching penalties.</p>
"
"<p>Microsoft states VS2010 supports the full set of AVX instructions:</p>

<p><a href=""http://blogs.msdn.com/b/vcblog/archive/2009/11/02/visual-c-code-generation-in-visual-studio-2010.aspx"" rel=""nofollow"">http://blogs.msdn.com/b/vcblog/archive/2009/11/02/visual-c-code-generation-in-visual-studio-2010.aspx</a></p>

<p>...
In VS2010 release, all AVX features and instructions are <strong>fully</strong> supported via intrinsic and <code>/arch:AVX</code>. 
...</p>

<p>But I cannot find any Intrinsics for Fused Multiply Add Operations</p>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_avx_fma.htm#intref_bk_avx_fma"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_avx_fma.htm#intref_bk_avx_fma</a></p>

<p>I need to use <code>_mm256_fmadd_ps</code> function but it is missing in ""immintrin.h"" header. I'm really stuck with it.</p>
","922184","","<p>The Fused-Multiply Add intrinsics aren't part of AVX. Intel got rid of it in their later revisions for AVX. So FMA is separate instruction set.</p>

<p>Even worse, there will be two of them FMA3 (Intel - Haswell), FMA4 (AMD - Bulldozer).</p>

<p>VS2010 SP1 supports FMA4 - AMD's version of it.</p>

<p>Neither processor line has been released yet (except for AMD - Interlagos, which is the server part of Bulldozer).</p>

<p>The Intel FMA intrinsics are for FMA3. Since no processor implements it yet, you won't be able to use/test it yet.</p>
"
"<p>I have a bit that I am toggling in my program, and was wondering if I can do this:</p>

<pre><code>    char *toggle = // some address;
    *toggle = 0; // initially

    // if(something)
    //    *toggle = 1;

    // other code that continues to toggle under certain conditions...
</code></pre>

<p>But dereferencing a char* treats the value like a char, nothing more and nothing less. So I was wondering if it is a valid method of storing the 1 and 0 (which are integers)?</p>
","922184","","<p>Yes, that's a completely valid method. <code>char</code> can be treated like an integer <strike>in most cases</strike> - and as such you can also do arithmetic on variables of type <code>char</code>.</p>
"
"<p>I have used this code. Here a string is present from location starting from 4 and length of string is 14. All these calculations are done prior to this code. I am pasting a small snippet of the error containing code.</p>

<pre><code>void *data = malloc(4096);
int len = 14;
int fileptr = 4;
string str;
cout&lt;&lt;len&lt;&lt;endl;
cout&lt;&lt;fileptr&lt;&lt;endl;
memcpy(&amp;str, (char *)data+fileptr, len);        
cout&lt;&lt;len&lt;&lt;endl;
cout&lt;&lt;fileptr&lt;&lt;endl;
</code></pre>

<p>Output i get is:</p>

<pre><code>14
4
4012176
2009288233
</code></pre>

<p>Here i am reading a string ""System Catalog"" from memory. Its displaying the string correctly. But the values of fileptr and len are abruptly changing after using memcpy() function.</p>
","922184","","<p><code>string</code> is not the same as a <code>char*</code>. <code>string</code> is an object. So you can't just <code>memcpy()</code> data to it. So the behavior of this code is undefined.</p>

<p>In your case, you are copying 14 bytes of junk data into <code>str</code> and corrupting the stack.
The result is that you are overwriting both <code>len</code> and <code>fileptr</code> with junk from the <code>malloc()</code>.</p>

<p>I'm not sure exactly what you're trying to do, but if you want to create a string, you should do it like this:</p>

<pre><code>string str = ""System Catalog"";
</code></pre>
"
"<p>If I have a class that defines multiple constant variables like so...    </p>

<pre><code>class SomeClass {
public:
    SomeClass() : SOME_CONSTANT(20), ANOTHER_CONSTANT(45), ANOTHER_CONSTANT2(25), ANOTHER_CONSTANT2(93) { }

private:
    const int SOME_CONSTANT;
    const int ANOTHER_CONSTANT;
    const int ANOTHER_CONSTANT2;
    const int ANOTHER_CONSTANT3;
</code></pre>

<p>Will multiple instances of this class be optimized to point to the same memory for the constants? or can I save memory by making each constant static?</p>
","922184","","<p>If they are not static, then no, they will not be optimized out. Each instance will have space for all the constants. (In fact, I don't think the compiler is even allowed to combine them in any way.)</p>

<p>If you do declare them static, they are in global memory and not in each instance. So yes, it will use less memory.</p>

<p>EDIT:</p>

<p>If you want to make them static constants, it should be done like this:</p>

<pre><code>class SomeClass {
    public:
        SomeClass(){ }

    private:
        static const int SOME_CONSTANT;
        static const int ANOTHER_CONSTANT;
        static const int ANOTHER_CONSTANT2;
        static const int ANOTHER_CONSTANT3;

};

const int SomeClass::SOME_CONSTANT     = 20;
const int SomeClass::ANOTHER_CONSTANT  = 45;
const int SomeClass::ANOTHER_CONSTANT2 = 25;
const int SomeClass::ANOTHER_CONSTANT3 = 93;
</code></pre>
"
"<p>The title is actually a bit misleading, but I wanted to keep it short.  I've read about why I should use size_t and I often found statements like this:</p>

<blockquote>
  <p><code>size_t</code> is guaranteed to be able to express the maximum size of any object, including any array</p>
</blockquote>

<p>I don't really understand what that means. Is there some kind of cap on how much memory you can allocate at once and size_t is guaranteed to be large enough to count every byte in that memory block?</p>

<blockquote>
  <p><strong>Follow-up question:</strong><br>
  <a href=""http://stackoverflow.com/questions/7850482/what-determines-how-much-memory-can-be-allocated"">What determines how much memory can be allocated?</a></p>
</blockquote>
","922184","","<p>Basically it means that <code>size_t</code>, is guaranteed to be large enough to index any array and get the size of any data type.</p>

<p>It is preferred over using just <code>int</code>, because the size of <code>int</code> and other integer types can be smaller than what can be indexed. For example <code>int</code> is usually 32-bits long which is not enough to index large arrays on 64-bit machines. (This is actually a very common problem when porting programs to 64-bit.)</p>
"
"<p>as I am starting to study at university we are learning how to write in C and we got to the point where I've learned that I can use pointers as function parameters but what they haven't told us is how to get the value from it. I am not able as a person who doesn't know about C as much, to come up with other solution than use two parameters (one as pointer to the variable and other as value. See the example which is not real code but it's just for purpose of demonstration:</p>

<pre>
<code>
int main(int argc, char* argv []) {

     int a;
     addNumber(&a);


}

void addNumber(int * a) {
     *a = *a + 1; // this obviously does not work
}

</code>
</pre>

<p>Any input would be appreciated.
Thanks!</p>
","922184","","<p>Only one major thing: You forgot to initialize <code>a</code>. Otherwise, it looks fine.</p>

<pre><code> int a = 0;
 addNumber(&amp;a);
</code></pre>

<p>The only other thing is that you're missing the return statement in <code>main</code>.</p>
"
"<p>Please bear with me, I've just started digging into this whole CPU thing.</p>

<p>The <code>RAM</code> squares shown on the diagram below, what do they refer to? Memory pages? As far as I know, CPUs only have one thing that's related to memory at all - their cache.</p>

<p>So is the <code>RAM</code> on the diagram just a shared cache, or what is it?</p>

<p><img src=""http://i.stack.imgur.com/qNb4h.png"" alt=""NUMA Architecture Diagram""></p>
","922184","","<p>In that diagram, each group of 4 CPUs and their central RAM block is a NUMA node. Cache is inside each CPU so it's not shown in the diagram. So each group of 4 CPUs share a block of fast local RAM.</p>

<p>Within each node, memory access to local RAM is very fast. Remote access to another node needs to go through the communication network, therefore it is slower - hence NUMA.</p>
"
"<p>Let's say I have the following</p>

<pre><code>struct A
{
    __m256 a;
}
struct B
{
    __m256 a;
    float b;
}
</code></pre>

<p>Which of the following's generally better (if any and why) in a hard core loop?</p>

<pre><code>void f0(A a) { ... }
void f1(A&amp; a) { ... } //and the pointer variation
void f2(B b) { ...}
void f3(B&amp; b) { ... } //and the pointer variation
</code></pre>
","922184","","<p>The answer is that it doesn't matter.</p>

<p>According to this:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms235286.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms235286.aspx</a></p>

<p>The calling convention states that 16-byte (and probably 32-byte) operands are always passed by reference. So even if you to pass by value, the compiler will pass it by reference underneath.</p>

<p>In other words, XMM and YMM registers are never passed by value in Windows. But the lower halves of XMM0-4 can still be used to pass 64-bit parameters by value.</p>

<p>EDIT:</p>

<p>In your second example with the <code>float</code> value, there is a slight difference since it will still affect whether or not <code>b</code> is passed by reference or by value.</p>
"
"<p>Please I have two questions in respect to vectors in C++:</p>

<ol>
<li><p>How to fix the problem in the following code:</p>

<ul>
<li><p>In my header file I have:</p>

<pre><code>vector&lt; vector&lt; char &gt; &gt; vec;
</code></pre></li>
<li><p>In my (.cpp) file in the definition of the constructor I have:</p>

<pre><code>vec(20, vector&lt;char&gt;(25, "" ""));
</code></pre></li>
<li><p>The error I'm receiving is the following:</p>

<pre><code>error: invalid conversion from 'const char*' to 'char'
</code></pre></li>
</ul>

<p>I know there is something wrong but I have no idea how to fix it. </p></li>
<li><p>After the end of my program, how do I properly destruct my two dimensional vector in order to free the memory?</p></li>
</ol>

<p>Any suggestions, ideas or solutions to my questions are greatly appreciated. </p>
","922184","","<p>You probably wanted single quotes <code>' '</code>:</p>

<pre><code>vec(20, vector(25, ' '));
</code></pre>

<p>Otherwise, you're be passing a string <code>"" ""</code> which is causing that error.</p>

<p>As for your second question. You don't need to destroy it. It will automatically free itself when it falls out of scope.</p>

<p>EDIT:</p>

<p>You also need to do it together:</p>

<pre><code>vector&lt; vector&lt; char &gt; &gt; vec(20, vector&lt;char&gt;(25, ' '));
</code></pre>

<p>You can't separate the declaration and the initializer like that. (at least not without an extra assignment.)</p>
"
"<p>I've been struggling for a while with the performance of the network coding in an application I'm developing (see <a href=""http://stackoverflow.com/questions/7794941/optimzing-sse-code"">Optimzing SSE-code</a>, <a href=""http://stackoverflow.com/questions/7737488/improving-performance-of-network-coding-encoding"">Improving performance of network coding-encoding</a> and <a href=""http://stackoverflow.com/questions/7751019/opencl-distribution"">OpenCL distribution</a>). Now I'm quite close to achieve acceptable performance. This is the current state of the innermost loop (which is where >99% of the execution time is being spent):</p>

<pre><code>    while(elementIterations-- &gt;0)
        {   
            unsigned int firstMessageField = *(currentMessageGaloisFieldsArray++);
            unsigned int secondMessageField = *(currentMessageGaloisFieldsArray++);
            __m128i valuesToMultiply = _mm_set_epi32(0, secondMessageField, 0, firstMessageField);
            __m128i mulitpliedHalves = _mm_mul_epu32(valuesToMultiply, fragmentCoefficentVector);               
        }
</code></pre>

<p>Do you have any suggestions on how to further optimize this? I understand that it's hard to do without more context but any help is appreciated!</p>
","922184","","<p><strong>Now that I'm awake, here's my answer:</strong></p>

<p>In your original code, the bottleneck is almost certainly <code>_mm_set_epi32</code>. This single intrinsic gets compiled into this mess in your assembly:</p>

<pre><code>633415EC  xor         edi,edi  
633415EE  movd        xmm3,edi  
...
633415F6  xor         ebx,ebx  
633415F8  movd        xmm4,edi  
633415FC  movd        xmm5,ebx  
63341600  movd        xmm0,esi  
...
6334160B  punpckldq   xmm5,xmm3  
6334160F  punpckldq   xmm0,xmm4 
...
63341618  punpckldq   xmm0,xmm5 
</code></pre>

<p><strong>What is this? 9 instructions?!?!?!</strong> Pure overhead...</p>

<p>Another place that seems odd is that the compiler didn't merge the adds and loads:</p>

<pre><code>movdqa      xmm3,xmmword ptr [ecx-10h]
paddq       xmm0,xmm3
</code></pre>

<p>should have been merged into:</p>

<pre><code>paddq       xmm0,xmmword ptr [ecx-10h]
</code></pre>

<p>I'm not sure if the compiler went brain-dead, or if it actually had a legitimate reason to do that... Anyways, it's a small thing compared to the <code>_mm_set_epi32</code>.</p>

<p><strong>Disclaimer:</strong> The code I will present from here on violates strict-aliasing. But non-standard compliant methods are often needed to achieve maximum performance.</p>

<hr>

<p><strong>Solution 1: No Vectorization</strong></p>

<p>This solution assumes <code>allZero</code> is really all zeros.</p>

<p>The loop is actually simpler than it looks. Since there isn't a lot of arithmetic, it might be better to just not vectorize:</p>

<pre><code>//  Test Data
unsigned __int32 fragmentCoefficentVector = 1000000000;

__declspec(align(16)) int currentMessageGaloisFieldsArray_[8] = {10,11,12,13,14,15,16,17};
int *currentMessageGaloisFieldsArray = currentMessageGaloisFieldsArray_;

__m128i currentUnModdedGaloisFieldFragments_[8];
__m128i *currentUnModdedGaloisFieldFragments = currentUnModdedGaloisFieldFragments_;
memset(currentUnModdedGaloisFieldFragments,0,8 * sizeof(__m128i));


int elementIterations = 4;

//  The Loop
while (elementIterations &gt; 0){
    elementIterations -= 1;

    //  Default 32 x 32 -&gt; 64-bit multiply code
    unsigned __int64 r0 = currentMessageGaloisFieldsArray[0] * (unsigned __int64)fragmentCoefficentVector;
    unsigned __int64 r1 = currentMessageGaloisFieldsArray[1] * (unsigned __int64)fragmentCoefficentVector;

    //  Use this for Visual Studio. VS doesn't know how to optimize 32 x 32 -&gt; 64-bit multiply
//    unsigned __int64 r0 = __emulu(currentMessageGaloisFieldsArray[0], fragmentCoefficentVector);
//    unsigned __int64 r1 = __emulu(currentMessageGaloisFieldsArray[1], fragmentCoefficentVector);

    ((__int64*)currentUnModdedGaloisFieldFragments)[0] += r0 &amp; 0x00000000ffffffff;
    ((__int64*)currentUnModdedGaloisFieldFragments)[1] += r0 &gt;&gt; 32;
    ((__int64*)currentUnModdedGaloisFieldFragments)[2] += r1 &amp; 0x00000000ffffffff;
    ((__int64*)currentUnModdedGaloisFieldFragments)[3] += r1 &gt;&gt; 32;

    currentMessageGaloisFieldsArray     += 2;
    currentUnModdedGaloisFieldFragments += 2;
}
</code></pre>

<p>Which compiles to this on x64:</p>

<pre><code>$LL4@main:
mov ecx, DWORD PTR [rbx]
mov rax, r11
add r9, 32                  ; 00000020H
add rbx, 8
mul rcx
mov ecx, DWORD PTR [rbx-4]
mov r8, rax
mov rax, r11
mul rcx
mov ecx, r8d
shr r8, 32                  ; 00000020H
add QWORD PTR [r9-48], rcx
add QWORD PTR [r9-40], r8
mov ecx, eax
shr rax, 32                 ; 00000020H
add QWORD PTR [r9-24], rax
add QWORD PTR [r9-32], rcx
dec r10
jne SHORT $LL4@main
</code></pre>

<p>and this on x86:</p>

<pre><code>$LL4@main:
mov eax, DWORD PTR [esi]
mul DWORD PTR _fragmentCoefficentVector$[esp+224]
mov ebx, eax
mov eax, DWORD PTR [esi+4]
mov DWORD PTR _r0$31463[esp+228], edx
mul DWORD PTR _fragmentCoefficentVector$[esp+224]
add DWORD PTR [ecx-16], ebx
mov ebx, DWORD PTR _r0$31463[esp+228]
adc DWORD PTR [ecx-12], edi
add DWORD PTR [ecx-8], ebx
adc DWORD PTR [ecx-4], edi
add DWORD PTR [ecx], eax
adc DWORD PTR [ecx+4], edi
add DWORD PTR [ecx+8], edx
adc DWORD PTR [ecx+12], edi
add esi, 8
add ecx, 32                 ; 00000020H
dec DWORD PTR tv150[esp+224]
jne SHORT $LL4@main
</code></pre>

<p><strong>It's possible that both of these are already faster than your original (SSE) code...</strong> On x64, Unrolling it will make it even better.</p>

<hr>

<p><strong>Solution 2: SSE2 Integer Shuffle</strong></p>

<p>This solution unrolls the loop to 2 iterations:</p>

<pre><code>//  Test Data
__m128i allZero = _mm_setzero_si128();
__m128i fragmentCoefficentVector = _mm_set1_epi32(1000000000);

__declspec(align(16)) int currentMessageGaloisFieldsArray_[8] = {10,11,12,13,14,15,16,17};
int *currentMessageGaloisFieldsArray = currentMessageGaloisFieldsArray_;

__m128i currentUnModdedGaloisFieldFragments_[8];
__m128i *currentUnModdedGaloisFieldFragments = currentUnModdedGaloisFieldFragments_;
memset(currentUnModdedGaloisFieldFragments,0,8 * sizeof(__m128i));


int elementIterations = 4;

//  The Loop
while(elementIterations &gt; 1){   
    elementIterations -= 2;

    //  Load 4 elements. If needed use unaligned load instead.
    //      messageField = {a, b, c, d}
    __m128i messageField = _mm_load_si128((__m128i*)currentMessageGaloisFieldsArray);

    //  Get into this form:
    //      values0 = {a, x, b, x}
    //      values1 = {c, x, d, x}
    __m128i values0 = _mm_shuffle_epi32(messageField,216);
    __m128i values1 = _mm_shuffle_epi32(messageField,114);

    //  Multiply by ""fragmentCoefficentVector""
    values0 = _mm_mul_epu32(values0, fragmentCoefficentVector);
    values1 = _mm_mul_epu32(values1, fragmentCoefficentVector);

    __m128i halves0 = _mm_unpacklo_epi32(values0, allZero);
    __m128i halves1 = _mm_unpackhi_epi32(values0, allZero);
    __m128i halves2 = _mm_unpacklo_epi32(values1, allZero);
    __m128i halves3 = _mm_unpackhi_epi32(values1, allZero);


    halves0 = _mm_add_epi64(halves0, currentUnModdedGaloisFieldFragments[0]);
    halves1 = _mm_add_epi64(halves1, currentUnModdedGaloisFieldFragments[1]);
    halves2 = _mm_add_epi64(halves2, currentUnModdedGaloisFieldFragments[2]);
    halves3 = _mm_add_epi64(halves3, currentUnModdedGaloisFieldFragments[3]);

    currentUnModdedGaloisFieldFragments[0] = halves0;
    currentUnModdedGaloisFieldFragments[1] = halves1;
    currentUnModdedGaloisFieldFragments[2] = halves2;
    currentUnModdedGaloisFieldFragments[3] = halves3;

    currentMessageGaloisFieldsArray     += 4;
    currentUnModdedGaloisFieldFragments += 4;
}
</code></pre>

<p><strong>which gets compiled to this (x86):</strong> (x64 isn't too different)</p>

<pre><code>$LL4@main:
movdqa    xmm1, XMMWORD PTR [esi]
pshufd    xmm0, xmm1, 216               ; 000000d8H
pmuludq   xmm0, xmm3
movdqa    xmm4, xmm0
punpckhdq xmm0, xmm2
paddq     xmm0, XMMWORD PTR [eax-16]
pshufd    xmm1, xmm1, 114               ; 00000072H
movdqa    XMMWORD PTR [eax-16], xmm0
pmuludq   xmm1, xmm3
movdqa    xmm0, xmm1
punpckldq xmm4, xmm2
paddq     xmm4, XMMWORD PTR [eax-32]
punpckldq xmm0, xmm2
paddq     xmm0, XMMWORD PTR [eax]
punpckhdq xmm1, xmm2
paddq     xmm1, XMMWORD PTR [eax+16]
movdqa    XMMWORD PTR [eax-32], xmm4
movdqa    XMMWORD PTR [eax], xmm0
movdqa    XMMWORD PTR [eax+16], xmm1
add       esi, 16                   ; 00000010H
add       eax, 64                   ; 00000040H
dec       ecx
jne       SHORT $LL4@main
</code></pre>

<p>Only slightly longer than the non-vectorized version for two iterations. This uses very few registers, so you can further unroll this even on x86.</p>

<hr>

<p><strong>Explanations:</strong></p>

<ul>
<li>As Paul R mentioned, unrolling to two iterations allows you to combine the initial load into one SSE load. This also has the benefit of getting your data into the SSE registers.</li>
<li>Since the data starts off in the SSE registers, <code>_mm_set_epi32</code> (which gets compiled into about ~9 instructions in your original code) can be replaced with a single <code>_mm_shuffle_epi32</code>.</li>
</ul>
"
"<p>So if I have a procedure where the first formal parameter is an <code>int[]</code> and I'm enumerating through that loop, I'm confused about why one piece of code works where another doesn't.  I should be able to do this:</p>

<pre><code>#where ebp+8 is the location of the pointer, and ecx is the counter
mov edx, [ebp+ecx*4+8]
</code></pre>

<p>This gives me a gibberish value for edx, but this code works fine</p>

<pre><code>mov edx, [ebp+8]
mov edx, [edx+ecx*4]
</code></pre>

<p>I don't understand the difference between those statements.  </p>
","922184","","<p>They are different:</p>

<p>In the first code:</p>

<pre><code>mov edx, [ebp+ecx*4+8]
</code></pre>

<p>You are loading from the address: <code>ebp+ecx*4+8</code></p>

<p>In the second code:</p>

<pre><code>mov edx, [ebp+8]
mov edx, [edx+ecx*4]
</code></pre>

<p>You first load the value stored at <code>ebp+8</code>. Then you use it as the base address for the second load.</p>

<p>In other words, the base address is stored at the memory location pointed to by <code>ebp + 8</code>. It is not actually stored in the <code>ebp</code> register itself.</p>
"
"<p>When I run this code the program freezes,why?</p>

<pre><code>main()
{
int co;
    co=0;
    while (co&lt;10) {

        co=co+1;

        if (co==3)
            printf(""The number is now three."");
        if (co==7)
            printf(""The number is now seven."");
        else
            printf(co);

}
}
</code></pre>

<p>I'm compiling it with mingw GCC.</p>
","922184","","<p>You can't print <code>co</code> like that:</p>

<p>You need to do it like this:</p>

<pre><code>printf(""%d"",co);
</code></pre>

<p><code>printf</code> takes as a first parameter, a string with format specifiers. The latter (optional) parameters are the arguments themselves.</p>

<p><a href=""http://www.cplusplus.com/reference/clibrary/cstdio/printf/"" rel=""nofollow"">http://www.cplusplus.com/reference/clibrary/cstdio/printf/</a></p>

<p>Here's a more cleaned version of your code:</p>

<pre><code>int main(){

    int co = 0;
    while (co &lt; 10) {

        co = co + 1;

        if (co == 3)
            printf(""The number is now three."");
        if (co == 7)
            printf(""The number is now seven."");
        else
            printf(""%d\n"",co);
    }

    return 0;
}
</code></pre>
"
"<p>I tried the following code snippet: </p>

<pre><code>void main()
{
    int x = 1,y = 1,z = 1;
    ++x || ++y &amp;&amp; ++z;
    printf(""x = %d\ny = %d\nz = %d\n"",x,y,z);
}
</code></pre>

<p>The output I <em>expected</em> was:</p>

<pre><code>x = 2
y = 2
z = 2
</code></pre>

<p>But I am getting the output:</p>

<pre><code>x = 2
y = 1
z = 1
</code></pre>

<p>What is the reason for this?</p>
","922184","","<p>This is because of short-circuiting.</p>

<p><a href=""http://en.wikipedia.org/wiki/Short-circuit_evaluation"" rel=""nofollow"">http://en.wikipedia.org/wiki/Short-circuit_evaluation</a></p>

<p>When this is evaluated:</p>

<pre><code>++x || ++y &amp;&amp; ++z;
</code></pre>

<p>The first part <code>++x</code> already determines the value of the entire expression. So the <code>++y &amp;&amp; ++z</code> is not executed at all. So the side-effects of <code>++y</code> and <code>++z</code> are not invoked.</p>
"
"<p>I have in C++ a vector of 32 bits integers (variable size, continous memory; like a C-array), representing a number in base 4294967296. I would like to print it in base 10.</p>

<p>These numbers can be extremely big and take over a few megabytes of memory.</p>

<p>What would be the best way to do this in terms of performance? Can I use GMP to do this?</p>
","922184","","<p>Yes, you can use GMP for this. The function that you're looking for is <code>mpn_get_str</code>:</p>

<p><a href=""http://gmplib.org/manual/Low_002dlevel-Functions.html#Low_002dlevel-Functions"" rel=""nofollow"">http://gmplib.org/manual/Low_002dlevel-Functions.html#Low_002dlevel-Functions</a></p>

<p>Now the only issue is the size of <code>mp_limb_t</code>. It is either a 32-bit integer or a 64-bit integer depending on the platform.</p>

<ul>
<li>If it's a 32-bit integer, then you can call the function directly on your array of 32-bit integers. (if the endian matches)</li>
<li>If it's a 64-bit integer, you may be able to still use it with just a pointer cast. (depending on the alignment and the endianness) Otherwise, you'll have to copy your array into an array of 64-bit integers before you can call <code>mpn_get_str</code>.</li>
</ul>

<p>Alternatively, it might be easier to use the <code>mpz</code> integer class. <a href=""http://gmplib.org/manual/Integer-Import-and-Export.html#Integer-Import-and-Export"" rel=""nofollow"">Import</a> your integer array into a large integer, then <a href=""http://gmplib.org/manual/Converting-Integers.html#Converting-Integers"" rel=""nofollow"">print</a> it back out in base 10.</p>
"
"<p>This is how the code is:</p>

<pre><code>for(char c=0;c&lt;256;c++)
  printf(""hello"");
</code></pre>

<p>Why does this go into an infinite loop?</p>
","922184","","<p>This is because <code>char</code> is an 8-bit integer in your case.</p>

<p>So <code>char</code> only has the values <code>-128</code> to <code>127</code>, which is always less than <code>256</code>.</p>
"
"<p>I've found useful answers on other people's questions countless times here on stackoverflow, but this is my first time asking a question of my own.</p>

<p>I have a C function that dynamically needs to allocate space for an array of structs and then fill the struct members of each array element with values pulled from a file. The member assignment works fine on the first pass of the loop, but I get a segmentation fault on the second pass.</p>

<p>I've written up this quick program illustrating the essentials of the problem I'm having:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

typedef struct {
        int a;
        int b;
} myStruct;

void getData(int* count, myStruct** data) {
    *count = 5;
    *data = malloc(*count * sizeof(myStruct));

    int i;
    for (i = 0; i &lt; *count; i++) {
        data[i]-&gt;a = i;
        data[i]-&gt;b = i * 2;
        printf(""%d.a: %d\n"", i, data[i]-&gt;a);
        printf(""%d.b: %d\n"", i, data[i]-&gt;b);
    }
}

int main() {
    int count;
    myStruct* data;
    getData(&amp;count, &amp;data);
    return 0;
}
</code></pre>

<p>The output I get from this is:</p>

<pre><code>0.a: 0
0.b: 0
Segmentation fault
</code></pre>

<p>I'm not sure where my problem lies. It seems as though the malloc call is only allocating enough space for one struct when it should be allocating space for five.</p>

<p>Any help would be very much appreciated.</p>
","922184","","<p>The error is here:</p>

<pre><code>for (i = 0; i &lt; *count; i++) {
    data[i]-&gt;a = i;
    data[i]-&gt;b = i * 2;
    printf(""%d.a: %d\n"", i, data[i]-&gt;a);
    printf(""%d.b: %d\n"", i, data[i]-&gt;b);
}
</code></pre>

<p>you should do this:</p>

<pre><code>for (i = 0; i &lt; *count; i++) {
    (*data)[i].a = i;
    (*data)[i].b = i * 2;
    printf(""%d.a: %d\n"", i, (*data)[i].a);
    printf(""%d.b: %d\n"", i, (*data)[i].b);
}
</code></pre>

<p>The reason is that you are indexing the wrong ""dimension"" of <code>data</code>.</p>
"
"<p>I have a <code>#pragma omp parallel for</code> loop inside a class method. Each thread readonly accesses few method local variables, few call private data and a method's parameter. All of them are declared in a <code>shared</code> clause.
My questions:</p>

<ul>
<li>Performance wise should not make any difference declare these
variables <code>shared</code> or <code>firstprivate</code>. Right?</li>
<li>Is the same true if I'm not careful about making variable not sharing the same cache line?</li>
<li>If one of the shared variables is a pointer and inside the thread I read a value through it, is there an aliasing problem like in ordinary loops?</li>
</ul>

<p>Tomorrow I will try to profile my code. In the meantime thanks for your advice!</p>
","922184","","<ol>
<li><p>Well, they're not the same thing. With <code>shared</code>, they are shared between all the threads. With <code>firstprivate</code>, each thread gets it's own copy. If you're only reading the variable, then it's better to leave it as <code>shared</code> as to avoid copying it. (In C++, <code>firstprivate</code> will implicitly invoke the copy constructor.)</p></li>
<li><p>Correct, multiple threads reading and writing to values that sit on the same cacheline is called <a href=""http://en.wikipedia.org/wiki/False_sharing"">false sharing</a>. The cache line will bounce back and forth between the cores that are accessing it - which can result in significant slowdown if it happens often enough.</p></li>
<li><p>If you're just reading data through the shared pointer, then there shouldn't be a problem. But if you're also writing to it, then you need to make sure you don't have a race condition.</p></li>
</ol>
"
"<p>Can't get any code using header guards to compile in vs 2010. For example:</p>

<pre><code>#ifndef SIMPLE.H
#define SIMPLE.H

#include &lt;iostream&gt;

class Place {
private:
int m_xplace;
int m_yplace;
Place(){}
public:
Place(int x, int y) : m_xplace(x), m_yplace(y) {}
void Move(int x, int y);
void set_place(int x, int y) {m_xplace = x, m_yplace = y;}
int get_place_x() {return m_xplace;}
int get_place_y() {return m_yplace;}
};
#endif
</code></pre>

<p>I get this output from compiler:</p>

<pre><code>1&gt;------ Build started: Project: 1, Configuration: Release Win32 ------
1&gt;e:\projects\1\1\simple.h(1): warning C4067: unexpected tokens following preprocessor     directive - expected a newline
1&gt;e:\projects\1\1\simple.h(2): error C2008: '.' : unexpected in macro definition
1&gt;e:\projects\1\1\simple.h(1): warning C4067: unexpected tokens following preprocessor directive - expected a newline
1&gt;e:\projects\1\1\simple.h(2): error C2008: '.' : unexpected in macro definition
========== 
Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========
</code></pre>

<p>Am i missing something obvious here? I'm quite sure i have the syntax correct. Thanks.</p>
","922184","","<p>You can't use <code>.</code> in the identifier.</p>

<p>Try this instead:</p>

<pre><code>#ifndef SIMPLE_H
#define SIMPLE_H
</code></pre>
"
"<p>I have this problem:</p>

<p>A positive integer is called a <code>palindrome</code> if its representation in the decimal system is the same when read from left to right and from right to left. For a given positive integer <code>K</code> of not more than <code>1000000</code> digits, write the value of the smallest palindrome larger than <code>K</code> to output. Numbers are always displayed without leading zeros.
Input</p>

<p>The first line contains integer <code>t</code>, the number of test cases. Integers <code>K</code> are given in the next <code>t</code> lines.
Output</p>

<p>For each <code>K</code>, output the smallest palindrome larger than <code>K</code>.
Example</p>

<p>Input:</p>

<pre><code>2
808
2133
</code></pre>

<p>Output:</p>

<pre><code>818
2222
</code></pre>

<p>My code converts the input to a string and evaluates either end of the string making adjustments accordingly and moves inwards. However, the problem requires that it can take values up to 10^6 digits long, if I try to parse large numbers I get a number format exception i.e.</p>

<pre><code>Integer.parseInt(LARGENUMBER);
</code></pre>

<p>or</p>

<pre><code>Long.parseInt(LARGENUMBER);
</code></pre>

<p>and <code>LARGENUMBER</code> is out of range. can anyone think of a work around or how to handle such large numbers?</p>
","922184","","<p>You could probably use the <a href=""http://download.oracle.com/javase/1,5,0/docs/api/java/math/BigInteger.html"" rel=""nofollow"">BigInteger</a> class to handle large integers like this.</p>

<p>However, I wouldn't count on it being efficient at such massive sizes. Because it still uses <code>O(n^2)</code> algorithms for multiplication and conversions.</p>
"
"<p>I'm trying to make a little custom vector...</p>

<p>element class, should point to the adress of the next class but with this code</p>

<pre><code>class foo {
private:
    int attr;
public:
    foo(){attr = 10;}
    int get_attr(){return attr;}
    void set_attr(int a){attr =a;}
};

class element_foo {
private:
    foo data;
    element_foo *ptr_next;
public:
    element_foo(){ptr_next = NULL;}
    element_foo(int dat){data.set_attr(dat); ptr_next = NULL;}
    element_foo(int dat, element_foo next){
        data.set_attr(dat);
        ptr_next = &amp;next;
    }
    foo get_data(){return data;}

    element_foo get_next(){return *ptr_next;}

    void print_array(){
        if (ptr_next == NULL) {
            std::cout&lt;&lt; data.get_attr()&lt;&lt;std::endl;
        }
        else {
            std::cout&lt;&lt; data.get_attr()&lt;&lt;std::endl;
            this-&gt;get_next().print_array();
        }

    }
};



int main (int argc, char * const argv[]) {
    // insert code here...  
    element_foo a1(10);
    element_foo a2(15,a1);
    element_foo a3(20,a2);

    a3.print_array();

    std::cout &lt;&lt; ""Hello, World!\n"";
    return 0;
}
</code></pre>

<p>when I print a3, it get to segmentation fault... why? where is my mistake?</p>
","922184","","<p>The error is in this constructor:</p>

<pre><code>element_foo(int dat, element_foo next){
    data.set_attr(dat);
    ptr_next = &amp;next;
}
</code></pre>

<p>You are taking the address of a local. <code>ptr_next = &amp;next;</code> Once the function ends, the address is invalid.</p>

<p>What you need to do is to pass <code>next</code> in as a pointer:</p>

<pre><code>element_foo(int dat, element_foo *next){
    data.set_attr(dat);
    ptr_next = next;
}
</code></pre>

<p>And change your main to this:</p>

<pre><code>element_foo a1(10);
element_foo a2(15,&amp;a1);
element_foo a3(20,&amp;a2);
</code></pre>

<p>EDIT:</p>

<p>Alternatively, you can just pass it by reference:</p>

<pre><code>element_foo(int dat, element_foo &amp;next){
    data.set_attr(dat);
    ptr_next = &amp;next;
}
</code></pre>
"
"<p>I've got these prototypes:</p>

<pre><code>int *my_func(int x, void (*other_func)(int a, int b));

int func2(int val1, int val2);
</code></pre>

<p>Assume there is a function written that matches it.</p>

<p>If I want to actually call my_func, how would I do it? I've tried the following with no luck:</p>

<pre><code>my_func(1,func2);
</code></pre>

<p>Here's the error:</p>

<pre><code>warning: passing argument 2 of ‘my_func’ from incompatible pointer type
</code></pre>
","922184","","<p>That's because the function prototypes don't match:</p>

<pre><code>void (*other_func)(void *a, int *b)
</code></pre>

<p>is not the same as:</p>

<pre><code>int func2(int val1, int val2);
</code></pre>

<p>One takes a <code>void*</code> and <code>int*</code>, while the other takes two <code>int</code>s.</p>

<p>EDIT:</p>

<p>Also, the return type doesn't match.</p>

<p>EDIT 2:</p>

<p><strong>Since you've fixed both errors, this answer is out of context.</strong> I just tested it with these two fixes, and it compiles:</p>

<pre><code>int *my_func(int x, void (*other_func)(int a, int b)){
    return 0;
}
void func2(int val1, int val2){
    printf(""blah"");
}


int main(){
    my_func(1,func2);

    return 0;
}
</code></pre>
"
"<p>In Visual Studio 2005, I'm trying to compile a .c file:</p>

<pre><code>int i = 6;
int a[i];
</code></pre>

<p>It doesn't work, so which standard does my compiler follow? </p>
","922184","","<p>Visual Studio only supports C89/90. They have no support for C99. Therefore you cannot use variable-length arrays in Visual Studio. Furthermore, Microsoft has no plans to add support for C99 in their C compiler.</p>
"
"<p>I'm trying to create a basic function to swap the endianness of a short int but it's throwing an error:</p>

<pre><code>#ifndef __ENDIAN__
#define __ENDIAN__

#define Swap16(value) \
    ((((unsigned short)((value) &amp; 0x00FF)) &lt;&lt; 8) | \
    (((unsigned short)((value) &amp; 0xFF00)) &gt;&gt; 8))

#define Swap32(value) \
    ((((unsigned)((value) &amp; 0x000000FF)) &lt;&lt; 24) | \
    (((unsigned)((value) &amp; 0x0000FF00)) &lt;&lt; 8) | \
    (((unsigned)((value) &amp; 0x00FF0000)) &gt;&gt; 8) | \
    (((unsigned)((value) &amp; 0xFF000000)) &gt;&gt; 24))

void __inline SwapEndian(short* value) //ERROR HERE
{
    *value = Swap16(value);
}

#endif
</code></pre>

<p>I intend to use the code like:</p>

<pre><code>short val = 0x1234;
SwapEndian(&amp;val);
//val now contains 0x3412
</code></pre>

<p>I'm using VS2008 and the exact error is:</p>

<pre><code>C2296: '&amp;' : illegal, left operand has type 'short *'
</code></pre>

<p>What can I do to fix this error?</p>
","922184","","<p>If you look at how the macro is expanded it's pretty clear what's wrong.</p>

<p><code>&amp;val</code> is a pointer of type <code>short*</code>. But you macro does arithmetic directly off of it's parameter. So you're trying to perform integer arithmetic on a pointer.</p>

<p>So this gets expanded to:</p>

<pre><code>((((unsigned short)((&amp;val) &amp; 0x00FF)) &lt;&lt; 8)
...
</code></pre>

<p><code>&amp;val</code> is type <code>short*</code>, while the macros expects an integer.</p>

<p>In the function you'll need to dereference it into an integer before passing it in to the macro.</p>
"
"<p>I have a CPU consuming function <code>do_long</code> that I need to run on two different datasets.</p>

<pre><code>do_long(data1);
do_long(data2);

do_long() {
#pragma omp for
    for(...) {
        // do proccessing
    }
}
</code></pre>

<p>I have N threads available (depends on machine). How to tell OpenMP that I want that both <code>do_long</code>
functions are run in parallel, and N/2 threads should perform the loop in first <code>do_long</code> and another N/2 should process second <code>do_long</code>?</p>
","922184","","<p>One approach is to do it using nested parallelism:</p>

<pre><code>void do_long(int threads) {
#pragma omp parallel for num_threads(threads)
    for(...) {
        // do proccessing
    }
}


int main(){
    omp_set_nested(1);

    int threads = 8;
    int sub_threads = (threads + 1) / 2;

#pragma omp parallel num_threads(2)
    {
        int i = omp_get_thread_num();

        if (i == 0){
            do_long(data1, sub_threads);
        }
        if (i == 1 || omp_get_num_threads() != 2){
            do_long(data2, sub_threads);
        }
    }

    return 0;
}
</code></pre>
"
"<p>I found this code in a book and I executed it in Netbeans:</p>

<pre><code>boolean b = false;
if(b = true) {
    System.out.println(""true"");
} else {
    System.out.println(""false"");
}
</code></pre>

<p>I just don't understand why the output of this code is true,
Can anyone enlighten me please,
Thanks.</p>
","922184","","<p>This is because the if-statement condition isn't a comparison. It's an assignment:</p>

<pre><code>if(b = true)
</code></pre>

<p>Which will always return true. So it will always print <code>true</code>.</p>

<p>If you wanted to do a comparison, you need to use <code>==</code>.</p>
"
"<p>How do you compute the execution time of instructions? Is it just done by checking what the chip manufacturers say in terms of how many clock cycles an action may take to complete? Is there anything else i should know about this? Feels like i'm missing something.... </p>
","922184","","<p>This is a non-trivial task. The easiest way is to just look up the results of what others have found.</p>

<p>For example, Agner Fog as a great reference for this information on current x86/x64 processors: <a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">http://www.agner.org/optimize/instruction_tables.pdf</a></p>

<p>If you actually want to measure instruction latencies and throughput yourself, you will need very in-depth knowledge of how processors work. And then you'll have to dive into assembly coding. Writing micro-benchmarks to measure these things is almost a field in itself as there's a lot of reverse engineering that's needed.</p>

<p>And of course, in the end - performance of an application depends on many more factors than just instruction latencies/throughput...</p>
"
"<p>works:meaning no precision error::Just array out of bounds</p>

<pre><code>long a[] =new long[1000000];
int no=2,n;
long i;
a[no]=i+a[n];
if(a[no]&gt;longChain)
{
    longChain = a[no];
    startNo = no;
}
</code></pre>

<p>and when I do</p>

<pre><code>long a[] =new long[1000000];
long no=2,n;
long i,longChain=1,startNo;
a[no]=i+a[n];
if(a[no]&gt;longChain)
{
    longChain = a[no];
    startNo = no;
}
</code></pre>

<p>then loss of precision</p>

<p>found:long</p>

<p>required: int</p>

<p>what is the problem?</p>

<p>My Code  for above problem, its ProjectEuler Problem No. 14</p>

<pre><code>class P14
{
    public static void main(String args[])
    {
        long a[] =new long[1000000];
        long no=2,n;
        long i,longChain=1,startNo;
        a[1]=1;
        while(no&lt;1000000)
        {
            n=no;
            i=0;
            while(n&gt;no-1)
            {
                if(n%2==0)
                    n=n/2;
                else
                    n=3*n+1;
                i++;
                //System.out.println(n);
            }
            a[no]=i+a[n];
            if (a[no] &gt; longChain)
            {
                longChain=a[no];
                startNo=no;
            }
            no++;
            //System.out.println(no);
        }
    }
}
</code></pre>

<p>This is my code for where above problem is occurring</p>

<p>Answer:: Replace a[no] by a[(int)n]</p>

<p>a[n],a[(int)n]</p>
","922184","","<p>This is likely because array indexing takes an <code>int</code> as the index. But all your variables are of type <code>long</code>.</p>

<pre><code>a[no]
</code></pre>

<p><code>no</code> is a <code>long</code>.</p>

<p>So using <code>long</code> as an array index is an implicit downcast which could result in loss of precision.</p>

<p>So either you manually cast it down, or you change <code>no</code> to an <code>int</code>.</p>

<p><strong>EDIT: (after additional info in the question)</strong></p>

<p>I'm not 100% sure if this is the cause:</p>

<pre><code>n=3*n+1;
</code></pre>

<p>You use <code>n</code> as in index. But <code>n</code> can get pretty large to begin with. So a <code>*3</code> could make it larger than the size of the array.</p>

<p>You should probably double-check whatever your algorithm is. (which I can't figure out from the code itself)</p>
"
"<p>What the codes basically do is to print the address of each element in the int and char arrays pointed to by pointers i and ch.</p>

<pre><code>#include&lt;stdio.h&gt;

int main()
{
    char *ch;
    int *i;
    int ctr;

    ch = malloc(sizeof(char)*10);
    i = malloc(sizeof(int)*10);

    printf(""Index\ti Address\tch Address\n\n"");

    for(ctr=0; ctr&lt;10; ctr++)
    {
        printf(""%d\t%p\t%p\n"",ctr,i+ctr,ch+ctr);
    }

    getch(); 
    return  0;
}
</code></pre>

<p>Result:</p>

<pre><code>Index   i Address       ch Address

0       00511068        00511050
1       0051106C        00511051
2       00511070        00511052
3       00511074        00511053
4       00511078        00511054
5       0051107C        00511055
6       00511080        00511056
7       00511084        00511057
8       00511088        00511058
9       0051108C        00511059 
</code></pre>

<p>I understand that each element in two arrays occupies space size of their data type. My problem is, I'm confused to this operation:</p>

<pre><code>i+1
</code></pre>

<p>If <code>i</code> is 00511068 , then <code>i+1</code> is <code>00511069</code> as opposed to the result. What does <code>i+1</code> means? How do you read it? I think I don't fully understand pointer. Please help me understand it. Thank you.</p>
","922184","","<p>This is because <code>int</code> is 4 bytes on this system. So <code>+1</code> on a pointer will increment it by 4 instead of just 1.</p>

<p>When you increment a pointer, you increment it by it's actual size and not the pointer value itself.</p>
"
"<p>I'm experiencing a weird problem with C today. Have a quick look at this simplified code snippet:</p>

<pre><code>typedef struct
{
    /* The number of index terms */
    int nTerms;
    /* Information about each index term */
    TERMINFO *terms;
} INDEX;

INDEX *buildIndex(char *termsfile, char *dirs[], int n, OPTIONS opts)
{
    INDEX *ind = NULL;
    ind-&gt;nTerms = 5;
    return ind;
}

int main(int argc, char *argv[]) {
    ... // declare and assign values for TERMFILE, DIRS and opts.
    INDEX *ind = buildIndex(TERMFILE, DIRS, sizeof(DIRS), opts); // LINE A 
    printf(""Does NOT print %d\n"",ind-&gt;nTerms); // LINE B
    printf(""Does NOT print as well""); // LINE C
    return 0;
}
</code></pre>

<p>When I compile this program, there is no errors occurred, however when I run the compiled file, it doesn't print anything to the commmand-line (I'm using PuTTy on Windows machine). It becomes even weird when I remove the line <code>LINE A</code> and <code>LINE B</code>, then LINE C can be printed.</p>

<p>In short, whatever goes after LINE A can't be printed out (or executed?).</p>

<p>I don't know if there is any problem with my code.</p>
","922184","","<p>The reason why it isn't printing anything is because it's crashing:</p>

<pre><code>INDEX *ind = NULL;
ind-&gt;nTerms = 5;
</code></pre>

<p>You're dereferencing a NULL. (which is undefined behavior)</p>

<p>When you remove LINE A and LINE B, it doesn't crash so it prints LINE C. (you also forgot the <code>\n</code> in LINE C to flush the buffer.)</p>

<p>What you need to do it dynamically allocate <code>ind</code> via malloc and return. (and be sure to free it later)</p>

<pre><code>INDEX *buildIndex(char *termsfile, char *dirs[], int n, OPTIONS opts)
{
    INDEX *ind = malloc(sizeof(INDEX));   //  Allocate

    //  You may wish to check if `ind == NULL` to see if the allocation failed.

    ind-&gt;nTerms = 5;
    return ind;
}

int main(int argc, char *argv[]) {
    ... // declare and assign values for TERMFILE, DIRS and opts.
    INDEX *ind = buildIndex(TERMFILE, DIRS, sizeof(DIRS), opts); // LINE A 
    printf(""Does NOT print %d\n"",ind-&gt;nTerms); // LINE B
    printf(""Does NOT print as well""); // LINE C

    free(ind);  //  Free

    return 0;
}
</code></pre>
"
"<pre><code>#include &lt;stdio.h&gt;

int i, party;
char x = ' ';
float total = 0, perCost = 0;
main(){

            switch (toupper(x)) {
                case 'A':
                    printf(""Combo A: Friend Chicken with slaw [price: 4.25]"");
                    perCost = 4.24;             
                    break;
                case 'B':
                    printf(""Combo B: Roast beef with mashed potato [price: 5.75]"");
                    perCost = 5.75;
                    break;
                case 'C':
                    printf(""Combo A: Fish and chips [price: 5.25]"");
                    perCost = 5.25;
                    break;
                case 'D':
                    printf(""Combo A: soup and salad [price: 3.74]"");
                    perCost = 3.75;
                    break;
                default:
                    perCost = 0;
                    break;
            }

    printf(""Enter Party Total: "");
    scanf(""%d"", &amp;party);
    for (i = 0; i &lt; party; i++) {
            printf(""Enter item ordered [A/B/C/D/X]: "");
            scanf(""%c%*c"", &amp;x);
    }
    total = total + perCost;
    printf(""%f\n"", total);
}
</code></pre>

<p>What is causing my programming to not grab from the switch statement?</p>
","922184","","<p>I think your switch statement needs to be inside the loop:</p>

<pre><code>for (i = 0; i &lt; party; i++) {
    printf(""Enter item ordered [A/B/C/D/X]: "");
    scanf(""%c%*c"", &amp;x);


    //  Put your switch here.
    switch (toupper(x)) {
            case 'A':
                printf(""Combo A: Friend Chicken with slaw [price: 4.25]"");
                perCost = 4.24;             
                break;
            case 'B':
                printf(""Combo B: Roast beef with mashed potato [price: 5.75]"");
                perCost = 5.75;
                break;
            case 'C':
                printf(""Combo A: Fish and chips [price: 5.25]"");
                perCost = 5.25;
                break;
            case 'D':
                printf(""Combo A: soup and salad [price: 3.74]"");
                perCost = 3.75;
                break;
            default:
                perCost = 0;
                break;
        }



    total = total + perCost;  // Move this into the loop.

}
</code></pre>
"
"<p>This is a stripped down version of my program. I need to pass a pointer to pointers of structs to a function, modify the structs within the function, and have those changes persist. The function declaration must stay the same. </p>

<p>Currently I can modify the data within the function, but once returned to main, no changes were made.</p>

<p>Thank you for your help.</p>

<pre><code>int main()
{
    struct node** HuffmanNodes;
    read_Huffman_encoded_data(&amp;HuffmanNodes);
}

void read_Huffman_encoded_data(**HuffmanNodes)
{
    Huffman_node = (node**)malloc(sizeof(node*)*(*number_of_nodes));

    int index;
    for(index=0; index&lt;*number_of_nodes;index++)
    {
        Huffman_node[index] = (node*)malloc(sizeof(node));
        Huffman_node[index]-&gt;first_value=1;
        Huffman_node[index]-&gt;second_value=2;
    }
}
</code></pre>
","922184","","<p>You have a pointer typing problem. I'm surprised that it even compiles since <code>&amp;HuffmanNodes</code> is of type <code>node***</code>.</p>

<p>Try this:</p>

<pre><code>void read_Huffman_encoded_data(struct node ***HuffmanNodes)
{
    *Huffman_nodes = (node**)malloc(sizeof(node*)*(*number_of_nodes));

    int index;
    for(index=0; index&lt;*number_of_nodes;index++)
    {
        (*Huffman_nodes)[index] = (node*)malloc(sizeof(node));
        (*Huffman_nodes)[index]-&gt;first_value=1;
        (*Huffman_nodes)[index]-&gt;second_value=2;
    }
}
</code></pre>

<p>You also have some naming mismatches (which I fixed), I hope those are just typos from stripping down the program.</p>

<p>EDIT: Alternative Method</p>

<pre><code>int main()
{
    struct node** HuffmanNodes = (node*)malloc(sizeof(node) * (*number_of_nodes));
    read_Huffman_encoded_data(HHuffmanNodes);
}

void read_Huffman_encoded_data(struct node **HuffmanNodes)
{
    int index;
    for(index=0; index&lt;*number_of_nodes;index++)
    {
        Huffman_nodes[index] = (node*)malloc(sizeof(node));
        Huffman_nodes[index]-&gt;first_value=1;
        Huffman_nodes[index]-&gt;second_value=2;
    }
}
</code></pre>
"
"<p>In C++ how can I pass <strong>an array as a reference</strong> when I don't know the size at compile time? So far, I found out that the only way to make it work is to use something like</p>

<pre><code>const double( &amp;numbers ) [size]
</code></pre>

<p>but it means that I need to <strong>know the size of the array at compile time</strong>, thus I cannot use it in an external function.</p>

<p>My questions are:</p>

<ol>
<li>If I don't pass an array as a <code>( const double( &amp;numbers ) [length] )</code>, because for example I don't know its size, <strong>how do I make sure that it doesn't get copied</strong>, but it is <strong>referenced</strong>?</li>
<li>If I pass an array like in the above example, <code>( double array[] )</code> is it <strong>referenced</strong> or is it <strong>copied</strong>?</li>
</ol>
","922184","","<p>A couple things:</p>

<ol>
<li><p>C++ doesn't allow variable-sized arrays anyway. So all your arrays will need to have known sizes at compile time. So I'm not entirely sure if your initial question is even applicable since you won't be able to make an array with an unknown size in the first place.</p></li>
<li><p>When you pass an array, it is done by reference. It is not copied.</p></li>
</ol>

<p>In any case, you'll probably want to consider using <code>vector</code> instead.</p>

<p><strong>EDIT : See comments.</strong></p>

<pre><code>double average(const double *arr, size_t len){
    //  Compute average
    return accumulate(arr, arr + len, 0) / (double)len;
}

int main(){

    double array[10] = //  Initialize it

    cout &lt;&lt; average(array, 10) &lt;&lt; endl;

    //  Alternatively: This could probably be made a macro.
    //  But be careful though since the function can still take a pointer instead
    //  of an array.
    cout &lt;&lt; average(array, sizeof(array) / sizeof(double)) &lt;&lt; endl;

    return 0;
}
</code></pre>
"
"<p>My question is regarding the effect of <code>vector::push_back</code>, I know it adds an element in the end of the vector but what happens underneath the hood?</p>

<p>IIRC memory objects are allocated in a sequential manner, so my question is whether <code>vector::push_back</code> simply allocates more memory immediately after the vector, and if so what happens if there is not enough free memory in that location? Or perhaps a pointer is added in the ""end"" to cause the vector to ""hop"" to the location it continues? Or is it simply reallocated through copying it to another location that has enough space and the old copy gets discarded? Or maybe something else?</p>
","922184","","<p>When <code>vector</code> runs out of space, it is reallocated and all the elements are copied over to the new array. The old array is then destroyed.</p>

<p>To avoid an excessive number of allocations and to keep the average <code>push_back()</code> time at <code>O(1)</code>, a reallocation requires that the size be increased by at least a constant factor. (1.5 and 2 are common)</p>
"
"<p>I'm doing module testing of code written for a different platform and are having a problem where I need to constrict the sizes of the data types in the module being tested. Since I can't modify the module file directly I thought of using stdint.h typedefs and replace the modules declaration using defines. In essense this:</p>

<pre><code>#include &lt;stdint.h&gt;
#define int int16_t

int main() {
    uint16_t ui = 2;
    unsigned int uii = 3;
    printf(""Hello\n"");
    printf(""Test %d, %d\n"", ui, uii);
    return 0;
}
</code></pre>

<p>However this fails with this message:</p>

<pre><code>error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘uii’
</code></pre>

<p>Is there another way to do this kind of type replacement?</p>
","922184","","<p>For why your particular example fails it's because it's being expanded to:</p>

<pre><code>unsigned int16_t uii = 3;
</code></pre>

<p>with which the <code>unsigned</code> modifier apparently doesn't work on <code>int16_t</code>.</p>

<p><strong>Now to answer the question:</strong> I don't think you can do this unless the compiler has an internal option to change the size of <code>int</code>. Trying to force it will clash with internal library functions.</p>

<p>For example: Your <code>printf()</code> will also break because <code>%d</code> is going to expect the normal <code>int</code>, but you pass it a 16-bit integer.</p>

<p>EDIT: This <code>printf()</code> example is not a good example since <code>int16_t</code> will be promoted to <code>int</code>. But the general idea still holds. (see comments)</p>
"
"<p>I am trying to do modular exponentiation of integers with a very large modulus by repetitive squaring (the power is always a power of 2 in my case, so I believe this is the most efficient way).  Thanks to a nice property of my modulus, computing remainder is cheap; the hard part is multiplication.</p>

<p>Currently I run GMP on Intel Core 2 Quad.  I would like to make efficient use of the four cores of the processor, but GMP does not scale on SMP environments, so I am looking for a substitute arbitrary-precision arithmetic library.  I have found some libraries for parallel computation on <em>matrices</em>, but what I really need is a library for <em>integers</em>.</p>

<p>Does what I am looking for exist?</p>
","922184","","<p>The answer is yes, multi-threaded arbitrary-precision libraries <strong><em>do exist</em></strong>. But I'm not aware of a single one that is actually public. (with comparable speed to GMP)</p>

<p>For example, the arbitrary-precision libraries that are used in the Pi-computing programs, <a href=""http://bellard.org/pi/pi2700e9/tpi.html"" rel=""nofollow"">TachusPi</a> and <a href=""http://www.numberworld.org/y-cruncher/"" rel=""nofollow"">y-cruncher</a> are capable of multi-threaded arithmetic on large numbers.</p>

<p><em>However, both libraries are closed source and are not available to the public for use.</em></p>

<p><strong>Affiliation Disclosure:</strong> I'm the author of <a href=""http://www.numberworld.org/y-cruncher/"" rel=""nofollow"">y-cruncher</a>. So I have written one of such multi-threaded arbitrary-precision libraries myself.</p>
"
"<p>The function below calculates absolute value of 32-bit floating point value:</p>

<pre><code>__forceinline static float Abs(float x)
{
    union {
        float x;
        int a;
    } u;
    //u.x = x;
    u.a &amp;= 0x7FFFFFFF;
    return u.x;
}
</code></pre>

<p>union u declared in the function holds variable x, which is different from the x which is passed as parameter in the function. Is there any way to create a union with argument to the function - x? </p>

<p>Any reason the function above with uncommented line be executing longer than this one?</p>

<pre><code>__forceinline float fastAbs(float a)
{
    int b= *((int *)&amp;a) &amp; 0x7FFFFFFF;
    return *((float *)(&amp;b));
}
</code></pre>

<p>I'm trying to figure out best way to take Abs of floating point value in as little count of read/writes to memory as possible.</p>
","922184","","<p>For the first question, I'm not sure why you can't just what you want with an assignment. The compiler will do whatever optimizations that can be done.</p>

<p>In your second sample code. You violate strict aliasing. So it isn't the same.</p>

<p><strong>As for why it's slower:</strong></p>

<p>It's because CPUs today tend to have separate integer and floating-point units. By type-punning like that, you force the value to be moved from one unit to the other. This has overhead. (This is often done through memory, so you have extra loads and stores.)</p>

<p><strong>In the second snippet:</strong> <code>a</code> which is originally in the floating-point unit (either the x87 FPU or an SSE register), needs to be moved into the general purpose registers to apply the mask <code>0x7FFFFFFF</code>. Then it needs to be moved back.</p>

<p><strong>In the first snippet:</strong> The compiler is probably smart enough to load <code>a</code> directly into the integer unit. So you bypass the FPU in the first stage.</p>

<p>(I'm not 100% sure until you show us the assembly. It will also depend heavily on whether the parameter starts off in a register or on the stack. And whether the output is used immediately by another floating-point operation.)</p>
"
"<p>I have a matrix multiply code that looks like this:</p>

<pre><code>for(i = 0; i &lt; dimension; i++)
    for(j = 0; j &lt; dimension; j++)
        for(k = 0; k &lt; dimension; k++)
            C[dimension*i+j] += A[dimension*i+k] * B[dimension*k+j];
</code></pre>

<p>Here, the size of the  matrix is represented by <code>dimension</code>.
Now, if the size of the matrices is 2000, it takes 147 seconds to run this piece of code, whereas if the size of the matrices is 2048, it takes 447 seconds. So while the difference in no. of multiplications is (2048*2048*2048)/(2000*2000*2000) = 1.073, the difference in the timings is 447/147 = 3. Can someone explain why this happens? I expected it to scale linearly, which does not happen. I am not trying to make the fastest matrix multiply code, simply trying to understand why it happens. </p>

<p>Specs: AMD Opteron dual core node (2.2GHz), 2G RAM, gcc v 4.5.0</p>

<p>Program compiled as <code>gcc -O3 simple.c</code></p>

<p>I have run this on Intel's icc compiler as well, and seen similar results.</p>

<p>EDIT:</p>

<p>As suggested in the comments/answers, I ran the code with dimension=2060 and it takes 145 seconds.</p>

<p>Heres the complete program:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;sys/time.h&gt;

/* change dimension size as needed */
const int dimension = 2048;
struct timeval tv; 

double timestamp()
{
        double t;
        gettimeofday(&amp;tv, NULL);
        t = tv.tv_sec + (tv.tv_usec/1000000.0);
        return t;
}

int main(int argc, char *argv[])
{
        int i, j, k;
        double *A, *B, *C, start, end;

        A = (double*)malloc(dimension*dimension*sizeof(double));
        B = (double*)malloc(dimension*dimension*sizeof(double));
        C = (double*)malloc(dimension*dimension*sizeof(double));

        srand(292);

        for(i = 0; i &lt; dimension; i++)
                for(j = 0; j &lt; dimension; j++)
                {   
                        A[dimension*i+j] = (rand()/(RAND_MAX + 1.0));
                        B[dimension*i+j] = (rand()/(RAND_MAX + 1.0));
                        C[dimension*i+j] = 0.0;
                }   

        start = timestamp();
        for(i = 0; i &lt; dimension; i++)
                for(j = 0; j &lt; dimension; j++)
                        for(k = 0; k &lt; dimension; k++)
                                C[dimension*i+j] += A[dimension*i+k] *
                                        B[dimension*k+j];

        end = timestamp();
        printf(""\nsecs:%f\n"", end-start);

        free(A);
        free(B);
        free(C);

        return 0;
}
</code></pre>
","922184","","<p>Here's my wild guess: <strong>cache</strong></p>

<p>It could be that you can fit 2 rows of 2000 <code>double</code>s into the cache. Which is slighly less than the 32kb L1 cache. (while leaving room other necessary things)</p>

<p>But when you bump it up to 2048, it uses the <strong><em>entire</em></strong> cache (and you spill some because you need room for other things)</p>

<p>Assuming the cache policy is LRU, spilling the cache just a tiny bit will cause the entire row to be repeatedly flushed and reloaded into the L1 cache.</p>

<p>The other possibility is cache associativity due to the power-of-two. Though I think that processor is 2-way L1 associative so I don't think it matters in this case. (but I'll throw the idea out there anyway)</p>

<p><strong>Possible Explanation 2:</strong> Conflict cache misses due to super-alignment on the L2 cache.</p>

<p>Your <code>B</code> array is being iterated on the column. So the access is strided. Your total data size is <code>2k x 2k</code> which is about 32 MB per matrix. That's much larger than your L2 cache.</p>

<p>When the data is not aligned perfectly, you will have decent spatial locality on B. Although you are hopping rows and only using one element per cacheline, the cacheline stays in the L2 cache to be reused by the next iteration of the middle loop.</p>

<p>However, when the data is aligned perfectly (2048), these hops will all land on the same ""cache way"" and will far exceed your L2 cache associativity. Therefore, the accessed cache lines of <code>B</code> will not stay in cache for the next iteration. <strong><em>Instead, they will need to be pulled in all the way from ram.</em></strong></p>
"
"<pre><code>struct
{
    unsigned resizesCellWidths:1;
    unsigned numColumns:6;
    unsigned separatorStyle:3;
    unsigned allowsSelection:1;
    unsigned backgroundViewExtendsUp:1;
    unsigned backgroundViewExtendsDown:1;
    unsigned usesPagedHorizontalScrolling:1;
    unsigned updating:1;
    unsigned ignoreTouchSelect:1;
    unsigned needsReload:1;
    unsigned allCellsNeedLayout:1;
    unsigned isRotating:1;
    unsigned clipsContentWidthToBounds:1;
    unsigned isAnimatingUpdates:1;
    unsigned requiresSelection:1;
    unsigned contentSizeFillsBounds:1;
    unsigned delegateWillDisplayCell:1;
    unsigned delegateWillSelectItem:1;
    unsigned delegateWillSelectItemMultiTouch:1;
    unsigned delegateWillDeselectItem:1;
    unsigned delegateDidSelectItem:1;
    unsigned delegateDidSelectItemMultiTouch:1;
    unsigned delegateDidDeselectItem:1;
    unsigned delegateGestureRecognizerActivated:1;
    unsigned delegateAdjustGridCellFrame:1;
    unsigned delegateDidEndUpdateAnimation:1;
    unsigned dataSourceGridCellSize:1;
    unsigned int isEditing:1;
    unsigned __RESERVED__:1;
} _flags;
</code></pre>

<ol>
<li>What is the purpose of this struct?</li>
<li>What does the <code>:1</code> notation at the end of each line signify?</li>
<li>What is the meaning of <code>unsigned</code> modifier when there is no explicit type?</li>
</ol>

<p>Thanks</p>
","922184","","<p>Those are <a href=""http://en.wikipedia.org/wiki/Bit_field"">bitfields</a>. Since most of these are flags, they only have 2 possible values, so there's no need to assign more than 1 bit to each field. (with a couple exceptions in that struct)</p>

<p><code>unsigned</code> can stand alone as a type. It's just an <code>unsigned int</code>.</p>
"
"<pre><code>public class Geometry {

public static void main(String[] args) {
    input(0.0, 0.0);
    sphereVolume(0.0, 0.0);
    sphereSurface(0.0, 0.0);
    cylinderVolume(0.0, 0.0);
    cylinderSurface(0.0, 0.0);
    coneVolume(0.0, 0.0);
    coneSurface(0.0, 0.0);
    output(0.0, 0.0);
}
/**
 * @param radius
 * @param height
 */
public static void input(double radius, double height) {

    Scanner sc = new Scanner(System.in);

    System.out.print(""Enter radius r: "");
    radius = sc.nextInt();

    System.out.print(""Enter height h: "");
    height = sc.nextInt();
}

public static double sphereVolume(double radius, double height) {
    double volume = (4 / 3) * Math.PI * Math.pow(radius, 3.0);
    return volume;
}

public static double sphereSurface(double radius, double height) {
    double surface = 4 * Math.PI * Math.pow(radius, 2.0);
    return surface;
}

public static double cylinderVolume(double radius, double height) {
    double volume = Math.PI * Math.pow(radius, 2.0) * height;
    return volume;
}

public static double cylinderSurface(double radius, double height) {
    double surface = 2 * Math.PI * radius * height + 2 * Math.PI * Math.pow(radius, 2.0);
    return surface;
}

public static double coneVolume(double radius, double height) {
    double volume = (1 / 3) * Math.PI * Math.pow(radius, 2.0) * height;
    return volume;
}

public static double coneSurface(double radius, double height) {
    double surface = Math.PI * radius * (radius + Math.pow(( Math.pow(radius, 2.0) + Math.pow(height, 2.0)), .5));
    return surface;
}

public static void output(double radius, double height) {
    System.out.printf(""Volume of sphere: %f\n"", sphereVolume(0.0, 0.0));
    System.out.printf(""Surface area of Sphere: %f\n"", sphereSurface(0.0, 0.0));
    System.out.printf(""Volume of cylinder: %f\n"", cylinderVolume(0.0, 0.0));
    System.out.printf(""Surface area of cylinder: %f\n"", cylinderSurface(0.0, 0.0));
    System.out.printf(""Volume of cone: %f\n"", coneVolume(0.0, 0.0));
    System.out.printf(""Surface area of cone: %f\n"", coneSurface(0.0, 0.0));
}
</code></pre>

<p>My problem is that my output results in 0.0 everytime, regardless of the input.  I'm sure it is probably something simple, but I can't seem to figure it out. Can you please help me out?  Thanks a lot :)  I appreciate your time.</p>

<p>EDIT</p>

<p>So I am still getting 0.0 for my output even though I changed my code like this:</p>

<pre><code>    public static void output(double radius, double height) {
    System.out.printf(""Volume of sphere: %.13f\n"", sphereVolume(radius, height));
    System.out.printf(""Surface area of Sphere: %.13f\n"", sphereSurface(radius, height));
    System.out.printf(""Volume of cylinder: %.13f\n"", cylinderVolume(radius, height));
    System.out.printf(""Surface area of cylinder: %.13f\n"", cylinderSurface(radius, height));
    System.out.printf(""Volume of cone: %.13f\n"", coneVolume(radius, height));
    System.out.printf(""Surface area of cone: %.13f\n"", coneSurface(radius, height));
}
</code></pre>

<p>When I am calling my functions in main(), looks like this:</p>

<pre><code>public static void main(String[] args) {
    input(0.0, 0.0);
    sphereVolume(0.0, 0.0);
    sphereSurface(0.0, 0.0);
    cylinderVolume(0.0, 0.0);
    cylinderSurface(0.0, 0.0);
    coneVolume(0.0, 0.0);
    coneSurface(0.0, 0.0);
    output(0.0, 0.0);
}
</code></pre>

<p>Do I need to do something different here?</p>
","922184","","<p>You're dividing integers:</p>

<pre><code>public static double coneVolume(double radius, double height) {
    double volume = (1 / 3) * Math.PI * Math.pow(radius, 2.0) * height;
    return volume;
}
</code></pre>

<p>Integer division rounds down in Java. Therefore, <code>1 / 3</code> is evaluating to 0.</p>

<p>Change it to:</p>

<pre><code>double volume = (1. / 3.) * Math.PI * Math.pow(radius, 2.0) * height;
</code></pre>

<p>Here's the other occurrence:</p>

<pre><code>double volume = (4 / 3) * Math.PI * Math.pow(radius, 3.0);
</code></pre>

<p>change to:</p>

<pre><code>double volume = (4. / 3.) * Math.PI * Math.pow(radius, 3.0);
</code></pre>

<p><strong>EDIT :</strong></p>

<p>You're also calling all your functions with <code>0.0</code>. So of course the results will be zero.</p>

<pre><code>System.out.printf(""Volume of sphere: %f\n"", sphereVolume(0.0, 0.0));
System.out.printf(""Surface area of Sphere: %f\n"", sphereSurface(0.0, 0.0));
System.out.printf(""Volume of cylinder: %f\n"", cylinderVolume(0.0, 0.0));
System.out.printf(""Surface area of cylinder: %f\n"", cylinderSurface(0.0, 0.0));
System.out.printf(""Volume of cone: %f\n"", coneVolume(0.0, 0.0));
System.out.printf(""Surface area of cone: %f\n"", coneSurface(0.0, 0.0));
</code></pre>

<p><strong>EDIT : Another Suggestion</strong></p>

<p>You probably don't need all those <code>Math.pow()</code> calls since they're all called with 2 or 3. I'd say it's probably more concise and readable (and faster?) to just do:</p>

<pre><code>radius * radius + height * height
</code></pre>

<p>instead of</p>

<pre><code>Math.pow(radius, 2.0) + Math.pow(height, 2.0)
</code></pre>

<p><strong>EDIT 2: More fixes:</strong></p>

<p>Change your <code>main</code> to this. And get rid of the <code>input</code> function:</p>

<pre><code>public static void main(String[] args) {

    Scanner sc = new Scanner(System.in);

    System.out.print(""Enter radius r: "");
    double radius = sc.nextInt();

    System.out.print(""Enter height h: "");
    double height = sc.nextInt();

    output(radius, height);
}
</code></pre>
"
"<p>I have a number that I would like to convert to binary (from decimal) in C.</p>

<p>I would like my binary to always be in 5 bits (the decimal will never exceed 31). I already have a function that does it manually by dividing but that is hard to pad it to 5 bits.</p>

<p>Is there any easier way? Perhaps using bitwise shift?</p>

<p>I would also like the binary to be represented in a <code>char *</code></p>
","922184","","<p>One approach is this:</p>

<pre><code>unsigned int x = 30;

char bits[] = ""00000"";

bits[4] = (x &amp; 1) + '0';
x &gt;&gt;= 1;
bits[3] = (x &amp; 1) + '0';
x &gt;&gt;= 1;
bits[2] = (x &amp; 1) + '0';
x &gt;&gt;= 1;
bits[1] = (x &amp; 1) + '0';
x &gt;&gt;= 1;
bits[0] = x + '0';
</code></pre>

<p>Probably not the most elegant approach...</p>
"
"<p>What happens (behind the curtains) when this is executed?</p>

<pre><code>int x = 7;
x = x++;
</code></pre>

<p>That is, when a variable is post incrementednand assigned to itself in one statement? I compiled and executed this. <code>x</code> is still 7 <em>even after the entire statement</em>. In my book, it says that <code>x</code> is incremented!</p>
","922184","","<p><code>x</code> does get incremented. But you are assigning the old value of <code>x</code> back into itself.</p>

<pre><code>x = x++;
</code></pre>

<p><code>x++</code> increments <code>x</code> and returns its old value. <code>x =</code> assigns the old value back to itself.</p>

<p>So in the end, <code>x</code> gets assigned back to its initial value.</p>
"
"<p>I need to optimize some code where I multiply a vector of ints (32 bit) by a scalar modulo p (where p is the prime number (2^32)-5) and then subtract that vector from another vector modulo p. </p>

<p>The code looks like this:</p>

<pre><code>public static void multiplyAndSubtract(long fragmentCoefficient, long[] equationToSubtractFrom, long[] equationToSubtract) {
    for (int i = 0; i &lt; equationToSubtractFrom.length; i++) {
        equationToSubtractFrom[i] =  modP(equationToSubtractFrom[i] - multiplyModP(fragmentCoefficient, equationToSubtract[i]));
    }
}
</code></pre>

<p>I'm using longs because Java doesn't support unsigned integers but both vectors are mod p so you can expect every number to be 0 &lt;= x &lt; (2^32)-5</p>

<p>Any ideas to optimize this? The mod p operation is what's taking up most of the execution time so one way to optimize this could to somehow not do modP after the multiplication and only do it after the subtraction. Any ideas on how to do that?</p>
","922184","","<p>I know of two ways to do this without using division or modulus:</p>

<p><em><strong>Method 1: Invariant Multiplication</em></strong>. (<a href=""http://www.google.com/url?sa=t&amp;rct=j&amp;q=invarient%20multiplication&amp;source=web&amp;cd=1&amp;ved=0CCsQFjAA&amp;url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.1.2556%26rep%3Drep1%26type%3Dpdf&amp;ei=RjOpTvWmMuXn0QGQyN2oDg&amp;usg=AFQjCNGU0J-Es-VtoO0SylcMLWrs2mHXow&amp;sig2=whOZcSLbz7VD4taq5ORlRg&amp;cad=rja"" rel=""nofollow"">see this paper</a>)</p>

<p>The basic idea here is to pre-compute and approximation of the reciprocal of the <code>p</code> which allows you do an integer division using just a couple of integer multiplications. Then you can multiply back and obtain your modulus. This is the easier approach to implement.</p>

<p><em><strong>Method 2:</em></strong> (the one that I usually use), <strong><em>is to use floating-point</em></strong>. Convert the numbers to floating-point and multiply by a pre-computed reciprocal of <code>p</code>. Then round and convert back to an integer. This approach is harder to get right, but from my experience it's faster if done properly.</p>

<p>Both approaches here involve no divisions aside from a pre-computation of the reciprocal either in integer or floating-point.</p>

<p>Whether or not either of these methods will be faster than straight-forward use of <code>%</code>, will depend on how well you can implement them. So I can't guarantee that either one will be faster.</p>
"
"<p>This was probably asked somewhere but I couldn't find it. Could someone clarify why this code compiles and prints out <code>1</code>?</p>

<pre><code>long i = (byte) + (char) - (int) + (long) - 1;
System.out.println(i);
</code></pre>
","922184","","<p>It's being parsed as this:</p>

<pre><code>long i = (byte)( +(char)( -(int)( +(long)(-1) ) ) );
</code></pre>

<p>where all the <code>+</code> and <code>-</code> operators are unary <code>+</code> or <code>-</code>.</p>

<p>In which case, the <code>1</code> gets negated twice, so it prints out as a <code>1</code>.</p>
"
"<pre><code>if(a &amp;&amp; b)
{
  do something;
}
</code></pre>

<p>is there any possibility to evaluate arguments from right to left(b -> a)?</p>

<p>if ""yes"", what influences the evaluation order?</p>

<p>(i'm using VS2008)</p>
","922184","","<p>In this case, since you're using <code>&amp;&amp;</code>, <code>a</code> will always be evaluated first because the result is used to determine whether or not to short-circuit the expression.</p>

<p>If <code>a</code> returns false, then <code>b</code> is not allowed to evaluate at all.</p>
"
"<p>All of these functions gives the expected result on my machine. Do they all work on other platforms?</p>

<p>More specifically, if x has the bit representation 0xffffffff on 1's complement machines or 0x80000000 on signed magnitude machines what does the standard says about the representation of (unsigned)x ?</p>

<p>Also, I think the (unsigned) cast in v2, v2a, v3, v4 is redundant. Is this correct?</p>

<p>Assume sizeof(int) = 4 and CHAR_BIT = 8</p>

<pre><code>int logicalrightshift_v1 (int x, int n) {

    return (unsigned)x &gt;&gt; n;
}

int logicalrightshift_v2 (int x, int n) {

    int msb = 0x4000000 &lt;&lt; 1;
    return ((x &amp; 0x7fffffff) &gt;&gt; n) | (x &amp; msb ? (unsigned)0x80000000 &gt;&gt; n : 0);
}

int logicalrightshift_v2a (int x, int n) {

    return ((x &amp; 0x7fffffff) &gt;&gt; n) | (x &amp; (unsigned)0x80000000 ? (unsigned)0x80000000 &gt;&gt; n : 0);
}

int logicalrightshift_v3 (int x, int n) {

    return ((x &amp; 0x7fffffff) &gt;&gt; n) | (x &lt; 0 ? (unsigned)0x80000000 &gt;&gt; n : 0);
}

int logicalrightshift_v4 (int x, int n) {

    return ((x &amp; 0x7fffffff) &gt;&gt; n) | (((unsigned)x &amp; 0x80000000) &gt;&gt; n);
}

int logicalrightshift_v5 (int x, int n) {

    unsigned y;
    *(int *)&amp;y = x;
    y &gt;&gt;= n;
    *(unsigned *)&amp;x = y;
    return x;
}

int logicalrightshift_v6 (int x, int n) {

    unsigned y;
    memcpy (&amp;y, &amp;x, sizeof (x));
    y &gt;&gt;= n;
    memcpy (&amp;x, &amp;y, sizeof (x));
    return x;
}
</code></pre>
","922184","","<p>If you follow the standard to the word, none of these are guaranteed to be the same on all platforms.</p>

<p><strong>In v5,</strong> you violate strict-aliasing, which is undefined behavior.</p>

<p><strong>In v2 - v4,</strong> you have signed right-shift, which is implementation defined. (see comments for more details)</p>

<p><strong>In v1,</strong> you have signed to unsigned cast, which is implementation defined when the number is out of range.</p>

<p>EDIT:</p>

<p><strong>v6</strong> might actually work given the following assumptions:</p>

<ul>
<li>'int' is either 2's or 1's complement.</li>
<li><code>unsigned</code> and <code>int</code> are exactly the same size (in both bytes and bits, and are densely packed).</li>
<li>The endian of <code>unsigned</code> matches that of <code>int</code>.</li>
<li>The padding and bit-layout is the same: (See caf's comment for more details.)</li>
</ul>
"
"<pre><code>myClassVar = MyClass(3);  
</code></pre>

<p>I expected destructor being called on the previously created <code>myClassVar</code> on the left.<br>
But it is actually being called on the new object that's created by <code>MyClass(3)</code>.</p>

<p>My full test code and output follows..</p>

<h2>edit</h2>

<p>How do I fix the problem?<br>
Implement an assignment operator?<br>
MyClass actually has pointers, and MYSQL_STMT*, I wonder how should I deal with MYSQL_STMT* variable.</p>

<p>I just need MyClassVar(3) object not the MyClassVar() which was first created when ClientClass object was created.  </p>

<p>I came across this situation fairly often, and wonder if there's a good way to do it.</p>

<pre><code>#include &lt;stdio.h&gt;

class MyClass
{
public:
    MyClass() { printf(""MyClass %p\n"", this); }
    MyClass(int a) { printf(""Myclass(int) %p\n"", this); }
    ~MyClass() { printf(""~MyClass %p\n"", this); }

private:
    int mA;
};


class ClientClass
{
public:
    void Foo()
    {
        printf(""before &amp;myClassVar : %p\n"", &amp;myClassVar);
        myClassVar = MyClass(3); // this is the important line
        printf(""after &amp;myClassVar : %p\n"", &amp;myClassVar);
    }

private:
    MyClass myClassVar;
};

int main()
{   
    ClientClass c;
    c.Foo();
    return 0;
}
</code></pre>

<hr>

<pre><code>MyClass 0x7fff5fbfeba0
before &amp;myClassVar : 0x7fff5fbfeba0
Myclass(int) 0x7fff5fbfeb70
~MyClass 0x7fff5fbfeb70 // &lt;--- here destructor is called on the newly created object
after &amp;myClassVar : 0x7fff5fbfeba0
~MyClass 0x7fff5fbfeba0
</code></pre>
","922184","","<p>Here's how the critical line breaks down:</p>

<pre><code>myClassVar = MyClass(3);
</code></pre>

<p>First, <code>MyClass(3)</code> calls constructor and returns the object.</p>

<p>Second, <code>myClassVar =</code> copies the object to <code>myClassVar</code>.</p>

<p>Then the statement ends. The object (which is an immediate) is dead, and thus the destructor is invoked.</p>

<p><strong>EDIT :</strong></p>

<p>As for how to get around this. The only way I can think of is to use a <a href=""http://stackoverflow.com/questions/222557/cs-placement-new"">placement new</a>. I'm not sure if there's a better solution other than making a ""set"" method.</p>
"
"<p>Why can't I do something like this:</p>

<pre><code>int size = menu.size;
int list[size];
</code></pre>

<p>Is there anyway around this instead of using a vector? (arrays are faster, so I wanted to use arrays)</p>

<p>thanks</p>
","922184","","<p>C++ does not allow variable length arrays. The size must be known at compile-time. So you can't do that.</p>

<p>You can either use vectors or <code>new</code>.</p>

<pre><code>vector&lt;int&gt; list;
</code></pre>

<p>or </p>

<pre><code>int *list = new int[size];
</code></pre>

<p>If you go with the latter, you need to free it later on:</p>

<pre><code>delete[] list;
</code></pre>

<blockquote>
  <p>arrays are faster, so I wanted to use arrays</p>
</blockquote>

<p>This is not true. Where did you hear this from?</p>
"
"<p>Should I free up memory returned by the following two functions in the caller function? I see that it is ok with function <code>get_current_time</code> but not ok with the <code>get_filename_ext</code>. I see similar question <a href=""http://stackoverflow.com/questions/911517/freeing-memory-returned-from-c-functions"">here</a>, but not sure that answers my question. In general what should I look for?</p>

<pre><code>char *get_current_time(void){
    struct tm *local;
    time_t t;
    t = time(NULL);
    local = gmtime(&amp;t);
    return asctime(local);
}

char *get_filename_ext(const char *filename) {
        const char *dot = strrchr(filename, '.');
        if(!dot || dot == filename) return """";
        return dot + 1;
    }
</code></pre>
","922184","","<p>Neither of these functions allocate any memory. So there's actually nothing to free.</p>

<p>The <code>char*</code> returned by <code>asctime</code> is an internal buffer. So you can't free it anyway.</p>
"
"<p>These 4 containers, vector, list, map, unordered_map...are important b.c. they represent some of the most commonly used data structures.  Internally they are represented as a dynamic array, double linked list, a searchable tree, and a hash.</p>

<pre><code>   #include ""c_arclib.cpp""
    using namespace std;
    int main()
      {
    /*
    Define - Vector, List, Map, Unordered_map
    */
      vector&lt;int&gt; vector_int;
      list&lt;int&gt; list_int;
      map&lt;int,int&gt; map_int;
      unordered_map&lt;int, int&gt; unordered_map_int; 
    /*
    Define Loop and Time 
    */
      int i,j,loop1=5, loop2=4294967;
      clock_t time_start,time_end,time_diff;
    /*
    Run Timing Test
    */
      for(j=0;j&lt;loop1;j++)
        {
        time_start=clock();
        for(i=0;i&lt;loop2;++i)
          {
          unordered_map_int.insert(pair&lt;int,int&gt;(rand(),rand()));
          /*
          map_int.insert(pair&lt;int,int&gt;(rand(),rand()));
          vector_int.push_back(rand());
          list_int.push_back(rand());
          */
          }
        time_end=clock();
        time_diff=time_end-time_start;
        cout &lt;&lt; time_diff &lt;&lt; endl;
        }
    /*
    Results
    Push / Insert
    map (insert)                    9500
    unorderd_map (insert)           3300
    list (push)                     2600
    vector (push)                   900
    */
</code></pre>
","922184","","<p>I think you're probably looking to just do this?</p>

<pre><code>cout &lt;&lt; (double)(time_end - time_start) / CLOCKS_PER_SEC &lt;&lt; endl;
</code></pre>

<p>Also, there are more accurate timers than <code>clock()</code>.</p>
"
"<p>I am a beginner at C, I have a program where I'm trying to set values of a structure inside a function, but I'm unsure of how to pass the structure to the function and have it modify it's original values.</p>

<p>I have a simple structure that looks like this:</p>

<pre><code>struct player {

    char name[40];
    int acceleration;

};
</code></pre>

<p>And just to play around I do this:</p>

<pre><code>struct player terry;
terry.acceleration = 20;
strcpy(terry.name, ""John Terry"");
</code></pre>

<p>I want to move this functionality to a function so I can do something like this:</p>

<pre><code>createPlayer(terry, 20, ""John Terry"");
</code></pre>

<p>So far my function looks like this:</p>

<pre><code>void createPlayer(struct player currentPlayer, char name[], int acceleration) {

     strcpy(currentPlayer.name, name);

     currentPlayer.acceleration = acceleration;

}
</code></pre>

<p>But when I print this:</p>

<pre><code>printf(""The speed of %s is %d \n\n"", terry.name, terry.acceleration);
</code></pre>

<p>I see this:</p>

<pre><code>The speed of  is 0
</code></pre>

<p>What am I doing wrong here? Please suggest any changes to my code / style that goes against the usual convention.</p>

<p>Thank you so much!</p>
","922184","","<p>You'll need to pass the struct by pointer:</p>

<p>Change the function to this:</p>

<pre><code>void createPlayer(struct player *currentPlayer, char name[], int acceleration) {

     strcpy(currentPlayer-&gt;name, name);

     currentPlayer-&gt;acceleration = acceleration;

}
</code></pre>

<p>And call it like this:</p>

<pre><code>createPlayer(&amp;terry, 20, ""John Terry"");
</code></pre>

<p>EDIT:</p>

<p>In your original code, when you pass the struct into the function. It is done ""by value"". This means that a copy is made into the function. So what changes you make to it inside the function will be on the local copy and will not be applied to the original copy.</p>
"
"<pre><code>class Grade {
public static int f = 2;

public static void main(String[] args) {
    for (int f = 0; f &lt; 2; f++) {
        System.out.println(f);
    }
}
}
</code></pre>

<p>How does it happen, that ""int f"" overrides the static variable f? I thought that static int f is shared by the whole class and why does not the compiler give the error message that this variable is redefined? Why does it not become the duplicate of the static f? I thought that in java the scope blocks inherit the variables of their parent block.</p>
","922184","","<p>This is because the local <code>f</code>, ""shadows"" the outer-scope <code>f</code>. This means that whenever you refer to <code>f</code> after defining it locally, it will refer to the local version.</p>

<p>Wikipedia's page on variable shadowing uses a very similar example in Java:</p>

<p><a href=""http://en.wikipedia.org/wiki/Variable_shadowing"" rel=""nofollow"">http://en.wikipedia.org/wiki/Variable_shadowing</a></p>

<p>EDIT: If you need the “outer” <code>f</code>, you can access it by its more proper name: <code>Grade.f</code>. Similar example without static variables:</p>

<pre><code>public class Grade {
  public int f=0;
  public void setF(int f) {
    this.f = f; // setF(5) will set the “outer” f to 5.
  }
}
</code></pre>
"
"<p>I typed the following code into CodeLite (Linux) and it gave me the error below:</p>

<p>:18:62: error: invalid conversion from ‘void* (<em>)()’ to ‘void</em> (<em>)(void</em>)’ [-fpermissive]</p>

<p>//CODE HERE///</p>

<p><code></p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;
using namespace std;

    void *functionC();
    pthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;
    int  counter = 0;

    main()
    {
       int rc1, rc2;
       pthread_t thread1, thread2;

       /* Create independent threads each of which will execute functionC */

       if( (rc1=pthread_create( &amp;thread1, NULL, &amp;functionC, NULL)) )
       {
          printf(""Thread creation failed: %d\n"", rc1);
       }

       if( (rc2=pthread_create( &amp;thread2, NULL, &amp;functionC, NULL)) )
       {
          printf(""Thread creation failed: %d\n"", rc2);
       }

       /* Wait till threads are complete before main continues. Unless we  */
       /* wait we run the risk of executing an exit which will terminate   */
       /* the process and all threads before the threads have completed.   */

       pthread_join( thread1, NULL);
       pthread_join( thread2, NULL);

       exit(0);
    }

    void *functionC()
    {
       pthread_mutex_lock( &amp;mutex1 );
       counter++;
       printf(""Counter value: %d\n"",counter);
       pthread_mutex_unlock( &amp;mutex1 );
    }
</code></pre>

<p></code></p>

<p>Could anyone please explain to me why i got this error and how to correct it</p>

<p>Thankz for your answers and comments</p>
","922184","","<p>You have a type mismatch. <code>pthread_create</code> expects a function pointer of type <code>void *(*func_name)(void*)</code>. But you gave it a <code>void *functionC()</code>, which is not the same.</p>

<p>Change your function to this:</p>

<pre><code>void* functionC(void*)
{
   pthread_mutex_lock( &amp;mutex1 );
   counter++;
   printf(""Counter value: %d\n"",counter);
   pthread_mutex_unlock( &amp;mutex1 );

   return NULL;
}
</code></pre>

<p>And you will also need to change your prototype as well:</p>

<pre><code>void* functionC(void*);
</code></pre>
"
"<p>so i got that first problem working. i run the code and i am prompt to enter some list into the array. after entering the list i run this function as a search_func. but it keeps return no record found. is it because of [0], odd because i have it within a for loop.</p>

<p>Please help. <code>book books[]</code> is a class object..</p>

<pre><code>int search(book books[], char search) {
    const char* boook =books[0].gettitle();
  //......try this but it failed please help
  cout &lt;&lt; ""Search books by title:____  "";

  cin &gt;&gt; search;

  bool yes = false;
  int size=2;

  for(int index=0; index&lt;size; index++) {
    if(strcmp(boook,search) == 0 )//....error at this line
         { 
        found = true;
        cout&lt;&lt;""book found ""&lt;&lt;endl;
        //cout&lt;&lt;""Author Name: ""&lt;&lt;fn&lt;&lt;"" ""&lt;&lt;ln&lt;&lt;endl;
        break;
      }
  }

  if(!yes)
    cout&lt;&lt;""no book found""&lt;&lt;endl;
}
</code></pre>
","922184","","<p>Try this:</p>

<pre><code>const char* c_str = books[0].gettitle().c_str();
</code></pre>

<p><a href=""http://www.cplusplus.com/reference/string/string/c_str/"" rel=""nofollow"">http://www.cplusplus.com/reference/string/string/c_str/</a></p>

<p>EDIT:</p>

<p>If <code>gettitle()</code> returns a temporary, then the above method won't work. You will need to do this instead:</p>

<pre><code>string title = books[0].gettitle();
const char* c_str = title.c_str();
</code></pre>
"
"<p>sometimes we use this type of code in our c programming.  </p>

<pre><code>char *p = ""Sam"";
</code></pre>

<p>Here the address of constant character string ""Sam""  is going to be stored in char pointer p. now here<br>
i want to ask where the Sam is going to be stored ?</p>
","922184","","<p>The string ""Sam"" will usually be stored in global memory in the same region as the global constants.</p>

<p>However, if you did this:</p>

<pre><code>char p[] = ""Sam"";
</code></pre>

<p>Then it would be on the stack instead. (as an array initializer)</p>
"
"<p>The original question is the problem of my confusion, sorry.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

void func(int **p_in1, int **p_in2, int **p_in3){
  int *p_temp1 = (int *)malloc(5*sizeof(int));
  int *p_temp2 = (int *)malloc(5*sizeof(int));
  int *p_temp3 = (int *)malloc(5*sizeof(int));
  int i;
  for(i = 0; i &lt; 5; i++){
       p_temp1[i] = i+1;
       p_temp2[i] = i+2;
       p_temp3[i] = i+3;
  }
  *p_in1 = p_temp1;
  *p_in2 = p_temp2;
  *p_in3 = p_temp3;
}

int main(){
    int *p_out1 = NULL, *p_out2 = NULL, *p_out3 =NULL;
    int i;
    func(&amp;p_out1, &amp;p_out2, &amp;p_out3);

    for(i = 0; i &lt; 5; i++){
        printf(""%d"", p_out1[i]);
        printf("" "");
        printf(""%d"", p_out2[i]);
        printf("" "");
        printf(""%d\n"", p_out3[i]);
    }

   free(p_out1);
   free(p_out2);
   free(p_out3);
   p_out1 = NULL;
   p_out2 = NULL;
   p_out3 = NULL;
   return 0;
}
</code></pre>

<p>I want to make the ""func"" much shorter by just use one para. How can I put the ""p_in1, p_in2, p_in3"" together in continuous memory space?</p>
","922184","","<p>Now that you've edited in the output that you wanted, the question can be answered.</p>

<p>Change your print loop to this:</p>

<pre><code>for(i = 0; i &lt; 5; i++){
    printf(""%d"", p_out1[i]);
}
printf("" "");
for(i = 0; i &lt; 5; i++){
    printf(""%d"", p_out2[i]);
}
printf("" "");
for(i = 0; i &lt; 5; i++){
    printf(""%d"", p_out3[i]);
}
</code></pre>

<p>This will output:</p>

<pre><code>12345 23456 34567
</code></pre>

<p>In your original code, you were interleaving the 3 arrays. What you wanted was to print each one separately.</p>

<p>EDIT: As for your second question, you can combine <code>p_out1</code>, <code>p_out2</code>, and <code>p_out1</code> into an array.</p>

<p>Here's your code with this done:</p>

<pre><code>void func(int **p_in){
  int *p_temp1 = (int *)malloc(5*sizeof(int));
  int *p_temp2 = (int *)malloc(5*sizeof(int));
  int *p_temp3 = (int *)malloc(5*sizeof(int));
  int i;
  for(i = 0; i &lt; 5; i++){
       p_temp1[i] = i+1;
       p_temp2[i] = i+2;
       p_temp3[i] = i+3;
  }
  p_in[0] = p_temp1;
  p_in[1] = p_temp2;
  p_in[2] = p_temp3;
}

int main(){
    int *p_out[3];
    func(p_out);

    int i;
    for(i = 0; i &lt; 5; i++){
        printf(""%d"", p_out[0][i]);
    }
    printf("" "");
    for(i = 0; i &lt; 5; i++){
        printf(""%d"", p_out[1][i]);
    }
    printf("" "");
    for(i = 0; i &lt; 5; i++){
        printf(""%d"", p_out[2][i]);
    }

   free(p_out[0]);
   free(p_out[1]);
   free(p_out[2]);

   return 0;
}
</code></pre>
"
"<p>I m trying to assign a value to string pointer.It's compiling and running but not printing the  correct answer?    </p>

<pre><code>char *x = ""girl""; 
*x = x[3];
printf(""%s\n"",x);  
</code></pre>

<p>Why it's not printing ""lirl"" ?</p>
","922184","","<p>You cannot modify a string literal like that. It is undefined behavior.</p>

<p>You should do this instead:</p>

<pre><code>char x[] = ""girl""; 
x[0] = x[3];
printf(""%s\n"",x);  
</code></pre>

<p>This works because <code>""girl""</code> is now an array initializer for <code>x[]</code>. Which is just a short form for:</p>

<pre><code>char x[] = {'g', 'i', 'r', 'l', '\0'}; 
</code></pre>

<p>So this is allowed.</p>
"
"<p>I need to improve this statement by either correcting it or making it shorter</p>

<pre><code>if (0 &lt;= age &lt;= 100) // age is between 0 and 100)
</code></pre>

<p>I am totally confused about spending 20 minutes on the question. It seems really simple but the only revision I could think of is</p>

<pre><code>if (0 &lt;= age &amp;&amp; age &lt;= 100)
</code></pre>

<p>and that doesn't seem right. Am I just missing something obvious? Can someone help me please?</p>

<p>Thanks</p>
","922184","","<p>Your revision is correct. <code>if (0 &lt;= age &amp;&amp; age &lt;= 100)</code> is the correct way to do it. There really isn't a simpler way.</p>
"
"<p>I'm trying to make a struct that generates a random matrix and am getting ""error: expected â=â, â,â, â;â, âasmâ or â_<em>attribute</em>_â before âmatrixâ"" when compiling.  How can I get this to work effectively and efficiently?</p>

<p>I guess expected errors usually are caused by typos but I don't see any.</p>

<p>I'm very new to C so pointers and malloc are quite foreign to me.  I really appreciate your help.</p>

<pre><code>/* It's called RandomMatrixMaker.c */

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

typdef struct {
  char* name;
  int MID;
  int MRows;
  int MCols;
  long[][]* MSpace;
} matrix;

matrix makeRIDMatrix(char* name, int MID, int MRows, int MCols) {
  matrix m;
  static int i, j, r;
  m.name = name;
  m.MID = MID;
  m.MRows = MRows;
  m.MCols = MCols;
  for (i=0; i&lt;m.MRows; i++) {
    for (j=0; i&lt;m.MCols; j++) {
      r = random(101);
      *(m.MSpace[i][j]) = r; 
    }
  }
  return m;
}

int main(void) {
  makeRIDMatrix(""test"", 1, 10, 10);
  return 0;
}
</code></pre>
","922184","","<p>There is indeed a typo. You misspelled <code>typedef</code>:</p>

<pre><code>typdef struct {
</code></pre>

<p>should be:</p>

<pre><code>typedef struct {
</code></pre>

<p>EDIT:</p>

<p>Also, there's no reason to use <code>static</code> here:</p>

<pre><code>static int i, j, r;
</code></pre>

<p>You can just get rid of the <code>static</code> modifier.</p>

<pre><code>int i, j, r;
</code></pre>
"
"<p>I have a C++ program:</p>

<pre><code>struct arguments
{
  int a, b, c;  
  arguments(): a(3), b(6), c(9) {}
};

class test_class{
  public:

    void *member_func(void *args){
      arguments vars = (arguments *) (*args); //error: void is not a 
                                              //pointer-to-object type

      std::cout &lt;&lt; ""\n"" &lt;&lt; vars.a &lt;&lt; ""\t"" &lt;&lt; vars.b &lt;&lt; ""\t"" &lt;&lt; vars.c &lt;&lt; ""\n"";
    }
};
</code></pre>

<p>On compile it throws an error:</p>

<pre><code>error: ‘void*’ is not a pointer-to-object type
</code></pre>

<p>Can someone explain what I am doing wrong to produce this error?</p>
","922184","","<p>You have the <code>*</code> in the wrong place. So you're trying dereference the <code>void*</code>.
Try this instead:</p>

<pre><code>arguments vars = *(arguments *) (args);
std::cout &lt;&lt; ""\n"" &lt;&lt; vars.a &lt;&lt; ""\t"" &lt;&lt; vars.b &lt;&lt; ""\t"" &lt;&lt; vars.c &lt;&lt; ""\n"";
</code></pre>

<p>Alternatively, you can do this: (which also avoids the copy-constructor - as mentioned in the comments)</p>

<pre><code>arguments *vars = (arguments *) (args);
std::cout &lt;&lt; ""\n"" &lt;&lt; vars-&gt;a &lt;&lt; ""\t"" &lt;&lt; vars-&gt;b &lt;&lt; ""\t"" &lt;&lt; vars-&gt;c &lt;&lt; ""\n"";
</code></pre>
"
"<p>i had met same situation in my project. <br />
The following code were similarly reproduced. <br /></p>

<pre><code>#include &lt;iostream&gt;
#include &lt;vector&gt;
using namespace std;


class METHOD
{
public:
vector&lt;METHOD*&gt; m_arg;
string name;
string getName()
{
    return name;
}
METHOD()
{

}
METHOD(string n)
{
    name = n;
}
};

class PF : public METHOD
{
public:
PF(){};
};

void main()
{


PF p;
p.m_arg.push_back(new METHOD(string(""a"")));
p.m_arg.push_back(new METHOD(string(""b"")));
p.m_arg.push_back(new METHOD(string(""c"")));

for(int i = 0 ; i &lt; (int)p.m_arg.size() ; ++i)
{
    const char* ccs = p.m_arg[i]-&gt;getName().c_str();  //PROBLEM POINT

    size_t ss = strlen(ccs);
}

}
</code></pre>

<p>the problem is //PROBLEM POINT<br />
the return address of <strong>c_str()</strong> can't be assigned to <strong>const char* ccs</strong>. <br />
in debugger, the <strong>css</strong> assigned memory address of return of <strong>c_str()</strong>, but <strong>css</strong>'s value is """" and it work same as """"<br /></p>

<p>but the next code is working as expected.<br /></p>

<pre><code>    string str(""ok"");
const char* ckk = str.c_str();
</code></pre>

<p>after this code, <strong>ckk</strong> points after <strong>str.c_str()</strong> returnning addres, and <strong>ckk</strong>'s value in debugger is ""ok""<br /></p>

<p>the same problem is occuring in std::wstring, wchar_t, unicode.<br /></p>

<p>why did this problem occur?<br />
who knows? help me plz~</p>

<p>ADD:
thanks to mystical i solve the problem same way. but this solution also work OK. <br /></p>

<pre><code>    for(int i = 0 ; i &lt; (int)p.m_arg.size() ; ++i)
{
    string&amp; strr = p.m_arg[i]-&gt;getName();
    const char* ccs = strr.c_str();
    size_t ss = strlen(ccs);
}
</code></pre>

<p>so i think the return value of <strong>getName()</strong> is live until the loop } closed. <br />
but interestingly, the next is don't work</p>

<pre><code>    for(int i = 0 ; i &lt; (int)p.m_arg.size() ; ++i)
{
    string* strr = &amp;p.m_arg[i]-&gt;getName();
    const char* ccs = strr-&gt;c_str();
    size_t ss = strlen(ccs);
}
</code></pre>

<p>the css is 'dangling' and also strr is """" <br />
i've dazed and confused!</p>
","922184","","<p>In your <code>getName()</code> function:</p>

<pre><code>string getName()
{
    return name;
}
</code></pre>

<p>The string that is returned is a copy of the original. It becomes an intermediate in the following expression:</p>

<pre><code>const char* ccs = p.m_arg[i]-&gt;getName().c_str();
</code></pre>

<p>When the expression ends, that intermediate is destroyed. Therefore invalidating the pointer returned by <code>c_str()</code>. <strong>The result is that <code>ccs</code> becomes a dangling pointer.</strong></p>

<p>The reason why this works:</p>

<pre><code>string str(""ok"");
const char* ckk = str.c_str();
</code></pre>

<p>is because <code>str</code> is not an intermediate.</p>

<p><strong>To make it work, change your loop to this:</strong></p>

<pre><code>for(int i = 0 ; i &lt; (int)p.m_arg.size() ; ++i)
{
    string str = p.m_arg[i]-&gt;getName()
    const char* ccs = str.c_str();

    size_t ss = strlen(ccs);
}
</code></pre>

<p><strong>EDIT : To answer your new question:</strong></p>

<p>The reason why this doesn't work:</p>

<pre><code>string* strr = &amp;p.m_arg[i]-&gt;getName();
</code></pre>

<p>is the same as before. <code>getName()</code> returns an intermediate. You then take the address of this and assign it to <code>strr</code>. The intermediate is destroyed after the statement, so <code>strr</code> becomes a dangling pointer as in the first case.</p>
"
"<pre><code>#include&lt;stdio.h&gt;
#include&lt;string.h&gt;

int main() 
{
    char s[100] =""4.0800"" ; 

    printf(""float value : %4.8f\n"" ,(float) atoll(s)); 
    return 0; 
}
</code></pre>

<p>I expect the output should be : 4.08000000
where as I got only  4.00000000</p>

<p>Is there any way to get the numbers after the dot </p>
","922184","","<p>Use <code>atof()</code> or <code>strtof()</code>* instead:</p>

<pre><code>printf(""float value : %4.8f\n"" ,atof(s)); 
printf(""float value : %4.8f\n"" ,strtof(s, NULL)); 
</code></pre>

<p><a href=""http://www.cplusplus.com/reference/clibrary/cstdlib/atof/"">http://www.cplusplus.com/reference/clibrary/cstdlib/atof/</a><br>
<a href=""http://www.cplusplus.com/reference/cstdlib/strtof/"">http://www.cplusplus.com/reference/cstdlib/strtof/</a></p>

<ul>
<li><code>atoll()</code> is meant for integers.</li>
<li><code>atof()</code>/<code>strtof()</code> is for floats.</li>
</ul>

<p>The reason why you only get <code>4.00</code> with <code>atoll()</code> is because it stops parsing when it finds the first non-digit.</p>

<p>*Note that <code>strtof()</code> requires C99 or C++11.</p>
"
"<pre><code>void *stackAddr[NUM_THREADS];

stackAddr[i] = malloc(STACKSIZE);
</code></pre>

<p>The compiler (g++ 4.4.3) complains where the malloc is called...</p>

<pre><code>warning: pointer of type ‘void *’ used in arithmetic
error: ‘void*’ is not a pointer-to-object type
</code></pre>

<p>If you are interested in seeing the whole code, here it goes...</p>

<pre><code>#include &lt;pthread.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
#define NUM_THREADS 4

void *stackAddr[NUM_THREADS];
pthread_t thread[NUM_THREADS];
pthread_attr_t attr;

void *BusyWork(void *t)
{
   int i;
   long tid;
   double result=0.0;
   tid = (long)t;

   printf(""Thread %ld starting...\n"",tid);
   for ( i = 0; i &lt; 1000; i++)
   {
      result = result + sin(i*tid) * tan(i*tid);
   }
   printf(""Thread %ld done. Result = %e\n"", tid, result);
   pthread_exit((void*) t);
}

void pthread_create_with_stack( pthread_t * pthread, void *(*start_routine) (void *), int tid )
{
    const size_t STACKSIZE = 0xC00000; //12582912
    void *stackAddr;
    int rc;
    size_t i;
    pthread_t thread;
    pid_t pid;

    stackAddr[tid] = malloc(STACKSIZE); // Error here!
    pthread_attr_setstack(&amp;attr, stackAddr[tid], STACKSIZE);

    rc = pthread_create( pthread, &amp;attr, start_routine, (void*)tid );
}

int main (int argc, char *argv[])
{
   int rc;
   long t;
   void *status;

   /* Initialize and set thread detached attribute */
   pthread_attr_init(&amp;attr);
   pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);

   for(t=0; t&lt;NUM_THREADS; t++) 
   {
      printf(""Main: creating thread %ld\n"", t);
      rc = pthread_create_with_stack(&amp;thread[t], BusyWork, t); 
      if (rc) 
      {
         printf(""ERROR; return code from pthread_create() is %d\n"", rc);
         exit(-1);
      }
   }

   /* Free attribute and wait for the other threads */
   pthread_attr_destroy(&amp;attr);
   for(t=0; t&lt;NUM_THREADS; t++) 
   {
      rc = pthread_join(thread[t], &amp;status);
      if (rc) 
      {
         printf(""ERROR; return code from pthread_join() is %d\n"", rc);
         exit(-1);
      }
      printf(""Main: completed join with thread %ld having a status""   
            ""of %ld\n"",t,(long)status);
    }

    printf(""Main: program completed. Exiting.\n"");
    pthread_exit(NULL);
}
</code></pre>
","922184","","<p>You messed up your declaration:</p>

<pre><code>void *stackAddr;
</code></pre>

<p>should be:</p>

<pre><code>void *stackAddr[];
</code></pre>

<p>(You may also need to set a size for the array.)</p>

<p>Then you try to do this:</p>

<pre><code>stackAddr[tid] = malloc(STACKSIZE);
</code></pre>

<p>So you're accessing an array element of a <code>void*</code>.</p>
"
"<p>I have two kind of jobs to do, <code>foobar1</code> to be done 3 times in parallel and <code>foobar2</code> to be done 5 times in parallel.
My Idea is to make the master thread create those two teams of work. but I face one difficulty.</p>

<p>Is It possible to make a thread escape from a parallel loop ? I mean to realize such a code where the master task can
escape the first team of work to create the second team</p>

<pre><code>#pragma omp parallel num_threads(8)
{
    // first team of task which will execute the foobar1 function in parallel

    #pragma omp for schedule(static,1) nowait 
    for(i = 0; i &lt; 3; i++)
    {
        #pragma omp master
        {
            //escape here to create a second team in parallel
        }

        foobar1();
    }

    // second team of task which will execute the foobar2
    #pragma omp for schedule(static,1) nowait
    for(j = 0; j &lt; 5; j++)
    {
        foobar2();
    }
}
</code></pre>
","922184","","<p>Here's one (clean) approach that completely bypasses your problem:</p>

<pre><code>#pragma omp parallel for num_threads(8)
for(i = 0; i &lt; 8; i++)
{
    if (i &lt; 3){
        foobar1();
    }else{
        foobar2();
    }
}
</code></pre>

<p>If this isn't suitable, then the other solution I have in mind is to use nested parallelism. But that's messy.</p>
"
"<p>This is an extended question from</p>

<p><a href=""http://stackoverflow.com/questions/7963150/how-can-i-remove-this-segmentation-fault-in-c-program"">How can i remove this Segmentation fault in C Program</a></p>

<p>here segmentation fault occur because of stack overflow due to recursion so manny times </p>

<p>so i have changed his code like this..</p>

<p><strong>make a MACRO insted of that function so function call is removed</strong> </p>

<pre><code>#include &lt;stdio.h&gt;

static inline void p(char *a, int b); 


#define MAGIC(a,b)  p(a,b) 

void p(char *a, int b) 
{
    static long int i = 0;

    if (i != 350000) 
    {
        printf(""\n%ld \t at Hi hello"", i);
        i++;
        return MAGIC(a, b);
    } else 
    {
        return;
    }
}


int main() 
{
    char *a = ""HI"";
    int b = 10;
    MAGIC(a, b);
    printf(""\nComplete"");
    return 0;

}
</code></pre>

<p>still i am getting segmentation fault ...still stack overflow.... why?</p>
","922184","","<p>No, it will not work. A macro is just a text copy-paste, so the result is still the same.</p>

<p>So your code will be expanded as:</p>

<pre><code>void p(char *a, int b) 
{
    static long int i = 0;

    if (i != 350000) 
    {
        printf(""\n%ld \t at Hi hello"", i);
        i++;
        return p(a, b);
    } else 
    {
        return;
    }
}


int main() 
{
    char *a = ""HI"";
    int b = 10;
    p(a, b);
    printf(""\nComplete"");
    return 0;

}
</code></pre>

<p>which still has the recursion and will likely stackoverflow.</p>

<p><strong>EDIT : One way to redesign the algorithm is as follows:</strong></p>

<pre><code>void p(char *a, int b) 
{
    long int i = 0;

    while (i != 350000)
    {
        printf(""\n%ld \t at Hi hello"", i);
        i++;
    }
}
</code></pre>
"
"<p>I want to fill in a dynamically created array once only at the top of my function. Then every function after can only access the contents but not modify it. What is the correct way:</p>

<pre><code>const double *pt = malloc(sizeof(double)*num);
</code></pre>

<p>OR</p>

<pre><code>double *pt = malloc(sizeof(double)*num);
void f(const double array[], ...);
</code></pre>

<p>When I use the second method, do I have to cast <em>pt</em> to const?</p>
","922184","","<p>The first method will not work because you won't be able to populate the array in the first place (since you have declared it <code>const</code>).</p>

<p>The second method will work if you have already populated the array <em>before</em> calling <code>f()</code>.</p>
"
"<p>I'm trying to learn mor eabout C++ and ran into some code in a chess program that I need help understanding. I have a union such as:</p>

<pre><code>union b_union {

    Bitboard b;
    struct {
    #if defined (BIGENDIAN)
        uint32_t h;
        uint32_t l;
    #else
        uint32_t l;
        uint32_t h;
    #endif
    } dw;
};
</code></pre>

<p>The above code falls into the else condition.</p>

<p>Bitboard is defined as uint64_t. If I have a value let's say 0x0025f780, which is 282578800148862, and I set union.b = 0x0025f780, then union.dw.l is updated to 16843134 and union.dw.h is updated to 65793. Intitially l and h start off with 3435973836. Internally, what happened? I'm fairly new to C++. Just trying to wrap my head around unions in how they work internally.</p>

<p>Thanks much for any insights. </p>

<p>David</p>
","922184","","<p>The union means that the components will occupy the same memory location. In the code sample that you have shown, the intent is to allow you to reference the upper and lower 32-bits of the <code>b</code> directly.</p>

<p><em>Note that this code invokes undefined (or implementation defined) behavior.</em> This is because you are accessing a union element from a different element with which the data is written to.</p>

<p>So <code>b</code> which is a 64-bit integer, will share the same memory location as <code>l</code> and <code>h</code> which refer to the lower and upper 32-bits. Of course, the validity of this depends on the endian of the machine - which is why there is the preprocessor if-else.</p>

<p>EDIT: Your particular example is also not correct. But here's a fixed version:</p>

<p>When you set <code>b = 282578800148862</code>, <code>(b = 0x101010101017e)</code>. The upper and lower 32-bits are:</p>

<pre><code>00010101 0101017e
</code></pre>

<p>so</p>

<pre><code>l = 0x0101017e = 16843134
h = 0x00010101 = 65793
</code></pre>
"
"<p>My knowledge of programming is pretty basic, so I apologize if this question is poorly worded.</p>

<p>What I'm trying to figure out is if something such as this (written in C):</p>

<pre><code>#define FOO 15
#define BAR 23
#define MEH (FOO / BAR)
</code></pre>

<p>is allowed.  I would want the preprocessor to replace every instance of</p>

<pre><code>MEH
</code></pre>

<p>with</p>

<pre><code>(15 / 23)
</code></pre>

<p>but I'm not so sure that will work.  Certainly if the preprocessor only goes through the code once then I don't think it'd work out the way I'd like.</p>

<p>I found several similar examples but all were really too complicated for me to understand.  If someone could help me out with this simple one I'd be eternally grateful!</p>

<p>Best,
llakais</p>
","922184","","<p>Short answer yes. You can nest defines and macros like that - as many levels as you want as long as it isn't recursive.</p>
"
"<p>If I want to make a if statement that requires more than one thing to be true do I need to do it with ""else if""? Because I think it looks ugly so I would prefer if I could solve that in one statement. </p>

<p>Here is the code: </p>

<pre><code>if(x == 2 OR 4 OR 6 OR 8 OR 10)
{
    something......
}

  etc. etc. 
return 0; 
</code></pre>

<p>Will that work?  </p>
","922184","","<p>There isn't much of a better option than this:</p>

<pre><code>if (x == 2 || x == 4 || x == 6 || x == 8 || x == 10)
</code></pre>

<p>If you wanted to optimize at the cost of readability:</p>

<pre><code>if (x &gt; 0 &amp;&amp; x &lt;= 10 &amp;&amp; (x % 2 == 0))
</code></pre>

<p>The <code>%</code> will be optimized into a bit-wise AND by the compiler.</p>
"
"<p>This line of code gives the following warning:</p>

<pre><code>    short[] sh = null;

    for (int i = 0, n = b.length; i &lt; n; i++) {
        sh[i] = 0;

    }  
</code></pre>

<p>warning: The variable sh can only be null at this location.</p>

<pre><code>short[] sh;

for (int i = 0, n = b.length; i &lt; n; i++) {
    sh[i] = 0;

} 
</code></pre>

<p>And, this code gives the following warning:</p>

<p>warning: The local variable sh may not have been initialized.</p>
","922184","","<p>This is because you need to initialize the array. Try this:</p>

<pre><code>short[] sh = new short[b.length];
</code></pre>

<p>If you don't initialize, you will get those warnings, and will get <code>NullPointerException</code> if you run it.</p>
"
"<p>I need to interleave 2 array of floats , floats, strings and put them in a list.</p>

<pre><code>float[] array1;
float[] array2;
float value1;
float value2;
string name1;
string name2;
</code></pre>

<p>at the output something like:</p>

<pre><code>{array1[i], array2[i], ""name1"", value1, value2, ""name2"",  value1, value....}
</code></pre>

<p>is this possible in java?</p>

<p>ok I'm trying this but it wont work:</p>

<pre><code>static Object[] dumoToCurve(final float[] x, final float[] y)   {
    final Object[] output = new Object[x.length * 2];
    float value= 1;

    for (int i=0; i &lt; x.length; i++){

        output[i &lt;&lt; 1] = x[i];
        output[(i &lt;&lt; 1) + 1] = y[i];
        output[(i &lt;&lt; 1) + 2] = ""b0"";
        output[(i &lt;&lt; 1) + 3] = x[i]+value;
        output[(i &lt;&lt; 1) + 4] = y[i]+value;
        output[(i &lt;&lt; 1) + 5] = ""b1"";
    }

    return output;
}
</code></pre>

<p>do I need to cast? how?</p>
","922184","","<p>Here's an answer to your edit. I don't have a Java compiler in front of me to test it. So I'm not completely sure if it will work. Also, I think some of this can be simplified via auto-(un)boxing.</p>

<pre><code>for (int i=0; i &lt; x.length; i++){

    output[ i &lt;&lt; 1     ] = new Float(x[i]);
    output[(i &lt;&lt; 1) + 1] = new Float(y[i]);
    output[(i &lt;&lt; 1) + 2] = ""b0"";
    output[(i &lt;&lt; 1) + 3] = new Float(x[i] + value);
    output[(i &lt;&lt; 1) + 4] = new Float(y[i] + value);
    output[(i &lt;&lt; 1) + 5] = ""b1"";
}
</code></pre>

<p>To pull out a <code>float</code> value from the array:</p>

<pre><code>float val = ((Float)output[0]).floatValue();
</code></pre>

<p>If the cast fails, it'll give you an exception.</p>

<p>In the end, you might want to consider a different design pattern.</p>
"
"<p>I am trying to create a class for a game I am making for my highschool c++ class. All of my set functions are not working. I will post an example tailored just to show one(I get the same error for all of them). Here is the prob:</p>

<pre><code>#include &lt;iostream&gt;

using namespace std;

class room {

public:

    void set_desk(char *);
    char get_desk();

private:

char desk[16];

}

int main {

room room1;
room1.set_desk(""a desk"");

cout &lt;&lt; room1.get_desk();
return(0);
}
void room::set_desk(char *a){
     room::desk = *a;
}
char room::get_desk(){
     return(room::desk);
}
</code></pre>

<p>So when I try to compile this, I get this error: ""In member function void room::set_desk(char *)': error: incompatible types in assignment of char to char[16]"" and also this error: ""In member function char room::get_desk(): error: invalid conversion from char* to char"".</p>

<p>I need the char to have an array of 16, but the errors are gone if I remove the [16] from <code>char desk[16];</code> </p>
","922184","","<p>You can't assign pointers to arrays like that. Here's one way to get it to work.</p>

<pre><code>void room::set_desk(char *a){

    if (strlen(a) &gt;= sizeof(desk)){
        //  Internal buffer is not large enough. Handle error.
    }

    strcpy(desk,a);
}
char* room::get_desk(){
     return desk;
}
</code></pre>

<p><em>However, you're probably better off using <strong>strings</strong> or <strong>vectors</strong> in C++ instead of char arrays and pointers.</em></p>

<p>*You're also missing a semicolon after the class definition.</p>

<p>Here's a more C++-like approach:</p>

<pre><code>class room {

public:

    void set_desk(string);
    string get_desk();

private:

    string desk;

};

void room::set_desk(const string &amp;a){
     desk = a;
}
string room::get_desk(){
     return desk;
}

int main {

    room room1;
    room1.set_desk(""a desk"");

    cout &lt;&lt; room1.get_desk();

    return 0;
}
</code></pre>
"
"<p>I have a function using inline assembly:  </p>

<pre><code>  vec8w x86_sse_ldvwu(const vec8w* m) { 
     vec8w rd; 
     asm(""movdqu %[m],%[rd]"" : [rd] ""=x"" (rd) : [m] ""xm"" (*m)); 
     return rd; 
  } 
</code></pre>

<p>It gets compiled to the following assembly code: </p>

<pre><code>  sub    $0x1c,%esp
  mov    0x24(%esp),%eax
  movdqa (%eax),%xmm0 
  movdqu %xmm0,%xmm0
  movdqa %xmm0,(%esp)
  movdqa (%esp),%xmm0
  add    $0x1c,%esp
  ret 
</code></pre>

<p>The code isn't terribly efficient, but that isn't my concern. As you can see the inline assembler inserts a movdqa instruction copying from the address in %eax to xmm0. The problem is that the pointer vec8w* m is <strong>not</strong> 128 bytes aligned, so I get a seg fault when movdqa is being executed. 
My question is whether there is a way to instruct the inline assembler to use movdqu instead of movdqa (that it uses by default)? I tried to look for a workaround using SSE intrinsic functions for g++, but somehow I cannot find movdqu in xmmintrin.h file (where it should be declared, I suppose). 
Unfortunately, I cannot modify the code so that the function is always called for an <strong>aligned</strong> argument m.   </p>
","922184","","<p>The intrinsic that you are looking for is <code>_mm_loadu_si128</code>. It is defined in <code>emmintrin.h</code>. Which is SSE2. The <code>xmmintrin.h</code> header contains only SSE(1) instructions.</p>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_load.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_load.htm</a></p>

<p><code>_mm_loadu_si128</code> will emit the <code>movdqu</code> instruction which you are looking for. It seems that's exactly what you are trying to accomplish with your inline assembly function. (a misaligned load)</p>
"
"<p>I have a very simple program that I am trying to improve performance. One way that I know will help is to utilize SSE3 (since the machine that I am working supports this), but I have absolutely no idea how to to do this. Here is a code snippet (c++):</p>

<pre><code>int sum1, sum2, sum3, sum4;
for (int i=0; i&lt;length; i+=4) {
  for (int j=0; j&lt;length; j+=4) {
    sum1 = sum1 + input-&gt;value[i][j];
    sum2 = sum2 + input-&gt;value[i+1][j+1];
    sum3 = sum3 + input-&gt;value[i+2][j+3];
    sum4 = sum4 + input-&gt;value[i+3][j+4];    
  {
}
</code></pre>

<p>I've read a little about this, and understand the idea, but I have absolutely no idea how to implement this. Can somebody help me please? I think that this is fairly simple, particularly for my simple program, but sometimes getting started is the hardest part.</p>

<p>Thanks!</p>
","922184","","<p>Actually, in your case, it is not that simple. As it stands right now, your code is <strong><em>NOT</em></strong> vectorizable. (at least not without significant loop transformations)</p>

<p>The reason for this is that you are changing the index <code>i</code> as well inside the inner loop. The breaks any chance of being able to vectorize the <code>j</code> iteration because the memory locations are no longer adjacent and are in different rows of the matrix. (as you seem to be running down the matrix diagonally)</p>

<p>However, I get the feeling that you are trying to sum up all the elements in your matrix, and you actually intended your loop to be like this (and you had a number of typos too):</p>

<pre><code>int sum1 = 0, sum2 = 0, sum3 = 0, sum4 = 0;
for (int i=0; i&lt;length; i++) {
  for (int j=0; j&lt;length; j+=4) {
    sum1 = sum1 + input-&gt;value[i][j];
    sum2 = sum2 + input-&gt;value[i][j+1];
    sum3 = sum3 + input-&gt;value[i][j+2];
    sum4 = sum4 + input-&gt;value[i][j+3];    
  }
}

int total = sum1 + sum2 + sum3 + sum4;
</code></pre>

<p>If this is what you wanted, then it is very vectorizable.
In C/C++ using intrinsics, this can be done as follows using just SSE2:</p>

<pre><code>__m128i sum = _mm_setzero_si128();
for (int i=0; i&lt;length; i++) {
  for (int j=0; j&lt;length; j+=4) {
    __m128i val = _mm_load_si128(&amp;input-&gt;value[i][j]);
    sum = _mm_add_epi32(sum,val);
  }
}
</code></pre>

<p>Note that alignment restrictions will apply. And a lot more speedup can be gained by further unrolling the loop.</p>
"
"<p>I have a function which is quite time consuming and it goes like this since the value of n is very large</p>

<pre><code>sum=0; for(i=0;i&lt;n;i++)
{
     a=func(i,b);
     c=func(i,a);
     sum+=c;  
}
</code></pre>

<p>Is it possible to parallelize this loop using openMp?</p>
","922184","","<p>Here's the short way:</p>

<pre><code>int sum = 0;

#pragma omp parallel for reduction(+:sum)
    for(i = 0; i &lt; n; i++){
        int a = func(i,b);
        int c = func(i,a);
        sum += c;
    }
</code></pre>

<p>Here's a longer (but more flexible) way:</p>

<pre><code>int sum = 0;

#pragma omp parallel
    {
        int local_sum = 0;

#pragma omp for
        for(i = 0; i &lt; n; i++){
            a = func(i,b);
            c = func(i,a);
            local_sum += c;
        }

#pragma omp critical
        {
            sum += local_sum;
        }
    }
</code></pre>
"
"<p>I came across a piece of assembly code like following one</p>

<pre><code>int fourth(char *str) {
return str[3];
{
0804834f &lt;fourth&gt;:
804834f: 55 push %ebp
8048350: 89 e5 mov %esp,%ebp
8048352: 8b 45 08 mov 0x8(%ebp),%eax
8048355: 83 c0 03 add $0x3,%eax
8048358: 0f be 00 movsbl (%eax),%eax
804835c: c9 leave
804835d: c3 ret
</code></pre>

<p>how come does it reach M[(%eax)+3] ?</p>

<p>thanks in advance</p>
","922184","","<p>Yes of course. If you're only addressing a <code>byte</code>, then you have to be able to reach any address. (which is the case in the code snippet: <code>movsbl</code> is a byte access)</p>

<p>Furthermore, x86 allows misaligned memory access even for multi-byte words. (though usually at a performance cost) So even then, the address does not have to be a multiple of 4.</p>

<p>*The exception is with the SSE/AVX registers. Where you need to use explicit misaligned <code>mov</code> instructions for misaligned memory access.</p>
"
"<p>This is my first question posting so sorry if I make make any faux pas'</p>

<p>Using C</p>

<p>In my program I create a global variable pointer</p>

<pre><code>double *correlationData;
</code></pre>

<p>In main I create this local variable:</p>

<pre><code>int arrayLength = 0;
</code></pre>

<p>in main I have an if statement inside a for loop which contains</p>

<pre><code>arrayLength++;
</code></pre>

<p>after the for loop I initiate an array and assign it to the pointer</p>

<pre><code>double correlationArray[arrayLength];
correlationData = correlationArray; 
</code></pre>

<p>but I get a ""segmentation fault"" at this part of the code and I can't figure out why. If I print out arrayLength it is 1900000. First I thought maybe this was too big for an array so I tried </p>

<pre><code>correlationData = correlationArray[1900000];
</code></pre>

<p>and that worked without any errors. Why I am getting this error?</p>
","922184","","<p>This is due to a stackoverflow. You are creating a massive array on the stack.</p>

<p><code>1900000</code> of doubles is <code>~15 MB</code>. A typical stack is on the order of 1 MB.</p>

<p>What you need to do instead is to allocate it dynamically using <code>malloc()</code>.</p>

<p>In your second test case:</p>

<pre><code>correlationData = correlationArray[1900000];
</code></pre>

<p>That doesn't make the array. It's just a wild array access that (un)luckily didn't crash.</p>
"
"<p>I have a while loop in C program which was supposed to wait for system to tweak a single bit (<strong>bit0</strong>) ON and then continue execution. This bit or ""flag"" is located in a register (<strong>reg1</strong>). I have been trying to program this using bitwise &amp; operator for masking my register like this.</p>

<pre><code>unsigned int continue;
while(continue != (reg1 &amp; bit0));
</code></pre>

<p>I end up getting an error: ""<strong>Syntax error, multiple markers at this line, expected ')' before ';' token.</strong>""</p>
","922184","","<p><code>continue</code> is a keyword. You can't use it as an identifier.</p>

<p>Change the name to something else and see if it works:</p>

<pre><code>unsigned int cont = 0;        //  You also forgot to initialize.
while(cont != (reg1 &amp; bit0));
</code></pre>
"
"<p>In this code I passed a character pointer reference to function test
and in function test I malloc size and write data to that address and after this I print it and got null value.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt; 

void test(char*);

int main()
{

 char *c=NULL ;


 test(c);
 printf(""After test string is %s\n"",c);
 return 0;
}



void test(char *a)
{
 a = (char*)malloc(sizeof(char) * 6);
 a = ""test"";
 printf(""Inside test string is %s\n"",a);
}
</code></pre>

<p>output:</p>

<pre><code>Inside test string is test
After test string is (null)
</code></pre>
","922184","","<p>You can't just pass the pointer in. You need to pass the address of the pointer instead. Try this:</p>

<pre><code>void test(char**);


int main()
{

 char *c=NULL ;


 test(&amp;c);
 printf(""After test string is %s\n"",c);

 free(c);   //  Don't forget to free it!

 return 0;
}



void test(char **a)
{
 *a = (char*)malloc(sizeof(char) * 6);
 strcpy(*a,""test"");  //  Can't assign strings like that. You need to copy it.
 printf(""Inside test string is %s\n"",*a);
}
</code></pre>

<p>The reasoning is that the pointer is passed by value. Meaning that it gets copied into the function. Then you overwrite the local copy within the function with the malloc.</p>

<p>So to get around that, you need to pass the address of the pointer instead.</p>
"
"<p>I am trying to build a dll written in C and which will be imported by other programs also written in C.</p>

<p>So all the function that the dll is exporting are defined in a .dll <strong>""without __declspec(dllexport)""</strong> (intentional). I have defined a .def file with just an Export section and name of the functions I want to export (unmangled names).</p>

<p>I am using vc71/vs2003 to build this and I am still getting mangled names (which I can see if I open the .lib in notepad). Also just for clarification, visual studio causes name mangling in C code as well (most resources I could find mentioned it being an issue with only C++).</p>

<p>How can I prevent this name mangling?</p>

<p>Further Information:</p>

<p>The mangled names are of the form 'functionName@integer' where integer represent the parameter size in bytes (and not ordinal). For example,</p>

<p><strong>From .lib:</strong>
_PrepareSeverResponse@8</p>

<p><strong>Function declaration in .h:</strong>
char* PrepareSeverResponse(unsigned int* size ,handshake* ws_handshake);</p>

<p><strong>.def:</strong>
EXPORTS
    PrepareSeverResponse</p>

<p><strong>Calling Convention:</strong> __stdcall(/Gz)</p>

<p>Hope this makes it clearer.</p>
","922184","","<p>In order to prevent name mangling, you need to wrap your headers with <code>extern C</code>:</p>

<pre><code>#ifdef __cplusplus
extern ""C"" {
#endif


//  Headers


#ifdef __cplusplus
}
#endif
</code></pre>

<p>This will force the symbols to their C-style (unmangled) names.</p>
"
"<p>I want to know if there is a way to get the size of c function in memory at runtime.</p>

<p>I've used this code but it's not working:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stddef.h&gt;

int main(void)
{
    int t[10];
    char c;
    offsetof(t, p);
    p: 
    return 0;
}
</code></pre>
","922184","","<p>The answer is generally no. You can't. One reason is because functions are not necessarily contiguous in memory. So they don't have a ""size"". Sometimes, compilers (namely ICC) will make jumps out of the function to a remote part of the binary and jump back in.</p>

<p>See a related question here:</p>

<p><a href=""http://stackoverflow.com/questions/7354507/how-to-find-function-boundaries-in-binary-code/7354552#7354552"">how to find function boundaries in binary code</a></p>
"
"<p>I get a strange behavior when I compile the same program in Release in VS2010. If I run the program from cmd.exe multiple times, the results become gibberish. However, if I run the program in Debug, the result is always the same.</p>

<p>Starting a new command prompt makes the program give out the right outputs again.</p>

<p>Any idea of what might be causing this?</p>

<p><img src=""http://i.stack.imgur.com/NNAv9.png"" alt=""Screenshot of the command prompt""></p>

<p>Edit : The code :</p>

<pre><code>int main(int argc, char* argv[])
{
    int* R;
    int capacity;

    if (argc &lt; 2)
    {
        cerr &lt;&lt; ""Veuillez entrer le chemin du fichier d'entree"" &lt;&lt; endl;
        return 1;
    }

    vector&lt;BTS&gt; stations;
    LoadFromFile(argv[1], stations, capacity);

    int count = 1;
    if (argc == 3)
    {
        count = atoi(argv[2]);
    }

    clock_t startClock = clock();

    R = new int[capacity+1];
    for(int j = 0; j &lt; count; j++)
    {
        memset(R, 0, capacity + 1);

        for(unsigned int i=0; i &lt; stations.size(); i++)
        {
            for(int j=capacity; j &gt;= 0; j--)
            {
                if(j-stations[i].getNumberOfSubscribers() &gt;= 0)
                {
                    R[j] = max(stations[i].getRevenue() + R[j-stations[i].getNumberOfSubscribers()], R[j]);
                }
            }
        }
    }

    // Print the results
    cout &lt;&lt; ""Value : "" &lt;&lt; R[capacity] &lt;&lt; endl;
    cout &lt;&lt; ""Temps total : "" &lt;&lt; ((float)(clock() - startClock) / (float)CLOCKS_PER_SEC) &lt;&lt; "" s"" &lt;&lt; endl;

    delete[] R;

    return 0;
}

void LoadFromFile(std::string filePath, std::vector&lt;BTS&gt;&amp; baseStations, int&amp; capacity)
{
    fstream source(filePath);

    int numberOfStation;
    source &gt;&gt; numberOfStation;
    source &gt;&gt; capacity;

    for (int i = 0; i &lt; numberOfStation; i++)
    {
        int index, revenue, numberOfSuscribers;
        source &gt;&gt; index;
        source &gt;&gt; revenue;
        source &gt;&gt; numberOfSuscribers;

        BTS station = BTS(index, revenue, numberOfSuscribers);

        baseStations.push_back(station);
    }

    source.close();
}
</code></pre>

<p>The rest of the code is only getters. Now for the file I give as input : </p>

<pre>
10 25
    1     7     6
    2     4     4
    3     7     6
    4     2     1
    5     7     8
    6     9    10
    7     4     5
    8    10    10
    9     1     1
   10    10    10
</pre>
","922184","","<p>Your <code>memset</code> isn't correct. You forgot the <code>sizeof()</code>:</p>

<pre><code>memset(R, 0, capacity + 1);
</code></pre>

<p>should be:</p>

<pre><code>memset(R, 0, (capacity + 1) * sizeof(int));
</code></pre>

<p>Since you didn't zero all of <code>R</code>, the upper parts of it are undefined and are giving you junk data.</p>
"
"<p>I would like to calculate an inverse mask for an unsigned char.meaning if the original mask 0xc0 the the inverse mask should be 0x3f.that is to say all the bits should be flipped or inverted.I have tried the below but doesn't seem to be working.</p>

<pre><code>int flipBit(int x, unsigned char position)
{
  int mask = 1 &lt;&lt; position;
  return x ^ mask;
}

int main(int argc , char* argv[])
{
        uint8_t mask = 0x03;
        uint8_t inverse_mask = 0;
        uint8_t temp = 0;
        int loop = 0;

        for (loop = 0; loop &lt; 8 ; loop ++)
        {
                temp = flipBit(mask,loop);
                inverse_mask |= temp;
        }
        printf(""mask 0x%x inv mask 0x%x \n"",mask,inverse_mask);
        return 0;
}
</code></pre>

<p>The results I get are 
mask 0x3 inv mask 0xff</p>

<p>I cannot seem to find the bug in my code.</p>
","922184","","<p>Why can't you just do this:</p>

<pre><code>uint8_t mask = 0x03;
uint8_t inverse_mask = ~mask;
</code></pre>
"
"<p>I am trying to get a program to let a user enter a word or character, store it, and then print it until the user types it again, exiting the program. My code looks like this:</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    char input[40];
    char check[40];
    int i=0;
    printf(""Hello!\nPlease enter a word or character:\n"");
    gets(input);
    printf(""I will now repeat this until you type it back to me.\n"");

    while (check != input)
    {
        printf(""%s\n"", input);
        gets(check); 
    }

    printf(""Good bye!"");


    return 0;
}
</code></pre>

<p>The problem is that I keep getting the printing of the input string, even when the input by the user (check) matches the original (input). Am I comparing the two incorrectly?</p>
","922184","","<p>You can't compare strings using <code>!=</code> or <code>==</code>, you need to use <code>strcmp</code>:</p>

<pre><code>while (strcmp(check,input) != 0)
</code></pre>

<p>The reason for this is because <code>!=</code> and <code>==</code> will only compare the base addresses of those strings. Not the contents of the strings themselves.</p>
"
"<p>I am learning about how compilers represent C++ programs in assembly. I have a question about something that the compiler does that I can't make sense of. Here is some C++ code:</p>

<pre><code>class Class1 {
public:
  int i;
  char ch;
};

int main() {
  Class1 cls;
}
</code></pre>

<p>Compiling with ""g++ -S "" outputs this (I've stripped out everything but the function definition):</p>

<pre><code>main:
    push    ebp
    mov     ebp, esp
    sub     esp, 16
    mov     eax, 0
    leave
    ret
</code></pre>

<p>I don't understand the line <code>sub esp, 16</code>. Why would it allocate 16 bytes for an instance of this class that only requires 8 when you take into account <a href=""http://en.wikipedia.org/wiki/Data_structure_alignment"" rel=""nofollow"" title=""Wikipedia on data structure alignment"">data structure alignment and padding</a>? </p>

<p>It should be </p>

<pre><code>[int i - 4 bytes][char ch - 1 byte][padding - 3 bytes]
</code></pre>

<p>should it not?</p>

<p>When I compiled the code with the class definition also including a double, i.e.</p>

<pre><code>class Class1 {
public:
  int i;
  char ch;
  double dub;
}; 
</code></pre>

<p>it still allocated 16 bytes, which made sense in that case.</p>

<p>So why does the compiler allocate 16 bytes when it only needs 8?</p>
","922184","","<p>This has to do with stack-frame alignment, not structure alignment.</p>

<p>If you did a <code>sizeof()</code> on your objects, you'll see what you expect with struct alignment and padding.</p>

<p>However, stack-frames are slightly different. On most systems today, the stack alignment is 16 bytes (or more) to accommodate SSE memory accesses.</p>
"
"<p>I am having some troubles with my if loop.</p>

<p>First off I have I assigned char sign.</p>

<pre><code> void evaluate_ps(istream&amp; input) 
 {
    char sign;
    input &gt;&gt; sign;
    cout &lt;&lt; sign &lt;&lt; endl;
    check(sign);
 }
</code></pre>

<p>That prints / so my sign has the value '/'</p>

<p>Then I go to my void check(char operation) function </p>

<pre><code> void check(char operation)
 {
    if(operation != '-' || operation != '+' ||
      operation != '*' || operation != '/')
       {
       return false;
       }
       else return true;
 }
</code></pre>

<p>and it's returning false... WHY!!!! I can't seem to figure this out.</p>

<p>Thanks everyone.</p>
","922184","","<p>You probably meant all your <code>||</code> to be <code>&amp;&amp;</code>:</p>

<pre><code>if(operation != '-' &amp;&amp; operation != '+' &amp;&amp; 
  operation != '*' &amp;&amp; operation != '/')
</code></pre>

<p>Otherwise, it will always enter the if-statement since a character will always not equal one of 4 different things.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/513832/how-do-i-compare-strings-in-java"">How do I compare strings in Java?</a>  </p>
</blockquote>



<p>why first comparison ( s1 == s2 ) displays equal whereas 2nd comparison ( s1 == s3 ) displays not equal....?</p>

<pre><code>    public class StringComparison
    {

         public static void main( String [] args)
         {
              String s1 = ""Arsalan"";
              String s2 = ""Arsalan"";

              String s3 = new String (""Arsalan"");

              if ( s1 == s2 )
                 System.out.println ("" S1 and S2 Both are equal..."");
              else
                 System.out.println (""S1 and S2 not equal"");

              if ( s1 == s3 )
                 System.out.println ("" S1 and S3 Both are equal..."");
              else
                 System.out.println ("" S1 and S3 are not equal"");

         }
     }
</code></pre>
","922184","","<p>This has to do with the fact that you cannot compare strings with <code>==</code> as well as compiler optimizations.</p>

<p><code>==</code> in Java only compares if the two sides refer to the exact same instance of the same object. It does not compare the content. To compare the actual content of the strings, you need to use <code>s1.equals(s2)</code>.</p>

<p>Now the reason why <code>s1 == s2</code> is true and <code>s1 == s3</code> is false is because the JVM decided to optimize the code so that <code>s1</code> and <code>s2</code> are the same object. (It's called, ""String Pooling."")</p>

<hr>

<p>Per 3.10.5: Pooling of string literals is actually mandated by the standard.</p>

<blockquote>
  <p>Moreover, a string literal always refers to the same instance of class
  String. This is because string literals - or, more generally, strings
  that are the values of constant expressions (§15.28) - are ""interned""
  so as to share unique instances, using the method String.intern.</p>
</blockquote>
"
"<p>I have this function which I would like to parallelize using openmp:</p>

<pre><code>for(i=len-1;i&gt;=0;i--){
  if(bin[i]==49) // bin is a binary number &amp; is
                 // stored in a string. 49 is ascii value of 1
  {
     s=(s*x)%n;    
  }
  x=(x*x)%n;
}
</code></pre>

<p>I tried using <code>#pragma omp parallel for</code> but it dint work. I tried with the reduction function too and yet I got wrong answers.<br>
I think the reason is because value of s depends on x (which is dependent on each steps value).</p>
","922184","","<p>You are correct that the dependency on <code>x</code> causes problems. This dependency is between iterations. Each iteration requires the <code>x</code> from the previous iteration. So it renders the entire loop not parallelizable.</p>

<p>It looks like this loop is computing a power-modulus using repeated squaring.</p>

<p>So in short: No you won't be able to parallelize it. The dependency is inherent in the algorithm that you're using.</p>
"
"<p>I wrote this short program</p>

<pre><code>int main(){
    char * c = ""abcd"";
    c[1] = '\0';
    cout &lt;&lt; c &lt;&lt; endl;
}
</code></pre>

<p>and it doesn't work... actually it compiles the program but in the runtime an error occures...
Why? I thought it will print an ""a"" as the ""string"" now looks like this: ""a0cd"" so after a zero it is supposed to detect an end of the string, right? So where is the problem?</p>

<p>Thank you!</p>
","922184","","<p>You can't modify string literals like that.</p>

<p>Try this instead:</p>

<pre><code>int main(){
    char c[] = ""abcd"";
    c[1] = '\0';
    cout &lt;&lt; c &lt;&lt; endl;
}
</code></pre>

<p>The reason behind this is that string literals are stored in global memory (often in a read-only segment). Modifying them is undefined behavior. However, if you initialize it as an array <code>char c[] = ""abcd""</code> it will be on the stack (as opposed to global memory), so you can freely modify it.</p>
"
"<p>I executed the following code </p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    printf(""%f\n"", 9/5);
}
</code></pre>

<p>Output : <code>0.000000</code></p>

<p>why not <code>1</code> ?</p>

<p>if i write <code>printf(""%f %f %d %d\n"", (float)9/5, 4, sizeof(float), sizeof(int));</code></p>

<p>then output is <code>1.800000 0.000000 4 59</code></p>

<p>why not <code>1.800000 4 4 4</code></p>

<p>on my machine the <code>sizeof (float)</code> is <code>4</code></p>

<p>Thanks in advance</p>
","922184","","<p>This is because your <code>printf</code> format specifier doesn't match what you passed it:</p>

<p><code>9/5</code> is of type <code>int</code>. But <code>printf</code> expects a <code>float</code>.</p>

<p>So you need to either cast it to a float or make either literal a float:</p>

<pre><code>printf(""%f\n"", (float)9/5);
printf(""%f\n"", 9./5);
</code></pre>

<p>As for why you're getting <code>0.0</code>, it's because the <code>printf()</code> is reading the binary representation of <code>1</code> (an integer) and printing it as a <code>float</code>. Which happens to be a small denormalized value that is very close to <code>0.0</code>.</p>

<p><strong>EDIT :</strong> There's also something going with type-promotion on varargs.</p>

<p>In vararg functions, <code>float</code> is promoted to <code>double</code>. So <code>printf()</code> in this case actually expects a 64-bit parameter holding a <code>double</code>. But you only passed it a 32-bit operand so it's actually reading an extra 32-bits from the stack (which happens to be zero in this case) - even more undefined behavior.</p>
"
"<p>I'm using the read function to take in one character, then running the read function again.  Before I run the function again, I want to save what's in the buffer to a char variable.  Like this:</p>

<pre><code>void *buf;
read(0,buf,1);
char tempChar;
</code></pre>

<p>I want to store what's in *buf into the char tempChar.  I know I can't just set them equal, but is this possible at all?</p>

<p>Thanks.</p>
","922184","","<p>You can do it like this:</p>

<pre><code>char tempChar;
read(0,&amp;tempChar,1);
</code></pre>

<p>So there's actually no need to have a separate buffer at all.</p>
"
"<p>I've written the following line in C.
I want to know if is supported by the language.
it goes like that:</p>

<pre><code>char * mode[7] = Config_Msg.DHCP ? ""DHCP"" : ""Static"";
</code></pre>

<p>Basically I want to insert into mode the String value of ""DHCP"" or ""STATIC"", depended on the value in Config_Msg.DHCP.</p>

<p>When I compile in IAR, I get this warning:</p>

<pre><code>Warning[Pe520]: initialization with ""{...}"" expected for aggregate  
</code></pre>

<p>What does this warning mean ?</p>
","922184","","<p>You can't assign strings like that, so you should do it like this:</p>

<pre><code>char mode[7];
strcpy(mode,Config_Msg.DHCP ? ""DHCP"" : ""Static"");
</code></pre>

<p>Note that I also corrected your declaration for <code>mode</code>. You originally declared an array of pointers.</p>

<p>Alternatively, you could also do it with a pointer:</p>

<pre><code>char *mode = Config_Msg.DHCP ? ""DHCP"" : ""Static"";
</code></pre>
"
"<pre><code>class demoClass {
private:
    char item_name[50];

public:
    void set_item_name(char *item_name){ this-&gt;item_name=item_name; };
};
</code></pre>

<p>I am receiving error :
<strong>invalid assignment of char to char[50]</strong></p>
","922184","","<p>You can't assign strings like that. You have several options:</p>

<pre><code>class demoClass{
private:
    char *item_name;

public:

    void set_item_name(char *item_name){
        this-&gt;item_name = item_name;
    };
};
</code></pre>

<p>or</p>

<pre><code>class demoClass{
private:
    char item_name[50];


public:

    void set_item_name(char *item_name){
        strcpy(this-&gt;item_name,item_name);
    };
};
</code></pre>

<p>or</p>

<pre><code>class demoClass{
private:
    string item_name;


public:

    void set_item_name(char *item_name){
        this-&gt;item_name = item_name;
    };
};
</code></pre>

<p>Be aware that the first two of these have ""gotchas"" if you aren't careful.</p>

<p><strong>In the first one</strong>, if the life of the pointer you pass ends before the object is destroyed. You'll get a dangling pointer.</p>

<p><strong>In the second one</strong>, if your string is longer than 49 characters, you'll overrun the array.</p>

<p><strong>The third one</strong> is the preferred C++ way.</p>
"
"<p>Maybe it is different from platform to platform, but</p>

<p>when I compile using gcc and run the code below, I get 0 every time in my ubuntu 11.10.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    double *a = (double*) malloc(sizeof(double)*100)
    printf(""%f"", *a);
}
</code></pre>

<p>Why do malloc behave like this even though there is calloc?</p>

<p>Doesn't it mean that there is an unwanted performance overhead just to initialize the values to 0 even if you don't want it to be sometimes?</p>

<hr>

<p>EDIT: Oh, my previous example was not initiazling, but happened to use ""fresh"" block.</p>

<p>What I precisely was looking for was why it initializes it when it allocates a large block:</p>

<pre><code>int main()
{
    int *a = (int*) malloc(sizeof(int)*200000);
    a[10] = 3;
    printf(""%d"", *(a+10));

    free(a);

    a = (double*) malloc(sizeof(double)*200000);
    printf(""%d"", *(a+10));
}

OUTPUT: 3
        0 (initialized)
</code></pre>

<p>But thanks for pointing out that there is a SECURITY reason when mallocing! (Never thought about it). Sure it has to initialize to zero when allocating fresh block, or the large block.</p>
","922184","","<p><strong>Short Answer:</strong></p>

<p>It doesn't, it just happens to be zero in your case.<br>(Also your test case doesn't show that the data is zero. It only shows if one element is zero.)</p>

<hr>

<p><strong>Long Answer:</strong></p>

<p>When you call <code>malloc()</code>, one of two things will happen:</p>

<ol>
<li>It recycles memory that was previous allocated and freed from the same process.</li>
<li>It requests new page(s) from the operating system.</li>
</ol>

<p>In the first case, the memory will contain data leftover from previous allocations. So it won't be zero. This is the usual case when performing small allocations.</p>

<p>In the second case, the memory will be from the OS. This happens when the program runs out of memory - or when you are requesting a very large allocation. (as is the case in your example)</p>

<p>Here's the catch: <strong>Memory coming from the OS will be zeroed for <em>security</em> reasons.*</strong></p>

<p>When the OS gives you memory, it could have been freed from a different process. So that memory could contain sensitive information such as a password. So to prevent you reading such data, the OS will zero it before it gives it to you.</p>

<p><sub>*I note that the C standard says nothing about this. This is strictly an OS behavior. So this zeroing may or may not be present on systems where security is not a concern.</sub></p>

<hr>

<p><strong>To give more of a performance background to this:</strong> </p>

<p>As @R. mentions in the comments, this zeroing is why you should always <a href=""http://stackoverflow.com/questions/2688466/why-mallocmemset-slower-than-calloc?lq=1"">use <code>calloc()</code> instead of <code>malloc()</code> + <code>memset()</code></a>. <code>calloc()</code> can take advantage of this fact to avoid a separate <code>memset()</code>.</p>

<hr>

<p>On the other hand, this zeroing is sometimes a performance bottleneck. In some numerical applications (such as the <a href=""http://en.wikipedia.org/wiki/Fast_Fourier_transform"">out-of-place FFT</a>), you need to allocate a huge chunk of scratch memory. Use it to perform whatever algorithm, then free it.</p>

<p><em>In these cases, the zeroing is unnecessary and amounts to pure overhead.</em> </p>

<p>The most extreme example I've seen is a 20-second zeroing overhead for a 70-second operation with a 48 GB scratch buffer. (Roughly 30% overhead.)
<sub>(Granted: the machine did have a lack of memory bandwidth.)</sub></p>

<p>The obvious solution is to simply reuse the memory manually. But that often requires breaking through established interfaces. (especially if it's part of a library routine)</p>
"
"<p>I would rather just use a string, but we aren't supposed to as the teacher hates them and wants us to figure out ways to avoid them. So I looked into using a struct, but we aren't that far in the book and she hates it when I skip ahead. So I was thinking of doing this: </p>

<pre><code>#include &lt;iomanip&gt;
#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

using namespace std;

void myfunc(char&amp; );

int main()
{
    char myname[12];
    cout&lt;&lt;""enter  a name "";
    cin&gt;&gt;myname;
    cout&lt;&lt;""myname is ""&lt;&lt;myname;

    cout&lt;&lt;""myname is "" &lt;&lt; myfunc(myname);

    getchar();
    getchar();
    return 0;
}

void myfunc(char &amp;myname1)
{
    myname1 = ""Billy""
}
</code></pre>

<p>But this doesn't work and I don't know why.</p>
","922184","","<p>One way is to do it like this:</p>

<pre><code>void myfunc(char *myname1)
{
    strcpy(myname1,""Billy"");
}   
</code></pre>

<p>You will also need to change your main to:</p>

<pre><code>myfunc(myname);
cout&lt;&lt;""myname is "" &lt;&lt; myname;
</code></pre>

<p>However you have to be careful not to overflow your initial buffer.</p>

<p>The reason why your original code doesn't work is because you can't assign strings to <code>char</code> pointers. Instead you must copy the string to the <code>char*</code>.</p>
"
"<p>I'm very stumped.</p>

<p>When I run this code in Visual C++ 2008:</p>

<pre><code>__m128i a, b;
a.m128i_u64[0] = 1;
b.m128i_u64[0] = 0;
a.m128i_u64[1] = 0;
b.m128i_u64[1] = 0;
printf(""%d\n"", _mm_testc_si128(a, b));
</code></pre>

<p>it prints <code>1</code>. Which is contrary to what I expect, because it's supposed to be 1 only if <code>a</code> and <code>b</code> are the same.</p>

<p>How is this possible? Is there a bug in my CPU or in Visual C++ 2008 or something else?</p>
","922184","","<p>I know for a fact that a lot of SSE4.1 intrinsics are broken in VS2008. They fixed them for VS2010. In VS2010 (no SP), some of the AVX intrinsics are broken. They fixed those in VS2010 SP1.</p>

<p>I've never used the <code>_mm_testc_si128</code> intrinsic, so I don't know if that's another intrinsic that's broken in VS2008. But I've seen numerous cases where insert/extract intrinsics were broken.</p>

<p><strong>EDIT :</strong> I just tested this in VS2010 SP1, it also gives 1.</p>

<p>Now that I look at the <a href=""http://msdn.microsoft.com/en-us/library/bb513983.aspx"" rel=""nofollow"">documentation</a>, it looks like it ""should"" be returning 1.</p>

<blockquote>
  <p>Return value</p>
  
  <p>1 if all the bits set in b are set in a; otherwise 0.</p>
</blockquote>

<p>So I don't think it's a bug in this case.</p>
"
"<p>I am trying to learn arrays and pointers in C. I'm trying to write a program that in a function: gets 2 numbers from the user, puts them in an array, and returns them to the main function. I am getting an error and I don't understand what the problem is. Here is my code:</p>

<pre><code>#include&lt;stdio.h&gt;

void get_nums(float *x)
{
    float num1, num2;

    printf(""enter two numbers: "");
    scanf(""%f %f"", &amp;num1, &amp;num2);

    *x[0] = num1;
    *x[1] = num2;

}

main(){

    float x[2];
    float (*p_x)[2] = &amp;x;

    get_nums(p_x[2]);

    printf(""Number 1: %f\nNumber 2: %f"", x[0], x[1]);

    return 0;
}
</code></pre>

<p>I am getting an error on these 2 lines</p>

<pre><code>    *x[0] = num1;
    *x[1] = num2;
</code></pre>

<p>The error message is</p>

<blockquote>
  <p>Error: operand of '*' must be a pointer</p>
</blockquote>

<p>I don't see what it is that is wrong. Does anyone see the problem?</p>

<p>EDIT: I changed the 2 lines to </p>

<pre><code>    x[0] = num1;
    x[1] = num2;
</code></pre>

<p>and now I can run the program. However I get a new error after I enter the two numbers. The error message is: </p>

<blockquote>
<pre><code>  Unhandled exception at 0x40e00000 in arraysandpointers.exe: 0xC0000005: Access violation.
</code></pre>
</blockquote>
","922184","","<p>You don't need the <code>*</code>. Just this is fine:</p>

<pre><code>x[0] = num1;
x[1] = num2;
</code></pre>

<p>In your original code <code>x[0]</code> already is of type <code>float</code>. <code>*x[0]</code> will try to deference it - which is not possible since <code>x[0]</code> isn't a pointer. Therefore it doesn't compile.</p>

<p>EDIT : Also change your main to this:</p>

<pre><code>int main(){

    float x[2];
    get_nums(x);

    printf(""Number 1: %f\nNumber 2: %f"", x[0], x[1]);

    return 0;
}
</code></pre>

<p>It is not necessary to have the <code>p_x</code>. And it is what's causing the crash.</p>
"
"<p>I'm writing a C code for improving recursive functions learning. My function must calculate the average of a set of numbers received in an array. I got to calculate the sum of the numbers in the array, even to return it, same I got to calculate the average inside the function (I've printed it) but when I do the return, the main function always gets a trash number.</p>

<p>This is my code:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

float sum (int array[], int n)
{
    float f; float z=n;
    if (n==0) return (array[n]);
    f=(array[n]+sum(array,n-1));;
    return f/z;
}

int main ()
{
    int *array, n, i;
    float result;

    printf(""\nDimension de tu array: "");
    scanf(""%d"", &amp;n);
    array=(int *) malloc (n*sizeof (int));

    for (i=0; i&lt;n; i++)
    {
        printf(""Valor en A[%d]: "", i+1);
        scanf(""%d"", &amp;array[i]);
    }
    result=sum(array,n);
    printf(""\n\nEl promedio es igual a: %f "", result);
}
</code></pre>
","922184","","<p>The problem is here:</p>

<pre><code>return f/z;
</code></pre>

<p>Your function is supposed to compute the sum, but you are already dividing by the # of elements.</p>

<p>Change it to:</p>

<pre><code>return f;
</code></pre>

<p>And divide by the # of elements in your main:</p>

<pre><code>result = sum(array,n) / n;
</code></pre>

<p>And the other error is here:</p>

<pre><code>if (n==0) return (array[n]);
f=(array[n]+sum(array,n-1));;
</code></pre>

<p>should be (and indented):</p>

<pre><code>if (n==0)
    return array[n - 1];
f = array[n - 1] + sum(array,n-1);
</code></pre>

<p>The last index of an array is <code>n - 1</code>, not <code>n</code>.</p>
"
"<p>Is there a good way to modify a class in C++ so that its integers are 64-bit on a 64-bit system and 32-bit for 32-bit systems? Is there a way to check for that?</p>

<p>The class is something like:</p>

<pre><code>class B{
      public:
            int64_t size();
      private:
            int64_t m_size();
}
</code></pre>
","922184","","<p>If you really want exactly what you said (32-bit on 32-bit and 64-bit on 64-bit) you'll need to use macros.</p>

<p>But what you probably want instead is to just use <code>size_t</code>.</p>

<p>EDIT:</p>

<p><code>size_t</code> is guaranteed to be large enough to size any object and index any array. And as such, it is usually 32-bits on 32-bit and 64-bits on 64-bit. So it probably does exactly what you want.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/7924961/weird-java-behavior-with-casts-to-primitive-types"">Weird java behavior with casts to primitive types</a>  </p>
</blockquote>



<p>Let's look at the following code snippet in Java.</p>

<pre><code>package typecasting;

final public class TypeCasting
{
    public static void main(String[] args)
    {
        int i = (byte) + (char) - (int) + (long) - 1;
        System.out.print(""\n i = ""+i+""\n"");
    }
}
</code></pre>

<p>The statement <code>System.out.print(""\n i = ""+i+""\n"");</code> displays <strong>i = 1</strong>. How?</p>
","922184","","<p>The line:</p>

<pre><code>(byte) + (char) - (int) + (long) - 1;
</code></pre>

<p>is being parsed as:</p>

<pre><code>(byte) (+(char) (-(int) (+(long)(-1) ) ) );
</code></pre>

<p>All the <code>+</code> and <code>-</code> are unary operators. Since there are two <code>-</code>, the <code>1</code> gets negated twice so the entire expression evaluates to <code>1</code>.</p>
"
"<p>I'm trying to read in a line of characters, then print out the hexadecimal equivalent of the characters.</p>

<p>For example, if I have a string that is <code>""0xc0 0xc0 abc123""</code>, where the first 2 characters are <code>c0</code> in hex and the remaining characters are <code>abc123</code> in ASCII, then I should get </p>

<pre><code>c0 c0 61 62 63 31 32 33
</code></pre>

<p>However, <code>printf</code> using <code>%x</code> gives me</p>

<pre><code>ffffffc0 ffffffc0 61 62 63 31 32 33
</code></pre>

<p>How do I get the output I want without the <code>""ffffff""</code>? And why is it that only c0 (and 80) has the <code>ffffff</code>, but not the other characters?</p>
","922184","","<p>You are seeing the <code>ffffff</code> because <code>char</code> is signed on your system. In C, vararg functions such as <code>printf</code> will promote all integers smaller than <code>int</code> to <code>int</code>. Since <code>char</code> is an integer (8-bit signed integer in your case), your chars are being promoted to <code>int</code> via sign-extension.</p>

<p>Since <code>c0</code> and <code>80</code> have a leading 1-bit (and are negative as an 8-bit integer), they are being sign-extended while the others in your sample don't.</p>

<pre><code>char    int
c0 -&gt; ffffffc0
80 -&gt; ffffff80
61 -&gt; 00000061
</code></pre>

<p>Here's a solution:</p>

<pre><code>char ch = 0xC0;
printf(""%x"", ch &amp; 0xff);
</code></pre>

<p>This will mask out the upper bits and keep only the lower 8 bits that you want.</p>
"
"<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

main()
{
    const char* str_int = ""777"";
    const char* str_float = ""333.3"";
    int i = atoi(str_int);
    float f = atof(str_float);

    printf(""%s %s"", i, f); 
}
</code></pre>

<p>I have tried several bits of example code i've found online and all of them cause buss errors. Why is this happening? </p>
","922184","","<p>Your <code>printf</code> is incorrect. Try this instead:</p>

<pre><code>printf(""%d %f"", i, f); 
</code></pre>

<p>The problem is that your format specifiers are <code>%s</code>, which expect strings. But you gave it an <code>int</code>and a <code>float</code>. Therefore the result is undefined behavior.</p>

<p>The reason why it's crashing is because <code>printf</code> will try to read the parameters as strings (which are pointers) and deference them as such, but they are invalid pointers.</p>

<p>Here's a reference on <code>printf</code> and its format specifiers:</p>

<p><a href=""http://www.cplusplus.com/reference/clibrary/cstdio/printf/"" rel=""nofollow"">http://www.cplusplus.com/reference/clibrary/cstdio/printf/</a></p>
"
"<pre><code>#include&lt;stdio.h&gt;
#include&lt;string.h&gt;
int main()
{
  unsigned char *s;
  unsigned char a[30]=""Hello world welcome"";
  memcpy(s,&amp;a,15);
  printf(""%s"",s);
  return 0;
}
</code></pre>

<p>This is giving me a segmentation fault. Please help me fix this error</p>
","922184","","<p>You need to allocate memory for <code>s</code>. As it stands, it's just an uninitialized pointer that (most likely) points nowhere:</p>

<pre><code>unsigned char *s = malloc(16);
</code></pre>

<p>And as with all memory allocations, it should be freed when you're done using it:</p>

<pre><code>free(s);
</code></pre>

<p>EDIT: The other mistake (which I overlooked) is that you need to NULL terminate after you call <code>memcpy</code>.</p>

<pre><code>memcpy(s,a,15);
s[15] = '\0';
</code></pre>

<p>Alternatively, you could use <code>strcpy()</code>, and truncate the string to 15 characters, but you'll need to allocate enough to store all of <code>a</code> (including its NULL-terminator):</p>

<pre><code>unsigned char a[30]=""Hello world welcome"";
unsigned char *s = malloc(strlen(a) + 1);   //  Allocate
strcpy(s,a);        //  Copy entire string
s[15] = '\0';       //  Truncate to 15 characters by inserting NULL.
printf(""%s"",s);
free(s);            //  Free s
</code></pre>
"
"<p>I have following C++ code and running PC lint on code.</p>

<p>Question 1:</p>

<pre><code>#if !WIN32
#define ULONG_MAX 0xffffffff
#endif
</code></pre>

<p>Above code is throwing an lint error as follows</p>

<blockquote>
  <p>Error 26: Expected an expression, found 'WIN32'<br>
  Error 30: Expected an integer constant</p>
</blockquote>

<p>How to fix above error?</p>

<p>Question 2:</p>

<pre><code>const char CompanyName[] = ""mycompany""; 
</code></pre>

<blockquote>
  <p>Error: Note 960: Violates MISRA Required Rule 8.5, no object/function definitions in header files</p>
</blockquote>

<p>How to fix above error?</p>

<p>Question 3:</p>

<pre><code>unsigned long m_ClientThreadId; 
m_ClientThreadId        = 0;
</code></pre>

<blockquote>
  <p>Note 960: Violates MISRA Required Rule 10.1, Implicit conversion changes signedness</p>
</blockquote>

<p>How to fix above error?</p>
","922184","","<p><strong>First:</strong></p>

<p>You need to do this instead:</p>

<pre><code>#ifndef WIN32
#define ULONG_MAX 0xffffffff
#endif
</code></pre>

<p><strong>Second:</strong></p>

<p>You can't define that in a header file, otherwise the same symbol will appear in multiple compilation units.</p>

<p>What you need to do instead, is just declare in the header:</p>

<pre><code>extern const char CompanyName[];
</code></pre>

<p>And then define it once in one of the modules:</p>

<pre><code>const char CompanyName[] = ""mycompany""; 
</code></pre>

<p><strong>Third:</strong></p>

<pre><code>unsigned long m_ClientThreadId; 
m_ClientThreadId        = 0;
</code></pre>

<p>This is unusual, but it seems that <code>0</code> is a signed constant. And assigning it to <code>unsigned long</code> has a implicit type cast. Most compilers do not actually warn against this.</p>
"
"<pre><code>    #include &lt;iostream&gt;
    #include &lt;vector&gt;
    using namespace std;

    int main(){

    vector&lt;string&gt; row(7, ""0"");
    char input;
    int pos;

    cin &gt;&gt; input;
    cin &gt;&gt; pos;

    if(input == 'X')
        row[pos] = '1';

    //ascii value of 1 is 49

    if(row[pos] - 49 == 0)
        cout &lt;&lt; ""Correct"";

    return 0;
    }
</code></pre>

<p>I keep getting an error at my last <code>if</code> statement.  Any ideas why it's not working, and how I can fix it?  By the way, <code>row</code> <strong>has</strong> to be a string vector, I can't make it any other type.</p>

<p>I want <code>row[pos]</code> to take the character in <code>row</code> at the position <code>pos</code></p>
","922184","","<p>The problem with the last if-statement is that <code>row[pos]</code> is of type <code>string</code>. So you can't subtract 49 from it. What you want is the first character of the string:</p>

<pre><code>if(row[pos][0] - 49 == 0)
</code></pre>

<p>It's arguably more readable to do this instead:</p>

<pre><code>if(row[pos][0] - '1' == 0)
</code></pre>
"
"<p>In some code I have converted to SSE I preform some ray tracing, tracing 4 rays at a time using __m128 data types.</p>

<p>In the method where I determine which objects are hit first, I loop through all objects, test for intersection and create a mask representing which rays had an intersection earlier than previously found .</p>

<p>I also need to maintain data on the id of the objects which correspond to the best hit times. I do this by maintaining a __m128 data type called objectNo and I use the mask determined from the intersection times to update objectNo as follows:</p>

<pre><code>objectNo = _mm_blendv_ps(objectNo,_mm_set1_ps((float)pobj-&gt;getID()),mask);
</code></pre>

<p>Where pobj->getID() will return an integer representing the id of the current object. Making this cast and using the blend seemed to be the most efficient way of updating the objectNo for all 4 rays.</p>

<p>After all intersections are tested I try to extract the objectNo's individually and use them to access an array to register the intersection. Most commonly I have tried this:</p>

<pre><code>int o0 = _mm_extract_ps(objectNo, 0);
prv_noHits[o0]++;
</code></pre>

<p>However this crashes with EXC_BAD_ACCESS as extracting a float with value 1.0 converts to an int of value 1065353216. </p>

<p>How do I correctly unpack the __m128 into ints which can be used to index an array?</p>
","922184","","<p>There are two SSE2 conversion intrinsics which seem to do what you want:</p>

<ul>
<li><code>_mm_cvtps_epi32()</code></li>
<li><code>_mm_cvttps_epi32()</code></li>
</ul>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_conversion.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_conversion.htm</a></p>

<p>These will convert 4 single-precision FP to 4 32-bit integers. The first one does it with rounding. The second one uses truncation.</p>

<p>So they can be used like this:</p>

<pre><code>int o0 = _mm_extract_epi32(_mm_cvtps_epi32(objectNo), 0);
prv_noHits[o0]++;
</code></pre>

<p><strong>EDIT :</strong> Based on what you're trying to do, I feel this can be better optimized as follows:</p>

<pre><code>__m128i ids = _mm_set1_epi32(pobj-&gt;getID());

//  The mask will need to change
objectNo = _mm_blend_epi16(objectNo,ids,mask);

int o0 = _mm_extract_epi32(objectNo, 0);
prv_noHits[o0]++;
</code></pre>

<p>This version gets rid of the unnecessary conversions. But you will need to use a different mask vector.</p>

<p><strong>EDIT 2:</strong> Here's a way so that you won't have to change your mask:</p>

<pre><code>__m128 ids = _mm_castsi128_ps(_mm_set1_epi32(pobj-&gt;getID()));

objectNo = _mm_blendv_ps(objectNo,ids,mask);

int o0 = _mm_extract_ps(objectNo, 0);
prv_noHits[o0]++;
</code></pre>

<p>Note that the <code>_mm_castsi128_ps()</code> intrinsic doesn't map any instruction. It's just a bit-wise datatype conversion from <code>__m128i</code> to <code>__m128</code> to get around the ""typeness"" in C/C++.</p>
"
"<p>I don't use C that much and I recently got confused about 2d array initialization problem. I need to debug somebody's code and stuck in the following(her original code):</p>

<pre><code>const int location_num = 10000;
bool **location_matrix;
if (node_locations)
    {
        location_matrix = (bool **)malloc(location_num*sizeof(bool *));
        if (!location_matrix)
        {
                cout&lt;&lt;""error 1 allocating location_matrix"" &lt;&lt; endl;
                exit;
        }
        for (i=0; i&lt;location_num; i++)
        {
                location_matrix[i] = (bool *) malloc(location_num*sizeof(bool ));
                if (!location_matrix[i])
                {
                        cout&lt;&lt;""error 2 allocating location_matrix"" &lt;&lt; endl;
                        exit;
                }
                for (j=0; j&lt;location_num; j++)
                        location_matrix[i][j] = false;
        }
    }
</code></pre>

<p>I thought is was redundant, so I changed it to the following:</p>

<p><code>location_matrix[location_num][location_num] = { {false} };</code></p>

<p>However, segmentation fault happens at runtime. 
My question is: how does the above code fail? If it looks right, what's the difference between dynamically allocation and static allocation? Is it just because the dimension might not be constant, so we need to do it dynamically?
Also, just for curiosity, how do I malloc 2d array that stores pointers? Thanks.</p>
","922184","","<p>I actually don't see anything wrong with the code.</p>

<p>The following code doesn't work because <code>location_matrix</code> is not allocated:</p>

<pre><code>location_matrix[location_num][location_num] = { {false} };
</code></pre>

<p>GCC will allow the following (as an extension):</p>

<pre><code>bool location_matrix[location_num][location_num] = { {false} };
</code></pre>

<p>But it will blow your stack because <code>10000 x 10000</code> is too large.</p>

<p>Currently, your code uses dynamic allocation. That's the correct way to do it because the matrix is too large to be done as a static array (and may overrun the stack).</p>

<p>As for your last question, ""how to make a 2d array that stores pointers"": It can be done almost the same way as your current code. Just change <code>bool</code> to <code>int*</code>.</p>

<p>So a 2D array of NULL <code>int</code> pointers will look like this:</p>

<pre><code>int ***location_matrix;
if (node_locations)
{
    location_matrix = (int***)malloc(location_num*sizeof(int**));
    if (!location_matrix)
    {
            cout&lt;&lt;""error 1 allocating location_matrix"" &lt;&lt; endl;
            exit;
    }
    for (i=0; i&lt;location_num; i++)
    {
            location_matrix[i] = (int**) malloc(location_num*sizeof(int*));
            if (!location_matrix[i])
            {
                    cout&lt;&lt;""error 2 allocating location_matrix"" &lt;&lt; endl;
                    exit;
            }
            for (j=0; j&lt;location_num; j++)
                    location_matrix[i][j] = NULL;
    }
}
</code></pre>
"
"<p>If I want to bit shift the integer <code>5</code> by 3, so <code>int a = 5;   int b = a &lt;&lt; 3;</code>, the result would be <code>40</code> in decimal as <code>5</code> is <code>101</code> and <code>40</code> is <code>101000</code>.</p>

<p>What if however, I have the following <code>char</code> array:
<code>00000 00101</code> and by bit shifting three to the left, I want the result to be <code>00001 01000</code>. So I want to accommodate for the <code>0</code>'s padding. What do you suggest?</p>
","922184","","<p>If you meant an actual <code>char</code> array, you can use <code>memmove()</code> and <code>memset()</code>:</p>

<pre><code>char str[] = ""0000000101"";

int shift = 3;
int length = strlen(str);

memmove(str, str + shift,length - shift);
memset(str + length - shift,'0',shift);

//  Result:
//  ""0000101000""
</code></pre>
"
"<p>If I have an array declared like this:</p>

<pre><code>int a[3][2];
</code></pre>

<p>stored at address <code>A</code>.</p>

<p>Then a+1 is equal to <code>A+2*4</code>, this is clear to me, 
but why is <code>&amp;a+1</code> equal to <code>A+6*4</code>? </p>
","922184","","<p><code>a</code> is an array of <code>int[2]</code>. Which has size <code>2 * sizeof(int)</code>. That's why <code>a + 1 = A + 2*4</code>. (since <code>sizeof(int) = 4</code> in your case)</p>

<p>However, <code>&amp;a</code> is a pointer to <code>int[3][2]</code>. Since <code>sizeof(int[3][2]) = 6 * sizeof(int)</code>, therefore: <code>&amp;a + 1 = A + 6*4</code></p>
"
"<p>To me, a bool variable indicates either <strong>true</strong> or <strong>false</strong>.</p>

<p>Some bool variable was defined and initialized to a value unknown to us. I just want to get the opposite value of it. How should I do it in C++?</p>
","922184","","<p>Just use the <code>!</code> operator:</p>

<pre><code>bool x = // something

bool y = !x;  //  Get the opposite.
</code></pre>
"
"<p>I'm having some issues with my linked list.  I have <code>struct dListNode</code> used as the nodes for the list with a pointer to <code>struct data</code>, which is used as the data storage.</p>

<pre><code>struct data{
    int payload;
};

struct dListNode{
    struct dListNode *next;
    struct dListNode *prev;
    struct data *val;
}*dHead, *dTail;
</code></pre>

<hr>

<p>My program compiles fine, but I get a segmentation fault at the line indicated below. What is going on?</p>

<pre><code>newDNode = (struct dListNode *)malloc(sizeof(struct dListNode)+sizeof(struct data));
printf(""newnode created\n""); // this prints
newDNode-&gt;val-&gt;payload = rand() % 1000; //error here?
printf(""newnode payload: %i\n"", newDNode-&gt;val-&gt;payload); //seg fault before this is printed
</code></pre>

<p>Also, I have already ran this line in the program: <code>srand((unsigned)time(NULL))</code> </p>
","922184","","<p>You problem is that you never initialized the pointer <code>val</code>:</p>

<pre><code>newDNode-&gt;val-&gt;payload = rand() % 1000;
</code></pre>

<p><code>newDNode</code> is allocated, but none of the fields are initialized, so dereferencing <code>val</code> will likely cause that segmentation fault.</p>

<p>So you will need to allocate something for <code>val</code> before you access it.</p>

<pre><code>newDNode = malloc(sizeof(struct dListNode));   //  Allocate ""dListNode""
newDNode-&gt;val = malloc(sizeof(struct data));   //  Allocate ""data""
newDNode-&gt;val-&gt;payload = rand() % 1000;
</code></pre>

<p>You have a slight misunderstanding of how the allocation works. You need to allocate each pointer separately.</p>

<p><strong>EDIT :</strong> And alternate approach is just to not use a pointer for <code>val</code> in the first place:</p>

<pre><code>//  Declare struct as:
struct dListNode{
    struct dListNode *next;
    struct dListNode *prev;
    struct data val;
}*dHead, *dTail;


//  Build object like this:
newDNode = malloc(sizeof(struct dListNode));
newDNode-&gt;val.payload = rand() % 1000;
</code></pre>
"
"<p>Assume I have the variable <code>x</code> initialized to <code>425</code>. In binary, that is <code>110101001</code>.</p>

<p>Bitshifting it to the right by 2 as follows: <code>int a = x &gt;&gt; 2;</code>, the answer is: <code>106</code>. In binary that is <code>1101010</code>. This makes sense as the two right-most bits are dropped and two zero's are added to the left side.</p>

<p>Bitshifting it to the left by 2 as follows: <code>int a = x &lt;&lt; 2;</code>, the answer is: <code>1700</code>. In binary this is <code>11010100100</code>. I don't understand how this works. Why are the two left most bits preserved? How can I drop them?</p>

<p>Thank you,</p>
","922184","","<p>This is because <code>int</code> is probably 32-bits on your system. (Assuming x is type <code>int</code>.)</p>

<p>So your <code>425</code>, is actually:</p>

<pre><code>0000 0000 0000 0000 0000 0001 1010 1001
</code></pre>

<p>When left-shifted by 2, you get:</p>

<pre><code>0000 0000 0000 0000 0000 0110 1010 0100
</code></pre>

<p>Nothing gets shifted off until you go all the way past 32. (Strictly speaking, overflow of signed-integer is undefined behavior in C/C++.)</p>

<p>To drop the bits that are shifted off, you need to bitwise AND against a mask that's the original length of your number:</p>

<pre><code>int a = (425 &lt;&lt; 2) &amp; 0x1ff;  //  0x1ff is for 9 bits as the original length of the number.
</code></pre>
"
"<p>Trying to assess the performance gain from an embedded architecture I tried to search for the number of <strong>floating point</strong> multiplies that can be performed in a cycle on a single core of the Core 2 and Core i7 architectures, but could not find a quick answer to that. Unfortunately I am not familiar with the ISA so I cannot tell that from looking at the respective instructions. I assume it would be some kind of a SIMD instruction. Any idea?</p>
","922184","","<p>One thing: Core 2 is <strong><em>not</em></strong> Intel's latest architecture. That would be Sandy Bridge.</p>

<p>Core 2 and Core i7 Nehalem, can sustain <strong>1 SSE multiply/cycle</strong>. Each SSE instruction can handle up to 4 single-precision or 2 double-precision. So that's <strong>2 DP or 4 SP floating-point multiplies per cycle</strong>.</p>

<p>Core i7 Sandy Bridge can sustain <strong>1 AVX multiply/cycle</strong>. AVX is double the size of SSE. So that's <strong>4 DP or 8 SP floating-point multiplies per cycle</strong>.</p>
"
"<p>I am using Microsoft Visual Studio 2010. I wanted to measure time in micro seconds in C language on windows 7 platform. How can I do that.</p>
","922184","","<p>The way to get accurate time measurements is via performance counters.</p>

<p>In Windows, you can use <code>QueryPerformanceCounter()</code> and <code>QueryPerformanceFrequency()</code>:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms644904%28v=vs.85%29.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/windows/desktop/ms644904%28v=vs.85%29.aspx</a></p>

<p><strong>EDIT : Here's a simple example that measures the time needed to sum up from 0 to 1000000000:</strong></p>

<pre><code>LARGE_INTEGER frequency;
LARGE_INTEGER start;
LARGE_INTEGER end;

//  Get the frequency
QueryPerformanceFrequency(&amp;frequency);

//  Start timer
QueryPerformanceCounter(&amp;start);

//  Do some work
__int64 sum = 0;
int c;
for (c = 0; c &lt; 1000000000; c++){
    sum += c;
}
printf(""sum = %lld\n"",sum);


//  End timer
QueryPerformanceCounter(&amp;end);

//  Print Difference
double duration = (double)(end.QuadPart - start.QuadPart) / frequency.QuadPart;
printf(""Seconds = %f\n"",duration);
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>sum = 499999999500000000
Seconds = 0.659352
</code></pre>
"
"<p>trying to initialize a string from a vector. I am supposed to get ""hey"" as the output. but I got ""segmentation fault"". what did I do wrong?</p>

<pre><code>//write a program that initializes a string from a vector&lt;char&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
using namespace std;
int main ()
{
    vector&lt;char&gt; cvec;
    cvec[0]='h';
    cvec[1]='e';
    cvec[2]='y';
    string s(cvec.begin(),cvec.end());
    cout&lt;&lt;s&lt;&lt;endl;
    return 0;
}
</code></pre>
","922184","","<p>The vector class starts out with a size of zero (by default). So doing that will cause undefined behavior. (in your case, a segmentation fault)</p>

<p>You should use <code>push_back()</code> instead:</p>

<pre><code>vector&lt;char&gt; cvec;
cvec.push_back('h');
cvec.push_back('e');
cvec.push_back('y');
</code></pre>

<p>This will append each <code>char</code> to the vector.</p>
"
"<p>System config:  Win 7 64bit, visual Studio 2010 Premium, dell t7500 with 2 xeon 5690 chips, 48 gig of ram.  Each xeon has 6 cores, so there are 12 physical cores.  With hyperthreading, there should be 24 logical cores.</p>

<p>In my C app:</p>

<pre><code>Session.coresAvailable  =    omp_get_num_procs ( );
Session.threadsAvailable    =    omp_get_max_threads ( ) ;
</code></pre>

<p>The system comes back and tells me there are 12 cores and 12 threads.  Shouldn't it be 24 threads?</p>
","922184","","<p>Converting comment to answer:</p>

<p>You need to enable HyperThreading in the BIOS to see all 24 threads.</p>
"
"<p>I have this function that takes an array of 512 Vertices. (each one containing x,y,z coordinates). Anyway, I made a mistake and instead of accessing the array 512 times, I did it 513 times. Instead of ""zeros"" I got a number. I run it again, the same. I increased the iterations and the same thing again. Even though I was going beyond the limits of the array random values were showing up each time I the function. What are those values? Am I accessing anything in the OS? (it may sound stupid but im new to C++ and pointers)</p>

<pre><code>void print_facet_array(FACET3 *f)
{
    int i=0;
    for (i=0;i&lt;=513;i++)
    {
        printf(""The vertices (x,y,z) for facet %d are: V_1 =  x:%f , y:%f, z:%f. \n"", i, f[i].p1.x, f[i].p1.y, f[i].p1.z);
        printf(""The vertices (x,y,z) for facet %d are: V_2 =  x:%f , y:%f, z:%f. \n"", i, f[i].p2.x, f[i].p2.y, f[i].p2.z);
        printf(""The vertices (x,y,z) for facet %d are: V_3 =  x:%f , y:%f, z:%f. \n"", i, f[i].p3.x, f[i].p3.y, f[i].p3.z);
    }

}
</code></pre>
","922184","","<p>Actually, your loop goes through 514 times. So you're overrunning by 2.</p>

<p>Overrunning an array in C/C++ is completely undefined behavior. Anything can happen (crash, bad data).</p>

<p>In your case, you're probably reading stack or heap garbage - which can be anything.</p>
"
"<p>I am trying to initialize a heap-allocated object as follows:</p>

<pre><code>class Ball {
  int radius;
  string colour;
};

int main(){
    Ball *b = new Ball { radius = 5, colour = ""red"" };
}
</code></pre>

<p>Wondering why this is giving me an error?
Thanks</p>
","922184","","<p>That's not how you initialize an object in C++.</p>

<p>Here's one way to do it:</p>

<pre><code>class Ball {
    int radius;
    string colour;

public:

    //  Define a Constructor
    Ball(int _radius, const string &amp;_colour)
        : radius(_radius)
        , colour(_colour)
    {
    }
};

int main(){
    Ball *b = new Ball(5, ""red"");

    delete b;  //  Don't forget to free it.
}
</code></pre>
"
"<p>Today I've a weird question.</p>

<p><b>The Code(C++)</b></p>

<pre><code>#include &lt;iostream&gt;

union name
{
    int num;
    float num2;

}oblong;


int main(void)
{
    oblong.num2 = 27.881;

    std::cout &lt;&lt; oblong.num &lt;&lt; std::endl;

    return 0;
}
</code></pre>

<p><b>The Code(C)</b></p>

<pre><code>#include &lt;stdio.h&gt;

int main(void)
{
    float num = 27.881;

    printf(""%d\n"" , num);

    return 0;
}
</code></pre>

<p><b>The Question</b></p>

<ol>
<li><p>As we know, C++ unions can hold more than one type of data element but only one type at a time. So basically the <code>name oblong</code> will only reserve one portion of memory which is 32-bit (because the biggest type in the union is 32-bit, int and float) and this portion could either hold a integer or float.</p></li>
<li><p>So I just assign a value of 27.881 into <code>oblong.num2</code> (as you can see on the above code). But out of curiosity, I access the memory using <code>oblong.num</code> which is pointing to the same memory location.</p></li>
<li><p>As expected, it gave me a value which is not 27 because the way float and integer represented inside a memory is different, that's why when I use <code>oblong.num</code> to access the memory portion it'll treat that portion of memory value as integer and interpret it using integer representation way.</p></li>
<li><p>I know this phenomena also will happen in C , that's why I initialize a float type variable with a value and later on read it using the <code>%d</code>.So I just try it out by using the same value <code>27.881</code> which you can see above. But when I run it, something weird happens, that is the value of the one I get in C is different from C++.</p></li>
<li><p>Why does this happen? From what I know the two values I get from the two codes in the end are not garbage values, but why do I get different values? I also use the sizeof to verified both C and C++ integer and float size and both are 32-bit. So memory size isn't the one that causes this to happen, so what prompt this difference in values?</p></li>
</ol>
","922184","","<p>First of all, having the wrong <code>printf()</code> format string is undefined behavior. Now that said, here is what is actually happening in your case:</p>

<p>In vararg functions such as <code>printf()</code>, integers smaller than <code>int</code> are promoted to <code>int</code> and floats smaller than <code>double</code> are promoted to <code>double</code>.</p>

<p>The result is that your <code>27.881</code> is being converted to an 8-byte double as it is passed into <code>printf()</code>. Therefore, the binary representation is no longer the same as a <code>float</code>.</p>

<p>Format string <code>%d</code> expects a 4-byte integer. So in effect, you will be printing the lower 4-bytes of the double-precision representation of <code>27.881</code>. (assuming little-endian)</p>

<p>*Actually (assuming strict-FP), you are seeing the bottom 4-bytes of <code>27.881</code> after it is cast to <code>float</code>, and then promoted to <code>double</code>.</p>
"
"<p>I've been working on a project in C that requires me to mess around with strings a lot.  Normally, I do program in C++, so this is a bit different than just saying string.empty().</p>

<p>I'm wondering what would be the proper way to empty a string in C.  Would this be it?</p>

<pre>
buffer[80] = ""Hello World!\n"";

// ...

strcpy(buffer, """");
</pre>
","922184","","<p>It depends on what you mean by ""empty"". If you just want a zero-length string, then your example will work.</p>

<p>This will also work:</p>

<pre><code>buffer[0] = '\0';
</code></pre>

<p>If you want to zero the entire contents of the string, you can do it this way:</p>

<pre><code>memset(buffer,0,strlen(buffer));
</code></pre>

<p>but this will only work for zeroing up to the first NULL character.</p>

<p>If the string is a static array, you can use:</p>

<pre><code>memset(buffer,0,sizeof(buffer));
</code></pre>
"
"<p>Which macro statement may cause an unexpected results ? </p>

<pre><code>#define YEAR_LENGTH   365
#define MONTH_LENGTH  30
 #define DAYCALC(y, m, d) ((y * YEAR_LENGTH) + (m * MONTH_LENGTH) + d)

 int main()
 {
    int x = 5, y = 4 , z = 1;
    cout &lt;&lt; DAYCALC(x *3 , y %3 , z) &lt;&lt; endl ;
    cout &lt;&lt; DAYCALC(x +12 , y  , 300) &lt;&lt; endl ;
    cout &lt;&lt; DAYCALC(x , 40 - y , 3+z) &lt;&lt; endl ;
    cout &lt;&lt; DAYCALC(x  , y  , (z+50)) &lt;&lt; endl ;
    cout &lt;&lt; DAYCALC(x  , y %3 , z) &lt;&lt; endl ;
    cout &lt;&lt; DAYCALC(4 % x , y++ , z) &lt;&lt; endl;
    return 0;
 }
</code></pre>

<p>I run the program very well w/o any unexpected results. </p>

<p>Are there some hidden exceptions ? </p>
","922184","","<p>You have an operator precendence problem. Macros are literally expanded as text copy and paste.</p>

<p>For example:</p>

<pre><code>DAYCALC(x , 40 - y , 3+z)
</code></pre>

<p>gets expanded to:</p>

<pre><code>((40 - y * YEAR_LENGTH) + (x * MONTH_LENGTH) + 3+z)
</code></pre>

<p>Note that <code>40 - y * YEAR_LENGTH</code>, is not what you want due to operator precedence.</p>

<p>So you need to put <code>()</code> around your parameters in the macro:</p>

<pre><code>#define DAYCALC(y, m, d)     (((y) * YEAR_LENGTH) + ((m) * MONTH_LENGTH) + (d))
</code></pre>

<p>In general, if a macro parameter appears more than once in the macro, side effects such as <code>y++</code> (in your last statement) will also be applied more than once. So it's something to be careful of.</p>
"
"<p>I'm doing a simple challenge for a programming book that's asks to output the result of the formula f = (a − b)(x − y) using a single printf() function. and I get this Error: ""error: called object ‘a - b’ is not a function""</p>

<p>Here is the code:</p>

<pre><code>#include &lt;stdio.h&gt;

 main()
 {
       int a = 5;
       int b = 1;
       int x = 10;
       int y = 5;

       printf(""\nThe result of f = %d\n"", (a-b)(x-y));
}
</code></pre>
","922184","","<p>C/C++ doesn't allow implicit multiplication like in math. So you need to use *:</p>

<pre><code>printf(""\nThe result of f = %d\n"", (a-b) * (x-y) );
                                         ^
                                   insert * here
</code></pre>

<p>As it is right now, <code>(a-b)</code> is being treated as a function call with a single parameter of <code>x-y</code>. Of course <code>a-b</code> is not a function, therefore you are getting the error that you are seeing.</p>
"
"<p>main.h</p>

<pre><code>#define  DATA  struct   data
DATA
{
  int id;
  char data;
}
</code></pre>

<p>main.c</p>

<pre><code>DATA *listOfData[100];
</code></pre>

<p>So at this point I will/should be able to access DATA in the list like this:</p>

<pre><code>printf(listOfData[5]-&gt;data);
</code></pre>

<p>It isn't letting me do it, the run just freezes on that last print f...no error or anything. </p>
","922184","","<p>This is because you have defined an array of pointers. But you never initialized any of the pointers.</p>

<p>Therefore:</p>

<pre><code>printf(listOfData[5]-&gt;data);
</code></pre>

<p>will crash (undefined behavior) because you are dereferencing the (invalid) pointer at index 5.</p>

<p>*(And that's a very odd way to define a struct...)</p>

<p>To fix this issue, you will need to allocate for each of the pointers in the array. If you don't actually need it to be an array of pointers, then it might be better to just make it array of the struct itself:</p>

<pre><code>DATA listOfData[100];
</code></pre>

<p>and access it as:</p>

<pre><code>listOfData[5].data
</code></pre>

<p>Then you don't have to deal with allocating each element.</p>
"
"<p>I was asked how can a value of a const variable can be changed.</p>

<p>My my obvious answer was ""pointers!"" but I tried the next piece of code and I'm puzzled...</p>

<pre><code>int main()
{
    const int x = 5;
    int *ptr = (int *)(&amp;x); // ""Cast away"" the const-ness..
    cout &lt;&lt; ""Value at "" &lt;&lt; ptr &lt;&lt; "":""&lt;&lt; (*ptr) &lt;&lt;endl;
    *ptr = 6;
    cout &lt;&lt; ""Now the value of ""&lt;&lt; ptr &lt;&lt; "" is: "" &lt;&lt; (*ptr) &lt;&lt;endl;
    cout &lt;&lt; ""But the value of x is still "" &lt;&lt; x &lt;&lt;endl;
    return 0;
}
</code></pre>

<p>And the output was:</p>

<pre><code>Value at &lt;some address&gt; :5
Now the value of &lt;same address&gt; is: 6
But the value of x is still 5
</code></pre>

<p>Now, I'm not sure exactly what is returned from '&amp;x' but it's definitely not the actual address of x, since the value at x wasn't changed! </p>

<p>But on the over hand, ptr <strong>did</strong> contain the value of x at the beginning!
So, what is it exactly?</p>

<p><strong>EDIT</strong> compiled with VS2010</p>
","922184","","<p>First of all, this behavior is undefined. That said, here's what's probably going on:</p>

<p>When you do this:</p>

<pre><code>int *ptr = (int *)(&amp;x);
</code></pre>

<p>The <code>5</code> is stored at some address at somewhere. That's why the pointer seems to work properly. (although casting away the const is still undefined behavior)</p>

<p>However, due to compiler optimizations <code>x = 5</code> is just inlined as a literal in the final print statement. The compiler thinks it's safe because <code>x</code> is declared <code>const</code>.</p>

<pre><code>cout &lt;&lt; ""But the value of x is still "" &lt;&lt; x &lt;&lt;endl;
</code></pre>

<p>That's why you print out the original value 5.</p>
"
"<pre><code>std::vector&lt;float&gt; someOp(void)
{
    using namespace std;
    vector&lt;float&gt; results;
    // some operations done to results
    return results;
}

int main(void)
{
    using namespace std;
    vector&lt;float&gt; &amp;results = someOp();
}
</code></pre>

<p>Does the vector returned by someOp exist in the someOp() stack space or in the main() stack space?</p>

<p>I'm inclined to believe that it doesn't get copied/moved to the main() stack space since the results vector has the same address inside of both methods.</p>
","922184","","<p>It's a little more complicated than that.</p>

<p>Yes, it is initially in the stack space of <code>someOp</code>. But since you return by value, a copy is made. So it isn't lost (yet).</p>

<p>However, when you store it into <code>vector&lt;float&gt; &amp;results</code>, you store a reference to it. Which becomes invalid after the statement ends. The returned vector is an intermediate that is destroyed after the statement ends.</p>

<p>So the end result is that <code>vector&lt;float&gt; &amp;results</code> becomes a dangling ""pointer"".</p>

<p><strong>EDIT :</strong> (see comments)</p>

<p>Apparently, the code isn't supposed to compile at all. But it does in VS2010. So my answer only applies to the case where it does compile.</p>
"
"<p>I am getting this error for every int in this section of code;</p>

<pre><code>    if(choice==2)
    {inssort(int *a, int numLines);}
    if(choice==3)
    {bubblesort(int *a, int numLines);}
    if(choice==4) 
    {mergesort(int *a, int numLines);}
    if(choice==5) 
    {radixsort(int *a, int numLines);}
    if(choice==6) 
    {return 0;}
</code></pre>

<p>Thats where I call the functions in main.  If you are wondering I am writing a small program that gives the user a choice when sorting a list between 4 different types of sorting algorithms.</p>

<p>Any help would be appreciated.</p>
","922184","","<p>You can't use the declaration types when you're <strong><em>calling</em></strong> the functions. Only when you <strong><em>declare</em></strong> them are they needed:</p>

<pre><code>if(choice==2)
{
    inssort(a, numLines);
}
if(choice==3)
{
    bubblesort(a, numLines);
}
if(choice==4) 
{
    mergesort(a, numLines);
}
if(choice==5) 
{
    radixsort(a, numLines);
}
if(choice==6) 
{
    return 0;
}
</code></pre>
"
"<p>I was going through the stdio.h header file that comes with MinGW and noticed that the <code>printf</code> function is declared like this:</p>

<pre><code>int printf (const char *__format, ...)
{
    //body omitted
}
</code></pre>

<p>I have never seen ellipsis in function parameter list before so I tried it out. It compiles and runs without error. What, then, is the purpose of ""...""? </p>
","922184","","<p>That means that the function is a variadic function that takes a variable number of parameters:</p>

<p><a href=""http://en.wikipedia.org/wiki/Variadic_function"">http://en.wikipedia.org/wiki/Variadic_function</a></p>

<p><code>printf()</code> itself is probably the best example of a variadic function.</p>
"
"<p>I'm a little confused here- would comparison of doubles still work correctly when they're stored as opaque (binary) fields? The problem I'm facing is the fact that the double includes a leading bit for the sign (i.e. positive or negative) and when they're stored as binary data I'm not sure it will be compared correctly:</p>

<p><img src=""http://i.stack.imgur.com/VzSNv.png"" alt=""enter image description here""></p>

<p>I want to ensure that the comparison will work correctly, because I'm using a double as a part of a <a href=""http://leveldb.googlecode.com/svn/trunk/doc/index.html"">key tuple (e.g. ) in LevelDB</a> and I want to preserve the data locality for positive and negative numbers. LevelDB only uses opaque fields as keys, but it does allow the user to specify his/her own comparator.  However, I just want to make sure that I don't specify a comparator unless I absolutely need to:</p>

<pre><code>// Three-way comparison function:
//   if a &lt; b: negative result
//   if a &gt; b: positive result
//   else: zero result
inline int Compare(const unsigned char* a, const unsigned char* b) const 
{
    if (*(double*)a &lt; *(double*)b) return -1;
    if (*(double*)a &gt; *(double*)b) return +1;
    return 0;
}
</code></pre>
","922184","","<p>Making my comments an answer.</p>

<p>There are two things that could go wrong:</p>

<ol>
<li><p>If either (or both) parameters is <code>NAN</code>, comparisons will always return false. So even if the binary representation is the same, <code>NAN == NAN</code> will always be false. Furthermore, it violates comparison transitivity.</p></li>
<li><p>If either parameter isn't properly aligned (since they are char pointers), you could run into problems on machines that don't support misaligned memory access. And for those that do, you may encounter a performance hit.</p></li>
</ol>

<p>So to get around this problem, you'll need to add a trap case that will be invoked if either parameter turns out to be <code>NAN</code>. (I'm not sure on the status of <code>INF</code>.)</p>

<p>Because of the need for this trap case, you will need to define your own comparison operator.</p>
"
"<p>I don't understand the problem here. I've researched it, it compiles fine but when I run the program it gives me the ""Debug Assertion Failed!"" error and the above explanation.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;string&gt;
using namespace std;


bool checkVowel(char ch)
{
 switch(ch)
 {
     case 'a':
     case 'A':
     case 'e':
     case 'E':
     case 'i':
     case 'I':
     case 'o':
     case 'O':
     case 'u':
     case 'U':
          return true;
     default:
          return false;
 }}
int main()
{
string str;
char ch;
cout&lt;&lt;""Please enter a string, all vowels will be removed: "";
cin &gt;&gt; str;

for (int i=0;i=str.length();i++)
{

 if (checkVowel(str[i]))
     {
        str=str.erase(i);
 }}

cout &lt;&lt; str;
}
</code></pre>
","922184","","<p>One error is here:</p>

<pre><code>i=str.length()
</code></pre>

<p>should be:</p>

<pre><code>i &lt; str.length()
</code></pre>

<p>In your initial code, <code>i=str.length()</code> will always return true when the string is not-empty. So the effect is that you will be overrunning the string.</p>

<p>Furthermore, you don't want to increment the index when you do find a vowel, or you will skip the next character:</p>

<pre><code>for (int i = 0; i &lt; str.length(); )
{
    if (checkVowel(str[i]))
    {
        str.erase(i,1);
    }else{
        i++;
    }
}
</code></pre>

<p>Last thing: <code>str=str.erase(i);</code> is not necessary, just <code>str.erase(i,1);</code> is enough. (You'll need the second parameter as 1 as pointed out in the comments.)</p>
"
"<pre><code>for (int i = 0; i &lt; s.length(); ++i) 
    {
        if (s.charAt(i) &gt;= 'A' &amp;&amp; s.charAt(i) &lt;= 'Z') 
        {
            ++array[s.charAt(i) - 'A'];
        }
    }
</code></pre>

<p>I understand the For loop. the s.length() is 26, int[26] to be exact. so this loop will occur 26 times, 0-25. If the Char at i, 0-25 is between or are A-Z it will then proceed to <code>++array[s.charAt(i) - 'A'];</code> From what i see it adds array once per loop, or adds the value of array once per loop, for the String at char i so the first one would be 0 second would be 2,  because arrays start at 0. so adding an array at location of <code>i -'A'</code> is where i get confused.</p>
","922184","","<p>The statement <code>++array[s.charAt(i) - 'A'];</code> is incrementing the value in the array indexed by <code>s.charAt(i) - 'A'</code>.</p>

<p>What this loop does is that it counts up the number of occurrences of each letter in <code>s</code>.</p>

<p>The reason for <code>- 'A'</code>, is that it ""shifts"" the ascii/unicode value so that <code>A - Z</code> have values 0 - 25. And are thus more suitable as an array index.</p>
"
"<p>I have <code>Vector</code> class, representing a 3D point, written as follows in <code>Vector.h</code>:</p>

<pre><code>class Vector {
  public:
    float x,y,z;
    Vector(float _x=0.0,float _y=0.0,float _z=0.0){x=_x;y=_y;z=_z;};
    operator float *() { return &amp;x;};
};
</code></pre>

<p>I also declare a <code>extern vector&lt;Vector&gt;model_vertices;</code> on <code>model.h</code></p>

<p>On a <code>model.cpp</code> file I implement <code>Vector.h</code> and declare a <code>std::vector&lt;Vector&gt;model_vertices; globally</code> (yes, I know the vector/Vector thing is confusing, but I must use the Vector naming for consistency). </p>

<p>On <code>model.cpp</code>, when initializing the contents of this vector I use a for loop with the following content: </p>

<pre><code>float X,Y,Z;

offFileStream&gt;&gt;X;
offFileStream&gt;&gt;Y;
offFileStream&gt;&gt;Z;


Vector v=new Vector(X,Y,Z);


model_vertices[loadVertexIndex]=v;
</code></pre>

<p>I get the following error:</p>

<pre><code>error C2440: 'initializing' : cannot convert from 'Vector *' to 'Vector'
</code></pre>

<p>Why?</p>
","922184","","<p>The error is on this line:</p>

<pre><code>Vector v=new Vector(X,Y,Z);
</code></pre>

<p><code>v</code> is of type <code>Vector</code>, but <code>new Vector(X,Y,Z)</code> returns a <code>Vector*</code>:</p>

<p>What you probably wanted instead is just:</p>

<pre><code>Vector v(X,Y,Z);
</code></pre>

<p>As a side note, I didn't see you initialize a size for the <code>model_vertices</code>. So you may want to use <code>push_back()</code> instead.</p>
"
"<p>I don't know much about compilers, but know they are complicated and smart enough to optimize your code.  Say I had code that looked like this:</p>

<pre><code> string foo = ""bar"";
 for(int i = 0; i &lt; foo.length(); i++){
     //some code that does not modify the length of foo
 }
</code></pre>

<p>Would the GNU compiler be smart enough to realize that the length of <code>foo</code> does not change over the course of this loop and replace the <code>foo.length()</code> call with the proper value?  Or would <code>foo.length()</code> be called for every <code>i</code> comparison? </p>
","922184","","<p>The only way to know for sure is to try it and take a look at the assembly.</p>

<p>My guess is that if the call to <code>length()</code> is inlined, then <a href=""http://en.wikipedia.org/wiki/Loop-invariant_code_motion"" rel=""nofollow"">Loop Invariant Code Motion</a> will hoist the internals of <code>length()</code> out of the loop and replace it with a single variable.</p>

<p>As a second thought, this might even be moot. The size of a string is probably just a simple field in the <code>string</code> class - which is on the stack. So just inlining the call to <code>length()</code> will already have the effect of reducing the call to a simple variable access.</p>

<p><strong>EDIT :</strong>
In this latter case, it doesn't even matter whether or not the length of <code>foo</code> is modified inside the loop. Getting the length of a string is already just a variable access.</p>
"
"<p>I am new to C programming and I am unable to figure out why this is happening.</p>

<pre><code>char *example(char *temp) {
      char *xyz;
      memset(xyz,0,strlen(temp));
      strncpy(xyz,temp,3);
      strcat(xyz,""XX);
      return xyz;
      }

int main() {
      char temp[] = ""ABCDEF""
      char *xyz;
      xyz = example(temp);
      printf(""Returned string is: %s"",xyz);
      return 0;
      }
</code></pre>

<p>I just want to know what all I am doing wrong cause I tried to run GDB and it showed I am trying to access some unreachable part of memory but am not able to figure it out. Thanks in advance.</p>
","922184","","<p>The problem is here:</p>

<pre><code>char *xyz;
memset(xyz,0,strlen(temp));
</code></pre>

<p>You never initialized <code>xyz</code>. Therefore it's an invalid pointer.</p>

<p>What you need to do it allocate something for it:</p>

<pre><code>char *xyz = malloc(strlen(temp) + 1);   //  Allocate, +1 is for the '\0'.
memset(xyz,0,strlen(temp));
</code></pre>

<p>and free it when you're done with it:</p>

<pre><code>int main() {
    char temp[] = ""ABCDEF""
    char *xyz;
    xyz = example(temp);
    printf(""Returned string is: %s"",xyz);

    free(xyz);   //  Free

    return 0;
}
</code></pre>

<p><strong>EDIT : Other problems:</strong></p>

<p>These 3 lines here are very dangerous:</p>

<pre><code>  memset(xyz,0,strlen(temp));
  strncpy(xyz,temp,3);   //  The nul is not copied in strncpy.
  xyz[3] = '\0';         //  Add the nul manually.
  strcat(xyz,""XX"");      //  You need to ensure that xyz is large enough.
</code></pre>
"
"<p>This is a function call (so it is just a part of the whole program). It will generate a segmentation fault. I guess it is caused by ""pointer being a local variable""?</p>

<pre><code>int fileExists(const char *fname){
    int i = 0;
    fseek(fs, sizeof(NODE)*i, SEEK_SET);
    NODE* pointer;
    fread(pointer, sizeof(NODE), 1, fs);
    return 1;
}
</code></pre>

<p>Updated:</p>

<pre><code>typedef struct node {
    char fname[MAX_NAME];
    short fstart;
} NODE;

int findStart (const char *fname){
    fs = fopen(""Directory"", ""w+"");
    NODE* pointer = malloc(sizeof(NODE));
    int i;
    for(i=0;i&lt;numberNodes;i++){
        fseek(fs, sizeof(NODE)*i, SEEK_SET);
        fread(pointer, sizeof(NODE), 1, fs);
        if(strcmp(pointer-&gt;fname, fname)==0)
            return pointer-&gt;fstart;
    }
    return 0;
}
</code></pre>

<p>So if I want to run through the nodes in the directory file and find the ""fstart"" of the right node, can I achieve that without the need of free-ing the memory allocated to ""pointer""?</p>
","922184","","<p>The problem is here:</p>

<pre><code>NODE* pointer;
fread(pointer, sizeof(NODE), 1, fs);
</code></pre>

<p>You never allocated any space for <code>NODE</code>.</p>

<pre><code>NODE* pointer = malloc(sizeof(NODE));
</code></pre>

<p>However, I'm not sure what the purpose is since you're immediately leaving the function. Don't forget to later <code>free</code> the pointer.</p>

<p>Based on the name of the function <code>fileExists</code>, all you probably need to do is to just try to open the file, check whether it succeeds or fails, then return. All the code here is unnecessary.</p>

<p>Something like this will (almost) do what I think you want:</p>

<pre><code>int fileExists(const char *fname){
    FILE *file = fopen(fname,""r"");
    if (file == NULL)
        return 0;
    fclose(file);
    return 1;
}
</code></pre>

<p><strong>EDIT : Answer to the new question.</strong></p>

<p>To completely avoid the <code>malloc</code> in the first place you can just put <code>NODE</code> as a local variable on the stack:</p>

<pre><code>int findStart (const char *fname){
    fs = fopen(""Directory"", ""w+"");
    NODE node;
    int i;
    for(i=0;i&lt;numberNodes;i++){
        fseek(fs, sizeof(NODE)*i, SEEK_SET);
        fread(&amp;node, sizeof(NODE), 1, fs);
        if(strcmp(node.fname, fname)==0)
            return node.fstart;
    }
    return 0;
}
</code></pre>
"
"<p>I am diving into C after long time and struggling with reading and writing struct to the simple text file. I debuged this prog and I found out its reading and writing garbage value to the file. Can someone help me. Here is my code</p>

<pre><code>#define MAX_UserName_LEN 16
#define MAX_Password_LEN 8
#define MAX_FileName_LEN 32

struct userDetails
{
char userName[MAX_UserName_LEN];
char password[MAX_Password_LEN];
};

int registration(struct userDetails userInfo)
{
FILE *userDb;
userDb= fopen(""UserDataBase.txt"",""a"");
if(fwrite(&amp;userInfo,sizeof(userInfo),1,userDb))
{
    fclose(userDb);
    return 1;
}
else
{
    return 0;
}

}

int authenicate(struct userDetails userInfo)
{
FILE *userDb;
struct userDetails temp;
userDb = fopen(""UserDataBase.txt"",""r"");
while(!feof(userDb))
{
  fread(&amp;temp,sizeof(temp),1,userDb);
  if (temp.userName==userInfo.userName &amp;&amp; temp.password==userInfo.password)
  {
    printf(""Logged In Sucessfully"");
    return 1;
  }
 }
 return 0;

}
</code></pre>

<p>In main function, I an just declaring one struct variable and accepting user input into that struct and passing it to both above mentioned functions.</p>
","922184","","<p>The first major problem I see is here:</p>

<pre><code>if (temp.userName==userInfo.userName &amp;&amp; temp.password==userInfo.password)
</code></pre>

<p>You are trying to compare strings with <code>==</code>. You need to use <code>strcmp()</code> instead:</p>

<pre><code>if (strcmp(temp.userName, userInfo.userName) == 0 &amp;&amp; 
    strcmp(temp.password, userInfo.password) == 0)
</code></pre>

<p>I'm not sure if this has anything to do with the ""garbage"" you're getting, but it's definitely an error.</p>

<p>As your code stands right now, it will never enter the if-statement.</p>
"
"<p>I just started to use SSE to optimize my code for a computer vision project, aiming at detecting skin color in an image. Below is my function. The function takes a color image and looks at each pixel and returns a probability map. The commented out code was my original C++ implementation and the rest is the SSE version. I timed both of them and it is wierd to find out SSE isn't any faster than my original C++ code. Any suggestions about what's going on or how to optimize the function further?</p>

<pre><code>void EvalSkinProb(const Mat&amp; cvmColorImg, Mat&amp; cvmProb)
{
    std::clock_t ts = std::clock();  
    Mat cvmHSV = Mat::zeros(cvmColorImg.rows, cvmColorImg.cols, CV_8UC3);
    cvtColor(cvmColorImg, cvmHSV, CV_BGR2HSV);
    std::clock_t te1 = std::clock(); 

    float fFG, fBG;
    double dp;

    __declspec(align(16)) int frgb[4] = {0};
    __declspec(align(16)) int fBase[4] = {g_iLowHue, g_iLowSat, g_iLowVal, 0};
    __declspec(align(16)) int fIndx[4] = {0};
    __m128i* pSrc1 = (__m128i*) frgb;
    __m128i* pSrc2 = (__m128i*) fBase;
    __m128i* pDest = (__m128i*) fIndx;
    __m128i m1;

    for (int y = 0; y &lt; cvmColorImg.rows; y++)
    {
        for (int x = 0; x &lt; cvmColorImg.cols; x++)
        {
            cv::Vec3b hsv = cvmHSV.at&lt;cv::Vec3b&gt;(y, x);
            frgb[0] = hsv[0];hsv[1] = hsv[1];hsv[2] =hsv[2];
            m1 = _mm_sub_epi32(*pSrc1, *pSrc2);
            *pDest = _mm_srli_epi32(m1, g_iSValPerbinBit); 

            // c++ code
            //fIndx[0] = ((hsv[0]-g_iLowHue)&gt;&gt;g_iSValPerbinBit);
            //fIndx[1] = ((hsv[1]-g_iLowSat)&gt;&gt;g_iSValPerbinBit);
            //fIndx[2] = ((hsv[2]-g_iLowVal)&gt;&gt;g_iSValPerbinBit);

            fFG = m_cvmSkinHist.at&lt;float&gt;(fIndx[0], fIndx[1], fIndx[2]);
            fBG = m_cvmBGHist.at&lt;float&gt;(fIndx[0], fIndx[1], fIndx[2]);
            dp = (double)fFG/(fBG+fFG);
            cvmProb.at&lt;double&gt;(y, x) = dp;          
        }
    }
    std::clock_t te2 = std::clock();  
    double dSecs1 = (double)(te1-ts)/(CLOCKS_PER_SEC);
    double dSecs2 = (double)(te2-te1)/(CLOCKS_PER_SEC);
}
</code></pre>
","922184","","<p>The first problem here is that you're doing very little SSE work for a tremendous amount of data movement. You'll spend most of the time just packing/unpacking data in the SSE registers for 2 instructions...</p>

<p>Secondly, there is a very subtle performance penalty that will occur in this code.</p>

<p>You are using a buffer to transfer data between variables and SSE registers. This is a <strong>BIG NO-NO</strong>.</p>

<p>The reason for this is in the CPU load/store unit. When you write data to a memory location, and then immediately attempt to read it back in a different word size, it usually forces the data to be flushed all the way to cache and re-read. This can incur 20+ cycles of penalty.</p>

<p>This is because CPU load/store units are not optimized for this kind of unusual access.</p>
"
"<p>I have created the following program which allows a user to guess a word 3 times before ending the program. I'm using a function to read the users input. When I compile the program I get the error 'expected expression before char'. Some feedback would be great thanks!</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void get_user_input(char *guess[10]);

void get_user_input(char *guess[10])
{ 
     printf(""Please guess the word: \n"");
     scanf(""%s"", guess);
}

int main(void)
{
     const char secret[10] = ""pink"";
     char guess[10];
     int i;

     for (i=0; i &lt; 3; i++)
     {
         get_user_input(char *guess[10]);

         if (strcmp(secret, guess)==0)
         {
             printf(""Your guess was correct"");
             return 0;
         }
         else
         {
             printf(""Your guess was incorrect. Please try again\n"");
         }
     } 
     return 0;
}
</code></pre>
","922184","","<p>You have an extra <code>char</code> here:</p>

<pre><code>for (i=0; i &lt; 3; i++)
{
    get_user_input(char *guess[10]);
</code></pre>

<p>Just get rid of it. You just need to pass the variable in.</p>

<pre><code>get_user_input(guess);
</code></pre>

<p><strong>EDIT :</strong></p>

<p>The other problem seems to be this function:</p>

<pre><code>void get_user_input(char *guess[10]);
</code></pre>

<p>change it to this:</p>

<pre><code>void get_user_input(char *guess)
{ 
 printf(""Please guess the word: \n"");
 scanf(""%s"", guess);
}
</code></pre>

<p>and it should work. However, be aware that you run the risk of overrunning your <code>guess</code> array.</p>
"
"<p>In linux systems, pthreads library provides us a function (posix_memalign) for cache alignment to prevent false sharing. And to choose a specific NUMA node of the arhitecture we can use libnuma library. What I want is something needing both two. I bind certain threads to some certain processors and I want allocate local data structures for each thread from the corresponding NUMA node in order to decrease delay in memory operations for the threads. How can I do this?</p>
","922184","","<p>If you're just looking to get the alignment functionality around a NUMA allocator, you can easily build your own.</p>

<p>The idea is to call the unaligned <code>malloc()</code> with a little bit more space. Then return the first aligned address. To be able to free it, you need to store the base address at a known location.</p>

<p>Here's an example. Just substitute the names with whatever is appropriate:</p>

<pre><code>pint         //  An unsigned integer that is large enough to store a pointer.
NUMA_malloc  //  The NUMA malloc function
NUMA_free    //  The NUMA free function

void* my_NUMA_malloc(size_t bytes,size_t align, /* NUMA parameters */ ){

    //  The NUMA malloc function
    void *ptr = numa_malloc(
        (size_t)(bytes + align + sizeof(pint)),
        /* NUMA parameters */
    );

    if (ptr == NULL)
        return NULL;

    //  Get aligned return address
    pint *ret = (pint*)((((pint)ptr + sizeof(pint)) &amp; ~(pint)(align - 1)) + align);

    //  Save the free pointer
    ret[-1] = (pint)ptr;

    return ret;
}

void my_NUMA_free(void *ptr){
    if (ptr == NULL)
        return;

    //  Get the free pointer
    ptr = (void*)(((pint*)ptr)[-1]);

    //  The NUMA free function
    numa_free(ptr); 
}
</code></pre>

<p>To when you use this, you need to call <code>my_NUMA_free</code> for anything allocated with <code>my_NUMA_malloc</code>.</p>
"
"<p>I have a C++ program which is compiled under gcc (gcc version 4.5.1) with the -O3 flag.  I'm thinking about whether or not it would be worthwhile making an SSE2 version of this program (or at least, the busiest of it).  However, I'm worried that the compiler has already done this through automatic vectorization.</p>

<blockquote>
  <p><strong>Question</strong>: How do I determine (a) whether or not my program is using SSE/SSE2 and (b) how much time is spent using SSE/SSE2 (i.e. profiling)?</p>
</blockquote>
","922184","","<p>The easiest way to tell if you are gaining any benefit from compiler vectorization is to run the code with and without the <code>-ftree-vectorize</code> flag and compare the results.</p>

<p><code>-O3</code> will automatically enable that option. So you might want to try it under <code>-O2</code> instead.</p>

<p>To see which loops were vectorized, which were not, and why, you can add the <code>-ftree-vectorizer-verbose</code> option.</p>

<p>The last option, of course, is to look at the assembly. It's very easy to identify vectorized code in assembly.</p>
"
"<p>I'm getting an error I don't understand and can't find a solution.</p>

<p>The error is as follows:</p>

<p>missing prototype for isANumber</p>

<p>the code it refers to is:</p>

<pre><code>double prompt(char *promptString) {

    printf(""%s"", promptString);
    char *input = """";
    scanf(""%s"", &amp;*input);
    printf(""%s\n"", &amp;*input);

    int check = isANumber(input);


if (check) {
    return (double) *input;
} else {
    return 0.00;
}

}

int isANumber(char *check) {

    int result = 0;    /* Current isdigit() return value */
    do                           /* Check that each character of the...*/
        result = isdigit(*check++);  /* ...string is a digit and move on...*/
    while (result &amp;&amp; *check);       /* ...until non-digit found or at EOS */
    return result;  /* Return result of last isdigit() call */

}
</code></pre>

<p>libraries included:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;limits.h&gt;
#include &lt;ctype.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
</code></pre>

<p>Any help would be appreciated :)</p>
","922184","","<p>You can't forward reference like that. You need to declare or define <code>isANumber</code> before you can reference it:</p>

<p>Put this before your <code>prompt</code> function:</p>

<pre><code>int isANumber(char *check);
</code></pre>
"
"<pre><code>#include &lt;stdio.h&gt;

static void test()
{
    printf(""is this function considered for inline?"");
}

int main()
{
    test(); // definition does not have inline keyword. But declaration at the bottom (which is never used) has a inline keyword.
}

inline static void test(); // definition WITH inline keyword
</code></pre>

<p>Would compiler view <code>test()</code> as if <code>inline</code> keyword were attached to it?</p>

<p>EDIT: Sorry, I meant to have an inline keyword at the declaration at the end!</p>
","922184","","<p>The best to find out is to just look at the assembly.</p>

<p>The compiler flag to make GCC consider every function for inlining is <code>-finline-functions</code>. This is enabled by default at <code>-O3</code>.</p>

<p>So at<code>-O3</code>, GCC will consider every function for inlining even if isn't declared with <code>inline</code>.</p>
"
"<p>I simply write this:</p>

<pre><code>char* test=""test"";
printf(""%s"",test[0]);
</code></pre>

<p>it says seg fault;
then I change to 
<code>printf(""%s"",&amp;test[0]);</code> the error gone
But this is not what I want;
the console print: ""test ""
how to get just value ""t"" from that pointer? </p>
","922184","","<p>If you want just the <code>t</code>, you should do:</p>

<pre><code>printf(""%c"",test[0]);
</code></pre>

<p>The format <code>%c</code>, will print a single <code>char</code>.</p>

<p><code>%s</code> will print the entire null-terminated string.</p>
"
"<p>I have a question about pointer casting for C.</p>

<p>if I have a function with this signature:</p>

<p><code>uint8_t input_getc(void)</code></p>

<p>which reads user input from STDIN.</p>

<p>Then I have  a pointer</p>

<p><code>void* buffer</code></p>

<p>that I store return values from <code>input_getc()</code> in.  What would be the proper way to cast this?</p>

<pre><code>//read user input
for(i = 0; i &lt; SIZE; ++i)
{
    uint8_t temp = input_getc();

    //copy to void* buffer
    *(uint8_t *)(buffer + i) = temp //WAY #1
    *(buffer + i) = (void *)temp;   //WAY #2
}
</code></pre>

<p>Are both of these the same? </p>

<p>Thanks</p>
","922184","","<p>As it is right now, neither of those methods will compile. Since <code>buffer</code> is a <code>void*</code> you can't do arithmetic on it since it has an unknown size.</p>

<p>It's not entirely clear exactly where you are trying to store it. If you're just trying to store the <code>uint8_t</code> into the memory location pointed by <code>buffer</code> with offset <code>i</code>, then it can be done like this:</p>

<pre><code>((uint8_t*)buffer)[i] = temp;
</code></pre>

<p><strong>EDIT :</strong> </p>

<p>Okay, apparently arithmetic on <code>void*</code> is allowed in C, but not in C++. However, doing so it still considered unsafe behavior.</p>

<p>See this question: <a href=""http://stackoverflow.com/questions/3523145/pointer-arithmetic-for-void-pointer-in-c"">Pointer arithmetic for void pointer in C</a></p>
"
"<p>ok so I'm kinda new to java and I'm trying to make a class which will be able to ask the user to input a 12 digit long upc code, check to make sure its a valid code, and then display if it is or not. I've got quite a few errors with the current program that I have and I can't seem to figure it out. This is the code that I have so far: </p>

<pre><code>public class Upc {
    private long upc;

    public Upc(long upcs) {
        upc = upcs;
    }

    public long getUpc() {

        int m = (n2 + n4 + n6 + n8 + n10);
        long n = (n1 + n3 + n5 + n7 + n9 + n11);
        long r = (10 - (m + 3 * n) % 10);

        long n12 = (int) (upc % 10);
        upc /= 10;
        long n11 = (int) (upc % 10);
        upc /= 10;
        long n10 = (int) (upc % 10);
        upc /= 10;
        long n9 = (int) (upc % 10);
        upc /= 10;
        long n8 = (int) (upc % 10);
        upc /= 10;
        long n7 = (int) (upc % 10);
        upc /= 10;
        long n6 = (int) (upc % 10);
        upc /= 10;
        long n5 = (int) (upc % 10);
        upc /= 10;
        long n4 = (int) (upc % 10);
        upc /= 10;
        long n3 = (int) (upc % 10);
        upc /= 10;
        long n2 = (int) (upc % 10);
        upc /= 10;
        long n1 = (int) (upc % 10);

        if (r == n12) {
            return (upc + "" is a feasible UPC code"");
        } else {
            return (upc + "" is an invalid UPC code"");
        }
    }
}
</code></pre>

<p>and my errors are as follows:</p>

<pre><code>13 errors found:
File: C:\Users\Andrew\Downloads\Upc.java  [line: 10]
Error: n2 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 10]
Error: n4 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 10]
Error: n6 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 10]
Error: n8 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 10]
Error: n10 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 11]
Error: n1 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 11]
Error: n3 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 11]
Error: n5 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 11]
Error: n7 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 11]
Error: n9 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 11]
Error: n11 cannot be resolved to a variable
File: C:\Users\Andrew\Downloads\Upc.java  [line: 39]
Error: Type mismatch: cannot convert from java.lang.String to long
File: C:\Users\Andrew\Downloads\Upc.java  [line: 42]
Error: Type mismatch: cannot convert from java.lang.String to long
</code></pre>

<p>I feel like fixing one or two things will eliminate alot of this, can anyone help me?</p>
","922184","","<p>This is because you haven't declared those variables before you use them on this these lines:</p>

<pre><code>int m = (n2 + n4 + n6 + n8 + n10);
long n = (n1 + n3 + n5 + n7 + n9 + n11);
</code></pre>

<p>You declared them <strong><em>after</em></strong>...</p>

<p>Based on what I think you're trying to do, you need to move these three lines to <strong><em>after</em></strong> that large chunk of division/modulus code:</p>

<pre><code>int m = (n2 + n4 + n6 + n8 + n10);
long n = (n1 + n3 + n5 + n7 + n9 + n11);
long r = (10-(m+3*n)%10);
</code></pre>
"
"<p>EDIT: To answer some questions, this is the revised and still not working code (most of it was there to begin with, but I should have been explicit that I initialised the file pointer, etc).  Again, only works if I either add a write before the exp() or remove the exp() entirely:</p>

<pre><code>FILE *outfile;
char *outfilename;
outfilename = (char *)malloc(FILENAME_MAX*sizeof(char));
strcpy(outfilename, ""outfile.txt"");
outfile = fopen(realoutfilename, ""w"");

/* If this is uncommented, there isn't a segfault
if(realoutfile!=NULL &amp;&amp; imoutfile!=NULL){
    fprintf(outfile, ""\r\n"");
    fseek(outfile,0,SEEK_SET);
}
*/

gauss = (double*) calloc(points, sizeof(double));

/* Maths and stuff */

if(outfile!=NULL){
    for(i=0;i&lt;points;i++){
        /* this prints fine */
        printf(outfile, ""%g,\r\n"", gauss[i]);
        /* Seg fault is here */
        fprintf(outfile, ""%g,\r\n"", gauss[i]);

    }
}
fclose(outfile);
free(outfile);
</code></pre>

<p>And I'm compiling with:</p>

<p>gcc main.c -lm -Wall -Wextra -Werror -Wshadow -g -o main</p>

<p>To clarify, it doesn't reach the end of the function - so it's not the freeing that it crashes on.  The crash is when it tries to write to the file in that for loop.</p>

<p>I've checked that exp() isn't over or underflowing, as I say, I can printf the output, but file writing is a no-no.  It also fails if I try a simple call, say exp(2).</p>

<p>The gdb backtrace is (I'm not that familiar with gdb, thought it might help):</p>

<pre><code>#0  0xff15665c in _malloc_unlocked () from /lib/libc.so.1
#1  0xff15641c in malloc () from /lib/libc.so.1
#2  0xff1a8c80 in _findbuf () from /lib/libc.so.1
#3  0xff1a8f0c in _wrtchk () from /lib/libc.so.1
#4  0xff1ad834 in _fwrite_unlocked () from /lib/libc.so.1
#5  0xff1ad798 in fwrite () from /lib/libc.so.1
#6  0x000128ac in gaussian ()
#7  0x00010f78 in main ()
</code></pre>

<p>Any help would be greatly appreciated!</p>
","922184","","<p>The problem, is here:</p>

<pre><code>outfilename = (char *)malloc(FILENAME_MAX*sizeof(char));
outfilename = ""file.txt"";
</code></pre>

<p>You can't assign a string like that, you have to use <code>strcpy</code>:</p>

<pre><code>strcpy(outfilename, ""file.txt"");
</code></pre>

<p>What's happening is that you're are overwriting the <code>outfilename</code> pointer with the string assignment. Then you try to free it <code>free(outfilename);</code>. Since you are freeing a string literal, the behavior is undefined, hence the crash you are getting.</p>

<p>As for why it crashes in one case and not the other. The behavior is undefined, therefore anything is allowed to happen. It's possible that your exponential function code does something to the stack/heap that could be causing it crash/not crash.</p>

<p><strong>EDIT :</strong> I hope it's just a typo or mis-copy, but I also don't see where <code>outfile</code> is initialized. If it really is never initialized, then that's the other error. (and most likely the one that's causing your particular segfault)</p>

<p>So it should look like this:</p>

<pre><code>FILE *outfile;
outfilename = (char *)malloc(FILENAME_MAX*sizeof(char));
strcpy(outfilename, ""file.txt"");

outfile = fopen(outfilename, ""w"");
if (outfile == NULL){
    //  Error, file cannot be openned.
}
</code></pre>
"
"<p>I want to convert signalling NaN to quiet NaN in C. Could anybody suggest a method?</p>

<p>Thanks.</p>
","922184","","<p>I guess I'll expand on my comment and provide a solution.</p>

<p>The tricky part here is being able to read/compare the <code>sNaN</code> without triggering an exception. After all it's called ""signalling"" for a reason. <a href=""http://en.wikipedia.org/wiki/Floating_point#NaNs"" rel=""nofollow"">Wikipedia says that even comparison operations on <code>sNaN</code> will trigger an exception.</a></p>

<p>So a direct use of <code>number != number</code> or <code>isnan(value)</code> probably don't work because they invoke comparisons and will trigger a hardware exception. (I'm not entirely sure how <code>isnan(value)</code> is implemented though.)</p>

<p><strong>EDIT :</strong> Correction, it looks like <code>isnan()</code> will never trigger an exception even on a signalling <code>NaN</code> so that makes the rest of this answer pointless.</p>

<blockquote>
  <p>The predicate isNaN(x) determines if a value is a NaN and never
  signals an exception, even if x is a signaling NaN.</p>
</blockquote>

<p>Meaning it can be done as just this as suggested by Chrisoph in the comments:</p>

<pre><code>if(isnan(value))
    value = NAN;
</code></pre>

<hr>

<p><strong>Here's my original answer that doesn't use <code>isnan(value)</code>:</strong></p>

<p>So the only way I can think of doing this is to go the bitwise route.</p>

<p>Assuming <code>float</code> is standard IEEE single-precision and <code>int</code> is a 32-bit integer, then here's one way to go about this: (Note that I haven't tested this.)</p>

<pre><code>union{
    int i;
    float f;
} val;

val.f = //  Read the value here.

//  If NaN, force it to a quiet NaN.
if ((val.i &amp; 0x7f80000) == 0x7f80000){
    val.i |= 0x00400000;
}
</code></pre>

<p>Note that this approach is not completely C-compliant and will invoke implementation defined behavior. Also note that this approach is not particularly efficient due to the need to move data between the FP and integer units.</p>

<p>Here's how this works:</p>

<ol>
<li>The union obviously is used to get the bits of the <code>float</code> into an <code>int</code>.</li>
<li>All <code>NaNs</code> will have the bits in the <code>0x7f80000</code> set. The if-statement test will check if all of these bits are set.</li>
<li><code>i |= 0x00400000;</code> forces the <code>NaN</code> to a quiet <code>NaN</code>. Bit 22 determines whether the <code>NaN</code> is silent or quiet. Forcing it to 1 will make it a quiet <code>NaN</code>.</li>
</ol>

<hr>

<p><strong>EDIT 2:</strong> If you can't use unions, here's are some other approaches (each of which have their own drawbacks):</p>

<p><strong>Method 1:</strong></p>

<pre><code>float f = //  Read the value here.

int i = *(int*)&amp;f;
if ((i &amp; 0x7f80000) == 0x7f80000){
    i |= 0x00400000;
}

f = *(float*)&amp;i;
</code></pre>

<p><strong>Downside:</strong> It violates strict aliasing, but will probably still work.</p>

<p><strong>Method 2:</strong></p>

<pre><code>char buf[sizeof(float)];

float f = //  Read the value here.

*(float*)&amp;buf = f;
int i = *(int*)&amp;buf;

if ((i &amp; 0x7f80000) == 0x7f80000){
    i |= 0x00400000;
}

*(int*)&amp;buf = i;
f = *(float*)&amp;buf;
</code></pre>

<p>Same idea works with <code>memcpy()</code>.</p>

<p><strong>Downside:</strong> If alignment matters, you need to make sure <code>buf</code> is aligned.</p>

<p><strong>Method 3:</strong> Implement your own <code>isnan()</code>:</p>

<p>See this question: <a href=""http://stackoverflow.com/questions/4185675/where-is-the-source-code-for-isnan"">Where is the source code for isnan?</a></p>
"
"<p>I got 2 functions:<br/>
- <code>stringCopy()</code> which copy the parameter <code>strToCopy</code> into another string dynamically allocated applying a sanitize (see 2nd function)<br/>
- <code>_sanitized()</code> which returns a dynamically allocated uppercased version of the parameter and removing non-letters char (such as numeric values &amp; spaces).</p>

<p>Considering the following, I got an <code>EXC_BAD_ACCESS</code> because of <code>k</code> growing too much.</p>

<pre><code>char* _sanitized(const char* str)
{
    char* uppercasedStr = malloc(sizeof str);

    int k = 0; // Index de parcours de la chaîne originale
    int i = k; // Index dans la nouvelle chaîne
    char evaluatedChar;
    while ( (evaluatedChar = str[k]) != '\0') 
    {
        if ('A' &lt;= evaluatedChar &amp;&amp; evaluatedChar &lt;= 'Z') 
        {
            uppercasedStr[i] = evaluatedChar;
            i++;
        }
        else if ('a' &lt;= evaluatedChar &amp;&amp; evaluatedChar &lt;= 'z') 
        {
            uppercasedStr[i] = evaluatedChar-32;
            i++;
        }

        k++;
    }
    i++;
    uppercasedStr[i] = '\0';

    return uppercasedStr;
}


char* stringCopy(char* strToCopy)
{
    char* uppercaseStr = _sanitized(strToCopy);

    char* copiedStr = malloc(sizeof uppercaseStr);

    int k = 0;
    while (uppercaseStr[k] != '\0') 
    {
        copiedStr[k] = uppercaseStr[k];
        k++;
    }
    k++;
    copiedStr[k] = '\0';

    free(uppercaseStr);

    return copiedStr;
}
</code></pre>

<p>I also noticed that when I copy char from <code>uppercaseStr</code> into <code>copiedStr</code> it modifies <code>uppercaseStr</code> in the same time which cause the overflow...</p>
","922184","","<p><strong>The error I see is here:</strong></p>

<pre><code>char* uppercasedStr = malloc(sizeof str);
</code></pre>

<p>You can't use <code>sizeof()</code> to get the length of a string. You need to use <code>strlen()</code>:</p>

<pre><code>char* uppercasedStr = malloc(strlen(str) + 1);  //  Need +1 for terminating null
</code></pre>

<p><strong>Here's the other occurrence of the same mistake:</strong></p>

<pre><code>char* copiedStr = malloc(sizeof uppercaseStr);
</code></pre>

<p>should be:</p>

<pre><code>char* copiedStr = malloc(strlen(uppercaseStr) + 1);
</code></pre>

<p><code>sizeof(str)</code> only gives you the size of a <code>char</code> pointer, not the length of the entire c-string.</p>

<p>Also note that I omitted the <code>sizeof(char)</code>. This is because <code>sizeof(char)</code> is defined to be 1 in C. Therefore it is not needed.</p>
"
"<p>What does a 0x prefix on a number mean?</p>

<blockquote>
  <p>const int shared_segment_size = 0x6400;</p>
</blockquote>

<p>It's from a C program written on linux. I haven't been dealing with integers like ""0x6400"" for a long time and can't recall what it amounts to and particularly what the letter ""x"" means.</p>
","922184","","<p>Literals that start with <code>0x</code> are hexadecimal integers. (base 16)</p>

<p>The number <code>0x6400</code> is <code>25600</code>.</p>

<pre><code>6 * 16^3 + 4 * 16^2 = 25600
</code></pre>
"
"<p>I have a problem. I need to allocate few very large fields with billions of float elements.</p>

<p>At the moment I'm using:</p>

<pre><code>float ****spaceE;
int x,y,z;
x = y = z = 100;

spaceE = (float****)malloc(x*sizeof(int));
for (int i=0; i&lt;x; i++)
{
    spaceE[i] = (float***)malloc(y*sizeof(int));
    for(int j=0; j&lt;y; j++)
    {
        spaceE[i][j] = (float**)malloc(z*sizeof(int));
        for(int k=0; k&lt;z; k++)
        {
            spaceE[i][j][k] = (float*)malloc(size[3]*sizeof(float));
        }
    }
}
</code></pre>

<p>But it eats over 2GB of memory and Windows terminates it. I need to have few arrays like this and much bigger, is there any better way of doing this?</p>
","922184","","<p>Think about it. You mention ""billions of float elements"". Each float is going to be 4 bytes. ""Billions"" already implies that's gonna need more than 4GB of ram...</p>

<p>What you're trying to do, is not possible because billions of floats is going to take more than 2GB of memory.</p>

<p>If you're just trying to get around the 2GB limit, you'll need to compile for 64-bit.</p>
"
"<p>I have a problem with the following code:</p>

<pre><code>IntegerSet&amp; IntegerSet::unionOfIntegerSets(IntegerSet a){

    IntegerSet result;

    for (int i = 0; i &lt; 100; i++){
        if ((array[i] == 1) || (a.getElement(i) == 1)){
                result.setElement(i, 1);
        }
    }
    return result;
}
</code></pre>

<p>The errors are:</p>

<ul>
<li><p>reference to local variable 'result' returned [enabled by default]</p></li>
<li><p>call of overloaded 'IntegerSet()' is ambiguous</p></li>
</ul>

<p>Can you tell me what I'm doing wrong? Thank you!</p>

<p>Header file:</p>

<pre><code>#ifndef INTEGERSET_H_
#define INTEGERSET_H_

class IntegerSet{
private:
    int* array;

public:
    IntegerSet();
    IntegerSet(int, int, int, int, int);
    ~IntegerSet();

    int getElement(int);
    void setElement(int, int);

    IntegerSet&amp; unionOfIntegerSets(IntegerSet);
    IntegerSet insertionOfIntegerSets(IntegerSet);
    void setPrint();

};


#endif
</code></pre>

<p>What is the workaround for this?</p>

<p><strong>EDIT</strong></p>

<pre><code>IntegerSet IntegerSet::unionOfIntegerSets(IntegerSet a){

    IntegerSet result;

    for (int i = 0; i &lt; 100; i++){
        if ((array[i] == 1) || (a.getElement(i) == 1)){
                result.setElement(i, 1);
        }
    }
    return result;
}
</code></pre>

<p>The error is:</p>

<ul>
<li>call of overloaded 'IntegerSet()' is ambiguous</li>
</ul>
","922184","","<p>The first error is exactly as it says. You are returning a reference to a local variable.</p>

<p><code>result</code> is declared on the stack. It will die after the function ends, therefore whatever references to it will becoming invalid and dangling.</p>

<p>As for the second error, we need to see the definition of the <code>IntegerSet</code> class to see where the ambiguity is.</p>

<p><strong>EDIT :</strong> You should also define a copy constructor for your class.</p>

<p><strong>EDIT 2:</strong> Okay, I think I figured it out:</p>

<p>Does your the definition for the second constructor looks something like this?</p>

<pre><code>IntegerSet::IntegerSet(int a = 0, int b = 0, int c = 0, int d = 0, int e = 0){

}
</code></pre>

<p>I tried this and I got the ambiguous overload call that you got.</p>

<p>In this case, calling the constructor with no parameters can go to either constructor call - hence the ambiguity. So what you should do it get rid of the default value for the first parameter.</p>
"
"<p>I have a signed integer variable
when I do this in main, it is giving me ""Error"" for integer values as well.</p>

<pre><code>int main(){
    unsigned int a;
    while(cin&gt;&gt;a){
        if(!isdigit(a)){
            cout&lt;&lt;""Error""&lt;&lt;endl;
        }
    }
}
</code></pre>

<p>[EDIT]:
Thanks to all the responses, I understood the issue. Now, how do I check if cin is reading integer only and not alphabets or any other character. Is there any function for that in c++. Thanks</p>
","922184","","<p>The problem is that <code>isdigit()</code> takes a character, not an integer.</p>

<p>It returns true when the character is <code>'0'</code>, <code>'1'</code>, etc... Which has ascii values of <code>48</code>, <code>49</code>, etc...</p>

<p>Try it this way instead:</p>

<pre><code>char a;
while(cin&gt;&gt;a){
    if(!isdigit(a)){
</code></pre>
"
"<p>I'm currently working on a personal project that I've been doing for nearly a year now. I am trying to port it over to a Windows environment, which has succeeded. Because I am trying to get a Windows version out to people soon, I decided to continue to develop in Windows while I try to add new features and get bugs that have existed for months out. While recently attempting to add functionality which relied heavily on trigonometry, I found that all 3 trigonometric functions, oddly enough, returned the same value (1072693887) regardless of the parameter I passed. As you can imagine, this is leading to some rather strange bugs in the system.</p>

<p>I have math.h included, and to my knowledge no other files that would contain this function. (Perhaps there's a debugger command to find where a symbol is defined? I couldn't find any such thing, but perhaps I missed something.) I've tried asking elsewhere and searching around on Google, but to no avail...</p>

<p>Has anyone else heard of this problem before, or know how to fix it?</p>
","922184","","<p><strong>EDIT : This answer is not relevant. See comments.</strong></p>

<hr>

<p>This is probably due to numerical instability.</p>

<p>When you pass such a large value into <code>sin()</code>, <code>cos()</code>, or any of the periodic trig functions, you have to remember that there's an implicit modulo by <code>2*pi</code>.</p>

<p>If you are using <code>float</code>, then the uncertainty of <code>1072693887</code>, is way more than <code>2*pi</code>. Therefore, whatever result you get is garbage.</p>

<p>We'll need to see some code to be able to see exactly what's going on though.</p>

<p><strong>EDIT : Here's an illustration:</strong></p>

<pre><code>sin(1072693886) =  0.6783204666
sin(1072693887) = -0.2517863119
sin(1072693888) = -0.9504019164
</code></pre>

<p>But if the datatype is <code>float</code>, then the uncertainty of <code>1072693887</code> is <code>+/- ~64</code>...</p>
"
"<p>Here are some instructions and their corresponding encodings:</p>

<pre><code>55                      push   %ebp
89 e5                   mov    %esp,%ebp
83 ec 18                sub    $0x18,%esp
a1 0c 9f 04 08          mov    0x8049f0c,%eax
85 c0                   test   %eax,%eax
74 12                   je     80484b1 &lt;frame_dummy+0x21&gt;
b8 00 00 00 00          mov    $0x0,%eax
85 c0                   test   %eax,%eax
74 09                   je     80484b1 &lt;frame_dummy+0x21&gt;
c7 04 24 0c 9f 04 08    movl   $0x8049f0c,(%esp)
</code></pre>

<p>Today's microprocessors are often 32- or 64-bit and I guess that they usually read data from memory in 4 byte or 8 byte chunks. However, instructions can have variable length. How does a microprocessor decode these instructions and why are they not of constant length to ease implementation?</p>
","922184","","<p>I won't be able to answer how exactly they are decoded, but I can answer why they are of variable length.</p>

<p>The reason for variable length is both due to the desire to keep code size small as well as unforeseen instruction set extensions.</p>

<hr>

<p><strong>Reducing Instruction Size</strong></p>

<p>Some instructions (by nature), need a lot more space to encode. If all instructions were set at a sufficiently large fixed length to accommodate these, there would be a lot of wasted space in the instruction code. Variable length instructions allows instructions to be ""compressed"" down to a smaller size.</p>

<hr>

<p><strong>(Unforeseen) Instruction Set Extensions</strong></p>

<p>The other reason is instruction set extensions. Originally, x86 only had 256 opcodes. (1 byte) Then there was a need to add more instructions, so they threw out one instruction and used its opcode as an escape character for new opcodes. The result is that the newer instructions were longer. But it was the only way to extend the instruction set and maintain backward compatibility.</p>

<p>As for how the processor decodes these, it's a complicated process. For each instruction, the processor needs to find the length and decode from there. This leads to an inherently sequential decoding process that is a common performance bottleneck.</p>

<p>Modern x86 processors have what is called a uop (micro-op) cache that caches the decoded instructions into something that's more manageable (and RISC-like) by the processor.</p>
"
"<p>I have read about segmentation faults, but fail to see why one should be caused by the following code.</p>

<pre><code>#include&lt;iostream&gt;
#include &lt;stdlib.h&gt;

using namespace std;

int main(){
  int input;
  cout &lt;&lt; ""Enter length of desired array."" &lt;&lt; ""\n"";
  cin &gt;&gt; input;

  int A [input];

  //Populate and print the Array.
  for(int i=0; i&lt;sizeof(A); i++){
    A[i] = rand()%99;
    cout &lt;&lt; A[i] &lt;&lt; "" "";
  }
  return 0;
}
</code></pre>
","922184","","<p>Several issues here:</p>

<ol>
<li>You're using variable-length arrays. It's not allowed in C++. So it must be a compiler extension.</li>
<li><code>sizeof(A)</code> returns the size in bytes, not the number of elements. Therefore you are overrunning the array. You need to divide it by the size of each element.</li>
</ol>

<p>You should change your loop to this:</p>

<pre><code>for(int i=0; i &lt; input; i++){
</code></pre>

<hr>

<p><strong>EDIT :</strong> Here's a solution that doesn't use variable length arrays:</p>

<pre><code>int main(){
    int input;
    cout &lt;&lt; ""Enter length of desired array."" &lt;&lt; ""\n"";
    cin &gt;&gt; input;

    int *A = new int[input];   //  Allocate

    //Populate and print the Array.
    for(int i=0; i&lt;sizeof(A); i++){
        A[i] = rand()%99;
        cout &lt;&lt; A[i] &lt;&lt; "" "";
    }

    delete[] A;    //  Free the allocated memory

    return 0;
}
</code></pre>
"
"<p>I have added a resource in my project. Its size is 4.096 byte.
i need to assign it to DWORD because 3rd argument of WriteFile() needs it.</p>

<pre><code>WriteFile(hFile, pExeResource,size, &amp;bytesWritten, NULL);
</code></pre>

<p>So i cast it like this:</p>

<p>UPDATE2:   DWORD bootsize = 4096; //and still warns me
But i get this warning. can you plesae help me?</p>
","922184","","<p>I think this is a combination of regional/language differences along with C-syntax.</p>

<p>I assume you mean <code>4.096</code> to be <code>4,096</code> with a comma separator. (Due to regional/language differences, you probably use <code>.</code> instead of <code>,</code>.)</p>

<p>In C/C++, you don't use the separators. Just do this instead:</p>

<pre><code>DWORD bootsize = (DWORD)4096;
</code></pre>
"
"<p>Here is a simple one line program using <code>printf</code> :</p>

<pre><code>void main()

{
printf(""%d%d"",printf(""Cis""),printf(""good""));
}
</code></pre>

<p>Output :</p>

<pre><code>goodCis34
</code></pre>

<p>How can this output be explained ??</p>
","922184","","<p>The reason why <code>good</code> and <code>Cis</code> are printed first is because the parameters need to be evaluated before the top-level <code>printf()</code> can be called.</p>

<p>Then the return values are printed out.</p>

<p><strong>Note that C does not specify the order of evaluation of the parameters.</strong> There are no sequence points within the statement. Therefore the order is undefined. And the result can appear in any order. (hence why they appear to be evaluated out-of-order in this case)</p>
"
"<p>I am using g++ version 4.1.2 on a RHEL 5.7 x86_64 box. This builds just fine with g++ version 4.4.5 which comes with RHEL 6.0 x86_64. What does this compiler error mean and how do you fix it?</p>

<pre><code>[mehoggan@hoggant35002 C]$ g++ -Wall -o binary ./binary.cpp 
./binary.cpp:2:5: error: invalid suffix ""b11111111111111111111111111111111"" on integer constant
./binary.cpp:3:5: error: invalid suffix ""b11111111111111111111111111111110"" on integer constant
./binary.cpp:4:5: error: invalid suffix ""b11111111111111111111111111111100"" on integer constant
./binary.cpp:5:5: error: invalid suffix ""b11111111111111111111111111111000"" on integer constant
./binary.cpp:6:5: error: invalid suffix ""b11111111111111111111111111110000"" on integer constant
./binary.cpp:7:5: error: invalid suffix ""b11111111111111111111111111100000"" on integer constant
./binary.cpp:8:5: error: invalid suffix ""b11111111111111111111111111000000"" on integer constant
./binary.cpp:9:5: error: invalid suffix ""b11111111111111111111111110000000"" on integer constant
./binary.cpp:10:5: error: invalid suffix ""b11111111111111111111111100000000"" on integer constant
./binary.cpp:11:5: error: invalid suffix ""b11111111111111111111111000000000"" on integer constant
./binary.cpp:12:5: error: invalid suffix ""b11111111111111111111110000000000"" on integer constant
./binary.cpp:13:5: error: invalid suffix ""b11111111111111111111100000000000"" on integer constant
./binary.cpp:14:5: error: invalid suffix ""b11111111111111111111000000000000"" on integer constant
./binary.cpp:15:5: error: invalid suffix ""b11111111111111111110000000000000"" on integer constant
./binary.cpp:16:5: error: invalid suffix ""b11111111111111111100000000000000"" on integer constant
./binary.cpp:17:5: error: invalid suffix ""b11111111111111111000000000000000"" on integer constant
./binary.cpp:18:5: error: invalid suffix ""b11111111111111110000000000000000"" on integer constant
./binary.cpp:19:5: error: invalid suffix ""b11111111111111100000000000000000"" on integer constant
./binary.cpp:20:5: error: invalid suffix ""b11111111111111000000000000000000"" on integer constant
./binary.cpp:21:5: error: invalid suffix ""b11111111111110000000000000000000"" on integer constant
./binary.cpp:22:5: error: invalid suffix ""b11111111111100000000000000000000"" on integer constant
./binary.cpp:23:5: error: invalid suffix ""b11111111111000000000000000000000"" on integer constant
./binary.cpp:24:5: error: invalid suffix ""b11111111110000000000000000000000"" on integer constant
./binary.cpp:25:5: error: invalid suffix ""b11111111100000000000000000000000"" on integer constant
./binary.cpp:26:5: error: invalid suffix ""b11111111000000000000000000000000"" on integer constant
./binary.cpp:27:5: error: invalid suffix ""b11111110000000000000000000000000"" on integer constant
./binary.cpp:28:5: error: invalid suffix ""b11111100000000000000000000000000"" on integer constant
./binary.cpp:29:5: error: invalid suffix ""b11111000000000000000000000000000"" on integer constant
./binary.cpp:30:5: error: invalid suffix ""b11110000000000000000000000000000"" on integer constant
./binary.cpp:31:5: error: invalid suffix ""b11100000000000000000000000000000"" on integer constant
./binary.cpp:32:5: error: invalid suffix ""b11000000000000000000000000000000"" on integer constant
./binary.cpp:33:5: error: invalid suffix ""b10000000000000000000000000000000"" on integer constant
</code></pre>

<p>The code:</p>

<pre><code>static int s_bitCountMask[32] = {
    0b11111111111111111111111111111111,
    0b11111111111111111111111111111110,
    0b11111111111111111111111111111100,
    0b11111111111111111111111111111000,
    0b11111111111111111111111111110000,
    0b11111111111111111111111111100000,
    0b11111111111111111111111111000000,
    0b11111111111111111111111110000000,
    0b11111111111111111111111100000000,
    0b11111111111111111111111000000000,
    0b11111111111111111111110000000000,
    0b11111111111111111111100000000000,
    0b11111111111111111111000000000000,
    0b11111111111111111110000000000000,
    0b11111111111111111100000000000000,
    0b11111111111111111000000000000000,
    0b11111111111111110000000000000000,
    0b11111111111111100000000000000000,
    0b11111111111111000000000000000000,
    0b11111111111110000000000000000000,
    0b11111111111100000000000000000000,
    0b11111111111000000000000000000000,
    0b11111111110000000000000000000000,
    0b11111111100000000000000000000000,
    0b11111111000000000000000000000000,
    0b11111110000000000000000000000000,
    0b11111100000000000000000000000000,
    0b11111000000000000000000000000000,
    0b11110000000000000000000000000000,
    0b11100000000000000000000000000000,
    0b11000000000000000000000000000000,
    0b10000000000000000000000000000000,
};

#include &lt;stdio.h&gt;

int main(int argc, char *argv[])
{
    for (int i = 0; i &lt; 32; i++) {
        printf(""%d\n"",s_bitCountMask[i]);
    }
}
</code></pre>
","922184","","<p>Rup has the correct answer to this. But I'll add this:</p>

<p>Depending on how you're accessing that table, it might be more appropriate to just generate the value on the spot with this:</p>

<pre><code>unsigned mask = ~((1 &lt;&lt; index) - 1);
unsigned mask = -1 &lt;&lt; index;          //  Better solution (by Rup)
</code></pre>

<p>Alternatively, you could also declare the table like this:</p>

<pre><code>static int s_bitCountMask[32] = {
    -1 &lt;&lt;  0,
    -1 &lt;&lt;  1,
    -1 &lt;&lt;  2,
    -1 &lt;&lt;  3,

    ...

    -1 &lt;&lt; 31,
};
</code></pre>

<p>*Assuming that <code>-1</code> is all one-bits (which it is on nearly every machine now).</p>
"
"<p>it's my first time using arrays and I'm stuck on this.
How can I change the values inside a 2D array and print it out? </p>

<p>For example, I want to replace the 1s with ""<code></code>"" (space) and the 2s with ""<code>*</code>"" and then print them out. How can i do that? </p>

<p>This is my code:</p>

<pre><code>#include &lt;iostream&gt;

using namespace std;

int main(){

    int Xshape[5][5] = {{2,1,1,1,2},
                        {1,2,1,2,1},
                        {1,1,2,1,1},
                        {1,2,1,2,1},
                        {2,1,1,1,2},

    };
    {
        for (int row = 0; row&lt;5 ; row++)
        for (int column=0; column &lt; 5; column++)
        {
            cout &lt;&lt; Xshape[row][column] &lt;&lt; endl;
        }

    }
    system(""pause"");

}
</code></pre>

<p>i think it has something to do with the if-else statement but i cant pull it off
can someone help me please?</p>
","922184","","<p>Yes, it can be done with a simple if-statement:</p>

<pre><code>for (int column=0; column &lt; 5; column++)
{
    int val = Xshape[row][column];
    if (val == 1){
        cout &lt;&lt; "" "" &lt;&lt; endl;
    }else if (val == 2){
        cout &lt;&lt; ""*"" &lt;&lt; endl;
    }else{
        //  Handle error case of neither 0 nor 1.
    }
}
</code></pre>
"
"<p>While working with pointers i wrote the following code,</p>

<pre><code>int main()
{
    int a[]={10,20,30,40,50};
    int i;
    for(i=0;i&lt;5;i++)
    {
        printf(""\n%d"",*a);
        a++;
    }
    return 0;
}
</code></pre>

<p>Now as per my understanding array name itself is an address in c and the pointer arithmetic done is here is correct as per my knowledge. But when i try to run the code it is giving me ""Lvalue Required"" error. </p>

<p>So what is the exact reason for occuring Lvalue required error because before this also i have come across situations where this error is there. Secondly why the arithmetic on the pointer is not legal here in this case?</p>
","922184","","<p>You can't do <code>a++</code> on a static array - which is not an Lvalue. You need to do on a pointer instead. Try this:</p>

<pre><code>int *ptr = a;
int i;
for(i=0;i&lt;5;i++)
{
    printf(""\n%d"",*ptr);
    ptr++;
}
</code></pre>

<p>Although in this case, it's probably better to just use the index:</p>

<pre><code>int i;
for(i=0;i&lt;5;i++)
{
    printf(""\n%d"",a[i]);
}
</code></pre>
"
"<p>my problem is that <code>const string* p</code> gives me an error. What is wrong with this? since I am not change the original value. <code>const int&amp; n = 0</code> works fine. </p>

<pre><code>#include &lt;iostream&gt;
using namespace std;
class HasPtr
{
private:
    int num;
    string* sp;
public:
    //constructor
    HasPtr(const int&amp; n = 0, const string* p = 0): num(n), sp(p) {}
    //copy-constructor
    HasPtr(const HasPtr&amp; m): num(m.num), sp(m.sp) {}
    //assignment operator
    HasPtr&amp; operator=(const HasPtr&amp; m)
    {
        num = m.num;
        sp = m.sp;
        return *this;   
    }
    //destructor
    ~HasPtr() {}
};
int main ()
{
    return 0;
}
</code></pre>

<p>output Error is : </p>

<pre><code>error: invalid conversion from ‘const std::string*’ to ‘std::string*’
</code></pre>
","922184","","<p>This is because your <code>sp</code> member is not <code>const</code>.</p>

<pre><code>string* sp;
</code></pre>

<p>But your parameter <code>p</code> is a <code>const</code>. The result is that you are trying to assign a <code>const</code> pointer to a non-const pointer - hence the error.</p>

<p>To fix this, you need to declare <code>sp</code> const at as well.</p>

<pre><code>const string* sp;
</code></pre>
"
"<p>Can someone explain this code please? how is it that the function bar accepts a reference to the first element of the vector?</p>

<pre><code>jintArray arry;
std::vector&lt;int&gt; foo = GetIntegerArray(env, arry);
bar(&amp;foo[0])
</code></pre>

<p>where the protoytpe of bar is</p>

<pre><code>bar(int* array)
</code></pre>
","922184","","<p>This is valid as long as the template type isn't <code>bool</code>. The C++ vector type specifies that the vector elements are consecutive in memory like that so that you can do exactly this.</p>

<p>The reason why it doesn't work with <code>bool</code> is due to template specialization. Where the bools are compressed down to a bitfield.</p>

<p><a href=""http://en.wikipedia.org/wiki/Vector_%28C%2B%2B%29#vector.3Cbool.3E_specialization"">http://en.wikipedia.org/wiki/Vector_%28C%2B%2B%29#vector.3Cbool.3E_specialization</a></p>
"
"<pre><code>#include &lt;iostream&gt;

using namespace std;

int main()
{
    HelloWorld();
    return 0;
}

void HelloWorld()
{
    cout &lt;&lt; ""Hello, World"" &lt;&lt; endl;
}
</code></pre>

<p>I am getting the following compilation error with g++:</p>

<pre><code>l1.cpp: In function 'int main()':
l1.cpp:5:15: error: 'HelloWorld' was not declared in this scope
</code></pre>
","922184","","<p>You need to either declare or define the function before you can use it. Otherwise, it doesn't know that <code>HelloWorld()</code> exists as a function.</p>

<p>Add this before your main function:</p>

<pre><code>void HelloWorld();
</code></pre>

<p>Alternatively, you can move the definition of <code>HelloWorld()</code> before your <code>main()</code>:</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;

void HelloWorld()
{
  cout &lt;&lt; ""Hello, World"" &lt;&lt; endl;
}

int main()
{
  HelloWorld();
  return 0;
}
</code></pre>
"
"<p>Given the following sample:</p>

<pre><code>public class Main {
    public static void main(String[] args) {
        System.out.println(1234);
        System.out.println(01234);
    }
}
</code></pre>

<p>The Output is:</p>

<pre><code>1234
668
</code></pre>

<p>Why?</p>
","922184","","<p>This is because integer literals with a leading zero are octal integers (base 8):</p>

<pre><code>1 * 8^3 + 2 * 8^2 + 3 * 8 + 4 = 668
</code></pre>
"
"<p>Just need a confirmation on something real quick. 
If an algorithm takes <code>n(n-1)/2</code> tests to run, is the big oh <code>O(n^2)</code>?</p>
","922184","","<p>Yes, that is correct.</p>

<p><code>n(n-1)/2</code> expands to <code>n^2/2 - n/2</code>:</p>

<p>The linear term <code>n/2</code> drops off because it's of lower order. This leaves <code>n^2/2</code>. The constant gets absorbed into the big-O, leaving <code>n^2</code>.</p>
"
"<p>i`m trying to concatenate a characters using memcpy function, however, i kinda get a weird length of my buffer after couple of memcpy. please see code below</p>

<pre><code>int main()
{
uint8 txbuffer[13]={0};
uint8 uibuffer[4] = ""abc"";
uint8 rxbuffer[4] = ""def"";
uint8 l[2]=""g"";
int index = 1;

cout &lt;&lt; strlen((char*)txbuffer) &lt;&lt;endl;
memcpy(&amp;txbuffer[1],&amp;uibuffer, strlen((char*)uibuffer));
index+=strlen((char*)uibuffer);

cout &lt;&lt;""after first memcpy: ""&lt;&lt; strlen((char*)txbuffer) &lt;&lt;endl;
memcpy(&amp;txbuffer[index],&amp;rxbuffer, strlen((char*)uibuffer));

cout &lt;&lt;""after second memcpy: ""&lt;&lt; strlen((char*)txbuffer) &lt;&lt;endl;
memcpy(&amp;txbuffer[0],&amp;l, strlen((char*)l));

cout &lt;&lt;""after third memcpy: ""&lt;&lt; strlen((char*)txbuffer) &lt;&lt;endl;
for (int i = 0; i &lt; sizeof(txbuffer); i += 1)
{
    cout &lt;&lt; (int(txbuffer[i]))&lt;&lt;"" : ""&lt;&lt; char(int(txbuffer[i]))&lt;&lt;endl;
}
return 0;
}
</code></pre>

<p>the output is: </p>

<pre><code>after first memcpy: 0
after second memcpy: 0
after third memcpy: 7
103 : g
97 : a
98 : b
99 : c
100 : d
101 : e
102 : f
0 : 
0 : 
0 : 
0 : 
0 : 
0 :
</code></pre>

<p>my question is why after the first memcpy, the strlen of the buffer still is zero?</p>
","922184","","<p>This is because the first character in <code>txbuffer</code> is the null character <code>\0</code>. (You initialized it this way.) So the string effectively has zero-length when you print it out.</p>

<p>You didn't overwrite the first character in the first or second copies. But you finally do overwrite it in the 3rd copy. That's why the length is zero until after the 3rd copy.</p>

<pre><code>//  Start
{  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0}

//  After 1st memcpy(): strlen() is still zero
{  0, 'a', 'b', 'c',   0,   0,   0,   0,   0,   0,   0,   0,   0}
   ^ first null character

//  After 2nd memcpy(): strlen() is still zero
{  0, 'a', 'b', 'c', 'd', 'e', 'f',   0,   0,   0,   0,   0,   0}
   ^ first null character

//  After 3rd memcpy(): strlen() is now 7
{'g', 'a', 'b', 'c', 'd', 'e', 'f',   0,   0,   0,   0,   0,   0}
                                      ^ first null character
</code></pre>
"
"<p>I recently got confused by the following c++ snippet:</p>

<pre><code>#include &lt;cstdio&gt;

int lol(int *k){
  *k +=5;
   return *k;
}

int main(int argc, const char *argv[]){
  int k = 0;
  int w = k + lol(&amp;k);
  printf(""%d\n"", w);
  return 0;
}
</code></pre>

<p>Take a look at line:</p>

<pre><code>int w = k + lol(&amp;k);
</code></pre>

<p>Until now I thought that this expression would be evaluated from left to right: take current value of k (which before calll to lol function is 0) and then add it to the result of lol function. But compiler proves me I'm wrong, the value of w is 10. Even if I switch places to make it </p>

<pre><code>int w = lol(&amp;k) + k;
</code></pre>

<p>the result would be still 10. What am I doing wrong?</p>

<p>Tomek</p>
","922184","","<p>This is because the parameters in an expression are <strong><em>not</em></strong> specified to be evaluated in any particular order. </p>

<p>The compiler is free to execute either parameter <code>k</code> or <code>lol(&amp;k)</code> first. There are no sequence points in that expression. <strong>This means that the side-effects of the parameters can be executed in any order.</strong></p>

<p>So in short, it's not specified whether the code prints <code>5</code> or <code>10</code>. Both are valid outputs.</p>

<p>The exception to this is short-circuiting in boolean expressions because <code>&amp;&amp;</code> and <code>||</code> are sequence points. (see comments)</p>
"
"<p>What is the difference between 'accurate' and 'precise' ? </p>

<p>If there is a difference, can you give an example of </p>

<ul>
<li>a number that is accurate but not precise</li>
<li>a number that is precise but not accurate</li>
<li>a number that is both accurate and precise</li>
</ul>

<p>Thanks!</p>
","922184","","<p>One way to think of it is this:</p>

<ul>
<li>A number that is ""precise"" has a lot of digits. But it might not be very correct.</li>
<li>A number that is ""accurate"" is correct, but may not have a lot of digits.</li>
</ul>

<p>Examples:</p>

<ul>
<li><code>3.14</code> is an ""accurate"" approximation to Pi. But it is not very precise.</li>
<li><code>3.13198408654198</code> is a very ""precise"" approximation to Pi, but it is not accurate,</li>
<li><code>3.14159265358979</code> is both accurate and precise.</li>
</ul>

<p>So precision gives a lot of information. But says nothing about how correct it is.</p>

<p>Accuracy says how correct the information is, but says nothing about how much information there is.</p>
"
"<p>How can you tell what will or what won't be made inline by the compiler? </p>

<p>Sometimes I have been told that some minor optimisations are pointless because the compiler will inline certain calls or calculations, other times similar optimisations seem to be recommended.</p>

<p>What are the rules that allow us to know when we do or don't need to optimise these things?</p>
","922184","","<p>The only sure way to see if a something is inlined is to look at the assembly.</p>

<p>Whether or not something is inlined is completely compiler dependent - as the compiler has the final decision on whether to inline something.</p>

<p><strong>Premature optimization aside:</strong> If it really matters (or if you're just curious) you can use compiler-specific pragmas to force inlining/no inlining on a function and then profile appropriately to see if you can make better decisions than the compiler.</p>

<p>Nevertheless there are some cases where you can be sure that a function cannot be inlined:</p>

<ul>
<li>Virtually called functions where the type cannot be determined at compile time.</li>
<li>Recursive functions can never by fully inlined unless the maximum depth can be statically determined.</li>
</ul>
"
"<p>What is the difference between int and char arrays below: </p>

<pre><code>int main()
{
    int numbers[] = {2,1,3};
    char letter[] = {'a','b','\0'};
    cout&lt;&lt; numbers&lt;&lt;endl;
    cout&lt;&lt; letter&lt;&lt;endl;
}
</code></pre>

<p>Output: </p>

<pre><code>0x22ff12 // an address
ab
</code></pre>

<p>Why isn't the 213 displayed ? 
I know the name of an array will point to the address of its first element, but why
does a char array display different behavior?</p>
","922184","","<p>When you print an array with <code>cout</code> it will print the base address of the array.</p>

<p>The exception is with char arrays which have been overloaded to print it as a c-string.</p>

<p>If you want to print the elements of the <code>int</code> array, you need to do it element-by-element.</p>
"
"<p>I have an array of characters populated by <code>cin</code>, but im trying to find a way to check each character individually to make sure its only one of a set number of characters (a-z,A-Z,0-9,[space]).</p>

<p>The easiest way I thought this could be done is to check if the code of the character fell within a certain range. But not sure how to get it.</p>

<p>Alternatively if anyone knows any other ways of doing it, that would be great.</p>
","922184","","<p>The easiest way is to use <code>isalpha()</code>, <code>isdigit()</code> or <code>isalnum()</code>:</p>

<pre><code>char ch = ...  //  The character

//  Original solution
if (isalpha(ch) || isdigit(ch)){

}

//  Better solution by fefe (see comments)
if (isalnum(ch)){

}
</code></pre>

<p>These are defined in <code>ctype.h</code>: <a href=""http://www.cplusplus.com/reference/clibrary/cctype/"" rel=""nofollow"">http://www.cplusplus.com/reference/clibrary/cctype/</a></p>

<p>Otherwise you can also use comparisons:</p>

<pre><code>if ('a' &lt;= ch &amp;&amp; ch &lt;= 'z' ||
    'A' &lt;= ch &amp;&amp; ch &lt;= 'Z' ||
    '0' &lt;= ch &amp;&amp; ch &lt;= '9'
){

}
</code></pre>

<p>This latter approach using comparisons will generalize to arbitrary ranges.</p>
"
"<pre><code>__asm__ (       
    ""loop:\n\t""
    ""movl   $1,%3\n\t""
    ""movl   $0, %6\n""
    ""start:\n\t""

    ""movl   (%1,%3,4),%4\n\t""       
    ""movl   -4(%1, %3, 4), %5\n\t""  
    ""cmpl   %4, %5\n\t""         
    ""jle    next\n\t""

    ""xchgl  %4, %5\n\t""     
    ""movl   %4, (%1, %3, 4)\n\t""    
    ""movl   %5, -4(%1, %3, 4)\n\t""  
    ""movl   $1, %6\n""

    ""next:\n\t""
    ""incl   %3\n\t"" 

    ""cmpl   %3, %2\n\t"" 
    ""jge    start\n\t""  

    ""cmpl   $0, %6\n\t""
    ""je end\n\t""

    ""jmp    loop\n"" 
    ""end:    \n\t""


:""=r""(input_array)
:""r""(input_array), ""r""(size-1), ""r""(1), ""r""(0), ""r""(0), ""r""(0)

);
</code></pre>

<p>I get:</p>

<blockquote>
  <p>error: can't find a register in class ‘GENERAL_REGS’ while reloading ‘asm’ error: ‘asm’ operand has impossible constraints</p>
</blockquote>
","922184","","<p>You have to remember that these machines have a limited number of registers. And its possible to actually run out - that's what the error you're getting is telling you.</p>

<p>On x86, there are only 8 general-purpose registers. <code>esp</code> is reserved for the stack pointer. <code>ebp</code> is probably in use as a base-pointer. So that leaves only 6.</p>

<p>However, your inline assembly snippet appears to want 7 registers? You don't have enough of them.</p>

<p>So the solution is that you will need to use fewer registers. Put some of the parameters in memory or change the algorithm...</p>
"
"<p>I know that a lot of people meet this error. I did do search work but it seems that this error msg appears in all different situations. Could you please tell me what's wrong? Basically this class stores an int array of a long input. THis error is in the function num()</p>

<p>and another error:</p>

<pre><code>main.cpp:43: error: invalid conversion from ‘num*’ to ‘long int’
main.cpp:43: error:   initializing argument 1 of ‘num::num(long int)’

#include &lt;iostream&gt;
#include &lt;fstream&gt;
using namespace std;
//ifstream fin;
//ofstream fout;
class num 
{
     public:
     int dig[9];
      void breakDown(long input)
     {   
             for(int digPos=0;input&gt;0;digPos++)
             {   
                     dig[digPos]=input-((int)input/10)*10;
                     input=(int)input/10;
             }   
     }   
     num(long in) // constructor
     {   
             breakDown(long in);
     }   
     int outPut()
     {   
             for(int digPos=0;digPos&lt;9;digPos++)
             {   
                     cout &lt;&lt; dig[digPos];
             }   
             return 0;
     }    
};

//int init()
//{
//      fin.open(""runround.in"",ifstream::in);
//      fout.open(""runround.out"");
//}


int main()
{
//        init();
     num num1=new num((long)81236);
}
</code></pre>
","922184","","<p>The error is here:</p>

<pre><code>num(long in) // constructor
{   
    breakDown(long in);
}
</code></pre>

<p>change it to this:</p>

<pre><code>num(long in) // constructor
{
    breakDown(in);
}
</code></pre>

<p>You don't specify types when you call a function.</p>

<hr>

<p>The other error is here:</p>

<pre><code>num num1=new num((long)81236);
</code></pre>

<p><code>new num</code> returns a pointer. But you are assigning it to a <code>num</code> object - which is incompatible.</p>

<p>You have two options here:</p>

<pre><code>num num1((long)81236);
</code></pre>

<p>This will create a num object locally on the stack.</p>

<p>The other option is:</p>

<pre><code>num *num1 = new num((long)81236);
</code></pre>

<p>This will allocate a num object on the heap. But you need to free it later with <code>delete</code>.</p>
"
"<p>I'm trying to copy a continuous block of data from one location in the Main Memory to another location. Here's what I did so far, but it's not working. It seems that after applying 'memcpy', the content of my array 'testDump' becomes all zeros.</p>

<pre><code>//Initialize array to store pixel values of a 640x480 image
int testDump[204800];   
for(int k = 0; k&lt;204800; k++)
   testDump[k] = -9;

//pImage is a pointer to the first pixel of an image 
pImage = dmd.Data();

//pTestDump is a pointer to the first element in the array
int* pTestDump = testDump;

//copy content from pImage to pTestDump
memcpy (pTestDump, pImage, 204800);

for(int px_1 = 0; px_1&lt;300; px_1++)
{
   std::cout&lt;&lt;""Add of pPixel: ""&lt;&lt;pImage+px_1&lt;&lt;"", content: ""&lt;&lt;*(pImage+px_1);
   std::cout&lt;&lt;""Add of testDump: ""&lt;&lt;pTestDump+px_1&lt;&lt;"", content: ""&lt;&lt;*(pTestDump+px_1);
}
</code></pre>

<p>Advice and suggestions are appreciated.</p>

<p>Thanks</p>

<p>Roronoa Zoro</p>
","922184","","<p>The first problem I see is this:</p>

<pre><code>memcpy (pTestDump, pImage, 204800);
</code></pre>

<p>should be this:</p>

<pre><code>memcpy (pTestDump, pImage, 204800 * sizeof(int));
</code></pre>

<p>You forgot the <code>sizeof(int)</code> so you're only copying a part of the data.</p>

<p>The other problem is that you switched the order of the operands in <code>memcpy()</code>. The destination is the first operand:</p>

<pre><code>memcpy (pImage, pTestDump, 204800 * sizeof(int));
</code></pre>
"
"<p>I got many answers for this when I Googled ""How to find factorial of a number""...</p>

<p>One of those examples is...</p>

<pre><code>private double getFactorial(double f){
    if ( f == 0 ) 
        return 1;
    return (f * getFactorial(f - 1));
}
</code></pre>

<p>And it works... However, the Windows Calculator surprised me: It works for decimal numbers as well!!</p>

<p>For example: On the Windows Calculator, the factorial of <code>0.5</code> is <code>0.886226925</code>...</p>

<p>Is that the desired behavior? Is the factorial defined for non-integers?</p>
","922184","","<p>Making my comment an answer:</p>

<p>The factorial can be generalized to nearly all numbers (real/complex/non-integral) via the <strong><em><a href=""http://en.wikipedia.org/wiki/Gamma_function"" rel=""nofollow"">Gamma Function</a></em></strong>.</p>

<p>The only points for which it is still undefined are for negative integers due to singularities. (This is easy to see by reversing the recursion identity for the factorial. Going from <code>0!</code> to <code>(-1)!</code> leads to a divide by zero.)</p>

<p>Obviously, your code will work only for integers. For anything else it will go into an infinite recursion and cause a stackoverflow.</p>

<hr>

<p>For integers, it's easy to compute it with a simple loop or a recursion. But for anything else, it's much harder to do.</p>

<p>There are two main algorithms for evaluating the factorial/Gamma Function at non-integral points:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Stirling%27s_approximation"" rel=""nofollow"">Stirling's Formula</a> combined with the usual recursion property.</li>
<li><a href=""http://en.wikipedia.org/wiki/Lanczos_approximation"" rel=""nofollow"">Lanczos approximation</a></li>
</ul>

<p>Wikipedia has an implementation of the latter in Python.</p>
"
"<pre><code>#include &lt;stdio.h&gt;

int main()
{
    struct value
    {
        int bit1:1;
        int bit2:4;
        int bit3:4;
    } bit;

    printf (""%d\n"", sizeof(bit));
    return 0;
}
</code></pre>

<p>Output on Tc/Tc++:</p>

<blockquote>
  <p>2</p>
</blockquote>

<p>Output under Linux:</p>

<blockquote>
  <p>4</p>
</blockquote>

<p>I know I am missing some concept of bit fields.</p>
","922184","","<p>The <code>sizeof</code> for the struct is not the same as the sum of the sizes of all the elements - this is especially the case with bitfields.</p>

<p>Typically, the struct needs to be padded to a certain size and alignment. (Which apparently is 2 on Tc/Tc++ and 4 in Linux.)</p>

<p>So although there's only 9 bits in use, it's being padded out to the word-size.</p>

<p><strong>EDIT :</strong></p>

<p>Note that the C standard does not specify how much padding is done. And therefore, you are getting different results from two different compilers.</p>
"
"<p>I am returning a char pointer from a function. But the caller is unable to see the string.</p>

<pre><code>char* getFileContent(char* file)
{

FILE* fp = fopen(""console.txt"", ""r"");

fseek(fp, 0L, SEEK_END);
size_t sz = ftell(fp);
fseek(fp, 0L, SEEK_SET);


char* message = (char*)malloc(sz+1);
char buf[sz+1];

size_t len = 0;
if (fp != NULL)
{
    len = fread(buf, sizeof(char), sz, fp);
}

printf(""MALLOC SIZE:%d FILE SIZE:%d"", sz, len);

strcpy(message,buf);    //Modified code. This line fixed the code
message[++len] = '\0';
//printf(""MESSAGE:%s"", message);

return(message);

}
</code></pre>

<p>This is the caller. Output is empty.</p>

<pre><code>int main(int argc, char **argv, char **env)
{

char* msg = getFileContent(imagefile);

if(msg != NULL)
    printf(""Output:%s \n"", msg);

free(msg);

return 0;
}
</code></pre>

<p>Please help.</p>
","922184","","<p>The error is here:</p>

<pre><code>printf(""Output:"", msg);
</code></pre>

<p>You're not printing the string. Try this instead:</p>

<pre><code>printf(""Output: %s"", msg);
</code></pre>

<p>The <code>%s</code> is needed to tell <code>printf()</code> to print <code>msg</code> as a string.</p>

<hr>

<p>Note that due to buffering, you may also need to add a <code>\n</code>:</p>

<pre><code>printf(""Output: %s \n"", msg);
</code></pre>

<hr>

<p>Here's another minor error:</p>

<pre><code>message[++len] = '\0';
</code></pre>

<p>should be:</p>

<pre><code>message[len] = '\0';
</code></pre>
"
"<p>In this C++ code I try to erase element from the end of the vector but the program stops and I receive the message: <code>Expression: vector erase iterator outside range.</code></p>

<p>What is the problem? 
After all is by this code the vector a vector of pointers or the way I pass them in push_back inserts only a copy of pointer? </p>

<pre><code>int _tmain(int argc, _TCHAR* argv[])
{
    vector&lt;Player*&gt; allPlayers;
    allPlayers = createPlayers();

    int numPlayers;

    cout&lt;&lt;""Vector size: ""&lt;&lt;allPlayers.size();
    cout&lt;&lt;endl;
    cout&lt;&lt;""How many players are involved in the game(1-4)?\n"";
    cin&gt;&gt;numPlayers;
    cout&lt;&lt;endl;
    allPlayers.erase(allPlayers.end());

    return 0;
}


vector&lt;Player*&gt; createPlayers(){

    Player *Player1 = new Player(1,1500);
    Player *Player2 = new Player(2,1500);
    Player *Player3 = new Player(3,1500);
    Player *Player4 = new Player(4,1500);


    vector&lt;Player*&gt; allPlayers;
    allPlayers.push_back(Player1);
    allPlayers.push_back(Player2);
    allPlayers.push_back(Player3);
    allPlayers.push_back(Player4);


    return allPlayers;
}
</code></pre>
","922184","","<p><code>.end()</code> returns the iterator <strong><em>one past the last element</em></strong>. That's why you're getting that error. You want the iterator to point to the last element. Not one-past the last element.</p>

<p>So try changing the line to:</p>

<pre><code>allPlayers.erase(allPlayers.end() - 1);
</code></pre>

<p>And make sure that you properly handle the case where vector is empty.</p>

<hr>

<p>Alternatively you could use <code>.pop_back()</code>, but in either case, you're gonna want to deal with the memory leaks as well as mentioned in the comments.</p>
"
"<p>I read from a book saying that the following c++ code should not compile:</p>

<pre><code>  void f(int n, int m){
     int a[n] , b[n][m];
  }
</code></pre>

<p>because the size of the arrays are not determined at compile time.</p>

<p>But I tried it out and found no matter the function is a global one or a member function, I could get compilation successful using g++.</p>

<p>Was this something made legal in recent c++ implementation, or the book is simply wrong.</p>

<p>Thank you.</p>

<p><strong>Edit</strong></p>

<p>I saw a few replies immediately. I just have this wonder too in Java. I notice in java, this is supported (please correct me if this is also version dependent). So why the difference? Does it have anything to do with using references vs. objects? But still, in java, I can declare an array with variable length from function argument for primitives.</p>

<p><strong>Edit 2</strong></p>

<p>The following Java code did compile though, if you say it should not:</p>

<pre><code>class Test1 {
    public int[] f(int n,int k){
        int[] c=new int[n];
        Arrays.fill(c, k);
        return c;
    }
}
</code></pre>
","922184","","<p>These are called <a href=""http://en.wikipedia.org/wiki/Variable-length_array"" rel=""nofollow"">Variable Length Arrays</a>. They are not allowed in C++. But some compilers (such as GCC) support them as an extension.</p>

<p>In C99, Variable Length Arrays are allowed.</p>

<p><strong>EDIT :</strong></p>

<p>For your new question. The top answer for this question explains why C++ does not have variable length arrays.</p>

<p><a href=""http://stackoverflow.com/questions/7812566/why-no-variable-size-array-in-stack"">Why no variable size array in stack?</a></p>

<p><strong>EDIT 2:</strong></p>

<p>In Java, arrays are objects which are stored on the heap rather than the call stack. Therefore the question is moot - all arrays are on the heap, hence VLAs don't exist.</p>
"
"<p>We have a legacy c++ .dll compiled for windows under visual studio.  We have been running into issues where we get different results when we compile the program using different compiler options.  </p>

<p>I have done a pretty simple port so that I can compile it under linux using g++.  I just wanted to see what kind of warnings gcc would throw at me and possibly try to run it using valgrind to look for possible erros.</p>

<p>So that is the background.  Here is the question.  We have a bunch of fprintf function calls that print to a log file.  When compiled under g++, I get warnings like this.</p>

<pre><code>../f11.cpp:754:128: warning: format ‘%i’ expects type ‘int’, but argument 8 has type ‘long unsigned int’
</code></pre>

<p>Obviously this is a bad thing we need to fix, but I am just curious about the potential consequences of ignoring this warning?  Are the consequences only limited to the output in the log file, or could this cause things like buffer overruns or any other type of situation where we are overwriting memory without knowing it?  </p>
","922184","","<p>By definition, it's undefined behavior to have mismatching format strings and argument types.</p>

<p>So anything is allowed to happen. But more likely, you'll get completely garbled and non-sense output - especially if the sizes of the operands you pass don't match what's expected from the format strings.</p>

<p>It is possible for a buffer overrun to happen - if <code>printf()</code> ends up reading past the parameters, it will be reading stack garbage. But it will only reading it. It won't be writing to it, so it shouldn't corrupt anything. (with one exception - <code>%n</code>, see comments)</p>

<p>But then again, it's undefined behavior. Anything is possible.</p>
"
"<p>I just wrote a simple C++ program in Visual Studio 2010 and I use <code>ceil</code> function. But I forgot to include the <code>&lt;cmath&gt;</code> and only included the <code>&lt;iostream&gt;</code>. Surprisingly my code compiled successfully and ran without any error. I read a C++ book and it clearly says that to use <code>ceil</code> function you must include <code>&lt;cmath&gt;</code> or <code>&lt;math.h&gt;</code>. Why this happens? Can anyone explain me? Thanks!</p>
","922184","","<p>Technically speaking, implementations are allowed to automatically include any header in the system headers. But this is implementation defined.</p>

<p>In some cases, <code>&lt;cmath&gt;</code> is already included, in other cases, it isn't - same applies to all the other standard headers.</p>

<p>This issue came up on this question: <a href=""http://stackoverflow.com/questions/7632926/is-this-a-c-program-or-c-program-how-to-decide"">Is this a C program or C++ program, how to decide?</a></p>

<p>That aside, it's possible that it could be indirectly included by other includes.</p>
"
"<p>i have the indicated problem with the following code and i have no idea what it might be causing it. I searched before posting the problem, and i learned that it might be something going out of the scope like a reference to a freed memory location but i could not find it on my own.
Thank you for helping me. </p>

<pre><code>#include&lt;iostream&gt;
#include&lt;string&gt;
using namespace std;

class USR{
private:
    string name;
public:
    void setName(string name){  
        this-&gt;name = name;
    }
    string getName(){
        return name;
    }

};

class A{
private:
    USR* * a;
public:
    A(int size){
        a = new USR*[size];
    }   
    USR* getUser(){
        return a[0];
    }
};

int main(){
    A test = A(5);
    USR* u = test.getUser(); 
    (*u).setName(""test"");
    USR* u2 = test.getUser(); 
    cout &lt;&lt; (*u2).getName() &lt;&lt; endl;
    cout &lt;&lt; (*u).getName() &lt;&lt; endl;
}
</code></pre>
","922184","","<p>The problem is that you allocated the array of pointers, but you never allocated anything for the pointers themselves.</p>

<p>This gives you the array of pointers:</p>

<pre><code>a = new USR*[size];
</code></pre>

<p>But you never allocated anything for each of the pointers.</p>

<p>Therefore, it's crashing here:</p>

<pre><code>(*u).setName(""test"");
</code></pre>

<p>because <code>*u</code> is not initialized.</p>

<hr>

<p>There are two ways to fix this:</p>

<ol>
<li>Allocate (and initialize) something for each <code>USR</code> pointer.</li>
<li>Don't use the double pointers. Just use a simple array of <code>USR</code> objects.</li>
</ol>

<p>I'd prefer the latter since what you have is probably more complicated than it needs to be.</p>

<p>Something like this will probably do what you want:</p>

<pre><code>class A{
private:
    USR *a;
public:
    A(int size){
        a = new USR[size];
    }   
    USR* getUser(){
        return &amp;a[0];
    }
};
</code></pre>

<p>Don't forget that you'll want a destructor as well.</p>
"
"<p>I want to know if this causes a memory leak:</p>

<pre><code>std::string test() {
    return *(new std::string(""""));
}
</code></pre>
","922184","","<p>Yes, it's a memory leak. When the function returns, a copy is made of the original string object.</p>

<p>Then the original new'ed pointer falls out of scope and is lost - a leak.</p>
"
"<pre><code>typedef float v4sf __attribute__ ((mode(V4SF)));
</code></pre>

<p>This is in GCC. Anyone knows the equivalence syntax? </p>

<p>VS 2010 will show ""<strong>attribute</strong>"" has no storage class of this type, and mode is not defined.</p>

<p>I searched on the Internet and it said </p>

<blockquote>
  <p>Equivalent to <strong>attribute</strong>( aligned( size ) ) in GCC </p>
  
  <p>It is helpful
  for former unix developers or people writing code that works on
  multiple platforms that in GCC you achieve the same results using
  <strong>attribute</strong>( aligned( ... ) )</p>
  
  <p>See here for more information:
  <a href=""http://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Type-Attributes.html#Type-Attributes"" rel=""nofollow"">http://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Type-Attributes.html#Type-Attributes</a></p>
</blockquote>

<p>The full GCC code is here:  <a href=""http://pastebin.com/bKkTTmH1"" rel=""nofollow"">http://pastebin.com/bKkTTmH1</a></p>

<p>Thanks.</p>
","922184","","<p>If you're looking for the alignment directive in VC++ it's <code>__declspec(align(16))</code>. (or whatever you want the alignment to be)</p>

<p>And example usage is this:</p>

<pre><code>__declspec(align(16)) float x[] = {1.,2.,3.,4.};
</code></pre>

<p><a href=""http://msdn.microsoft.com/en-us/library/83ythb65.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/83ythb65.aspx</a></p>

<p>Note that both <code>attribute</code> (in GCC) and <code>__declspec</code> (in VC++) are compiler-specific extensions.</p>

<p><strong>EDIT :</strong></p>

<p>Now that I take a second look at the code, it's gonna take more work than just replacing the <code>__attribute__</code> line with the VC++ equivalent to get it to compile in VC++.</p>

<p>VC++ doesn't have any if these macros/functions that you are using:</p>

<ul>
<li><code>__builtin_ia32_xorps</code></li>
<li><code>__builtin_ia32_loadups</code></li>
<li><code>__builtin_ia32_mulps</code></li>
<li><code>__builtin_ia32_addps</code></li>
<li><code>__builtin_ia32_storeups</code></li>
</ul>

<p>You're better off just replacing all of those with <a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_bk_intro.htm"" rel=""nofollow"">SSE intrinsics</a> - which will work on both GCC and VC++.</p>

<hr>

<p>Here's the code converted to intrinsics:</p>

<pre><code>float *mv_mult(float mat[SIZE][SIZE], float vec[SIZE]) {
    static float ret[SIZE];
    float temp[4];
    int i, j;
    __m128 m, v, r;

    for (i = 0; i &lt; SIZE; i++) {
        r = _mm_xor_ps(r, r);

        for (j = 0; j &lt; SIZE; j += 4) {
            m = _mm_loadu_ps(&amp;mat[i][j]);
            v = _mm_loadu_ps(&amp;vec[j]);
            v = _mm_mul_ps(m, v);
            r = _mm_add_ps(r, v);
        }

        _mm_storeu_ps(temp, r);
        ret[i] = temp[0] + temp[1] + temp[2] + temp[3];
    }

    return ret;
}
</code></pre>
"
"<p>just wondering, how do you use global arrays of a structure's?</p>

<p>For example:</p>

<pre><code>int y = 0;
object objectArray [100];

typedef struct object{
    time_t objectTime;
    int objectNumber;
} object;

int main(void)
{
    while(1)
    {
        time_t time_now;
        time_now = time(NULL);

        object x = {time_now, objectNo}
        objectArray[y] = x;
        y++;

    }
}
</code></pre>

<p>This always throws an ""error: array type has incomplete element type"", can anybody advise me of the problem and an appropriate solution?
Thanks </p>
","922184","","<p>Move the definition of the struct to before your declaration of the array:</p>

<pre><code>typedef struct object{
    time_t objectTime;
    int objectNumber;
} object;

object objectArray [100];
</code></pre>

<p>You're getting that error because the compiler doesn't know the size of <code>object</code> when it gets to the array declaration.</p>
"
"<p>I'm trying to find the cube root of a negative number but I get a NaN. Any help?</p>

<pre><code>System.out.println(Math.pow(-8, 1.0 / 3.0));
</code></pre>
","922184","","<p>Remember that mathematically, there are 3 cube-roots. Assuming you want the root that is real, you should do this:</p>

<pre><code>x = 8;  //  Your value

if (x &gt; 0)
    System.out.println(Math.pow(x, 1.0 / 3.0));
else
    System.out.println(-Math.pow(-x, 1.0 / 3.0));
</code></pre>

<p><strong>EDIT :</strong> As the other answers mention, there is <code>Math.cbrt(x)</code>. (which I didn't know existed)</p>

<p>The reason why <code>pow</code> returns <code>NaN</code> with a negative base and non-integral power is that powering is usually done by angle-magnitude in the complex plane.</p>

<ul>
<li>For positive real numbers, the angle is zero, so the answer will still be positive and real.</li>
<li>For negative real numbers, the angle is 180 degrees, which (after multiplying by a non-integral power) will always produce a complex number - hence a <code>NaN</code>.</li>
</ul>
"
"<p>All I'm trying to do is initialize my array to all 0s in C, but my compiler keeps giving me errors (and the errors aren't helpful). The array has 24 entries and the values are floating point values.</p>

<pre><code>main()
{

/* Array of users arrival &amp; departure time */
float user_queue[24];

/* Initialize queue to 0 */
int i;
for(i = 0; i &lt; 24; i++)
{
    user_queue[i] = 0.0;
}

/* Simulation time */
float time = 0;
</code></pre>

<p>The compiler is giving me an error on the ""float time"" line.  The error goes away if I remove my for loop.</p>

<blockquote>
  <p>syntax error : missing ; before type</p>
</blockquote>
","922184","","<p>You're overrunning the array by 1 element. Try this instead:</p>

<pre><code>for(i = 0; i &lt; 24; i++)
</code></pre>

<p>Change the <code>&lt;=</code> to <code>&lt;</code>.</p>

<p><strong>EDIT :</strong> With new information.</p>

<p>You're probably compiling in C89/90 or ANSI C mode. In those older C revisions, variable declarations must be at the start of the function or scope. You can't intermingle declarations and code like that.</p>

<p>Try this:</p>

<pre><code>main()
{

    /* Array of users arrival &amp; departure time */
    float user_queue[24];

    float time;  /* Declare up here */

    /* Initialize queue to 0 */
    int i;
    for(i = 0; i &lt; 24; i++)
    {
        user_queue[i] = 0.0;
    }

    /* Simulation time */
    time = 0;
</code></pre>
"
"<p>I'm interested in optimizing my code for multithreaded computing. In terms of the cache, pipelining, or any other aspects of memory access, how do the following compare for conserving those resources:</p>

<p>Case 1 </p>

<pre><code>struct something{
    float a;
    float b;
    int c;
    bool d;
};

vector &lt;something&gt; vec(n, something());

for(int q=0; q&lt;n; q++)
    {
         vec[q].a = expression1;
         vec[q].b = expression2;
         vec[q].c = expression3;
         vec[q].d = expression4;
    } 
</code></pre>

<p>Case 2</p>

<pre><code>struct something{
    float a;
    float b;
    int c;
    bool d;
};

vector &lt;something&gt; vec(n, something());

for(int q=0; q&lt;n; q++)
    vec[q].a = expression1;
for(int q=0; q&lt;n; q++)
    vec[q].b = expression2;
for(int q=0; q&lt;n; q++)
    vec[q].c = expression3;
for(int q=0; q&lt;n; q++)
    vec[q].d = expression4;
</code></pre>

<p>Case 3</p>

<pre><code>vector &lt;float&gt; a(n);
vector &lt;float&gt; b(n);
vector &lt;int&gt;   c(n);
vector &lt;bool&gt;  d(n); 

for(int q=0; q&lt;n; q++)
    a[q] = expression1;
for(int q=0; q&lt;n; q++)
    b[q] = expression2;
for(int q=0; q&lt;n; q++)
    c[q] = expression3;
for(int q=0; q&lt;n; q++)
    d[q] = expression4;
</code></pre>

<p>Also, are there better ways of approaching the above?  </p>
","922184","","<ul>
<li><strong>Case 1</strong> is the most readable.</li>
<li><strong>Case 1</strong> and <strong>case 3</strong> are equally cache friendly. Both make only one pass through all the data.*</li>
<li><strong>Case 2</strong> is the worst because it makes 4 passes over the data - each pass only touching one element.</li>
</ul>

<p>If all the struct fields are different, then <strong>case 3</strong> has a huge advantage of possibly being vectorizable while <strong>case 1</strong> doesn't.</p>

<p>The reason for this is because <strong>case 3</strong> is the <strong><em>struct of arrays</em></strong> packing that puts all the same datatypes together sequentially in memory - thereby exposing vectorization.</p>

<p><strong>EDIT :</strong></p>

<p>*<strong>Case 3</strong> is potentially even more cache friendly than <strong>case 1</strong> because it doesn't need struct-padding - so the data size is smaller.</p>
"
"<p>What, if anything, is theoretically wrong with this c/c++ statement:</p>

<pre><code>*memory++ = BIT_MASK &amp; *memory;
</code></pre>

<p>Where <code>BIT_MASK</code> is an arbitrary bitwise <code>AND</code> mask, and memory is a pointer.</p>

<p>The intent was to read a memory location, <code>AND</code> the value with the mask, store the result at the original location, then finally increment the pointer to point to the next memory location.</p>
","922184","","<p>It's undefined behavior since you have <code>memory++</code> and <code>memory</code> in the same statement.</p>

<p>This is because C/C++ does not specify exactly when the <code>++</code> will occur. It can be before or after <code>*memory</code> is evaluated.</p>

<p>Here are two ways to fix it:</p>

<pre><code>*memory = BIT_MASK &amp; *memory;
memory++;
</code></pre>

<p>or just simply:</p>

<pre><code>*memory++ &amp;= BIT_MASK;
</code></pre>

<p>Take your pick.</p>
"
"<p>How can I compile a C program without undergoing any optimizations using gcc/g++?</p>
","922184","","<pre><code>gcc main.c
</code></pre>

<p>or</p>

<pre><code>g++ main.cpp
</code></pre>

<p>by default it doesn't do any optimizations. Only when you specify <code>-O1, -O2, -O3, etc...</code> does it do optimizations.</p>

<p>Or you can use the <code>-O0</code> switch to make it explicit.</p>
"
"<p>I have 2 sets of values.  Each is in the range of -50 to + 50.</p>

<p>Is there any way to represent two of these values in a single byte?
 (I am working in C, using Vstudio 2010).
Thank you.</p>

<p>Clarification: the values are arbitrary integers; that is, the values can be
any integer between -50 and +50.  (So, question has been answered: it is ""no"".)</p>
","922184","","<p>No, not in 8 bits. -50 to +50 is 101 possibilities. With two of them, that's 10201 possibilities. 8 bits only has 256 combinations.</p>

<p>You will need a minimum of 14 bits to store two values -50 to +50.</p>
"
"<p>I am a beginner of Qt and this is my first Qt program.I almost copied a program from my textbook but it didn't work. I think I must made a stupid mistake but I can't google the answer out. I'll post the code and the compile result below. Thanks.</p>

<p>glface.h:</p>

<pre><code>#ifndef GLFACE_H

#define GLFACE_H

#include&lt;QWidget&gt;

#include&lt;QPoint&gt;

class glface: public QWidget
{
Q_OBJECT
public:
glface(QWidget *parent = 0);

protected:
void paintEvent(QPaintEvent *event);
void mousePressEvent(QMouseEvent *event);
void mouseMoveEvent(QMouseEvent *event);
void mouseReleaseEvent(QMouseEvent *event);

private slots:
void clear();

void toget();

void drawline(QPainter *painter);


private:
QTimer *recordtimer;

static bool got; //the flag for the timer

bool startdraw;

QPoint lastpoint;

QPoint point[100];

static int pointcount;
};

#endif // GLFACE_H
</code></pre>

<p>glface.cpp</p>

<pre><code>#include &lt;QtGui&gt;
#include ""glface.h""


glface::glface(QWidget *parent):QWidget(parent)
{
recordtimer= new QTimer(this);
connect(recordtimer,SIGNAL(timeout()),this,SLOT(toget()));


}
glface::mousePressEvent(QMouseEvent *event)
{
if (event-&gt;button==Qt::LeftButton )
{
    startdraw=true;
    point[pointcount]=event-&gt;pos();
    pointcount++;
    recordtimer-&gt;start(1000);

}


}
glface::toget()
{
got=true;
}

glface::mouseMoveEvent(QMouseEvent *event)
{
if (event-&gt;button()==Qt::LeftButton &amp;&amp; event-&gt;pos()!=lastpoint &amp;&amp; startdraw &amp;&amp; got)
{
    point[pointcount]=event-&gt;pos();
    pointcount++;
    got=false;
    drawline(&amp;painter);
}
}
glface::mouseReleaseEvent(QMouseEvent *event)
{
point[pointcount]=event-&gt;pos();
pointcount++;
startdraw=false;
recordtimer-&gt;stop();
got=false;
pointcount=0;
}

glface::paintEvent(QPaintEvent *event)
{
QPainter painter(this);
painter.setRenderHint(QPainter::Antialiasing, true);
painter.setPen(QPen(Qt::black, 15, Qt::SolidLine, Qt::RoundCap,
Qt::MiterJoin));
painter.setBackground(Qt::white);
painter.setWindow(0,0,400,300);
}
glface::drawline(QPainter *painter)
{
if (pointcount&gt;1)
    painter-&gt;drawLine(point[pointcount-1],point[pointcout-2]);

}
</code></pre>

<p>main.cpp</p>

<pre><code>#include &lt;QApplication&gt;
#include &lt;QtCore&gt;
#include ""glface.h""
int main(int argc,char *argv[])
{
QApplication app(argc, argv);
glface face;
face.show();
return app.exec();

}
</code></pre>

<p>compile results:</p>

<pre><code>glface.cpp:12: error: ISO C++ forbids declaration of ‘mousePressEvent’ with no type
glface.cpp:12: error: prototype for ‘int glface::mousePressEvent(QMouseEvent*)’ does not     match any in class ‘glface’
glface.h:15: error: candidate is: virtual void glface::mousePressEvent(QMouseEvent*)
glface.cpp:25: error: ISO C++ forbids declaration of ‘toget’ with no type
glface.cpp:25: error: prototype for ‘int glface::toget()’ does not match any in class ‘glface’
glface.h:20: error: candidate is: void glface::toget()
glface.cpp:30: error: ISO C++ forbids declaration of ‘mouseMoveEvent’ with no type
glface.cpp:30: error: prototype for ‘int glface::mouseMoveEvent(QMouseEvent*)’ does not match any in class ‘glface’
glface.h:16: error: candidate is: virtual void glface::mouseMoveEvent(QMouseEvent*)
glface.cpp:40: error: ISO C++ forbids declaration of ‘mouseReleaseEvent’ with no type
glface.cpp:40: error: prototype for ‘int glface::mouseReleaseEvent(QMouseEvent*)’ does not match any in class ‘glface’
glface.h:17: error: candidate is: virtual void glface::mouseReleaseEvent(QMouseEvent*)
glface.cpp:50: error: ISO C++ forbids declaration of ‘paintEvent’ with no type
glface.cpp:50: error: prototype for ‘int glface::paintEvent(QPaintEvent*)’ does not match any in class ‘glface’
glface.h:14: error: candidate is: virtual void glface::paintEvent(QPaintEvent*)
glface.cpp:59: error: ISO C++ forbids declaration of ‘drawline’ with no type
glface.cpp:59: error: prototype for ‘int glface::drawline(QPainter*)’ does not match any in class ‘glface’
glface.h:21: error: candidate is: void glface::drawline(QPainter*)
</code></pre>
","922184","","<p>All of your function definitions in <code>glface.cpp</code> are missing the return type:</p>

<pre><code>void glface::mousePressEvent(QMouseEvent *event)
^^^^ missing

void glface::mouseMoveEvent(QMouseEvent *event)
^^^^ missing
</code></pre>

<p>etc...</p>
"
"<p>I am trying to convert <code>65529</code> from an <code>unsigned int</code> to a signed <code>int</code>. I tried doing a cast like this:</p>

<pre><code>unsigned int x = 65529;
int y = (int) x;
</code></pre>

<p>But <code>y</code> is still returning 65529 when it should return -7. Why is that?</p>
","922184","","<p>It seems like you are expecting <code>int</code> and <code>unsigned int</code> to be a 16-bit integer. That's apparently not the case. Most likely, it's a 32-bit integer - which is large enough to avoid the wrap-around that you're expecting.</p>

<p>Note that there is no fully C-compliant way to do this because casting between signed/unsigned for values out of range is implementation-defined. But this will still work in most cases:</p>

<pre><code>unsigned int x = 65529;
int y = (short) x;      //  If short is a 16-bit integer.
</code></pre>

<p>or alternatively:</p>

<pre><code>unsigned int x = 65529;
int y = (int16_t) x;    //  This is defined in &lt;stdint.h&gt;
</code></pre>
"
"<p>I am trying to make the last element in an array of pointers a NULL but I am having some problems. My code is as follows:</p>

<pre><code>kernel-&gt;availMsgEnvQueue = (MsgEnv *)malloc(AVAIL_MSG_ENV_SIZE * sizeof(MsgEnv));
int i;
for(i=0; i&lt;AVAIL_MSG_ENV_SIZE-1; i++)
     {
    kernel-&gt;availMsgEnvQueue[i].nextMsgEnv = &amp;(kernel-&gt;availMsgEnvQueue[i+1]);
    kernel-&gt;availMsgEnvQueue[i].msg = (Msg)malloc(MSG_SIZE * sizeof(char));
}
kernel-&gt;availMsgEnvQueue[19].nextMsgEnv = NULL;
</code></pre>

<p>Where AVAIL_MSG_ENV_SIZE is 20. I am trying to make the 20th element a null but this is not working as I am getting a segmentation fault when I run the following to test:</p>

<pre><code>while (kernel-&gt;availMsgEnvQueue-&gt;nextMsgEnv) 
     {
    printf (""%d\n"", x);
    temp = temp-&gt;nextMsgEnv;
    x++;
}
</code></pre>

<p>X counts all the way upto 20 and then it crashes. Please assist.</p>

<hr>

<p><strong>EDIT :</strong> Apparantly the last element in the list is being sent to zero. I can't figure out if this code will dequeue the last message envelope from the queue::</p>

<pre><code>MsgEnv * k_request_msg_env (){
    MsgEnv * env = kernel-&gt;availMsgEnvQueue-&gt;nextMsgEnv;
    if(!env){
        printf (""This one was null"");
        PCB * pcb = kernel-&gt;current_process;
        if(pcb-&gt;state != IS_IPROCESS){
            printf (""Process %d is being blocked on request"",pcb-&gt;id);
            pcb-&gt;state = BLOCK_ON_ENV;
            enPQ(kernel-&gt;bq, pcb, pcb-&gt;priority);
            k_process_switch();
        }
    }else{
        kernel-&gt;availMsgEnvQueue-&gt;nextMsgEnv = kernel-&gt;availMsgEnvQueue-&gt;nextMsgEnv-&gt;nextMsgEnv;
        env-&gt;nextMsgEnv = NULL;

        //clear message
        memset(env-&gt;msg, 0, MSG_SIZE);
    }
    return env;
}
</code></pre>

<p>Thanks!</p>
","922184","","<p>Your loop-test doesn't change:</p>

<pre><code>while (kernel-&gt;availMsgEnvQueue-&gt;nextMsgEnv) {
</code></pre>

<p>So it's iterating through 20 times, and keeps on going...</p>

<p>Perhaps you meant this?</p>

<pre><code>while (kernel-&gt;availMsgEnvQueue[x].nextMsgEnv) {
</code></pre>
"
"<p>I want to know the difference between <code>str == NULL</code> and <code>str[0] == '\0'</code>:</p>

<pre><code>int convert_to_float(char *str, double *num)
{
    if ((str == NULL) || (str[0] == '\0'))
        return(-1);

    *num = strtod(str, (char **)NULL);
    return(0);
}
</code></pre>

<p>I'm using gcc on Linux.</p>
","922184","","<p><code>str==NULL</code> tells you whether the pointer is NULL.</p>

<p><code>str[0]=='\0'</code> tells you if the string is of zero-length.</p>

<p>In that code, the test:</p>

<pre><code>if ((str == NULL) || (str[0] == '\0'))
</code></pre>

<p>is used to catch the case where it is either NULL or has zero-length.</p>

<hr>

<p><strong>Note that short-circuiting plays a key role here:</strong> The point of the test is to make sure that <code>str</code> is a valid c-string with length at least 1.</p>

<ul>
<li>The second test <code>str[0] == '\0'</code> will only work if <code>str</code> is not NULL.</li>
<li>Therefore, the first test <code>str == NULL</code> is needed to break out early when <code>str</code> is NULL.</li>
</ul>
"
"<p>I'm working with OpenMP to parallelize a scalar nested for loop:</p>

<pre><code>double P[N][N];
double x=0.0,y=0.0;

for (int i=0; i&lt;N; i++)
{
    for (int j=0; j&lt;N; j++)
    {
        P[i][j]=someLongFunction(x,y);
        y+=1;
    }
    x+=1;
}
</code></pre>

<p>In this loop the important thing is that matrix P must be the same in both scalar and parallel versions:</p>

<p>All my possible trials didn't succeed...</p>
","922184","","<p>The problem here is that you have added iteration-to-iteration dependencies with:</p>

<pre><code>x+=1;
y+=1;
</code></pre>

<p>Therefore, as the code stands right now, it is not parallelizable. Attempting to do so will result in incorrect results. (as you are probably seeing)</p>

<p>Fortunately, in your case, you can directly compute them without introducing this dependency:</p>

<pre><code>for (int i=0; i&lt;N; i++)
{
    for (int j=0; j&lt;N; j++)
    {
        P[i][j]=someLongFunction((double)i, (double)N*i + j);
    }
}
</code></pre>

<p>Now you can try throwing an OpenMP pragma over this and see if it works:</p>

<pre><code>#pragma omp parallel for
for (int i=0; i&lt;N; i++)
{
    for (int j=0; j&lt;N; j++)
    {
        P[i][j]=someLongFunction((double)i, (double)N*i + j);
    }
}
</code></pre>
"
"<p>I'm wondering why the following code produces different results in its scalar and parallel variants:</p>

<pre><code>#define N 10
double P[N][N];
// zero the matrix just to be sure...
for (int i=0; i&lt;N; i++)
    for(int j=0; j&lt;N; j++)
        P[i][j]=0.0;


double xmin=-5.0,ymin=-5.0,xmax=5.0,ymax=5.0;
double x=xmin,y=ymin;
double step= abs(xmax-xmin)/(double)(N - 1 );
for (int i=0; i&lt;N; i++)
{
    #pragma omp parallel for ordered schedule(dynamic)
    for ( int j=0; j&lt;N; j++)
    {
        x = i*step+xmin;
        y = j*step+ymin;
        P[i][j]=x+y;
    }
}
</code></pre>

<p>This code produces not completely equal results in its two version (the scalar version has just the <code>#pragma ...</code> part commented out).
What I've noticed is that a very small percentual of the elements of <code>P[i][j]</code> in the parallel version are different from those of the scalar version, but I'm wondering why... </p>

<p>Putting the <code>#pragma</code> on the outer loop as suggested is mess...completely wrong results.</p>

<p>P.S.
g++-4.4, intel i7, linux</p>
","922184","","<p>Ah, now I can see the problem. Your comment <a href=""http://stackoverflow.com/questions/8338218/how-to-parallelize-correctly-a-nested-for-loops"">on the last question</a> didn't have enough context for me to see it. But now it's clear.</p>

<p>The problem is here:</p>

<pre><code>    x = i*step+xmin;
    y = j*step+ymin;
</code></pre>

<p><code>x</code> and <code>y</code> are declared outside the parallel region, so they are being shared among all the threads. (and thus a nasty race condition among all the threads...)</p>

<p>To fix it, make them local:</p>

<pre><code>for ( int j=0; j&lt;N; j++)
{
    double x = i*step+xmin;
    double y = j*step+ymin;
    P[i][j]=x+y;
}
</code></pre>

<p>With this fix, you should be able to put the <code>#pragma</code> on the outer loop instead of the inner loop.</p>
"
"<p>When I run the code below, in my <code>trainingVector</code> I get:</p>

<pre><code>{(10,0),(10,0),(10,0)...}
</code></pre>

<p>instead of:</p>

<pre><code>{(0,0),(1,0),(2,0)...}
</code></pre>

<p>How do i make this work correctly?     </p>

<pre><code>vector&lt; vector&lt; double &gt; * &gt; trainingVector; 
for(int i=0;i&lt;10;i++){     
    vector&lt;double&gt; ok (2,0);
    ok[0]=i;
    trainingVector.push_back(&amp;ok)
}
</code></pre>
","922184","","<p>The method you are using right now won't work because the life of each vector <code>ok</code> object lasts only within the iteration before it falls out of scope and dies.</p>

<p>You need to do this instead:</p>

<pre><code>vector&lt; vector&lt; double &gt; * &gt; trainingVector; 
for(int i=0;i&lt;10;i++){     
   vector&lt;double&gt; *ok = new vector&lt;double&gt;(2,0);
   (*ok)[0]=i;
   trainingVector.push_back(ok);
}
</code></pre>

<p>Be aware that you will need to free each inner vector manually later. Or you'll get a memory leak.</p>

<pre><code>for(int i=0;i&lt;10;i++){     
   delete trainingVector[i];
}
</code></pre>

<p>Alternatively, you can do it without pointers all together:</p>

<pre><code>vector&lt; vector&lt; double &gt; &gt; trainingVector; 
for(int i=0;i&lt;10;i++){     
   vector&lt;double&gt; ok = vector(2,0);
   ok[0]=i;
   trainingVector.push_back(ok);
}
</code></pre>

<p>Though this latter method implies copying the inner vector when it is put into the outer vector.</p>
"
"<p>Programs like CPUz are very good at giving in depth information about the system (bus speed, memory timings, etc.)</p>

<p>However, is there a programmatic way of calculating the per core (and per processor, in multi processor systems with multiple cores per CPU) frequency without having to deal with CPU specific info.</p>

<p>I am trying to develop a anti cheating tool (for use with clock limited benchmark competitions) which will be able to record the CPU clock during the benchmark run for all the active cores in the system (across all processors.)</p>
","922184","","<p>I'll expand on my comments here. This is too big and in-depth for me to fit in the comments.</p>

<p>What you're trying to do is very difficult - to the point of being impractical for the following reasons:</p>

<ul>
<li>There's no portable way to get the processor frequency. <code>rdtsc</code> does <strong><em>NOT</em></strong> always give the correct frequency due to effects such as SpeedStep and Turbo Boost.</li>
<li>All known methods to measure frequency require an accurate measurement of time. However, a determined cheater can tamper with all the clocks and timers in the system.</li>
</ul>

<hr>

<p><strong>There's no portable way to get the processor frequency:</strong></p>

<p>The ""easy"" way to get the CPU frequency is to call <a href=""http://en.wikipedia.org/wiki/Time_Stamp_Counter""><code>rdtsc</code></a> twice with a fixed time-duration in between. Then dividing out the difference will give you the frequency.</p>

<p>The problem is that <code>rdtsc</code> does not give the true frequency of the processor. Because real-time applications such as games rely on it, <code>rdtsc</code> needs to be consistent through CPU throttling and Turbo Boost. So once your system boots, <code>rdtsc</code> will always run at the same rate (unless you start messing with the bus speeds with <a href=""http://www.tomshardware.com/reviews/overclocking-software,2059-3.html"">SetFSB</a> or something).</p>

<p>For example, on my Core i7 2600K, <code>rdtsc</code> will always show the frequency at <code>3.4 GHz</code>. But in reality, it idles at <code>1.6 GHz</code> and clocks up to <code>4.6 GHz</code> under load via the overclocked Turbo Boost multiplier at <code>46x</code>.</p>

<p>Now suppose you find a way to measure the true frequency, (or you're happy enough with <code>rdtsc</code>). To get the frequencies of each core on each socket, you do that by playing with <a href=""http://en.wikipedia.org/wiki/Processor_affinity"">thread-affinities</a>.</p>

<p>I'm not sure exactly how CPUz measures the correct frequency. But I think it actually goes all the way into BIOS and does it's own bus-speed x multiplier arithmetic. This requires having a database of all the processor systems. (which explains why CPUz needs to be constantly updated with new processors)</p>

<p><strong>All known methods to measure frequency require an accurate measurement of time:</strong></p>

<p>This is perhaps the bigger problem. You need a timer to be able to measure the frequency. A capable hacker will be able to tamper with all the clocks that you can use in C/C++.
This includes all of the following:</p>

<ul>
<li><code>clock()</code></li>
<li><code>gettimeofday()</code></li>
<li><code>QueryPerformanceCounter()</code></li>
<li>etc...</li>
</ul>

<p>The list goes on and on. In other words, you cannot trust any of the timers as a capable hacker will be able to spoof all of them. For example <code>clock()</code> and <code>gettimeofday()</code> can be fooled by changing the system clock directly within the OS. Fooling <code>QueryPerformanceCounter()</code> is harder. At the request of the <a href=""http://www.xtremesystems.org/forums/forum.php"">XtremeSystems Forums</a> admins, I will not reveal how to do this. They have taught me some of the most powerful overclocking cheats just so that I could develop and implement countermeasures into my <a href=""http://www.numberworld.org/y-cruncher/"">y-cruncher Multi-threaded Pi Benchmark</a>. But for the most part, I'm not entirely successful in implementing these countermeasures...</p>

<hr>

<p>So to answer your question in the comments, yes I have implemented a decent anti-cheating system to prevent timer hacks. Although I don't try to get an accurate frequency measurement, the timer-protection is enough to make the benchmarks reasonably hard to cheat.</p>

<p>I obviously can't go into details, but part of it involves using multiple clocks and re-syncing them multiple times during a benchmark. If any of them get to far out-of-sync, then raise the cheat flag.</p>

<p>Overall, what I have is not perfect. I can hack it myself in about 5 min. (well, I know how it works). Furthermore, it occasionally gives false-positives... which is also bad.</p>
"
"<p>Usually I do <code>strcpy</code> but here is looking like I can't copy bigger-sized to lower-sized array. I understand that I need to skip an array element for it, I want to skip first <code>[0]</code> element but how can I do it? I really don't want to write something alike <code>a[39]=b[40]; a[38]=b[39]...</code> etc.</p>
","922184","","<p>You can just use <code>strcpy()</code> with the arguments shifted:</p>

<pre><code>strcpy(a,b + 1);
</code></pre>

<p>This will skip the first character of <code>b</code>.</p>
"
"<p>Cant seem to find the answer to this, I'm sure it's simple, but just want to understand this so I can move on.</p>

<p>I'm looking at integer types, and am wondering why this:</p>

<pre><code>long number = 645456645;
</code></pre>

<p>has the same effect as:</p>

<pre><code>long number = 654456654L;
</code></pre>

<p>What is the point of using that letter 'L' at the end? Same with the 'U' for unsigned case.</p>
","922184","","<p>It's to specify the type of the integer literal. <code>L</code> makes it a <code>long</code> and <code>U</code> makes it unsigned.</p>

<p>The use of it is cases like this:</p>

<pre><code>long long number = 123456789123456;
long long number = 123456789123456LL;
</code></pre>

<p>Some compilers will complain about the first one since <code>123456789123456</code> doesn't fit in the default <code>int</code>.</p>

<p>The other case where it is used is to disambiguate between overloaded functions.</p>

<hr>

<p><strong>EDIT: (see comments)</strong></p>

<p><strong>main.cpp</strong></p>

<pre><code>int main(){

    long long number = 123456789123456;

    return 0;
}
</code></pre>

<p>Compiling it gives:</p>

<pre><code>alex-desktop:~/Desktop/vm_shared&gt; g++ main.cpp
main.cpp:3: warning: integer constant is too large for ‘long’ type
alex-desktop:~/Desktop/vm_shared&gt; 
</code></pre>

<p>gcc version: 4.4.3</p>
"
"<p>I am new to bit manipulations tricks and I wrote a simple code to see the output of doing single bit shifts on a single number viz. <code>2</code></p>

<pre><code>#include &lt;iostream&gt;
int main(int argc, char *argv[])
{

  int num=2;

 do
   {
     std::cout&lt;&lt;num&lt;&lt;std::endl;
     num=num&lt;&lt;1;//Left shift by 1 bit.

   } while (num!=0);


  return 0;
}
</code></pre>

<p>The output of this is the following. </p>

<pre><code>2
4
8
16
32
64
128
256
512
1024
2048
4096
8192
16384
32768
65536
131072
262144
524288
1048576
2097152
4194304
8388608
16777216
33554432
67108864
134217728
268435456
536870912
1073741824
-2147483648
</code></pre>

<p>Obviously,  continuously bit shifting to the left by 1 bit, will result in zero as it has done above, but why does the computer output a negative number <em>at the very end</em> before   terminating the loop (since num turned zero)??</p>

<p>However when I replace <code>int num=2</code> by <code>unsigned int num=2</code> then I get the same output except 
that the last number is this time displayed as positive i.e. <code>2147483648</code> instead of <code>-2147483648</code></p>

<p>I am using the <code>gcc</code> compiler on Ubuntu Linux</p>
","922184","","<p>That's because <code>int</code> is a signed integer. In the <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""nofollow"">two's-complement representation</a>, the sign of the integer is determined by the upper-most bit.</p>

<p>Once you have shifted the 1 into the highest (sign) bit, it flips negative.</p>

<p>When you use <code>unsigned</code>, there's no sign bit.</p>

<pre><code>0x80000000 = -2147483648 for a signed 32-bit integer.
0x80000000 =  2147483648 for an unsigned 32-bit integer.
</code></pre>

<p><strong>EDIT :</strong></p>

<p>Note that strictly speaking, signed integer overflow is undefined behavior in C/C++. The behavior of GCC in this aspect is not completely consistent:</p>

<ul>
<li><code>num = num &lt;&lt; 1;</code> or <code>num &lt;&lt;= 1;</code> usually behaves as described above.</li>
<li><code>num += num;</code> or <code>num *= 2;</code> may actually <a href=""http://stackoverflow.com/questions/7682477/gcc-fail-or-undefined-behavior"">go into an infinite loop on GCC</a>.</li>
</ul>
"
"<pre><code>#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;

int main(int argc, char *argv[])
{

  int num=-2147483648;
  int positivenum=-num;
  int absval=abs(num);

  std::cout&lt;&lt;positivenum&lt;&lt;""\n"";
  std::cout&lt;&lt;absval&lt;&lt;""\n"";

  return 0;
}
</code></pre>

<p>Hi I am quite curious why the output of the above code is  </p>

<pre><code>-2147483648
-2147483648
</code></pre>

<p>Now I know that <code>-2147483648</code> is the smallest represntable number among signed ints, (assuming an <code>int</code> is 32 bits). I would have assumed that one would get garbage answers only after we went below this number. But in this case, +2147483648 IS covered by the 32 bit system of integers. So why the negative answer in both cases? </p>
","922184","","<blockquote>
  <p>But in this case, +2147483648 IS covered by the 32 bit system of integers.</p>
</blockquote>

<p>Not quite correct. It only goes up to +2147483647. So your assumption isn't right.</p>

<p>Negating <code>-2147483648</code> will indeed produce <code>2147483648</code>, but it will overflow back to <code>-2147483648</code>.</p>

<p>Furthermore, signed integer overflow is technically undefined behavior.</p>
"
"<p>I have learned how to work with 80x86 assembler, so in bit-wise shift operation, i faced a problem with SAL and SHL usage. I means the difference between lines of code as follow :</p>

<pre><code>MOV X, 0AAH
SAL X, 4

MOV X, 0AAH
SHL X, 4
</code></pre>

<p>When we should use SHL and when use SAL ? What is the difference of them ? </p>

<p>Thanks for your attention :)</p>
","922184","","<p>According to <a href=""http://siyobik.info/main/reference/instruction/SAL/SAR/SHL/SHR"">this</a>, they are the same:</p>

<blockquote>
  <p>The shift arithmetic left (SAL) and shift logical left (SHL)
  instructions perform the same operation; they shift the bits in the
  destination operand to the left (toward more significant bit
  locations). For each shift count, the most significant bit of the
  destination operand is shifted into the CF flag, and the least
  significant bit is cleared (see Figure 7-7 in the Intel®64 and IA-32
  Architectures Software Developer'sManual, Volume 1).</p>
</blockquote>

<p>Both were probably included just for completeness since there <em>is</em> a distinction for right-shifts.</p>
"
"<p>In C/C++ suppose  I define a simple struct named <code>point</code> as follows. </p>

<pre><code>struct test
{
double height;
int    age;
char   gender;
}
</code></pre>

<p>For a specific instance of this struct  say <code>test A</code> are <code>A.height, A.age, A.gender</code> contiguous
in memory? </p>

<p>More generally, how do the layouts in memory for a Structure of Arrays and an Array of structures look like? A picture would be really helpful. </p>
","922184","","<p>They will not necessarily be contiguous in memory. This is due to <a href=""http://en.wikipedia.org/wiki/Data_structure_alignment"">struct padding</a>.</p>

<p>However, in your particular case, it may very well be contiguous. But if you changed the order to something like this:</p>

<pre><code>struct test
{
    char   gender;
    int    age;
    double height;
}
</code></pre>

<p>then they most likely will not be. However, in your particular case, you will still likely get padding after <code>gender</code>, to realign the struct to 8 bytes.</p>

<hr>

<p>The difference between SoA and AoS would be like this:</p>

<p><strong>SoA:</strong></p>

<pre><code>-----------------------------------------------------------------------------------
| double | double | double | *pad* | int | int | int | *pad* | char | char | char |
-----------------------------------------------------------------------------------
</code></pre>

<p><strong>AoS:</strong></p>

<pre><code>-----------------------------------------------------------------------------------
| double | int | char | *pad* | double | int | char | *pad* | double | int | char |
-----------------------------------------------------------------------------------
</code></pre>

<p>Note that AoS pads within each struct. While SoA pads between the arrays.</p>

<p><strong>These have the following trade-offs:</strong></p>

<ol>
<li><strong>AoS</strong> tends to be more readable to the programmer as each ""object"" is kept together.</li>
<li><strong>AoS</strong> may have better cache locality if all the members of the struct are accessed together.</li>
<li><strong>SoA</strong> could potentially be more efficient since grouping same datatypes together sometimes exposes vectorization.</li>
<li>In many cases <strong>SoA</strong> uses less memory because padding is only between arrays rather than between every struct.</li>
</ol>
"
"<p>I keep getting zero as my time. I need to calculate the total time and the average time for searching though the hash table. Can someone please tell me what i am doing wrong? </p>

<pre><code>void HashTable_chaining::SearchChainingHT(vector&lt;string&gt; QueryArray)
{
    clock_t start, stop, time = 0;
    int i = 0;
    while(i != QueryArray.size())
    {
        start = clock();
        find(QueryArray[i]);
        stop = clock();
        time += stop - start;
        i++;
    }
    time = (double)(time/CLOCKS_PER_SEC)*1000;
    cout &lt;&lt; ""\nThe total time for Search Chaining was "" &lt;&lt; time &lt;&lt; ""\nThe average time was "" &lt;&lt; time/QueryArray.size();
}
</code></pre>
","922184","","<p>You're doing integer division:</p>

<pre><code>(double)(time/CLOCKS_PER_SEC)*1000;
</code></pre>

<p>you want the cast inside the <code>()</code> instead:</p>

<pre><code>((double)time/CLOCKS_PER_SEC)*1000;
</code></pre>

<p>Furthermore, I'm not sure why you are assigning it back to <code>time</code> since that's an integer variable. If you wanted it in milliseconds, you might want to make it explicit:</p>

<pre><code>cout &lt;&lt; ""\nThe total time for Search Chaining was "" &lt;&lt; time &lt;&lt; ""  (milliseconds)"" &lt;&lt; ...
</code></pre>

<p><strong>EDIT :</strong></p>

<p>I overlooked this initially (because of the horizontal scrolling), but you also have integer division here at the end of the printing line:</p>

<pre><code>.. &lt;&lt; ""\nThe average time was "" &lt;&lt; time/QueryArray.size();
</code></pre>

<p>You may want to cast that one to <code>double</code> as well.</p>
"
"<p>i have several nested for loops in my code and i try to use intel SSE instructions on an intel i7 core to speed up the application.
The code structure is as follows (val is set in a higher for loop):</p>

<pre><code>_m128 in1,in2,tmp1,tmp2,out;
float arr[4] __attribute__ ((aligned(16)));
val = ...;

... several higher for loops ...
for(f=0; f&lt;=fend; f=f+4){
    index2 = ...;
    for(i=0; i&lt;iend; i++){
        for(j=0; j&lt;jend; j++){
            inputval = ...;
            index = ...;
            if(f&lt;fend-4){
                arr[0] = array[index];
                arr[1] = array[index+val];
                arr[2] = array[index+2*val];
                arr[3] = array[index+3*val];
                in1  = _mm_load_ps(arr);
                in2  = _mm_set_ps1(inputval);
                tmp1 = _mm_mul_ps(in1, in2);
                tmp2 = _mm_loadu_ps(&amp;array2[index2]);
                out  = _mm_add_ps(tmp1,tmp2);
                _mm_storeu_ps(&amp;array2[index2], out);
            } else {
                //if no 4 values available for SSE instruction execution execute serial code
                for(int u = 0; u &lt; fend-f; u++ ) array2[index2+u] += array[index+u*val] * inputval;
            }
        }
    }
}
</code></pre>

<p>I think there are two main problems: the buffer used for aligning the values from 'array', and the fact that when no 4 values are left (e.g. when fend = 6, two values are left over which should be executed with the sequential code). Is there any other way of loading the values from in1 and/or executing SSE intructions with 3 or 2 values? </p>

<hr>

<p>Thanks for the answers so far. The loading is as good as it gets i think, but is there any workaround for the 'leftover' part within the else statement that could be solved using SSE instructions?</p>
","922184","","<p>I think the bigger problem is that there is so little computation for such a massive amount of data movement:</p>

<pre><code>arr[0] = array[index];                   //  Data Movement
arr[1] = array[index+val];               //  Data Movement
arr[2] = array[index+2*val];             //  Data Movement
arr[3] = array[index+3*val];             //  Data Movement
in1  = _mm_load_ps(arr);                 //  Data Movement
in2  = _mm_set_ps1(inputval);            //  Data Movement
tmp1 = _mm_mul_ps(in1, in2);             //  Computation
tmp2 = _mm_loadu_ps(&amp;array2[index2]);    //  Data Movement
out  = _mm_add_ps(tmp1,tmp2);            //  Computation
_mm_storeu_ps(&amp;array2[index2], out);     //  Data Movement
</code></pre>

<p>While it ""might"" be possible to simplify this. I'm not at all convinced that vectorization is going to be beneficial at all in this situation.</p>

<p>You'll have to change your data layout to make avoid the strided access <code>index + n*val</code>.</p>

<p>Or you can wait until AVX2 gather/scatter instructions become available in 2013?</p>
"
"<p>How can the theoretical peak performance of 4 floating point operations (double precision) per cycle be achieved on a modern x86-64 Intel cpu?</p>

<p>As far as I understand it take 3 cycles for an sse <code>add</code> and 5 cycles for a <code>mul</code> to complete on most of the modern Intel cpu's (see e.g. <a href=""http://agner.org/optimize/instruction_tables.pdf"">Agner Fog's 'Instruction Tables'</a> ). Due to pipelining one can get a throughput of 1 <code>add</code> per cycle if the algorithm has at least 3 independent summations. Since that is true for packed <code>addpd</code> as well as the scalar <code>addsd</code> versions and sse registers can contain 2 <code>double</code>'s the throughput can be as much as 2 flops per cycle.
Furthermore it seems (although I've not seen any proper doc on this) <code>add</code>'s and <code>mul</code>'s can be executed in parallel giving a theoretical max throughput of 4 flops per cycle.</p>

<p>However, I've not been able to replicate that performance with a simple c/c++ programme. My best attempt resulted in about 2.7 flops/cycle. If anyone can contribute a simple c/c++ or assembler programme which demonstrates peak performance that'd be greatly appreciated.</p>

<p>My attempt:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
#include &lt;sys/time.h&gt;

double stoptime(void) {
   struct timeval t;
   gettimeofday(&amp;t,NULL);
   return (double) t.tv_sec + t.tv_usec/1000000.0;
}

double addmul(double add, double mul, int ops){
   // need to initialise differently otherwise compiler might optimise away
   double sum1=0.1, sum2=-0.1, sum3=0.2, sum4=-0.2, sum5=0.0;
   double mul1=1.0, mul2= 1.1, mul3=1.2, mul4= 1.3, mul5=1.4;
   int loops=ops/10;          // we have 10 floating point ops inside the loop
   double expected = 5.0*add*loops + (sum1+sum2+sum3+sum4+sum5)
               + pow(mul,loops)*(mul1+mul2+mul3+mul4+mul5);

   for(int i=0; i&lt;loops; i++) {
      mul1*=mul; mul2*=mul; mul3*=mul; mul4*=mul; mul5*=mul;
      sum1+=add; sum2+=add; sum3+=add; sum4+=add; sum5+=add;
   }
   return  sum1+sum2+sum3+sum4+sum5+mul1+mul2+mul3+mul4+mul5 - expected;
}

int main(int argc, char** argv) {
   if(argc!=2) {
      printf(""usage: %s &lt;num&gt;\n"", argv[0]);
      printf(""number of operations: &lt;num&gt; millions\n"");
      exit(EXIT_FAILURE);
   }
   int n=atoi(argv[1])*1000000;
   if(n&lt;=0) n=1000;

   double x=M_PI;
   double y=1.0+1e-8;
   double t=stoptime();
   x=addmul(x,y,n);
   t=stoptime()-t;
   printf(""addmul:\t %.3f s, %.3f Gflops, res=%f\n"",t,(double)n/t/1e9,x);

   return EXIT_SUCCESS;
}
</code></pre>

<p>Compiled with</p>

<pre><code>g++ -O2 -march=native addmul.cpp ; ./a.out 1000
</code></pre>

<p>produces the following output on an Intel Core i5-750, 2.66 GHz</p>

<pre><code>addmul:  0.270 s, 3.707 Gflops, res=1.326463
</code></pre>

<p>i.e. just about 1.4 flops per cycle. Looking at the assembler code with
<code>g++ -S -O2 -march=native -masm=intel addmul.cpp</code> the main loop seems kind of
optimal to me:</p>

<pre><code>.L4:
inc eax
mulsd   xmm8, xmm3
mulsd   xmm7, xmm3
mulsd   xmm6, xmm3
mulsd   xmm5, xmm3
mulsd   xmm1, xmm3
addsd   xmm13, xmm2
addsd   xmm12, xmm2
addsd   xmm11, xmm2
addsd   xmm10, xmm2
addsd   xmm9, xmm2
cmp eax, ebx
jne .L4
</code></pre>

<p>Changing the scalar versions with packed versions (<code>addpd</code> and <code>mulpd</code>) would double the flop count without changing the execution time and so I'd get just short of 2.8 flops per cycle. Any simple example which achieves 4 flops per cycle?</p>

<p><strong>Edit:</strong></p>

<p>Nice little programme by Mysticial,
here are my results (run just for a few seconds though):</p>

<ul>
<li><code>gcc -O2 -march=nocona</code>: 5.6 Gflops out of 10.66 Gflops (2.1 flops/cycle)</li>
<li><code>cl /O2</code>, openmp removed: 10.1 Gflops out of 10.66 Gflops (3.8 flops/cycle)</li>
</ul>

<p>It all seems a bit complex but my conclusions so far:</p>

<ul>
<li><p><code>gcc -O2</code> changes the order of independent floating point operations with
the aim of alternating
<code>addpd</code> and <code>mulpd</code>'s if possible. Same applies to <code>gcc-4.6.2 -O2 -march=core2</code>.</p></li>
<li><p><code>gcc -O2 -march=nocona</code> seems to keep the order of fp operations as defined in
the C++ source.</p></li>
<li><p><code>cl /O2</code>, the 64-bit compiler from the
<a href=""http://www.microsoft.com/download/en/details.aspx?id=3138"">SDK for Windows 7</a>
does loop-unrolling automatically and seems to try and arrange operations
so that groups of 3 <code>addpd</code>'s alternate with 3 <code>mulpd</code>'s (well at least on my
system and for my simple programme).</p></li>
<li><p>My <a href=""http://en.wikipedia.org/wiki/List_of_Intel_Core_i5_microprocessors#Based_on_Nehalem_microarchitecture"">Core i5 750</a> (<a href=""http://en.wikipedia.org/wiki/Nehalem_%28microarchitecture%29"">Nahelem architecture</a>)
doesn't like alternating add's and mul's and seems unable
to run both ops in parallel. However, if grouped in 3's it suddenly works like
magic.</p></li>
<li><p>Other architectures (possibly <a href=""http://en.wikipedia.org/wiki/Sandy_bridge"">Sandy Bridge</a> and others) appear to
be able to execute add/mul in parallel without problems 
if they alternate in the assembly code.</p></li>
<li><p>Although difficult to admit, but on my system <code>cl /O2</code> does a much better job
at low level optimising operations for my system and achieves close to peak
performance for the little c++ example above. I measured between
1.85-2.01 flops/cycle (have used clock() in Windows which is not that precise
I guess, need to use a better timer - thanks Mackie Messer).</p></li>
<li><p>The best I managed  with <code>gcc</code> was to manually loop unroll and arrange
additions and multiplications in groups of three. With
<code>g++ -O2 -march=nocona  addmul_unroll.cpp</code>
I get at best <code>0.207s, 4.825 Gflops</code> which corresponds to 1.8 flops/cycle
which I'm quite happy with now.</p></li>
</ul>

<p>In the c++ code I've replaced the <code>for</code> loop with</p>

<pre><code>   for(int i=0; i&lt;loops/3; i++) {
      mul1*=mul; mul2*=mul; mul3*=mul;
      sum1+=add; sum2+=add; sum3+=add;
      mul4*=mul; mul5*=mul; mul1*=mul;
      sum4+=add; sum5+=add; sum1+=add;

      mul2*=mul; mul3*=mul; mul4*=mul;
      sum2+=add; sum3+=add; sum4+=add;
      mul5*=mul; mul1*=mul; mul2*=mul;
      sum5+=add; sum1+=add; sum2+=add;

      mul3*=mul; mul4*=mul; mul5*=mul;
      sum3+=add; sum4+=add; sum5+=add;
   }
</code></pre>

<p>and the assembly now looks like</p>

<pre><code>.L4:
mulsd   xmm8, xmm3
mulsd   xmm7, xmm3
mulsd   xmm6, xmm3
addsd   xmm13, xmm2
addsd   xmm12, xmm2
addsd   xmm11, xmm2
mulsd   xmm5, xmm3
mulsd   xmm1, xmm3
mulsd   xmm8, xmm3
addsd   xmm10, xmm2
addsd   xmm9, xmm2
addsd   xmm13, xmm2
...
</code></pre>
","922184","","<p>I've done this exact task before. But it was mainly to measure power consumption and CPU temperatures. The following code (which is fairly long) achieves close to optimal on my Core i7 2600K.</p>

<p>The key thing to note here is the massive amount of manual loop-unrolling as well as interleaving of multiplies and adds...</p>

<p>The full project can be found on my GitHub: <a href=""https://github.com/Mysticial/Flops"">https://github.com/Mysticial/Flops</a></p>

<h1>Warning:</h1>

<p><strong>If you decide to compile and run this, pay attention to your CPU temperatures!!!</strong><br>Make sure you don't overheat it. And make sure CPU-throttling doesn't affect your results!</p>

<p>Furthermore, I take no responsibility for whatever damage that may result from running this code.</p>

<p><strong>Notes:</strong></p>

<ul>
<li>This code is optimized for x64. x86 doesn't have enough registers for this to compile well.</li>
<li>This code has been tested to work well on Visual Studio 2010/2012 and GCC 4.6.<br>ICC 11 (Intel Compiler 11) surprisingly has trouble compiling it well.</li>
<li>These are for pre-FMA processors. In order to achieve peak FLOPS on Intel Haswell and AMD Bulldozer processors (and later), FMA (Fused Multiply Add) instructions will be needed. These are beyond the scope of this benchmark.</li>
</ul>

<p></p>

<pre><code>#include &lt;emmintrin.h&gt;
#include &lt;omp.h&gt;
#include &lt;iostream&gt;
using namespace std;

typedef unsigned long long uint64;

double test_dp_mac_SSE(double x,double y,uint64 iterations){
    register __m128d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;

    //  Generate starting data.
    r0 = _mm_set1_pd(x);
    r1 = _mm_set1_pd(y);

    r8 = _mm_set1_pd(-0.0);

    r2 = _mm_xor_pd(r0,r8);
    r3 = _mm_or_pd(r0,r8);
    r4 = _mm_andnot_pd(r8,r0);
    r5 = _mm_mul_pd(r1,_mm_set1_pd(0.37796447300922722721));
    r6 = _mm_mul_pd(r1,_mm_set1_pd(0.24253562503633297352));
    r7 = _mm_mul_pd(r1,_mm_set1_pd(4.1231056256176605498));
    r8 = _mm_add_pd(r0,_mm_set1_pd(0.37796447300922722721));
    r9 = _mm_add_pd(r1,_mm_set1_pd(0.24253562503633297352));
    rA = _mm_sub_pd(r0,_mm_set1_pd(4.1231056256176605498));
    rB = _mm_sub_pd(r1,_mm_set1_pd(4.1231056256176605498));

    rC = _mm_set1_pd(1.4142135623730950488);
    rD = _mm_set1_pd(1.7320508075688772935);
    rE = _mm_set1_pd(0.57735026918962576451);
    rF = _mm_set1_pd(0.70710678118654752440);

    uint64 iMASK = 0x800fffffffffffffull;
    __m128d MASK = _mm_set1_pd(*(double*)&amp;iMASK);
    __m128d vONE = _mm_set1_pd(1.0);

    uint64 c = 0;
    while (c &lt; iterations){
        size_t i = 0;
        while (i &lt; 1000){
            //  Here's the meat - the part that really matters.

            r0 = _mm_mul_pd(r0,rC);
            r1 = _mm_add_pd(r1,rD);
            r2 = _mm_mul_pd(r2,rE);
            r3 = _mm_sub_pd(r3,rF);
            r4 = _mm_mul_pd(r4,rC);
            r5 = _mm_add_pd(r5,rD);
            r6 = _mm_mul_pd(r6,rE);
            r7 = _mm_sub_pd(r7,rF);
            r8 = _mm_mul_pd(r8,rC);
            r9 = _mm_add_pd(r9,rD);
            rA = _mm_mul_pd(rA,rE);
            rB = _mm_sub_pd(rB,rF);

            r0 = _mm_add_pd(r0,rF);
            r1 = _mm_mul_pd(r1,rE);
            r2 = _mm_sub_pd(r2,rD);
            r3 = _mm_mul_pd(r3,rC);
            r4 = _mm_add_pd(r4,rF);
            r5 = _mm_mul_pd(r5,rE);
            r6 = _mm_sub_pd(r6,rD);
            r7 = _mm_mul_pd(r7,rC);
            r8 = _mm_add_pd(r8,rF);
            r9 = _mm_mul_pd(r9,rE);
            rA = _mm_sub_pd(rA,rD);
            rB = _mm_mul_pd(rB,rC);

            r0 = _mm_mul_pd(r0,rC);
            r1 = _mm_add_pd(r1,rD);
            r2 = _mm_mul_pd(r2,rE);
            r3 = _mm_sub_pd(r3,rF);
            r4 = _mm_mul_pd(r4,rC);
            r5 = _mm_add_pd(r5,rD);
            r6 = _mm_mul_pd(r6,rE);
            r7 = _mm_sub_pd(r7,rF);
            r8 = _mm_mul_pd(r8,rC);
            r9 = _mm_add_pd(r9,rD);
            rA = _mm_mul_pd(rA,rE);
            rB = _mm_sub_pd(rB,rF);

            r0 = _mm_add_pd(r0,rF);
            r1 = _mm_mul_pd(r1,rE);
            r2 = _mm_sub_pd(r2,rD);
            r3 = _mm_mul_pd(r3,rC);
            r4 = _mm_add_pd(r4,rF);
            r5 = _mm_mul_pd(r5,rE);
            r6 = _mm_sub_pd(r6,rD);
            r7 = _mm_mul_pd(r7,rC);
            r8 = _mm_add_pd(r8,rF);
            r9 = _mm_mul_pd(r9,rE);
            rA = _mm_sub_pd(rA,rD);
            rB = _mm_mul_pd(rB,rC);

            i++;
        }

        //  Need to renormalize to prevent denormal/overflow.
        r0 = _mm_and_pd(r0,MASK);
        r1 = _mm_and_pd(r1,MASK);
        r2 = _mm_and_pd(r2,MASK);
        r3 = _mm_and_pd(r3,MASK);
        r4 = _mm_and_pd(r4,MASK);
        r5 = _mm_and_pd(r5,MASK);
        r6 = _mm_and_pd(r6,MASK);
        r7 = _mm_and_pd(r7,MASK);
        r8 = _mm_and_pd(r8,MASK);
        r9 = _mm_and_pd(r9,MASK);
        rA = _mm_and_pd(rA,MASK);
        rB = _mm_and_pd(rB,MASK);
        r0 = _mm_or_pd(r0,vONE);
        r1 = _mm_or_pd(r1,vONE);
        r2 = _mm_or_pd(r2,vONE);
        r3 = _mm_or_pd(r3,vONE);
        r4 = _mm_or_pd(r4,vONE);
        r5 = _mm_or_pd(r5,vONE);
        r6 = _mm_or_pd(r6,vONE);
        r7 = _mm_or_pd(r7,vONE);
        r8 = _mm_or_pd(r8,vONE);
        r9 = _mm_or_pd(r9,vONE);
        rA = _mm_or_pd(rA,vONE);
        rB = _mm_or_pd(rB,vONE);

        c++;
    }

    r0 = _mm_add_pd(r0,r1);
    r2 = _mm_add_pd(r2,r3);
    r4 = _mm_add_pd(r4,r5);
    r6 = _mm_add_pd(r6,r7);
    r8 = _mm_add_pd(r8,r9);
    rA = _mm_add_pd(rA,rB);

    r0 = _mm_add_pd(r0,r2);
    r4 = _mm_add_pd(r4,r6);
    r8 = _mm_add_pd(r8,rA);

    r0 = _mm_add_pd(r0,r4);
    r0 = _mm_add_pd(r0,r8);


    //  Prevent Dead Code Elimination
    double out = 0;
    __m128d temp = r0;
    out += ((double*)&amp;temp)[0];
    out += ((double*)&amp;temp)[1];

    return out;
}

void test_dp_mac_SSE(int tds,uint64 iterations){

    double *sum = (double*)malloc(tds * sizeof(double));
    double start = omp_get_wtime();

#pragma omp parallel num_threads(tds)
    {
        double ret = test_dp_mac_SSE(1.1,2.1,iterations);
        sum[omp_get_thread_num()] = ret;
    }

    double secs = omp_get_wtime() - start;
    uint64 ops = 48 * 1000 * iterations * tds * 2;
    cout &lt;&lt; ""Seconds = "" &lt;&lt; secs &lt;&lt; endl;
    cout &lt;&lt; ""FP Ops  = "" &lt;&lt; ops &lt;&lt; endl;
    cout &lt;&lt; ""FLOPs   = "" &lt;&lt; ops / secs &lt;&lt; endl;

    double out = 0;
    int c = 0;
    while (c &lt; tds){
        out += sum[c++];
    }

    cout &lt;&lt; ""sum = "" &lt;&lt; out &lt;&lt; endl;
    cout &lt;&lt; endl;

    free(sum);
}

int main(){
    //  (threads, iterations)
    test_dp_mac_SSE(8,10000000);

    system(""pause"");
}
</code></pre>

<p><strong>Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>

<pre><code>Seconds = 55.5104
FP Ops  = 960000000000
FLOPs   = 1.7294e+010
sum = 2.22652
</code></pre>

<p>The machine is a Core i7 2600K @ 4.4 GHz. Theoretical SSE peak is 4 flops * 4.4 GHz = <strong>17.6 GFlops</strong>. This code achieves <strong>17.3 GFlops</strong> - not bad.</p>

<p><strong>Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>

<pre><code>Seconds = 117.202
FP Ops  = 7680000000000
FLOPs   = 6.55279e+010
sum = 17.8122
</code></pre>

<p>Theoretical SSE peak is 4 flops * 4 cores * 4.4 GHz = <strong>70.4 GFlops.</strong> Actual is <strong>65.5 GFlops</strong>.</p>

<hr>

<h2>Let's take this one step further. AVX...</h2>

<pre><code>#include &lt;immintrin.h&gt;
#include &lt;omp.h&gt;
#include &lt;iostream&gt;
using namespace std;

typedef unsigned long long uint64;

double test_dp_mac_AVX(double x,double y,uint64 iterations){
    register __m256d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;

    //  Generate starting data.
    r0 = _mm256_set1_pd(x);
    r1 = _mm256_set1_pd(y);

    r8 = _mm256_set1_pd(-0.0);

    r2 = _mm256_xor_pd(r0,r8);
    r3 = _mm256_or_pd(r0,r8);
    r4 = _mm256_andnot_pd(r8,r0);
    r5 = _mm256_mul_pd(r1,_mm256_set1_pd(0.37796447300922722721));
    r6 = _mm256_mul_pd(r1,_mm256_set1_pd(0.24253562503633297352));
    r7 = _mm256_mul_pd(r1,_mm256_set1_pd(4.1231056256176605498));
    r8 = _mm256_add_pd(r0,_mm256_set1_pd(0.37796447300922722721));
    r9 = _mm256_add_pd(r1,_mm256_set1_pd(0.24253562503633297352));
    rA = _mm256_sub_pd(r0,_mm256_set1_pd(4.1231056256176605498));
    rB = _mm256_sub_pd(r1,_mm256_set1_pd(4.1231056256176605498));

    rC = _mm256_set1_pd(1.4142135623730950488);
    rD = _mm256_set1_pd(1.7320508075688772935);
    rE = _mm256_set1_pd(0.57735026918962576451);
    rF = _mm256_set1_pd(0.70710678118654752440);

    uint64 iMASK = 0x800fffffffffffffull;
    __m256d MASK = _mm256_set1_pd(*(double*)&amp;iMASK);
    __m256d vONE = _mm256_set1_pd(1.0);

    uint64 c = 0;
    while (c &lt; iterations){
        size_t i = 0;
        while (i &lt; 1000){
            //  Here's the meat - the part that really matters.

            r0 = _mm256_mul_pd(r0,rC);
            r1 = _mm256_add_pd(r1,rD);
            r2 = _mm256_mul_pd(r2,rE);
            r3 = _mm256_sub_pd(r3,rF);
            r4 = _mm256_mul_pd(r4,rC);
            r5 = _mm256_add_pd(r5,rD);
            r6 = _mm256_mul_pd(r6,rE);
            r7 = _mm256_sub_pd(r7,rF);
            r8 = _mm256_mul_pd(r8,rC);
            r9 = _mm256_add_pd(r9,rD);
            rA = _mm256_mul_pd(rA,rE);
            rB = _mm256_sub_pd(rB,rF);

            r0 = _mm256_add_pd(r0,rF);
            r1 = _mm256_mul_pd(r1,rE);
            r2 = _mm256_sub_pd(r2,rD);
            r3 = _mm256_mul_pd(r3,rC);
            r4 = _mm256_add_pd(r4,rF);
            r5 = _mm256_mul_pd(r5,rE);
            r6 = _mm256_sub_pd(r6,rD);
            r7 = _mm256_mul_pd(r7,rC);
            r8 = _mm256_add_pd(r8,rF);
            r9 = _mm256_mul_pd(r9,rE);
            rA = _mm256_sub_pd(rA,rD);
            rB = _mm256_mul_pd(rB,rC);

            r0 = _mm256_mul_pd(r0,rC);
            r1 = _mm256_add_pd(r1,rD);
            r2 = _mm256_mul_pd(r2,rE);
            r3 = _mm256_sub_pd(r3,rF);
            r4 = _mm256_mul_pd(r4,rC);
            r5 = _mm256_add_pd(r5,rD);
            r6 = _mm256_mul_pd(r6,rE);
            r7 = _mm256_sub_pd(r7,rF);
            r8 = _mm256_mul_pd(r8,rC);
            r9 = _mm256_add_pd(r9,rD);
            rA = _mm256_mul_pd(rA,rE);
            rB = _mm256_sub_pd(rB,rF);

            r0 = _mm256_add_pd(r0,rF);
            r1 = _mm256_mul_pd(r1,rE);
            r2 = _mm256_sub_pd(r2,rD);
            r3 = _mm256_mul_pd(r3,rC);
            r4 = _mm256_add_pd(r4,rF);
            r5 = _mm256_mul_pd(r5,rE);
            r6 = _mm256_sub_pd(r6,rD);
            r7 = _mm256_mul_pd(r7,rC);
            r8 = _mm256_add_pd(r8,rF);
            r9 = _mm256_mul_pd(r9,rE);
            rA = _mm256_sub_pd(rA,rD);
            rB = _mm256_mul_pd(rB,rC);

            i++;
        }

        //  Need to renormalize to prevent denormal/overflow.
        r0 = _mm256_and_pd(r0,MASK);
        r1 = _mm256_and_pd(r1,MASK);
        r2 = _mm256_and_pd(r2,MASK);
        r3 = _mm256_and_pd(r3,MASK);
        r4 = _mm256_and_pd(r4,MASK);
        r5 = _mm256_and_pd(r5,MASK);
        r6 = _mm256_and_pd(r6,MASK);
        r7 = _mm256_and_pd(r7,MASK);
        r8 = _mm256_and_pd(r8,MASK);
        r9 = _mm256_and_pd(r9,MASK);
        rA = _mm256_and_pd(rA,MASK);
        rB = _mm256_and_pd(rB,MASK);
        r0 = _mm256_or_pd(r0,vONE);
        r1 = _mm256_or_pd(r1,vONE);
        r2 = _mm256_or_pd(r2,vONE);
        r3 = _mm256_or_pd(r3,vONE);
        r4 = _mm256_or_pd(r4,vONE);
        r5 = _mm256_or_pd(r5,vONE);
        r6 = _mm256_or_pd(r6,vONE);
        r7 = _mm256_or_pd(r7,vONE);
        r8 = _mm256_or_pd(r8,vONE);
        r9 = _mm256_or_pd(r9,vONE);
        rA = _mm256_or_pd(rA,vONE);
        rB = _mm256_or_pd(rB,vONE);

        c++;
    }

    r0 = _mm256_add_pd(r0,r1);
    r2 = _mm256_add_pd(r2,r3);
    r4 = _mm256_add_pd(r4,r5);
    r6 = _mm256_add_pd(r6,r7);
    r8 = _mm256_add_pd(r8,r9);
    rA = _mm256_add_pd(rA,rB);

    r0 = _mm256_add_pd(r0,r2);
    r4 = _mm256_add_pd(r4,r6);
    r8 = _mm256_add_pd(r8,rA);

    r0 = _mm256_add_pd(r0,r4);
    r0 = _mm256_add_pd(r0,r8);

    //  Prevent Dead Code Elimination
    double out = 0;
    __m256d temp = r0;
    out += ((double*)&amp;temp)[0];
    out += ((double*)&amp;temp)[1];
    out += ((double*)&amp;temp)[2];
    out += ((double*)&amp;temp)[3];

    return out;
}

void test_dp_mac_AVX(int tds,uint64 iterations){

    double *sum = (double*)malloc(tds * sizeof(double));
    double start = omp_get_wtime();

#pragma omp parallel num_threads(tds)
    {
        double ret = test_dp_mac_AVX(1.1,2.1,iterations);
        sum[omp_get_thread_num()] = ret;
    }

    double secs = omp_get_wtime() - start;
    uint64 ops = 48 * 1000 * iterations * tds * 4;
    cout &lt;&lt; ""Seconds = "" &lt;&lt; secs &lt;&lt; endl;
    cout &lt;&lt; ""FP Ops  = "" &lt;&lt; ops &lt;&lt; endl;
    cout &lt;&lt; ""FLOPs   = "" &lt;&lt; ops / secs &lt;&lt; endl;

    double out = 0;
    int c = 0;
    while (c &lt; tds){
        out += sum[c++];
    }

    cout &lt;&lt; ""sum = "" &lt;&lt; out &lt;&lt; endl;
    cout &lt;&lt; endl;

    free(sum);
}

int main(){
    //  (threads, iterations)
    test_dp_mac_AVX(8,10000000);

    system(""pause"");
}
</code></pre>

<p><strong>Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>

<pre><code>Seconds = 57.4679
FP Ops  = 1920000000000
FLOPs   = 3.34099e+010
sum = 4.45305
</code></pre>

<p>Theoretical AVX peak is 8 flops * 4.4 GHz = <strong>35.2 GFlops</strong>. Actual is <strong>33.4 GFlops</strong>.</p>

<p><strong>Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>

<pre><code>Seconds = 111.119
FP Ops  = 15360000000000
FLOPs   = 1.3823e+011
sum = 35.6244
</code></pre>

<p>Theoretical AVX peak is 8 flops * 4 cores * 4.4 GHz = <strong>140.8 GFlops.</strong> Actual is <strong>138.2 GFlops</strong>.</p>

<hr>

<p><strong>Now for some explanations:</strong></p>

<p>The performance critical part is obviously the 48 instructions inside the inner loop. You'll notice that it's broken into 4 blocks of 12 instructions each. Each of these 12 instructions blocks are completely independent from each other - and take on average 6 cycles to execute.</p>

<p>So there's 12 instructions and 6 cycles between issue-to-use. The latency of multiplication is 5 cycles, so it's just enough to avoid latency stalls.</p>

<p>The normalization step is needed to keep the data from over/underflowing. This is needed since the do-nothing code will slowly increase/decrease the magnitude of the data.</p>

<p>So it's actually possible to do better than this if you just use all zeros and get rid of the normalization step. However, since I wrote the benchmark to measure power consumption and temperature, <strong>I had to make sure the flops were on ""real"" data, rather than zeros</strong> - as the execution units may very well have special case-handling for zeros that use less power and produce less heat.</p>

<hr>

<h2>More Results:</h2>

<ul>
<li><strong>Intel Core i7 920 @ 3.5 GHz</strong></li>
<li>Windows 7 Ultimate x64</li>
<li>Visual Studio 2010 SP1 - x64 Release</li>
</ul>

<p><strong>Threads: 1</strong></p>

<pre><code>Seconds = 72.1116
FP Ops  = 960000000000
FLOPs   = 1.33127e+010
sum = 2.22652
</code></pre>

<p>Theoretical SSE Peak: 4 flops * 3.5 GHz = <strong>14.0 GFlops</strong>. Actual is <strong>13.3 GFlops</strong>.</p>

<p><strong>Threads: 8</strong></p>

<pre><code>Seconds = 149.576
FP Ops  = 7680000000000
FLOPs   = 5.13452e+010
sum = 17.8122
</code></pre>

<p>Theoretical SSE Peak: 4 flops * 4 cores * 3.5 GHz = <strong>56.0 GFlops</strong>. Actual is <strong>51.3 GFlops</strong>.</p>

<p><em><strong>My processor temps hit 76C on the multi-threaded run! If you runs these, be sure the results aren't affected by CPU throttling.</em></strong></p>

<hr>

<ul>
<li><strong>2 x Intel Xeon X5482 Harpertown @ 3.2 GHz</strong></li>
<li>Ubuntu Linux 10 x64</li>
<li>GCC 4.5.2 x64 - (-O2 -msse3 -fopenmp)</li>
</ul>

<p><strong>Threads: 1</strong></p>

<pre><code>Seconds = 78.3357
FP Ops  = 960000000000
FLOPs   = 1.22549e+10
sum = 2.22652
</code></pre>

<p>Theoretical SSE Peak: 4 flops * 3.2 GHz = <strong>12.8 GFlops</strong>. Actual is <strong>12.3 GFlops</strong>.</p>

<p><strong>Threads: 8</strong></p>

<pre><code>Seconds = 78.4733
FP Ops  = 7680000000000
FLOPs   = 9.78676e+10
sum = 17.8122
</code></pre>

<p>Theoretical SSE Peak: 4 flops * 8 cores * 3.2 GHz = <strong>102.4 GFlops</strong>. Actual is <strong>97.9 GFlops</strong>.</p>
"
"<p>I've just realized that I've never learned to read strings from file, so I did a little messing around to figure it out, but I'm having a problem with my compiler.</p>

<p>For my programming class I use visual c++ 2010 because it is required and it hasn't given me much problem so I haven't switched to any other.</p>

<p>Anyways heres my code and my problem.
It is basically supposed to read in full names from a file and store them in an array.</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;
using namespace std;

int main()
{
 const int maxsize = 100;
 string friendArray[maxsize];

 ifstream friends;
 friends.open(""myFriends.dat"");

 int sub = 0;

 while (friendArray[sub] &lt;= 100)
 {
   getline(friends, friendArray[sub]);
   sub++;
 }

}
</code></pre>

<p>in my while loop, I am recieving: error: no operator ""&lt;="" matches these operands.</p>

<p>I'm getting the same thing with any other operators I use also.
Any help?</p>
","922184","","<p>You want this instead:</p>

<pre><code>while (sub &lt; 100)
</code></pre>

<p>Originally, you were comparing a string to an integer literal. You obviously can't do that.</p>

<p>Note that I also changed the <code>&lt;=</code> to <code>&lt;</code> otherwise, you'll be overrunning the array.</p>
"
"<p>I am optimizing a c++ code. 
at one critical step, I want to implement the following function <code>y=f(x)</code>: </p>

<pre><code>f(0)=1

f(1)=2

f(2)=3

f(3)=0
</code></pre>

<p>which one is faster ? using a lookup table or  <code>i=(i+1)&amp;3</code>  or  <code>i=(i+1)%4</code> ? or any better suggestion?</p>
","922184","","<p>I won't get into the discussion of premature optimization. But the answer is that they will be the same speed.</p>

<p>Any sane compiler will compile them to the same thing. Division/modulus by a power of two will be optimized to bitwise operations anyway.</p>

<p><strong>So use whichever you find (or others will find) to be more readable.</strong></p>

<p>EDIT : As Roland has pointed out, it does sometimes behave different depending on the signness:</p>

<p><strong>Unsigned &amp;:</strong></p>

<pre><code>int main(void)
{
    unsigned x;
    cin &gt;&gt; x;
    x = (x + 1) &amp; 3;
    cout &lt;&lt; x;

    return 0;
}

mov eax, DWORD PTR _x$[ebp]
inc eax
and eax, 3
push    eax
</code></pre>

<p><strong>Unsigned Modulus:</strong></p>

<pre><code>int main(void)
{
    unsigned x;
    cin &gt;&gt; x;
    x = (x + 1) % 4;
    cout &lt;&lt; x;

    return 0;
}

mov eax, DWORD PTR _x$[ebp]
inc eax
and eax, 3
push    eax
</code></pre>

<p><strong>Signed &amp;:</strong></p>

<pre><code>int main(void)
{
    int x;
    cin &gt;&gt; x;
    x = (x + 1) &amp; 3;
    cout &lt;&lt; x;

    return 0;
}

mov eax, DWORD PTR _x$[ebp]
inc eax
and eax, 3
push    eax
</code></pre>

<p><strong>Signed Modulus:</strong></p>

<pre><code>int main(void)
{
    int x;
    cin &gt;&gt; x;
    x = (x + 1) % 4;
    cout &lt;&lt; x;

    return 0;
}

mov eax, DWORD PTR _x$[ebp]
inc eax
and eax, -2147483645            ; 80000003H
jns SHORT $LN3@main
dec eax
or  eax, -4                 ; fffffffcH
</code></pre>
"
"<p>i get those errors when i try to compile a simple AVL tree program :</p>

<pre><code>no matching function for call to A::max(A*&amp;, A*&amp;)
candidates are: int A::max(A&amp;, A&amp;)
request for member 'levels' in 'b', wich is of non-class type 'A*' 
</code></pre>

<p>Here is the method that cause the problems :</p>

<pre><code>void A::simpleLeftRotation(A &amp; tree){
   A* b = tree.leftNode;
   tree.leftNode = b-&gt;RightNode;
   b-&gt;rightNode = &amp;tree;
   tree.levels = 1 + max(tree.leftNode, tree.rightNode); // Problem 1
   b.levels = 1 + max(b.rightNode, tree); // Problem 2
   tree = b;       
}
</code></pre>

<p>And here are my class Members :</p>

<pre><code>A* righNode;
A* leftNode;
int levels;
int element;
</code></pre>

<p>In the line :</p>

<pre><code>b.levels = 1 + max(b.rightNode, tree);
</code></pre>

<p>if i use the -> insted of the point operator i get :</p>

<pre><code>no matching function for call to A::max(A*&amp;, A&amp;)
candidates are: int A::max(A&amp;, A&amp;)
</code></pre>

<p>I dont know what i am doing wrong.<br>
Thank you.</p>
","922184","","<p>Although you didn't show us the declarations for all the types, I suspect this will fix the problem:</p>

<pre><code>tree.levels = 1 + max(*(tree.leftNode), *(tree.rightNode));
b.levels = 1 + max(*(b.rightNode), tree);
</code></pre>

<p>Originally, you were passing pointers in when the <code>max</code> function expects references. Hence, a type mismatch leading to your errors. So you need to dereference your pointers as shown.</p>
"
"<p>I am trying to make an <code>if</code>-statement with more than one <code>else</code>.</p>

<p>Here is what I am trying to do:</p>

<pre><code>    if(value1&gt;value2)
      printf(""value1 is greater"");       
    else
      printf(""value2 is greater"");
    else
      printf(""Invalid output"");
    endif
</code></pre>

<p>Is this possible? If so, how do I do it and what is the syntax for it?</p>
","922184","","<p>You can do it like this:</p>

<pre><code>if(value1 &gt; value2)
    printf(""value1 is greater"");       
else if (value2 &gt; value1)
    printf(""value2 is greater"");
else
    printf(""Invalid output"");
</code></pre>

<p>Or preferably with brackets:</p>

<pre><code>if(value1 &gt; value2)
{
    printf(""value1 is greater"");       
}
else if (value2 &gt; value1)
{
    printf(""value2 is greater"");
}
else
{
    printf(""Invalid output"");
}
</code></pre>

<p>If you wish to put more than one statement in your if-else blocks, you will <em>need</em> to use brackets.</p>
"
"<p>im trying to create a dynamic memory. the size of the array is determine by the user input. i'm getting the following error, ""expression must have a constant value"". seems like im doing something wrong, please help how can i make this dynamic. this is what i have so far.</p>

<pre><code>int* IntPtr = NULL;
int main(){

 int arraySize;
 cout &lt;&lt; ""How many numbers will be on the list? "";
 cin &gt;&gt; arraySize;

 IntPtr = new int[arraySize];

Contact list[arraySize]; // &lt;-- expression must be constant

//more code

delete [] IntPtr;
</code></pre>
","922184","","<p>You're trying to use <a href=""http://en.wikipedia.org/wiki/Variable-length_array"" rel=""nofollow"">Variable Length Arrays</a>. Unfortunately, C++ does not allow them. (though some compiles allow them by extension)</p>

<p>What you need instead is to dynamically allocate the array using <code>new</code>. (and manually deallocate later with <code>delete</code>)</p>

<p>You're already doing this correctly with:</p>

<pre><code>IntPtr = new int[arraySize];
</code></pre>

<p>Now you can do the same with the <code>list</code> variable:</p>

<pre><code>Contact *list = new Contact[arraySize];
delete [] list;
</code></pre>

<p>Alternatively, you can use the <code>vector</code> class, which is often preferred over dynamic arrays.</p>

<pre><code>vector&lt;Contact&gt; list(arraySize);
</code></pre>
"
"<p>I am getting this error when I run the program. It compiles successfully but gives me a few warnings about the uninitialized variables which, I thought are initialized. I get the error ""Debug error! Run-Time Check Failure #3- The variable 'sumMaleGPA' is being used without being initialized.""</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;fstream&gt;

using namespace std;

void openFiles(ifstream&amp; inFile, ofstream&amp; outFile)
{
inFile.open(""finalin.dat"");
outFile.open(""finalout.dat"");
outFile &lt;&lt; fixed &lt;&lt; showpoint &lt;&lt; setprecision(2);
inFile &gt;&gt; fixed &gt;&gt; showpoint &gt;&gt; setprecision(2);
if (!inFile||!outFile)
{
    cout &lt;&lt; ""Problem opening file."";
}
}
void initialize(int countFemale,int countMale,float sumFemaleGPA,float sumMaleGPA)
{
countFemale=0;
countMale=0;
sumFemaleGPA=0;
sumMaleGPA=0;
}
void sumGrades(ifstream&amp; inFile, float sumFemaleGPA, float sumMaleGPA,int m,int f)
{
sumFemaleGPA=0;
sumMaleGPA=0;

if (!inFile)
    {
        inFile.open(""finalin.dat"");
    }
char sex;
float grade;    

while(!inFile.eof())
{

    inFile &gt;&gt; sex &gt;&gt; grade;

    switch (sex)
    {
    case 'f': (sumFemaleGPA= sumFemaleGPA + grade);
         f++;
        break;
    case 'm': (sumMaleGPA= sumMaleGPA + grade);
        m++; 
         break;
    }
}
}
void averageGPA(float avgfGPA, float avgmGPA, int m, int f, float sumFemaleGPA, float sumMaleGPA)
{
avgmGPA=0;
avgfGPA=0;

avgfGPA=sumFemaleGPA/f;
avgmGPA=sumMaleGPA/m;
}

void printResults(float avgfGPA, float avgmGPA, ofstream&amp; outFile)
{
        cout &lt;&lt;""The average GPA of the female students is: ""&lt;&lt;  avgfGPA &lt;&lt; endl;
        cout &lt;&lt;""The average GPA of the male students is: ""&lt;&lt; avgmGPA;

        outFile &lt;&lt; ""The average GPA of the female students is: ""&lt;&lt;  avgfGPA  &lt;&lt; endl;
        outFile &lt;&lt;""The average GPA of the male students is: ""&lt;&lt; avgmGPA;

}

        int main()
{

int countFemale;
int countMale;
float sumFemaleGPA;
float sumMaleGPA;
float avgfGPA; 
float avgmGPA;

ifstream inFile;
ofstream outFile;

openFiles(inFile,outFile);
initialize(countFemale,countMale,sumFemaleGPA,sumMaleGPA);
sumGrades(inFile,sumFemaleGPA,sumMaleGPA,countMale,countFemale);
averageGPA(avgfGPA,avgmGPA,countMale,countFemale,sumFemaleGPA,sumMaleGPA);
printResults(avgfGPA,avgmGPA, outFile);


}
</code></pre>

<p>Not sure where the error is happening so I posted the entire file.</p>
","922184","","<p>Your <code>initialize</code> and <code>averageGPA</code> functions are not correct.</p>

<p>Any parameter you want to modify inside the function should be <a href=""http://www.learncpp.com/cpp-tutorial/73-passing-arguments-by-reference/"" rel=""nofollow"">passed by reference</a>:</p>

<pre><code>void initialize(int &amp;countFemale,int &amp;countMale,float &amp;sumFemaleGPA,float &amp;sumMaleGPA)
void averageGPA(float &amp;avgfGPA, float &amp;avgmGPA, int m, int f, float &amp;sumFemaleGPA, float &amp;sumMaleGPA)
</code></pre>

<p>As it is, the <code>initialize()</code> function doesn't actually initialize the variables - hence why the you get the debug error when you first try to use them.</p>

<p>Right now, you are passing by value. The parameters are copied into the function. The function then modifies the local copies instead of the ones that are passed in.</p>
"
"<p>I was looking at the wikipedia page on <a href=""http://en.wikipedia.org/wiki/Prime_number"" rel=""nofollow"">primes</a> and of course, I came across the largest known prime which is <code>2^43,112,609 − 1</code>. This number is exceptionally large. So for fun, I decided to put this into <code>BigInteger</code>. To calculate this, it would take a very long time (I gave up after a while).</p>

<p>Is there any faster of computing a very large number like this? Or is <code>BigInteger</code> and a better computer the only way? Any reduction of time would be great.</p>

<p>*Note that my question has nothing to do with finding prime numbers. I'm asking if there is a better way to compute the number <code>2^43,112,609 − 1</code>.</p>
","922184","","<p>The problem with <code>BigInteger</code> is that it isn't meant for such large numbers. Last time I checked, it was still using <strong><em>quadratic run-time algorithms</em></strong> for both its multiplication and it's base conversion.</p>

<p>So the reason why computing <code>2^43,112,609 − 1</code> takes so long is that it's just huge - and you're trying to put that through a quadratic run-time algorithm.</p>

<p>Unfortunately, if you want something faster you will need to use a better bignum library. In C/C++ you have <a href=""http://gmplib.org/"" rel=""nofollow"">GMP</a>. There are Java wrappers for it if you google around.</p>

<hr>

<p>*Note that computing <code>2^43,112,609 − 1</code> itself is fast since you can do it with just a shift. The slow part is printing out as a string in base 10. Java still uses an <code>O(n^2)</code> algorithm for this conversion. </p>

<p>Efficient programs will be able do this conversion in roughly <code>O(n * log(n)^2)</code> time - which will be under a minute using the latest version of GMP on most up-to-date machines today.</p>
"
"<p>When I run the following C code, I get different output depending on whether or not the code was run with optimization turned on (gcc -O) or not.</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    int b = 55;
    int a[2] = {4, 5};
    int index;

    printf("" index    a[index]\n "");
    printf(""==================\n "");

    for(index = 0; index &lt; 6; index++)
    {
        printf(""%2d%12d\n"", index, a[index]);
    }

    return 0;
}
</code></pre>

<p>I understand that accessing an index out-of-bounds in C will simply access the stack memory further down from the array (assuming there is enough stack space allocated for that index, otherwise it segfaults) because arrays are just pointers in C. But how does the optimization affect this?</p>
","922184","","<p>Accessing out-of-bounds is undefined behavior. So the compiler is allowed to do anything it wants and anything is allowed to happen. So there isn't much of a point in trying to ""guess"" what will happen.</p>

<p>In your case, optimization is probably affecting the ordering and contents of the stack beyond the array. This would give you the varying results.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/2685854/why-should-the-copy-constructor-accept-its-parameter-by-reference-in-c"">Why should the copy constructor accept its parameter by reference in C++?</a><br>
  <a href=""http://stackoverflow.com/questions/4391350/can-a-object-be-passed-as-value-to-the-copy-constructor"">Can a object be passed as value to the copy constructor</a>  </p>
</blockquote>



<p>Consider this piece of code:</p>

<pre><code>class complex{
        private:
                double re, im;
        public:
                complex(double _re, double _im):re(_re),im(_im){}
                complex(complex c):re(c.re),im(c.im){}
};
</code></pre>

<p>When compiled, I got an error message: <code>invalid constructor; you probably meant ‘complex (const complex&amp;)’</code></p>

<p>In the book <code>C++ Programming Language</code>, it is written that:</p>

<blockquote>
  <p>The copy constructor defines what copying means – including what
  copying an argument means – so writing</p>
  
  <p>complex : complex(complex c) :re(c.re) , im(c.im) { } // error</p>
  
  <p>is an error because any call would have involved an infinite recursion.</p>
</blockquote>

<p>Why does this cause infinite recursion? It doesn't make sense.</p>
","922184","","<p>Passing by value means that the parameter is <strong><em>copied</em></strong> into the function. That calls the copy constructor.</p>

<p>If your copy constructor parameter is pass-by-value... It would call itself... over and over again...</p>
"
"<p>I am attempting to generate QR codes on an extremely limited embedded platform. Everything in <a href=""http://raidenii.net/files/datasheets/misc/qr_code.pdf"">the specification</a> seems fairly straightforward except for generating the error correction codewords. I have looked at a bunch of existing implementations, and they all try to implement  a bunch of polynomial math that goes straight over my head, particularly with regards to the Galois fields. The most straightforward way I can see, both in mathematical complexity and in memory requirements is a circuit concept that is laid out in the spec itself:</p>

<p><img src=""http://i.stack.imgur.com/xtppQ.png"" alt=""circuit diagram""> </p>

<p>With their description, I am fairly confident I could implement this with the exception of the parts labeled GF(256) addition and GF(256) Multiplication.</p>

<p>They offer this help: </p>

<blockquote>
  <p>The polynomial arithmetic for QR Code shall be calculated using bit-wise modulo 2 arithmetic and byte-wise
  modulo 100011101 arithmetic. This is a Galois field of 2^8
  with 100011101 representing the field's prime modulus
  polynomial x^8+x^4+x^3+x^2+1.</p>
</blockquote>

<p>which is all pretty much greek to me.</p>

<p>So my question is this: What is the easiest way to perform addition and multiplication in this kind of Galois field arithmetic? Assume both input numbers are 8 bits wide, and my output needs to be 8 bits wide also. Several implementations precalculate, or hardcode in two lookup tables to help with this, but I am not sure how those are calculated, or how I would use them in this situation. I would rather not take the 512 byte memory hit for the two tables, but it really depends on what the alternative is. I really just need help understanding how to do a single multiplication and addition operation in this circuit.</p>
","922184","","<p>In practice only one table is needed. That would be for the GP(256) multiply. Note that all arithmetic is carry-less, meaning that there is no carry-propagation.</p>

<p>Addition and subtraction without carry is equivalent  to an xor.</p>

<p>So in GF(256), <code>a + b</code> and <code>a - b</code> are both equivalent to <code>a xor b</code>.</p>

<p>GF(256) multiplication is also carry-less, and can be done using carry-less multiplication in a similar way with carry-less addition/subtraction. This can be done efficiently with hardware support via say <a href=""http://en.wikipedia.org/wiki/CLMUL_instruction_set"">Intel's CLMUL instruction set</a>.</p>

<p>However, the hard part, is reducing the modulo <code>100011101</code>. In normal integer division, you do it using a series of compare/subtract steps. In GF(256), you do it in a nearly identical manner using a series of compare/xor steps.</p>

<p>In fact, it's bad enough where it's still faster to just precompute all 256 x 256 multiplies and put them into a 65536-entry look-up table.</p>

<p>page 3 of the following pdf has a pretty good reference on GF256 arithmetic:</p>

<p><a href=""http://www.eecs.harvard.edu/~michaelm/CS222/eccnotes.pdf"">http://www.eecs.harvard.edu/~michaelm/CS222/eccnotes.pdf</a></p>

<p>I've done an implementation of Reed-Solomon error correction using GF(256), but it was with the polynomial <code>10010010</code> instead of <code>100011101</code>.</p>
"
"<p>How would one create a mask using SSE intrinsics which indicates whether the signs of two packed floats (__m128's) are the same for example if comparing a and b where a is [1.0 -1.0 0.0 2.0] and b is [1.0 1.0 1.0 1.0] the desired mask we would get is [true false true true].</p>
","922184","","<p>Here's one solution:</p>

<pre><code>const __m128i MASK = _mm_set1_epi32(0xffffffff);

__m128 a = _mm_setr_ps(1,-1,0,2);
__m128 b = _mm_setr_ps(1,1,1,1);

__m128  f = _mm_xor_ps(a,b);
__m128i i = _mm_castps_si128(f);

i = _mm_srai_epi32(i,31);
i = _mm_xor_si128(i,MASK);

f = _mm_castsi128_ps(i);

//  i = (0xffffffff, 0, 0xffffffff, 0xffffffff)
//  f = (0xffffffff, 0, 0xffffffff, 0xffffffff)
</code></pre>

<p>In this snippet, both <code>i</code> and <code>f</code> will have the same bitmask. I assume you want it in the <code>__m128</code> type so I added the <code>f = _mm_castsi128_ps(i);</code> to convert it back from an <code>__m128i</code>.</p>

<p>Note that this code is sensitive to the sign of the zero. So <code>0.0</code> and <code>-0.0</code> will affect the results.</p>

<hr>

<p><strong>Explanations:</strong></p>

<p>The way the code works is as follows:</p>

<pre><code>f = _mm_xor_ps(a,b);       //  xor the sign bits (well all the bits actually)

i = _mm_castps_si128(f);   //  Convert it to an integer. There's no instruction here.

i = _mm_srai_epi32(i,31);  //  Arithmetic shift that sign bit into all the bits.

i = _mm_xor_si128(i,MASK); //  Invert all the bits

f = _mm_castsi128_ps(i);   //  Convert back. Again, there's no instruction here.
</code></pre>
"
"<p>I'm writing code using the C intrinsics for Intel's AVX instructions. If I have a packed double vector (a <code>__m256d</code>), what would be the most efficient way (i.e. the least number of operations) to store each of them to a different place in memory (i.e. I need to fan them out to different locations such that they are no longer packed)? Pseudocode:</p>

<pre><code>__m256d *src;
double *dst;
int dst_dist;
dst[0] = src[0];
dst[dst_dist] = src[1];
dst[2 * dst_dist] = src[2];
dst[3 * dst_dist] = src[3];
</code></pre>

<p>Using SSE, I could do this with <code>__m128</code> types using the <code>_mm_storel_pi</code> and <code>_mm_storeh_pi</code> intrinsics. I've not been able to find anything similar for AVX that allows me to store the individual 64-bit pieces to memory. Does one exist?</p>
","922184","","<p>You can do it with a couple of extract instrinsics: (warning: untested)</p>

<pre><code> __m128d src = ...  //  data

__m128d a = _mm256_extractf128_pd(src, 0);
__m128d b = _mm256_extractf128_pd(src, 1);

_mm_storel_pd(dst + 0*dst_dist, a);
_mm_storeh_pd(dst + 1*dst_dist, a);
_mm_storel_pd(dst + 2*dst_dist, b);
_mm_storeh_pd(dst + 3*dst_dist, b);
</code></pre>

<p>What you want is the gather/scatter instructions in AVX2... But that's still a few years down the road.</p>
"
"<p>I have this code that works fine for regular signed integers that I am trying to write an equivalent version that will work with size_t (as in that as of now start and count are ints and i need them to be size_t) :</p>

<pre><code>int count,start;
for (start = (count-2)/2; start &gt;=0; start--)
{
     someFunction( x, start, count); // x is to illustrate function has other parameters
}
</code></pre>

<p>I feel like this code is straight forward enough for a really simple solution but I am drawing a blank.</p>
","922184","","<p>You could rewrite it like this:</p>

<pre><code>start = count/2;
while (start &gt; 0){
    start--;
    someFunction( x, start, count);
}
</code></pre>

<p>Otherwise, the only other option I can think of is to do some non-standard compliant casting between signed and unsigned... or to do something with <code>~(size_t)0</code>...</p>

<p>Here are some non-standard compliant alternatives:</p>

<pre><code>for (start = (count-2)/2; (ssize_t)start &gt;= 0; start--)
{
     someFunction( x, start, count);
}

for (start = (count-2)/2; start != ~(size_t)0; start--)
{
     someFunction( x, start, count);
}
</code></pre>
"
"<p>I want to typecast a <code>float</code> as an <code>int</code>. However, this does not do a bit by bit copy. Is it possible to typecast a <code>float</code> into an <code>int</code> while maintaining all the bits (sign, exponent, mantissa)?</p>
","922184","","<p>It's not possible to do this in a completely C-compliant way, but you could use unions:</p>

<pre><code>union{
    int i;
    float f;
} u;

u.f = 123.456;  //  Your value.

//  Read u.i.
</code></pre>

<p>This should still work on nearly all systems today. And of course assumes that <code>float</code> and <code>int</code> are the same size.</p>

<p>The alternative is to use pointer casting, but strictly speaking, that violates strict-aliasing and is considered undefined behavior.</p>

<hr>

<p>Another (possibly compliant - see comments) approach is to use <code>memcpy()</code>:</p>

<pre><code>int i;
float f;

f = 123.456;  //  Your value.

memcpy(&amp;i, &amp;f, sizeof(int));

//  Read i
</code></pre>
"
"<p>So I'm a bit of a newbie to C and I am curious to figure out why I am getting this unusual behavior.</p>

<p>I am reading a file 16 bits at a time and just printing them out as follows.</p>

<pre><code>#include &lt;stdio.h&gt;

#define endian(hex) (((hex &amp; 0x00ff) &lt;&lt; 8) + ((hex &amp; 0xff00) &gt;&gt; 8))

int main(int argc, char *argv[])
 {
  const int SIZE = 2;
  const int NMEMB = 1;
  FILE *ifp; //input file pointe
  FILE *ofp; // output file pointer

  int i;
  short hex;
  for (i = 2; i &lt; argc; i++)
   {
    // Reads the header and stores the bits
    ifp = fopen(argv[i], ""r"");
    if (!ifp) return 1;
    while (fread(&amp;hex, SIZE, NMEMB, ifp))
     {
      printf(""\n%x"", hex);
      printf(""\n%x"", endian(hex)); // this prints what I expect
      printf(""\n%x"", hex);
      hex = endian(hex);
      printf(""\n%x"", hex);
     }   
   }
 }
</code></pre>

<p>The results look something like this:</p>

<pre><code>ffffdeca
cade // expected
ffffdeca
ffffcade
0
0 // expected
0
0
600
6 // expected
600
6
</code></pre>

<p>Can anyone explain to me why the <em>last</em> line in each block doesn't print the same value as the second?</p>
","922184","","<p>This is due to integer type-promotion.</p>

<p>Your <code>shorts</code> are being implicitly promoted to <code>int</code>. (which is 32-bits here) So these are sign-extension promotions in this case.</p>

<p>Therefore, your <code>printf()</code> is printing out the hexadecimal digits of the full 32-bit <code>int</code>.</p>

<p>When your <code>short</code> value is negative, the sign-extension will fill the top 16 bits with ones, thus you get <code>ffffcade</code> rather than <code>cade</code>.</p>

<hr>

<p>The reason why this line:</p>

<pre><code>printf(""\n%x"", endian(hex));
</code></pre>

<p>seems to work is because your macro is implicitly getting rid of the upper 16-bits.</p>
"
"<pre><code>#include &lt;stdio.h&gt;

union u1 {
    struct {
        int *i;
    } s1;
    struct {
        int i, j;
    } s2;
};

union u2 {
    struct {
        int *i, j;
    } s1;
    struct {
        int i, j;
    } s2;
};

int main(void) {
    printf(""        size of int: %zu\n"", sizeof(int));
    printf(""size of int pointer: %zu\n"", sizeof(int *));
    printf(""   size of union u1: %zu\n"", sizeof(union u1));
    printf(""   size of union u2: %zu\n"", sizeof(union u2));
    return 0;
}
</code></pre>

<p>Results in:</p>

<pre><code>$ gcc -O -Wall -Wextra -pedantic -std=c99 -o test test.c
$ ./test
        size of int: 4
size of int pointer: 8
   size of union u1: 8
   size of union u2: 16
</code></pre>

<p>Why does adding an integer of 4 bytes to nested struct s1 of union u2 increase the size of the union as a whole by 8 bytes?</p>
","922184","","<p>That's because the compiler needs to keep the entire struct (as well as the union) aligned to 8 bytes - due to the fact that you have a pointer inside. (which is 8-bytes in your case)</p>

<p>So even though you add only 4 bytes with the extra <code>int</code>, struct-alignment forces everything to be aligned to 8 bytes - hence the +8 to bring the total size to 16 bytes.</p>

<p>The result of this is that:</p>

<pre><code>struct {
    int *i, j;
} s1;
</code></pre>

<p>has a size of 16 bytes. Since a union must be at least as large as the largest element, it is also forced up to 16.</p>

<p><a href=""http://en.wikipedia.org/wiki/Data_structure_alignment"" rel=""nofollow"">http://en.wikipedia.org/wiki/Data_structure_alignment</a></p>
"
"<p>I have written a code in C which works fine for int but when I try to do this with float it is showing error what can i do to make it correct.</p>

<pre><code>#include&lt;stdio.h&gt;

int main()
{
    float a,y;
    float square();
    scanf(""%f"", &amp;a);
    y = square( a );
    printf(""%f %f "",a ,y);
}

float square(float b)
{
    float z;
    z = b*b;
    printf(""%f %f"",z ,b);
    return(z);
}
</code></pre>

<p>error:</p>

<pre><code>return.c:12: error: conflicting types for 'square'
return.c:13: note: an argument type that has a default promotion can't match an empty parameter name list declaration
return.c:6: note: previous declaration of 'square' was here
</code></pre>
","922184","","<p>Move the declaration of <code>square()</code> out of the function and make sure the prototype matches:</p>

<pre><code>float square(float b);  //  Make sure this matches the definition.

int main()
{
    float a,y;
    scanf(""%f"", &amp;a);
    y = square( a );
    printf(""%f %f "",a ,y);
}

float square(float b)
{
    float z;
    z = b*b;
    printf(""%f %f"",z ,b);
    return(z);
}
</code></pre>

<p>As for why it ""worked"" for <code>int</code>, you'll have to show us the exact code you used for that case.</p>
"
"<p>This is the code I created for a project. Its basic stuff but I must have overlooked something because when I run it, no matter what number I put on the radious it gives me the same answer:</p>

<pre><code>radious given:288  
x=260444.
</code></pre>

<p>why is that?</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
#define pi 3.14

using std::cout;
using std::cin;
using std::endl;


class Circle 
{
private:          
    int Radious;
public:
    bool setRadious(int R);
    int getRadious(){return Radious;}
    double getx();
};


bool Circle::setRadious(int R)
{   
    bool RadiousSet = false;

    if (R &gt; 0) //check validity of R
    {
        int Radious = R;
        RadiousSet = true;
    }     
    return RadiousSet;
}

//x = pi *R^2
double Circle::getx()
{
    return  pi*pow(Radious,2);
}

// -----------------------------

int main()
{
    int R=0;
    bool rslt;

    Circle myCircle;  


    cout&lt;&lt;""Give Radious: "";
    cin&gt;&gt;R;
    rslt = myCircle.setRadious(R);

    if(rslt == true) 
    {
        cout &lt;&lt; ""Radious given: "" &lt;&lt;myCircle.getRadious();
        cout&lt;&lt;""x: ""&lt;&lt;myCircle.getx()&lt;&lt;endl;
    }
    else
        cout&lt;&lt;""Radious must be greater than zero""&lt;&lt;endl;

    system(""pause"");
    return 0;

}
</code></pre>
","922184","","<p>Change this:</p>

<pre><code>if (R &gt; 0) //check validity of R
{
    int Radious = R;
    RadiousSet = true;
} 
</code></pre>

<p>to this:</p>

<pre><code>if (R &gt; 0) //check validity of R
{
    Radious = R;
    RadiousSet = true;
} 
</code></pre>

<p>You are redeclaring <code>Radious</code> as a local variable which <a href=""http://en.wikipedia.org/wiki/Variable_shadowing"">shadows the one you want</a>. Its value is lost after the function returns.</p>
"
"<p>This program estimates <code>Pi</code> by throwing random ""darts"" (sampling points) to a circle or radius=1 inscribed inside a square board of length=2. Using the relationship </p>

<pre><code>Area of circle / Area of Square = Pi/4
</code></pre>

<p>we can estimate Pi using the same relationship expressed as</p>

<pre><code>Darts Inside Circle / Darts Outside Circle = Pi/4
</code></pre>

<p>The program works fine when I specify <code>NDARTS</code> in a <code>#define</code>, but when trying to broadcast it as a <code>long long int</code>, read from <code>scanf</code>, I get the following execution error:</p>

<pre><code>mpirun -np 4 ./pi_montecarlo.x
-----------------------------------------------------------------------------
One of the processes started by mpirun has exited with a nonzero exit
code.  This typically indicates that the process finished in error.
If your process did not finish in error, be sure to include a ""return
0"" or ""exit(0)"" in your C code before exiting the application.

PID 10591 failed on node n0 (127.0.0.1) due to signal 11.
</code></pre>

<p><strong>Why?</strong></p>

<p>Is there anything wrong with my MPI_Bcast declaration?</p>

<pre><code>long long int *NDARTS=0;
scanf(""%Ld"",NDARTS); 
MPI_Bcast(NDARTS, 1, MPI_LONG_LONG_INT, 0, MPI_COMM_WORLD);
</code></pre>

<p>Full code:   </p>

<pre><code>/*


    mpicc -g -Wall -lm pi_montecarlo3.c -o pi_montecarlo.x 



    mpirun -np 4 ./pi_montecarlo.x





*/





#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
#include &lt;time.h&gt;
#include &lt;mpi.h&gt;


#define MASTER 0
#define PI 3.1415926535




d    ouble pseudo_random (double a, double b) {



    double r; 


    r = ((b-a) * ((double) rand() / (double) RAND_MAX)) +a;


    return r; 
}

int main(int argc, char*argv[]){

    long long int *NDARTS=0; 

    int proc_id, 
        n_procs, 
        llimit,  
        ulimit,  
        n_circle, 
        i;      


    double pi_current, 
           pi_sum,     
           x,         
           y,         
           z,          
           error,      
           start_time, 
           end_time;   

    struct timeval stime;

    llimit = -1;
    ulimit = 1;
    n_circle =0; 

    MPI_Init(&amp;argc, &amp;argv); 


    MPI_Comm_rank (MPI_COMM_WORLD, &amp;proc_id);
    MPI_Comm_size (MPI_COMM_WORLD, &amp;n_procs);

    if (proc_id == MASTER){
        printf(""\nMonte Carlo Method to estimate Pi \n\n"");

                printf(""Introduce Number of Darts \n"");

            scanf(""%Ld"",NDARTS); 


        printf(""  Number of processes: %d \n"", n_procs);
        printf(""  Number of darts: %Ld \n"", *NDARTS);



                MPI_Bcast(NDARTS, 1, MPI_LONG_LONG_INT, 0, MPI_COMM_WORLD);



        start_time = MPI_Wtime();

    }


    gettimeofday(&amp;stime, NULL); 
    srand(stime.tv_usec * stime.tv_usec * stime.tv_usec * stime.tv_usec);


    for (i=1; i&lt;=*NDARTS;i++){



        x = pseudo_random(llimit, ulimit);
        y = pseudo_random(llimit, ulimit);


        z = pow(x,2) + pow(y,2);



        if (z&lt;=1.0){
            n_circle++;
        }
    }


    pi_current = 4.0 * (double)n_circle / (double) *NDARTS; 



    MPI_Reduce (&amp;pi_current, &amp;pi_sum, 1, MPI_DOUBLE, MPI_SUM, MASTER, MPI_COMM_WORLD);



       if (proc_id == MASTER) {



        pi_sum = pi_sum / n_procs;


        error = fabs ((pi_sum -PI) / PI) *100;


        end_time = MPI_Wtime();


        printf(""Known value of PI  : %11.10f \n"", PI);
        printf(""Estimated Value of PI  : %11.10f\n"", pi_sum);
        printf(""Error Percentage   : %10.8f\n"", error);
        printf(""Time    : %10.8f\n\n"", end_time - start_time);

    }


    MPI_Finalize();

    return 0;
}
</code></pre>
","922184","","<p>You're not using <code>scanf()</code> correctly. It should be like this instead:</p>

<pre><code>long long int NDARTS;
scanf(""%lld"",&amp;NDARTS); 
MPI_Bcast(&amp;NDARTS, 1, MPI_LONG_LONG_INT, 0, MPI_COMM_WORLD);
</code></pre>

<p>In your current code, <code>long long int *NDARTS=0;</code> effectively initializes <code>NDARTS</code> as a NULL pointer. So <code>scanf()</code> will obviously seg-fault when it tries to write to it.</p>
"
"<p>Why next code gives me <strong>stack around variable x was corrupted</strong>?</p>

<pre><code>char x[1][21];
char *ch = x[1];
strcpy(ch,""12345678901234567890"");

for (int i = 0; i &lt; 20; i++)
    cout &lt;&lt; i &lt;&lt; "": "" &lt;&lt; &amp;x[1][i] &lt;&lt; "" "" &lt;&lt; x[1][i] &lt;&lt; endl;
</code></pre>

<p>output:</p>

<pre><code>0: 12345678901234567890 1
1: 2345678901234567890 2
...
</code></pre>
","922184","","<p><code>char x[1][21];</code> is a 1 x 21 matrix.</p>

<p>The line <code>char *ch = x[1];</code> is accessing the second row. So that's already out of bounds.</p>

<p>Try changing it to:</p>

<pre><code>char x[2][21];
char *ch = x[1];
strcpy(ch,""12345678901234567890"");

for (int i = 0; i &lt; 20; i++)
    cout &lt;&lt; i &lt;&lt; "": "" &lt;&lt; &amp;x[1][i] &lt;&lt; "" "" &lt;&lt; x[1][i] &lt;&lt; endl;
</code></pre>

<p>or</p>

<pre><code>char x[1][21];
char *ch = x[0];
strcpy(ch,""12345678901234567890"");

for (int i = 0; i &lt; 20; i++)
    cout &lt;&lt; i &lt;&lt; "": "" &lt;&lt; &amp;x[0][i] &lt;&lt; "" "" &lt;&lt; x[0][i] &lt;&lt; endl;
</code></pre>
"
"<p>my code is </p>

<pre><code>final int CONST_1 = 1010;
final int CONST_2 = 1011;

System.out.println(""CONST_1 &amp; CONST_2: "" + Integer.toBinaryString(CONST_1 &amp; CONST_2));
System.out.println(""CONST_1 ^ CONST_2: "" + Integer.toBinaryString(CONST_1 ^ CONST_2));
System.out.println(""CONST_1 | CONST_2: "" + Integer.toBinaryString(CONST_1 | CONST_2));
System.out.println(""~CONST_1 : "" + Integer.toBinaryString(~CONST_1));
</code></pre>

<p>Output is </p>

<pre><code>CONST_1 &amp; CONST_2: 1111110010
CONST_1 ^ CONST_2: 1
CONST_1 | CONST_2: 1111110011
~CONST_1 : 11111111111111111111110000001101
</code></pre>

<p>In my opinion it's wrong and it should be: </p>

<pre><code>CONST_1 &amp; CONST_2: 1010
CONST_1 ^ CONST_2: 1
CONST_1 | CONST_2: 1011
~CONST_1 : 101
</code></pre>

<p>Please explain me why I have such result. Thanks!</p>
","922184","","<p>Change this:</p>

<pre><code>final int CONST_1 = 1010;
final int CONST_2 = 1011;
</code></pre>

<p>to this:</p>

<pre><code>final int CONST_1 = 0b1010;
final int CONST_2 = 0b1011;
</code></pre>

<p>Don't forget that literals are decimal by default. You clearly wanted them to be binary.</p>

<hr>

<p>Binary literals require Java 1.7. So if that's not available, you can go with this:</p>

<pre><code>final int CONST_1 = Integer.parseInt(""1010"",2);
final int CONST_2 = Integer.parseInt(""1011"",2);
</code></pre>
"
"<p>Seems like I still didn't get the pointers in C right.</p>

<p>I want the length of the global array (pointer) j being dynamic.</p>

<p>I have this (Arduino) code</p>

<pre><code>unsigned int* j;

void setup() {

  Serial.begin(9600);

  initj();

  Serial.println(j[0]); //111 -&gt; right
  Serial.println(j[0]); //768 -&gt; wrong!
  Serial.println(j[1]); //32771 -&gt; wrong!
}

void initj() {
  unsigned int i[2];
  i[0] = 111;
  i[1] = 222;

  j = i;

  Serial.println(j[0]); // 111 -&gt; right
  Serial.println(j[1]); // 222 -&gt; right
}

void loop() {
}
</code></pre>

<p>How can I do this right?</p>

<p>Thank you in advance!</p>
","922184","","<p>This because the array <code>i[2]</code> is local to the <code>initj()</code> function. Therefore, once the function returns, it is no longer valid. So the pointer <code>j</code> becomes a dangling pointer.</p>

<p>So you have invoked undefined behavior.</p>

<p>As for why these two lines behave the way they do:</p>

<pre><code>Serial.println(j[0]); //111 -&gt; right
Serial.println(j[0]); //768 -&gt; wrong!
</code></pre>

<p>Even though the values are lost, they still happen to be on the stack. So when you access it before you call <code>Serial.println</code>, you get the ""right"" value. But that function call ends up overwriting the stack. So on the second call, it gives the wrong value.</p>

<p>But in any case, it's still undefined behavior. Anything is allowed to happen.</p>

<hr>

<p>To fix this, you need to put the values in a scope that is visible to the <code>setup()</code> function. You can either declare <code>i[2]</code> globally, or in <code>setup()</code> and pass it into the <code>initj()</code> function.</p>

<p>You can also dynamically allocate the array in heap memory with <code>malloc()</code>. (and be sure to free it later with <code>free()</code>)</p>
"
"<p>I have the following class definition:</p>

<pre><code>class foo {
  private:
    bool m_active;

  public:
    const bool isActive() const // (btw do I need return type `const bool&amp;` here?)
    {
       return m_active;
    }  
};
</code></pre>

<ol>
<li><p>Does a class with a <code>const</code> getter (<code>foo-&gt;isActive()</code>) work faster then <code>foo-&gt;m_active</code> (if it would be public)? I tried to look at disassembled code, but didn't find anything interesting.</p></li>
<li><p>Where can I read about <code>const</code> getters and setters? I need a deep understanding as to where and why these methods are used.</p></li>
</ol>
","922184","","<p>By default, all member functions are considered for function inlining. This means that the compiler will optimize out the entire function call and replace it with a direct access to the member.</p>

<p>So the answer is yes. The compiler will optimize it.</p>
"
"<p>I am curious why I am getting the following behaviour in my code. </p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;


int main(int argc, char *argv[])
{
    int M=24;
    int arr[M];
    int N=24;
    int* ptr=(int*) malloc(sizeof(int)*N); /*Allocate memory of size N  */

    printf(""Size of your malloced array is %lu\n"",sizeof(ptr)/sizeof(ptr[0])); /* Get the size of memory alloctaed. Should be the same as N?*/

    printf (""Size of your normal arrays is %lu\n"",sizeof(arr)/sizeof(arr[0])); /* Ditto  */

    free(ptr);

    return 0;
}
</code></pre>

<p>The output is </p>

<pre><code>Size of your malloced array is 2
Size of your normal arrays is 24
</code></pre>

<p>I would have thought the output would be <code>24</code> in both places. How then does one get the size of the malloced array If somehow I have ""forgotten"" it? </p>

<p>Surely the pointer <code>ptr</code> will contain some information about the size of the malloced array since when we call <code>free(ptr)</code> it will release the array just malloced</p>
","922184","","<p>When you use <code>sizeof()</code> on a pointer, you get the size of the pointer. Not the size of the allocated array. In your case, a pointer is probably 8 bytes and an <code>int</code> is 4 bytes, hence why you get 2.</p>

<p>In short, you can't get the size of an allocated array. You need to keep track of it yourself.</p>

<hr>

<p><strong>EDIT :</strong> Note that some compilers do actually support this functionality as an extension:</p>

<p>For example, MSVC supports <code>_msize()</code>: <a href=""http://msdn.microsoft.com/en-us/library/z2s077bc.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/z2s077bc.aspx</a></p>
"
"<p>Could anyone please explain why this code compiles :</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

int main (int argc, char *argv [])
{
    FILE *ptr;

    char string[10] = ""Testing"";

    ptr = fopen(""C:\\Users\\Jordan\\Desktop\\Hello.txt"", ""wb"");

    fwrite(string,sizeof(string[0]), sizeof(string)/sizeof(string[0]), ptr);
}
</code></pre>

<p>Yet this does not : Gives an Error C2065:'string' : undeclared identifer</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;


int main (int argc, char *argv [])
{
    FILE *ptr;

    ptr = fopen(""C:\\Users\\Jordan\\Desktop\\Hello.txt"", ""wb"");

    char string[10] = ""Testing"";

    fwrite(string,sizeof(string[0]), sizeof(string)/sizeof(string[0]), ptr);

}
</code></pre>

<p>I am using Visual Studio 2010 on a Windows 7 Machine.</p>

<p>Thanks</p>
","922184","","<p>Visual Studio uses the old C89/90 C. In that older C version, you can't mix declarations and code.</p>

<p>All your declarations must go on top. That's why the second example fails to compile.</p>

<pre><code>//  This a declaration
FILE *ptr;

//  This is code
ptr = fopen(""C:\\Users\\Jordan\\Desktop\\Hello.txt"", ""wb"");

//  This is another declaration. Not Allowed in C89/C90!!!
char string[10] = ""Testing"";
</code></pre>
"
"<p>I want to get the overall total CPU usage for an application in C, the total CPU usage like we get in the TaskManager... 
I want to know ... for windows and linux :: current Total CPU utilization by all processes ..... as we see in the task manager.</p>
","922184","","<p>This is platform-specific:</p>

<ul>
<li>In Windows, you can use the <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms683223%28v=vs.85%29.aspx""><code>GetProcessTimes()</code></a> function.</li>
<li>In Linux, you can actually just use <code>clock()</code>.</li>
</ul>

<p>These can be used to measure the amount of CPU time taken between two time intervals.</p>

<p><strong>EDIT :</strong></p>

<p>To get the CPU consumption (as a percentage), you will need to divide the total CPU time by the # of logical cores that the OS sees, and then divided by the total wall-clock time:</p>

<pre><code>% CPU usage = (CPU time) / (# of cores) / (wall time)
</code></pre>

<p>Getting the # of logical cores is also platform-specific:</p>

<ul>
<li>Windows: <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms724381%28v=vs.85%29.aspx""><code>GetSystemInfo()</code></a></li>
<li>Linux: <code>sysconf(_SC_NPROCESSORS_ONLN)</code></li>
</ul>
"
"<p>In the next code:</p>

<pre><code>mov ebx, 0xFF
add ebx, 1
</code></pre>

<p>Why the Carry flag is not set? </p>

<pre><code>ebx = 11111111
+   = 00000001
     100000000
</code></pre>
","922184","","<p>That's because <code>ebx</code> is a 32-bit register. It's large enough to hold the value (256) - hence no carryout.</p>

<p>A better test would be:</p>

<pre><code>mov ebx, 0xFFFFFFFF
add ebx, 1
</code></pre>
"
"<p>This is exert from a book about data alignment of primitive types in memory. </p>

<blockquote>
  <p>Microsoft Windows imposes a stronger alignment requirement—any primitive object of K bytes, for
  K = 2, 4, or 8, must have an address that is a multiple of K. In particular, it requires that the address
  of a double or a long long be a multiple of 8. This requirement enhances the memory performance at
  the expense of some wasted space. The Linux convention, where 8-byte values are aligned on 4-byte
  boundaries was probably good for the i386, back when memory was scarce and memory interfaces were
  only 4 bytes wide. With modern processors, Microsoft’s alignment is a better design decision. Data type
  long double, for which gcc generates IA32 code allocating 12 bytes (even though the actual data type
  requires only 10 bytes) has a 4-byte alignment requirement with both Windows and Linux.</p>
</blockquote>

<p>Questions are:  </p>

<ol>
<li>What imposes data alignment, OS or compiler?</li>
<li>Can I change it or it is fixed?</li>
</ol>
","922184","","<p>Generally speaking, it's the compiler that imposes the alignment. Whenever you declare a primitive type (eg. <code>double</code>), the compiler will automatically align it to 8 bytes on the stack.</p>

<p>Furthermore, memory allocations are also generally aligned to the largest primitive type so that you can safely do this:</p>

<pre><code>double *ptr = (double*)malloc(size);
</code></pre>

<p>without having to worry about alignment.</p>

<p>Therefore, generally speaking, if you're programming with good habits, you won't have to worry about alignment. One way to get something misaligned is to do something like this:</p>

<pre><code>char *ch_ptr = (char*)malloc(size);

double *d_ptr = (double*)(ch_ptr + 1);
</code></pre>

<hr>

<p><strong>There are some exceptions to this</strong>: When you start getting into SSE and vectorization, things get a bit messy because <code>malloc</code> no longer guarantees 16-byte alignment.</p>

<hr>

<p>To override the alignment of something, MSVC has the <a href=""http://msdn.microsoft.com/en-us/library/83ythb65%28v=vs.80%29.aspx"" rel=""nofollow""><code>declspec(align)</code></a> modifier which will allow this. It's used to <em>increase</em> the alignment of something. <strike>Though I'm not sure if it lets you <em>decrease</em> the alignment of a primitive type.</strike> It says explicitly that you cannot decrease alignment with this modifier.</p>

<hr>

<p><strong>EDIT :</strong></p>

<p>I found the documentation stating the alignment of <code>malloc()</code> on GCC:</p>

<blockquote>
  <p>The address of a block returned by malloc or realloc in the GNU system
  is always a multiple of eight (or sixteen on 64-bit systems).</p>
</blockquote>

<p>Source: <a href=""http://www.gnu.org/s/hello/manual/libc/Aligned-Memory-Blocks.html"" rel=""nofollow"">http://www.gnu.org/s/hello/manual/libc/Aligned-Memory-Blocks.html</a></p>

<p>So yes, GCC now aligns to at least 8 bytes.</p>
"
"<p>Consider the following code:</p>

<pre><code>char* pointerTesting(void) {

    char* test = ""hello"";
    return test;
}

int main() {

   char* string = pointerTesting();
   printf(""string: %s\n"", string);
}
</code></pre>

<p>This has no problem compiling and running. However, in my understanding, this shouldn't work, as the memory allocated to the <code>test</code> pointer is on the stack and it's destroyed when returning to main.</p>

<p>So the question is, how does this manages to work without a malloc in the pointerTesting() function?</p>
","922184","","<p>In this case, the string <code>""hello""</code> is stored in global memory*. So it's <em>already</em> allocated.</p>

<p>Therefore, it's still valid when you return from the function.</p>

<p>However, if you did this:</p>

<pre><code>char test[] = ""hello"";
return test;
</code></pre>

<p>Then no, it would not work. (undefined behavior) In this case, the string is actually a local array - which is no longer live when the function returns.</p>

<p>*Although this usually is the case, the standard doesn't say that it has to be stored in global memory.<br><strong>But the important part is that the lifetime of a string literal is the duration of the entire program. (see comments)</strong></p>
"
"<blockquote>
  <p>(4.1/1) <strong>If the object to which the lvalue refers is not an object of
  type T and is not an object of a type derived from T</strong>, or if the object
  is uninitialized, a program that necessitates this conversion has
  undefined behavior.</p>
</blockquote>

<p>From this, I assume</p>

<pre><code>struct B {
     int x; };

B *p;
*p; //undefined behavior
</code></pre>

<p><code>*p</code> is a lvalue which refers to an uninitialized object. How can it refer to an object which is not the type of 'B' or its derived type? Am i misunderstanding something?</p>
","922184","","<p>One way to make it point to something that isn't of object T, or a derived type, is to type-pun with pointer casts:</p>

<pre><code>struct A{ int x; };
struct B{ float x; };


A x;
B *p = (B*)&amp;x;

*p;  //  Undefined behavior
</code></pre>

<p>In this example, the pointer <code>p</code> isn't pointing to something of type <code>B</code>. It points to something of type <code>A</code> which is incompatible.</p>

<p>Note that this example also violates strict-aliasing - which is also undefined behavior.</p>
"
"<p>Here is the code in question</p>

<pre><code>#include &lt;stdio.h&gt;

struct test {
    unsigned char t;
    unsigned short u;
    unsigned char v;
};


int main ()
{
    struct test  * a = (void *) 0x1000;

    printf(""%x %p %p\n"",
           sizeof(struct test),
           a + sizeof(struct test),
           a - sizeof(struct test));

    return 0;
}
</code></pre>

<p>The sizeof(struct test) prints 6, so I would <em>expect</em> to see:</p>

<p><code>6 0xffa 0x1006</code></p>

<p>Instead I get</p>

<pre><code>6 0x1024 0xfdc
</code></pre>

<p>Last time I checked, 0x24, or 36, was not equal to 6. It's not even aligned to anything that I can tell. I am at a complete loss.</p>

<p>Can someone please explain to me why I'm getting these values?</p>
","922184","","<p>The problem is that when you do pointer arithmetic, it increments by a <strong>multiple</strong> of the size of the datatype.</p>

<p>So what you're effectively doing is adding by the square of <code>sizeof(struct test)</code>.</p>

<p>Since <code>sizeof(struct test) = 6</code>, you are incrementing the address by <code>6 * 6 = 36</code>. Hence why you get <code>0x1024</code> and <code>0xfdc</code> instead of <code>0x1006</code> and <code>0xffa</code>. (You also switched the <code>+</code> and <code>-</code>, but that's a small thing.)</p>

<p>Instead, just do this:</p>

<pre><code>printf(""%x %p %p\n"",
       sizeof(struct test),
       a + 1,
       a - 1);
</code></pre>
"
"<p>So when i compile this code (using the mersenne twister found here: <a href=""http://www-personal.umich.edu/~wagnerr/MersenneTwister.html"" rel=""nofollow"">http://www-personal.umich.edu/~wagnerr/MersenneTwister.html</a> ):</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;cmath&gt;
#include ""mtrand.h""

using namespace std;
double pythag(double x, double y) {
    double derp=0;
    derp=(x*x)+(y*y);
    derp=sqrt(derp);
}

int main() {
    double x=0;
    double y=0;
    double pi=0;
    double hold1=0;

    double hold2=0;
    double hits=0;
    MTRand mt;
    mt.seed();
   // cout.precision(10);
    for(long i=1; i&lt;=100000000000l; i++) {
        x=abs(mt.rand());
        y=abs(mt.rand());
        if(pythag(x,y)&lt;=1) {
            hits++;
        }
        if(i%100000l==0) {
            pi=(4*hits)/i;
            cout &lt;&lt; ""\r"" &lt;&lt; i &lt;&lt; ""   "" &lt;&lt; pi ;
        }
    }
    cout  &lt;&lt;""\n"";
    return 42;
}
</code></pre>

<p>Using g++ (""g++ pi.cc -o pi"")
And run the resulting application, I get the output i wanted, a running tally of pi calculated using the Monte Carlo method.
But, when i compile with mingw g++ (""i686-pc-mingw32-g++ -static-libstdc++ -static-libgcc pi.cc -o pi.exe"")
I always get a running tally of 0.
Any help is greatly appreciated.</p>
","922184","","<p>Perhaps it's because you omitted the return statement:</p>

<pre><code>double pythag(double x, double y) {
    double derp=0;
    derp=(x*x)+(y*y);
    derp=sqrt(derp);

    //  You're missing this!!!
    return derp;

}
</code></pre>

<p>I'd be surprised that you didn't get any warnings or errors on this.</p>
"
"<p>I'm working on some ancient Delphi code and I've come across something which I don't quite understand.</p>

<pre><code>[bla is set to 130245932]

outresult := ((bla * 1103516849) + 12359);

[outresult is equal to -413953101]
</code></pre>

<p>How does multiplying two positive numbers result in a negative number? And why is it that when I take the bla variable out of the equation and just use the integer directly (like this)</p>

<pre><code>outresult := ((130245932 * 1103516849) + 12359);
</code></pre>

<p>I receive an error before the app even compiles</p>

<pre><code>[DCC Error] Unit1.pas(60): E2099 Overflow in conversion or arithmetic operation
</code></pre>

<p>Some genius would be appreciated. Thanks.</p>
","922184","","<p>Alright, I'll make this an answer.</p>

<p>The error message should be pretty clear. You have an integer overflow here:</p>

<pre><code>130245932 * 1103516849
</code></pre>

<p>because <code>130245932 * 1103516849 = 143728580475708268</code> which is too large to fit into a 32-bit integer.</p>
"
"<p>My gut feeling is that this isn't possible but I'm no expert.
Here's what I would like to do:</p>

<pre><code>#define KEY(i) #if (i == 0) KeyClassA(arg.fieldA)
               #elif (i == 1) KeyClassB(arg.fieldB)
//...
#endif

//inside a function with given arg
for(int i = 0; i &lt; N; i++) {
    Data* data = array[i]-&gt;find(KEY(i));
    //do things with data
}
</code></pre>

<p>That code is obviously more pseudo-code than C++ code and I personally don't think anything like this will compile, but my intention should be clear: provide a temporary class object to the find function according to the appropriate data structure in the array. That is, each data structure in the array requires a different key matching class.</p>

<p>Macro text replacement seems like the ""cleverest"" way to attempt to achieve this but I would obviously welcome any other ideas to get something like this to work.</p>
","922184","","<p>In this case it's not possible anyway because <code>i</code> isn't a compile-time constant. (not just a compile-time constant, but constant at the preprocessor stage)</p>

<p>So you will have to do it using normal C++ if-statements. (or a switch)</p>

<p>Based on what I think you are trying to do, using a loop will make it more complicated than it needs to be. Just write it all out and you don't need any loops or if-statements.</p>

<pre><code>array[0]-&gt;find(arg.fieldA);
array[1]-&gt;find(arg.fieldB);
...
</code></pre>

<p>(you also don't seem to be doing anything with <code>Data* data</code>)</p>

<p><strong>EDIT : With new information.</strong></p>

<p>In this case, you can put the loop-body into a function call. Something like this:</p>

<pre><code>void loop_body(KeyClass &amp;key, /* other parameters */ ){
    Data* data = array[0]-&gt;find(key);

    //  Rest of the body
}
</code></pre>

<p>And just call it for each field.</p>

<pre><code>loop_body(arg.fieldA);
loop_body(arg.fieldB);
...
</code></pre>
"
"<p>I was curious as to whether or not there was any advantage in regards to efficiency to utilizing memset() in a situation similar to the one below.</p>

<p>Given the following buffer declarations...</p>

<pre><code>struct More_Buffer_Info
{
    unsigned char a[10];
    unsigned char b[10];
    unsigned char c[10];
};

struct My_Buffer_Type
{
    struct More_Buffer_Info buffer_info[100];
};

struct My_Buffer_Type my_buffer[5];

unsigned char *p;
p = (unsigned char *)my_buffer;
</code></pre>

<p>Besides having less lines of code, is there an advantage to using this:</p>

<pre><code>memset((void *)p, 0, sizeof(my_buffer));
</code></pre>

<p>Over this:</p>

<pre><code>for (i = 0; i &lt; sizeof(my_buffer); i++)
{
    *p++ = 0;
}
</code></pre>
","922184","","<p>This applies to both <code>memset()</code> and <code>memcpy()</code>:</p>

<ol>
<li><strong>Less Code:</strong> As you have already mentioned, it's shorter - fewer lines of code.</li>
<li><strong>More Readable:</strong> Shorter usually makes it more readable as well. (<code>memset()</code> is more readable than that loop)</li>
<li><strong>It can be faster:</strong> It can sometimes allow more aggressive compiler optimizations. (so it may be faster)</li>
<li><strong>Misalignment:</strong> In some cases, when you're dealing with misaligned data on a processor that doesn't support misaligned accesses, <code>memset()</code> and <code>memcpy()</code> may be the only clean solution.</li>
</ol>

<p>To expand on the 3rd point, <code>memset()</code> can be heavily optimized by the compiler using SIMD and such. If you write a loop instead, the compiler will first need to ""figure out"" what it does before it can attempt to optimize it.</p>

<p>The basic idea here is that <code>memset()</code> and similar library functions, in some sense, ""tells"" the compiler your intent.</p>

<hr>

<p>As mentioned by @Oli in the comments, there are some downsides. I'll expand on them here:</p>

<ol>
<li>You need to make sure that <code>memset()</code> actually does what you want. The standard doesn't say that zeros for the various datatypes are necessarily zero in memory.</li>
<li>For non-zero data, <code>memset()</code> is restricted to only 1 byte content. So you can't use <code>memset()</code> if you want to set an array of <code>int</code>s to something other than zero (or <code>0x01010101</code> or something...).</li>
<li>Although rare, there are some corner cases, where it's actually possible to beat the compiler in performance with your own loop.*</li>
</ol>

<p>*I'll give one example of this from my experience:</p>

<p>Although <code>memset()</code> and <code>memcpy()</code> are usually compiler intrinsics with special handling by the compiler, they are still <em>generic</em> functions. They say nothing about the datatype including the alignment of the data.</p>

<p>So in a few (abeit rare) cases, the compiler isn't able to determine the alignment of the memory region, and thus must produce extra code to handle misalignment. Whereas, if you the programmer, is 100% sure of alignment, using a loop might actually be faster.</p>

<p>A common example is when using SSE/AVX intrinsics. (such as copying a 16/32-byte aligned array of <code>float</code>s) If the compiler can't determine the 16/32-byte alignment, it will need to use misaligned load/stores and/or handling code. If you simply write a loop using SSE/AVX aligned load/store intrinsics, you can <em>probably</em> do better.</p>

<pre><code>float *ptrA = ...  //  some unknown source, guaranteed to be 32-byte aligned
float *ptrB = ...  //  some unknown source, guaranteed to be 32-byte aligned
int length = ...   //  some unknown source, guaranteed to be multiple of 8

//  memcopy() - Compiler can't read comments. It doesn't know the data is 32-byte
//  aligned. So it may generate unnecessary misalignment handling code.
memcpy(ptrA, ptrB, length * sizeof(float));

//  This loop could potentially be faster because it ""uses"" the fact that
//  the pointers are aligned. The compiler can also further optimize this.
for (int c = 0; c &lt; length; c += 8){
    _mm256_store_ps(ptrA + c, _mm256_load_ps(ptrB + c));
}
</code></pre>
"
"<p>This block of openMP Code is running fine but I need to ensure that there is no race condition. Therefore, I have made the <code>j</code> variable private. </p>

<p>By doing this, I don't think that any race condition should exist for the assignment operation in the most inner loop. Please correct me if I am wrong.</p>

<pre><code>#pragma omp parallel for private(i,j,k) shared (result_buffer,trans_a,element_b)
for (i=0; i&lt;N; i++)
result_buffer[i]=0; 
{   
    for (j = 0; j&lt;(N/comm_size); j++)
    {               
            for(k=0; k&lt;N; k++)
            result_buffer[k]=result_buffer[k]+trans_a[j*N+k]*element_b[j];
    }               
 } 
</code></pre>
","922184","","<p>Well, one problem right now is that your ""outer-loop"" isn't an outer-loop because you don't have the <code>{}</code> in the right place.</p>

<p>So in that sense, no you don't have a race-condition because the <code>pragma</code> will only apply to this:</p>

<pre><code>for (i=0; i&lt;N; i++)
    result_buffer[i]=0;
</code></pre>

<p>and not the rest of the code. Your other two loops are <strong><em>not</em></strong> parallelized and therefore no race condition.</p>

<hr>

<p>That aside, if you intended your code to be this:</p>

<pre><code>for (i=0; i&lt;N; i++)
    result_buffer[i]=0; 

#pragma omp parallel for private(i,j,k) shared (result_buffer,trans_a,element_b)
for (j = 0; j&lt;(N/comm_size); j++)
{               
    for(k=0; k&lt;N; k++)
        result_buffer[k]=result_buffer[k]+trans_a[j*N+k]*element_b[j];
}               
</code></pre>

<p>Then yes, you <em>will</em> have a race condition.</p>

<p>Your inner loop modifies the entire <code>result_buffer</code> array. All iterations of the outer-loop will also clash on the same dataset.
So there will be a race condition.</p>

<p>As it stands right now, the only loop that that's parallelizable is the inner-most loop.</p>
"
"<p><code>theMessageMaxLength</code> keeps giving me a value of <code>4</code> even if the length is larger than 4. Why is this happening and how do I fix it? It is of type <code>size_t</code> and I don't have it declared anywhere, rather it is just a value being passed in as such:</p>

<pre><code>place_value(int task, struct PDB *llist, char *theMessage, size_t theMessageMaxLength)
</code></pre>

<p>The above method is being called as follows:</p>

<pre><code>place_value(task, llist, theMessage, sizeof(theMessage)); 
</code></pre>

<p>I'm assuming this is where the length gets set to 4, however, shouldn't it be set to something larger if my message is larger? How would I increase the size so it's not just 4...?</p>

<p>and then used like this within the function it is being passed into:</p>

<pre><code>strncpy(llist-&gt;data1, theMessage, theMessageMaxLength);
llist-&gt;data1[theMessageMaxLength] = '\0';
</code></pre>
","922184","","<p>It looks like you're confusing <code>sizeof()</code> with <code>strlen()</code>.</p>

<p><code>sizeof(theMessage)</code> will only give you the size of a <code>char*</code> which is a pointer - (4 bytes in your case). If you want the length of the string, you'll need to use <code>strlen(theMessage)</code> instead.</p>

<pre><code>place_value(task, llist, theMessage, strlen(theMessage)); 
</code></pre>
"
"<p>I would like to generate a random number between 0 and 3 and I have the following in my code:</p>

<pre><code>int random = rand() % 4;
</code></pre>

<p>This works fine but I would like it to generate 1, 2, and 3 most of the time and 0 only occasionally.</p>

<p>What is the best way to go about this? What are the names of common algorithms to address this problem?</p>
","922184","","<p>Here's one way. Suppose you want 0, 1, 2, 3 to have a distribution of 5%, 20%, 30%, 45%.<br>
You could do it like this:</p>

<pre><code>double val = (double)rand() / RAND_MAX;

int random;
if (val &lt; 0.05)       //  5%
    random = 0;
else if (val &lt; 0.25)  //  5% + 20%
    random = 1;
else if (val &lt; 0.55)  //  5% + 20% + 30%
    random = 2;
else
    random = 3;
</code></pre>

<p>Of course it doesn't have to be done with floating-point. I just did it this way since it's more intuitive.</p>
"
"<p>Maybe somebody can help me. In my project I'm using a linked list with dynamic allocation. And I don't know why, but it just doesn't work :(</p>

<pre><code>void insertLast (TList *list, wchar_t *string) {
    TWord *newWord;
    if ((newWord = malloc (sizeof(TWord))) == NULL)
        exit (EXIT_FAILURE);
    newWord-&gt;prev = list-&gt;tail;
    newWord-&gt;next = NULL;
    newWord-&gt;word = malloc(wcslen(string) * sizeof(wchar_t));
    wcscpy(newWord-&gt;word, string);
    if (list-&gt;tail != NULL) {
        list-&gt;tail-&gt;next = newWord;
    } else {
        list-&gt;head = newWord;
    }
    list-&gt;tail = newWord;
}
</code></pre>

<p>When I'm trying to compile that, I'm just seeing </p>

<pre><code>lab: malloc.c:3096: sYSMALLOc: Assertion `(old_top == (((mbinptr) (((char ￼ &amp;((av)-&gt;bins[((1) - 1) * 2])) - __builtin_offsetof (struct malloc_chunk, fd)))) &amp;&amp; old_size == 0) || ((unsigned long) (old_size) &gt;= (unsigned long)((((__builtin_offsetof (struct malloc_chunk, fd_nextsize))+((2 * (sizeof(size_t))) - 1)) &amp; ~((2 * (sizeof(size_t))) - 1))) &amp;&amp; ((old_top)-&gt;size &amp; 0x1) &amp;&amp; ((unsigned long)old_end &amp; pagemask) == 0)' failed.
</code></pre>

<p>Aborted</p>

<p>Maybe can somebody tell why I have this troubles? Thanks :)</p>
","922184","","<p>Here's one problem:</p>

<pre><code>newWord-&gt;word = malloc(wcslen(string) * sizeof(wchar_t));
wcscpy(newWord-&gt;word, string);
</code></pre>

<p>You forgot to allocate space for the terminating null character.</p>

<pre><code>newWord-&gt;word = malloc((wcslen(string) + 1) * sizeof(wchar_t));
</code></pre>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/2030366/what-do-the-brackets-mean-in-x86-asm"">What do the brackets mean in x86 asm?</a>  </p>
</blockquote>



<p>I've been confused about this for a while. What is the difference between ""si"" and ""[si]""? (This is using 16-bit NASM syntax)</p>
","922184","","<p><code>si</code> refers to the register <code>si</code>. <code>[si]</code> refers the address pointed to by <code>si</code>.</p>

<pre><code>mov ax, si    //  Copy the ""si"" to ""ax"".

mov ax, [si]  //  Load the value stored at address ""si"" into ""ax"".
</code></pre>
"
"<p>I'm trying to read the first line of an MP3 file (I edited this mp3 file to contain the text ""I'm an MP3"" right at the beginning of the file).</p>

<p>This is what I'm trying to do:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;fstream&gt;
using namespace std;

int main()
{
    fstream mp3;
    mp3.open(""05 Imagine.mp3"", ios::binary | ios::in | ios::out);
    /*mp3.seekg(0, ios::end);
    int lof = mp3.tellg();
    cout &lt;&lt; ""Length of file: "" &lt;&lt; lof &lt;&lt; endl;
    mp3.seekg(0, ios::beg);*/

    //char ch;
    //cout &lt;&lt; mp3.get(ch) &lt;&lt; endl;

    char* somebuf;
    while(mp3.read(somebuf, 10)) //Read the first 10 chars which are ""I'm an MP3 file"".
    {
        //cout &lt;&lt; somebuf;
    }
    return 0;
}
</code></pre>

<p>For some reason, that is crashing. At some point it didn't crash, but it didn't print anything when I did cout &lt;&lt; somebuf. Can someone help me with this? </p>
","922184","","<p>You never allocated anything for <code>somebuf</code>:</p>

<pre><code>char* somebuf;
</code></pre>

<p>therefore, it doesn't point anywhere.</p>

<pre><code>char* somebuf = new char[11];
somebuf[10] = '\0';          //  Not sure if it is necessary to null-terminate...
while(mp3.read(somebuf, 10)) //  Read the first 10 chars which are ""I'm an MP3 file"".
{
    //cout &lt;&lt; somebuf;
}


//  and free it later
delete [] somebuf;
</code></pre>

<p>Alternatively:</p>

<pre><code>char somebuf[11];
somebuf[10] = '\0';          //  Not sure if it is necessary to null-terminate...
while(mp3.read(somebuf, 10)) //  Read the first 10 chars which are ""I'm an MP3 file"".
{
    //cout &lt;&lt; somebuf;
}
</code></pre>
"
"<p>Hi all,</p>

<p>I'm trying to learn basic shellcoding and I've run across something curious that I hope someone can explain to me. I've compiled the following code two ways: declaring the shellcode as an array and as a char*. When I declare shellcode as an array, linux detects that I am trying to execute data and I get a segfault on the first instruction. However, when I declare shellcode as a char* all of the shellcode executes and I get a ""Hello world!"". How does the compiler treat these two declarations differently and why does one end in shellcode that lives in memory that is unprotected? Thanks in advance.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

/* This declaration ends in a segfault */
//char shellcode[] =

/* This declaration ends in successful execution */
char* shellcode = 

/* Shellcode prints ""Hello world!"" and exits */    
""\xeb\x1f\x48\x31\xc0\x48\x31\xdb\x48\x31\xc9\x48\x31\xd2\xb0\x04\xb3\x01\x59\xb2\x0c\xcd\x80\x48\x31\xc0\xb0\x01\x48\x31\xdb\xcd\x80\xe8\xdc\xff\xff\xff\x48\x65\x6c\x6c\x6f\x20\x57\x6f\x72\x6c\x64\x21"";

int main()
{
    void (*f)();
    f = (void (*)())shellcode;
    (void)(*f)();
}
</code></pre>
","922184","","<p>In your first case:</p>

<pre><code>char shellcode[] =
</code></pre>

<p>This puts the string literal on the stack as a local array. The stack and heap memory usually does not have execute permissions (for obvious reasons of security).</p>

<p>In your second case:</p>

<pre><code>char* shellcode = 
</code></pre>

<p>The string lives in static memory - typically in the same region as the rest of the program binary - which is executable.</p>
"
"<p>The following is my implementation of merge sort.</p>

<pre><code>private static void mergeSort(int[] a, int low , int high,int[] res)
{
    int mid = (low + high)  /2;
    if (low  &lt; high)
    {
        mergeSort(a,low,mid-1,res);
        mergeSort(a,mid,high-1,res);
        merge(a,low,mid,high,res);

    }
}



   private static void merge(int[] a, int low , int mid , int high,int[] res)
{

    int i = low;
    int j = mid ;

    int k =0;

    while (i &lt; mid &amp;&amp; j &lt; high)
        if(a[i] &lt; a[j])
               res[k++] = a[i++];
        else
              res[k++] = a[j++];


    while(i &lt; mid)
        res[k++] = a[i++];

    while(j &lt; high)
        res[k++] =a[j++];
}
</code></pre>

<p>When I run this program in the main method, I get the original array printed. Not sure what the problem is. The merge method works when I test is individually though.</p>

<pre><code>public static void main(String[] args)
{
    int[] a = {45,24,53,13,54,45,63,23};
    int[] res = new int[a.length];
    mergeSort(a,0,a.length,res);
    for(int i=0 ; i &lt; res.length ; i++)
    {
       System.out.print(res[i] +"","");
    }
}
</code></pre>

<p><strong>Output :</strong></p>

<pre><code> 45,24,53,13,54,45,63,23,
</code></pre>

<p>I have spent a lot of time looking for the problem. I am not able to fix it.</p>
","922184","","<p>The problem is actually fairly complicated.</p>

<p>The main issue is that you are only merging into <code>res</code>, but you never use it again. So you end up overwriting it with each level of recursion.</p>

<p>Here's a patched version that merges back and forth between <code>a</code> and <code>res</code>. It does destroy the contents of <code>a</code>, so it might not be what you want.</p>

<pre><code>private static void mergeSort(int[] a, int low , int high,int[] res)
{
    int mid = (low + high)  /2;
    if (low + 1 &lt; high)
    {
        //  Sort sub-parts
        mergeSort(a,low,mid,res);
        mergeSort(a,mid,high,res);

        //  Copy back to ""a""
        for (int c = low; c &lt; high; c++){
            a[c] = res[c];
        }

        //  Merge back to ""res""
        merge(a,low,mid,high,res);
    }else{
        res[low] = a[low];
    }
}

private static void merge(int[] a, int low , int mid , int high,int[] res)
{

    int i = low;
    int j = mid;

    int k = low;   //  Use ""low"" instead of 0.

    while (i &lt; mid &amp;&amp; j &lt; high)
        if(a[i] &lt; a[j])
               res[k++] = a[i++];
        else
              res[k++] = a[j++];


    while(i &lt; mid)
        res[k++] = a[i++];

    while(j &lt; high)
        res[k++] =a[j++];
}
</code></pre>

<p>Output:</p>

<pre><code>13,23,24,45,45,53,54,63,
</code></pre>
"
"<p>When I browsed the source code of unzip, I encoutered a main function as follows,</p>

<pre><code>int MAIN(argc, argv)   /* return PK-type error code (except under VMS) */
    int argc;
    char *argv[];
{
    int r;

    CONSTRUCTGLOBALS();
    r = unzip(__G__ argc, argv);
    DESTROYGLOBALS();
    RETURN(r);
}
</code></pre>

<p>I think the main function defined like this would not pass while compiling. But my c compiler does not complain about it. Why it is syntactically correct?</p>

<p>Thanks.</p>
","922184","","<p>This is the old K&amp;R style function declaration. So yes, it's valid C, abeit <strong><em>very old</em></strong> C. </p>

<p>I wouldn't recommend writing this type declaration since it's completely obsolete and will likely confuse anyone reading your code who isn't familiar with the syntax.</p>
"
"<p>Suppose <code>a1</code>, <code>b1</code>, <code>c1</code>, and <code>d1</code> point to heap memory and my numerical code has the following core loop.</p>

<pre><code>const int n=100000

for(int j=0;j&lt;n;j++){
    a1[j] += b1[j];
    c1[j] += d1[j];
}
</code></pre>

<p>This loop is executed 10,000 times via another outer <code>for</code> loop. To speed it up, I changed the code to:</p>

<pre><code>for(int j=0;j&lt;n;j++){
    a1[j] += b1[j];
}
for(int j=0;j&lt;n;j++){
    c1[j] += d1[j];
}
</code></pre>

<p>Compiled on MS <a href=""http://en.wikipedia.org/wiki/Visual_C++#32-bit_versions"">Visual C++ 10.0</a> with full optimization and <a href=""http://en.wikipedia.org/wiki/SSE2"">SSE2</a> enabled for 32-bit on a <a href=""http://en.wikipedia.org/wiki/Intel_Core_2"">Intel Core 2</a> Duo (x64), the first example takes 5.5&nbsp;seconds and the double-loop example takes only 1.9&nbsp;seconds. My question is: (Please refer to the my rephrased question at the bottom)</p>

<p>PS: I am not sure, if this helps:</p>

<p>Disassembly for the first loop basically looks like this (this block is repeated about five times in the full program):</p>

<pre><code>movsd       xmm0,mmword ptr [edx+18h]
addsd       xmm0,mmword ptr [ecx+20h]
movsd       mmword ptr [ecx+20h],xmm0
movsd       xmm0,mmword ptr [esi+10h]
addsd       xmm0,mmword ptr [eax+30h]
movsd       mmword ptr [eax+30h],xmm0
movsd       xmm0,mmword ptr [edx+20h]
addsd       xmm0,mmword ptr [ecx+28h]
movsd       mmword ptr [ecx+28h],xmm0
movsd       xmm0,mmword ptr [esi+18h]
addsd       xmm0,mmword ptr [eax+38h]
</code></pre>

<p>Each loop of the double loop example produces this code (the following block is repeated about three times):</p>

<pre><code>addsd       xmm0,mmword ptr [eax+28h]
movsd       mmword ptr [eax+28h],xmm0
movsd       xmm0,mmword ptr [ecx+20h]
addsd       xmm0,mmword ptr [eax+30h]
movsd       mmword ptr [eax+30h],xmm0
movsd       xmm0,mmword ptr [ecx+28h]
addsd       xmm0,mmword ptr [eax+38h]
movsd       mmword ptr [eax+38h],xmm0
movsd       xmm0,mmword ptr [ecx+30h]
addsd       xmm0,mmword ptr [eax+40h]
movsd       mmword ptr [eax+40h],xmm0
</code></pre>

<p><strong>EDIT:</strong> The question turned out to be of no relevance, as the behavior severely depends on the sizes of the arrays (n) and the CPU cache. So if there is further interest, I rephrase the question:</p>

<p><strong>Could you provide some solid insight into the details that lead to the different cache behaviors as illustrated by the five regions on the following graph?</strong></p>

<p><strong>It might also be interesting to point out the differences between CPU/cache architectures, by providing a similar graph for these CPUs.</strong></p>

<p>PPS: The <strong>full code</strong> is at <a href=""http://pastebin.com/ivzkuTzG"">http://pastebin.com/ivzkuTzG</a>. It uses TBB Tick_Count for higher resolution timing, which can be disabled by not defining the
TBB_TIMING Macro.</p>

<p>(It shows FLOP/s for different values of <code>n</code>.)</p>

<p><img src=""http://i.stack.imgur.com/keuWU.gif"" alt=""enter image description here""></p>
","922184","","<p>Upon further analysis of this, I believe this is (at least partially) caused by data alignment of the four pointers. This will cause some level of cache bank/way conflicts.</p>

<p>If I've guessed correctly on how you are allocating your arrays, they <strong><em>are likely to be aligned to the page line</em></strong>.</p>

<p>This means that all your accesses in each loop will fall on the same cache way. However, Intel processors have had 8-way L1 cache associativity for a while. But in reality, the performance isn't completely uniform. Accessing 4-ways is still slower than say 2-ways.</p>

<p><strong>EDIT : It does in fact look like you are allocating all the arrays separately.</strong>
Usually when such large allocations are requested, the allocator will request fresh pages from the OS. Therefore, there is a high chance that large allocations will appear at the same offset from a page-boundary.</p>

<p><strong>Here's the test code:</strong></p>

<pre><code>int main(){
    const int n = 100000;

#ifdef ALLOCATE_SEPERATE
    double *a1 = (double*)malloc(n * sizeof(double));
    double *b1 = (double*)malloc(n * sizeof(double));
    double *c1 = (double*)malloc(n * sizeof(double));
    double *d1 = (double*)malloc(n * sizeof(double));
#else
    double *a1 = (double*)malloc(n * sizeof(double) * 4);
    double *b1 = a1 + n;
    double *c1 = b1 + n;
    double *d1 = c1 + n;
#endif

    //  Zero the data to prevent any chance of denormals.
    memset(a1,0,n * sizeof(double));
    memset(b1,0,n * sizeof(double));
    memset(c1,0,n * sizeof(double));
    memset(d1,0,n * sizeof(double));

    //  Print the addresses
    cout &lt;&lt; a1 &lt;&lt; endl;
    cout &lt;&lt; b1 &lt;&lt; endl;
    cout &lt;&lt; c1 &lt;&lt; endl;
    cout &lt;&lt; d1 &lt;&lt; endl;

    clock_t start = clock();

    int c = 0;
    while (c++ &lt; 10000){

#if ONE_LOOP
        for(int j=0;j&lt;n;j++){
            a1[j] += b1[j];
            c1[j] += d1[j];
        }
#else
        for(int j=0;j&lt;n;j++){
            a1[j] += b1[j];
        }
        for(int j=0;j&lt;n;j++){
            c1[j] += d1[j];
        }
#endif

    }

    clock_t end = clock();
    cout &lt;&lt; ""seconds = "" &lt;&lt; (double)(end - start) / CLOCKS_PER_SEC &lt;&lt; endl;

    system(""pause"");
    return 0;
}
</code></pre>

<hr>

<p><strong>Benchmark Results:</strong></p>

<h1>EDIT: Results on an <em>actual</em> Core 2 architecture machine:</h1>

<p><strong>2 x Intel Xeon X5482 Harpertown @ 3.2 GHz:</strong></p>

<pre><code>#define ALLOCATE_SEPERATE
#define ONE_LOOP
00600020
006D0020
007A0020
00870020
seconds = 6.206

#define ALLOCATE_SEPERATE
//#define ONE_LOOP
005E0020
006B0020
00780020
00850020
seconds = 2.116

//#define ALLOCATE_SEPERATE
#define ONE_LOOP
00570020
00633520
006F6A20
007B9F20
seconds = 1.894

//#define ALLOCATE_SEPERATE
//#define ONE_LOOP
008C0020
00983520
00A46A20
00B09F20
seconds = 1.993
</code></pre>

<p>Observations:</p>

<ul>
<li><p><strong>6.206 seconds</strong> with one loop and <strong>2.116 seconds</strong> with two loops. This reproduces the OP's results exactly.</p></li>
<li><p><strong>In the first two tests, the arrays are allocated separately.</strong> You'll notice that they all have the same alignment relative to the page.</p></li>
<li><p><strong>In the second two tests, the arrays are packed together to break that alignment.</strong> Here you'll notice both loops are faster. Furthermore, the second (double) loop is now the slower one as you would normally expect.</p></li>
</ul>

<p>As @Stephen Cannon points out in the comments, there is very likely possibility that this alignment causes <strong><em>false aliasing</em></strong> in the load/store units or the cache. I Googled around for this and found that Intel actually has a hardware counter for <strong><em>partial address aliasing</em></strong> stalls:</p>

<p><a href=""http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/~amplifierxe/pmw_dp/events/partial_address_alias.html"">http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/~amplifierxe/pmw_dp/events/partial_address_alias.html</a></p>

<hr>

<h1>5 Regions - Explanations</h1>

<p><strong>Region 1:</strong></p>

<p>This one is easy. The dataset is so small that the performance is dominated by overhead like looping and branching.</p>

<p><strong>Region 2:</strong></p>

<p><strike>Here, as the data sizes increases, the amount of relative overhead goes down and the performance ""saturates"". Here two loops is slower because it has twice as much loop and branching overhead.</strike></p>

<p>I'm not sure exactly what's going on here... Alignment could still play an effect as Agner Fog mentions <a href=""http://www.agner.org/optimize/blog/read.php?i=142"">cache bank conflicts</a>. (That link is about Sandy Bridge, but the idea should still be applicable to Core 2.)</p>

<p><strong>Region 3:</strong></p>

<p>At this point, the data no longer fits in L1 cache. So performance is capped by the L1 &lt;-> L2 cache bandwidth.</p>

<p><strong>Region 4:</strong></p>

<p>The performance drop in the single-loop is what we are observing. And as mentioned, this is due to the alignment which (most likely) causes <strong><em>false aliasing</em></strong> stalls in the processor load/store units.</p>

<p>However, in order for false aliasing to occur, there must be a large enough stride between the datasets. This is why you don't see this in region 3.</p>

<p><strong>Region 5:</strong></p>

<p>At this point, nothing fits in cache. So you're bound by memory bandwidth.</p>

<hr>

<p><img src=""http://i.stack.imgur.com/ElCGL.png"" alt=""2 x Intel X5482 Harpertown @ 3.2 GHz"">
<img src=""http://i.stack.imgur.com/QMpwj.png"" alt=""Intel Core i7 870 @ 2.8 GHz"">
<img src=""http://i.stack.imgur.com/NpyhG.png"" alt=""Intel Core i7 2600K @ 4.4 GHz""></p>
"
"<p>I am working on CPU detection and general environment detection code for my hobby OS. Is there ever a case where CPUID needs to be called multiple times? That is if the system has multiple cores, does the OS need to call CPUID on each core? Same for NUMA.</p>

<p>Both the <a href=""http://support.amd.com/us/Embedded_TechDocs/25481.pdf"" rel=""nofollow"">AMD</a> and <a href=""http://www.intel.com/content/dam/doc/application-note/processor-identification-cpuid-instruction-note.pdf"" rel=""nofollow"">Intel</a> CPUID manuals are unclear on this. There is an article on the osdev wiki that mentions calling CPUID called <a href=""http://wiki.osdev.org/Detecting_CPU_Topology_%2880x86%29"" rel=""nofollow"">Detecting CPU Topology</a>, but to my reading was not clear as to when and how many times CPUID needs to be called.</p>
","922184","","<p>Since it's been almost a week and nobody has been able to answer this (probably because of the holidays), I'll attempt to answer this anyway.</p>

<p><strong>I think the answer is yes.</strong> You may need to call <code>CPUID</code> on each core. One reason for this is that not all (even x86) systems today are homogeneous.</p>

<p>For example, I've read on an overclocking forum (I can't find the link) that it's possible to mix two <em>different</em> processor models on some dual-socket server boards. The person had a dual-socket 1366 system with two different speed processors. (and different model #s)</p>

<p>So in this case, calling <code>CPUID</code> will depend on which processor the thread was on - therefore you'll need to call it once each processor to get all the information.</p>

<p>In the manuals of one of my server-motherboards, it also states that you are allowed to mix processors of different models (with certain restrictions). And certainly, it's possible to mix two different <a href=""http://www.techpowerup.com/articles/overclocking/29"" rel=""nofollow"">steppings</a> of the same processor model.</p>

<hr>

<p>This reason alone (heterogeneous topology), is already reason to need to call <code>CPUID</code> on each core.</p>
"
"<p>I have an ANSI C program in Linux CentOS 64-bit computer containing the following lines: </p>

<pre><code>H1_real = malloc(len_SPURFREQ_TIE * sizeof(double)); /* allocate memory */
H1_imag = malloc(len_SPURFREQ_TIE * sizeof(double)); /* allocate memory */
H2_real = malloc(len_SPURFREQ_TIE * sizeof(double)); /* allocate memory */
H2_imag = malloc(len_SPURFREQ_TIE * sizeof(double)); /* allocate memory */
H3_real = malloc(len_SPURFREQ_TIE * sizeof(double)); /* allocate memory */
H3_imag = malloc(len_SPURFREQ_TIE * sizeof(double)); /* allocate memory */

if ( (H1_real == NULL) || (H1_imag == NULL) || (H2_real == NULL) || (H2_imag == NULL) || (H3_real == NULL) || (H3_imag = NULL) ) {
exit(6);
}
</code></pre>

<p>When I use gdb to check the allocated addresses of H1_real to H3_imag, they look fine. The if statement also executes fine, in that exit(6) is not triggered. But when checking the H3_imag address after the if statement executes, it now read 0x0. Anyone know what could be going on?</p>
","922184","","<pre><code>H3_imag = NULL
</code></pre>

<p>is supposed to be:</p>

<pre><code>H3_imag == NULL
</code></pre>
"
"<h2>Background</h2>

<p>The following critical loop of a piece of numerical software, written in C++, basically compares two objects by one of their members:</p>

<pre><code>for(int j=n;--j&gt;0;)
    asd[j%16]=a.e&lt;b.e;
</code></pre>

<p><code>a</code> and <code>b</code> are of class <code>ASD</code>:</p>

<pre><code>struct ASD  {
    float e;
    ...
};
</code></pre>

<p>I was investigating the effect of putting this comparison in a lightweight member function:</p>

<pre><code>bool test(const ASD&amp; y)const {
    return e&lt;y.e;
}
</code></pre>

<p>and using it like this:</p>

<pre><code>for(int j=n;--j&gt;0;)
    asd[j%16]=a.test(b);
</code></pre>

<p>The compiler is inlining this function, but the problem is, that the assembly code will be different and cause >10% of runtime overhead. I have to question:</p>

<h2>Questions</h2>

<ol>
<li><p>Why is the compiler prodrucing different assembly code?</p></li>
<li><p>Why is the produced assembly slower?</p></li>
</ol>

<p><strong>EDIT:</strong>  The second question has been answered by implementing @KamyarSouri's suggestion (j%16). The assembly code now looks almost identical (see <a href=""http://pastebin.com/diff.php?i=yqXedtPm"">http://pastebin.com/diff.php?i=yqXedtPm</a>). The only differences are the lines 18, 33, 48:</p>

<pre><code>000646F9  movzx       edx,dl 
</code></pre>

<h2>Material</h2>

<ul>
<li>The test code: <a href=""http://pastebin.com/03s3Kvry"">http://pastebin.com/03s3Kvry</a></li>
<li>The assembly output on MSVC10 with /Ox /Ob2 /Ot /arch:SSE2:
<ul>
<li>Compiler inlined version: <a href=""http://pastebin.com/yqXedtPm"">http://pastebin.com/yqXedtPm</a></li>
<li>Manually inlined version: <a href=""http://pastebin.com/pYSXL77f"">http://pastebin.com/pYSXL77f</a></li>
<li>Difference <a href=""http://pastebin.com/diff.php?i=yqXedtPm"">http://pastebin.com/diff.php?i=yqXedtPm</a></li>
</ul></li>
</ul>

<p>This chart shows the FLOP/s (up to a scaling factor) for 50 testruns of my code.</p>

<p><img src=""http://i.stack.imgur.com/BlGeJ.png"" alt=""enter image description here""></p>

<p>The gnuplot script to generate the plot: <a href=""http://pastebin.com/8amNqya7"">http://pastebin.com/8amNqya7</a></p>

<p>Compiler Options:</p>

<p>/Zi /W3 /WX- /MP /Ox /Ob2 /Oi /Ot /Oy /GL /D ""WIN32"" /D ""NDEBUG"" /D ""_CONSOLE"" /D ""_UNICODE"" /D ""UNICODE"" /Gm- /EHsc /MT /GS- /Gy /arch:SSE2 /fp:precise /Zc:wchar_t /Zc:forScope   /Gd /analyze-</p>

<p>Linker Options:
/INCREMENTAL:NO  ""kernel32.lib"" ""user32.lib"" ""gdi32.lib"" ""winspool.lib"" ""comdlg32.lib"" ""advapi32.lib"" ""shell32.lib"" ""ole32.lib"" ""oleaut32.lib"" ""uuid.lib"" ""odbc32.lib"" ""odbccp32.lib""  /ALLOWISOLATION /MANIFESTUAC:""level='asInvoker' uiAccess='false'"" /SUBSYSTEM:CONSOLE /OPT:REF /OPT:ICF /LTCG /TLBID:1 /DYNAMICBASE /NXCOMPAT /MACHINE:X86 /ERRORREPORT:QUEUE </p>
","922184","","<h1>Short Answer:</h1>

<p>Your <code>asd</code> array is declared as this:</p>

<pre><code>int *asd=new int[16];
</code></pre>

<p>Therefore, use <code>int</code> as the return type rather than <code>bool.</code><br>
Alternatively, change the array type to <code>bool</code>.</p>

<p><strong>In any case, make the return type of the <code>test</code> function match the type of the array.</strong></p>

<p>Skip to bottom for more details.</p>

<h1>Long Answer:</h1>

<p>In the manually inlined version, the ""core"" of one iteration looks like this:</p>

<pre><code>xor         eax,eax  

mov         edx,ecx  
and         edx,0Fh  
mov         dword ptr [ebp+edx*4],eax  
mov         eax,dword ptr [esp+1Ch]  
movss       xmm0,dword ptr [eax]  
movss       xmm1,dword ptr [edi]  
cvtps2pd    xmm0,xmm0  
cvtps2pd    xmm1,xmm1  
comisd      xmm1,xmm0  
</code></pre>

<p>The compiler inlined version is completely identical except for the first instruction.</p>

<p>Where instead of:</p>

<pre><code>xor         eax,eax
</code></pre>

<p>it has:</p>

<pre><code>xor         eax,eax  
movzx       edx,al
</code></pre>

<p>Okay, so it's <em>one</em> extra instruction. They both do the same - zeroing a register. This is the only difference that I see...</p>

<p>The <code>movzx</code> instruction has a single-cycle latency and <code>0.33</code> cycle reciprocal throughput on all the newer architectures. So I can't imagine how this could make a 10% difference. </p>

<p>In both cases, the result of the zeroing is used only 3 instructions later. So it's very possible that this could be on the critical path of execution.</p>

<hr>

<p><strong>While I'm not an Intel engineer, here's my guess:</strong></p>

<p>Most modern processors deal with zeroing operations (such as <code>xor eax,eax</code>) via <a href=""http://en.wikipedia.org/wiki/Register_renaming"">register renaming</a> to a bank of zero registers. It completely bypasses the execution units. However, it's possible that this special handling could cause a pipeline bubble when the (partial) register is accessed via <code>movzx edi,al</code>.</p>

<p>Furthermore, there's also a <em>false</em> dependency on <code>eax</code> in the compiler inlined version:</p>

<pre><code>movzx       edx,al  
mov         eax,ecx  //  False dependency on ""eax"".
</code></pre>

<p>Whether or not the <a href=""http://en.wikipedia.org/wiki/Out-of-order_execution"">out-of-order execution</a> is able to resolve this is beyond me.</p>

<hr>

<h1>Okay, this is basically turning into a question of reverse-engineering the MSVC compiler...</h1>

<p>Here I'll to explain <strong><em>why</em></strong> that extra <code>movzx</code> is generated as well as why it stays.</p>

<p>The key here is the <code>bool</code> return value. Apparently, <code>bool</code> datatypes are probably as stored 8-bit values inside the MSVC internal-representation.
Therefore when you implicitly convert from <code>bool</code> to <code>int</code> here:</p>

<pre><code>asd[j%16] = a.test(b);
^^^^^^^^^   ^^^^^^^^^
 type int   type bool
</code></pre>

<p>there is an 8-bit -> 32-bit integer promotion. This is the reason why MSVC generates the <code>movzx</code> instruction.</p>

<p>When the inlining is done manually, the compiler has enough information to optimize out this conversion and keeps everything as a 32-bit datatype IR.</p>

<p>However, when the code is put into it's own function with a <code>bool</code> return value, the compiler is not able to optimize out the 8-bit intermediate datatype. Therefore, the <code>movzx</code> stays.</p>

<p>When you make both datatypes the same (either <code>int</code> or <code>bool</code>), no conversion is needed. Hence the problem is avoided altogether.</p>
"
"<p>I have the following code for a vector of vectors of integers (i.e. an integer matrix..)</p>

<pre><code>vector&lt;vector&lt;int&gt; &gt; scores (3, vector&lt;int&gt;(2,0));
cout&lt;&lt;scores[1][5];
</code></pre>

<p>This does not give EXC_BAD_ACCESS,  but this does:</p>

<pre><code>cout&lt;&lt;scores[5][1];
</code></pre>

<p>Why the difference in behavior?</p>

<p>Just to clarify:  This is not specific to the example numbers given. When the inner dimension is out of bounds, there is never an error, not so for the outer!</p>
","922184","","<p>Either way, it's undefined behavior to access out-of-bounds.</p>

<p>So anything is allowed to happen. It just ""happens"" that one case crashes and the other doesn't.</p>

<hr>

<p>As for why exactly the first case does not crash and the second one does in your particular scenario, the first case is mostly just reading past the array into junk heap memory.</p>

<p>But in the second case, you are accessing a bad <code>vector</code> object. Since a <code>vector</code> object is just a wrapper for a pointer, dereferencing that (bad) pointer upon the second index will crash.</p>
"
"<p>I have made a function for posterizing images.</p>

<pre><code>// =(
#define ARGB_COLOR(a, r, g, b) (((a) &lt;&lt; 24) | ((r) &lt;&lt; 16) | ((g) &lt;&lt; 8) | (b))

inline UINT PosterizeColor(const UINT &amp;color, const float &amp;nColors)
{
    __m128 clr = _mm_cvtepi32_ps(  _mm_cvtepu8_epi32((__m128i&amp;)color)  );

    clr = _mm_mul_ps(clr,  _mm_set_ps1(nColors / 255.0f)  );
    clr = _mm_round_ps(clr, _MM_FROUND_TO_NEAREST_INT);
    clr = _mm_mul_ps(clr, _mm_set_ps1(255.0f / nColors)  );

    __m128i iClr = _mm_cvttps_epi32(clr);

    return ARGB_COLOR(iClr.m128i_u8[12],
                      iClr.m128i_u8[8],
                      iClr.m128i_u8[4],
                      iClr.m128i_u8[0]);
}
</code></pre>

<p>in the first line, I unpack the color into 4 floats, but I can't find the proper way to do the reverse.</p>

<p>I searched through the SSE docs and could not find the reverse of <code>_mm_cvtepu8_epi32</code></p>

<p>does one exist?</p>
","922184","","<p>Unfortunately, there's no instruction to do that even in AVX (none that I'm aware of). So you will have to do it manually like are right now.</p>

<p>However, your current method is very sub-optimal and you're relying on <code>.m128i_u8</code> which is an MSVC extension. Based on my experience with MSVC, it will use an aligned buffer to access the individual elements. This has a very heavy penalty because of partial-word access.</p>

<p>Instead of <code>.m128i_u8</code>, use <a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse41_reg_ins_ext.htm"" rel=""nofollow""><code>_mm_extract_epi32()</code></a>. This is in SSE4.1. But you're already relying with SSE4.1 with <code>_mm_cvtepu8_epi32()</code>.</p>

<p>This situation is particularly bad since you're working with 1-byte granularity. If you were working with 2-byte (16-bit integer) granularity instead, there is an efficient solution using <a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_misc.htm"" rel=""nofollow"">shuffle intrinsics</a>.</p>
"
"<p>At the start of <code>#pragma omp parallel</code> a bunch of threads are created, then when we get to <code>#pragma omp for</code> the workload is distributed. What happens if this for loop has a for loop inside it, and I place a <code>#pragma omp for</code> before it as well? Does each thread create new threads? If not, which threads are assigned this task? What exactly happens in this situation?</p>
","922184","","<p>By default, no threads are spawned for the inner loop. It is done sequentially using the thread that reaches it.</p>

<p>This is because nesting is disabled by default. However, if you enable nesting via <a href=""http://msdn.microsoft.com/en-us/library/sk3zt8e1%28v=vs.80%29.aspx"" rel=""nofollow""><code>omp_set_nested()</code></a>, then a new set of threads will be spawned.</p>

<p>However, if you aren't careful, this will result in <code>p^2</code> number of threads (since each of the original <code>p</code> threads will spawn another <code>p</code> threads.) Therefore nesting is disabled by default.</p>
"
"<p>Consider the following C-function:</p>

<pre><code>double foo (int n) {
    int i;
    double sum;
    if (n==0)
        return 1.0;
    else {
        sum = 0.0;
        for (i=0; i&lt;n; i++)
        sum +=foo(i);
        return sum;
    }
}
</code></pre>

<p>The space complexity of the above function is:</p>

<blockquote>
  <p>(a) O(1) (b) O(n) (c) O(n!) (d) O(n^n)</p>
</blockquote>

<p>What I've done is calculating the recurrence relation for the above code but I'm still not able to solve that recurrence. I know this is not home work related site. But any help would be appreciated.</p>

<p>This is my recurrence.</p>

<blockquote>
  <p>T(n) = T(n-1) + T(n-2) + T(n-3) + T(n-4) +........+ T(1)+ S</p>
</blockquote>

<p>Where S is some constant.</p>
","922184","","<p>That would depend on whether you're talking about stack, or heap space complexity.</p>

<p>For the heap, it's <code>O(1)</code> or <code>O(0)</code> since you're using no heap memory. (aside from the basic system/program overhead)</p>

<p>For the stack, it's <code>O(n)</code>. This is because the recursion gets up the <code>N</code> levels deep.</p>

<p>The deepest point is:</p>

<pre><code>foo(n)
    foo(n - 1)
        foo(n - 2)

        ...

        foo(0)
</code></pre>
"
"<p>Suppose I have an array of non-repeating decimal numbers:</p>

<pre><code>v1 = 0.0588235294117647, 0.1428571428571429, 0.0526315789473684, 0.0769230769230769
</code></pre>

<p>I would like to convert this to an array of integers by multiplying/dividing all the elements by a single number:</p>

<pre><code>v2 = 1729, 4199, 1547, 2261
</code></pre>

<p><em>All numbers need to be in their most simple form as well.</em> To clarify, this is the solutions column of a matrix with one free variable. I need to make that variable equal something that makes the entire column consist of whole integers.</p>

<p>I've tried a bunch of things, but nothing seems to work all the time.</p>

<p>I need some type of algorithm so that I can automate this process.</p>
","922184","","<p>Based on your comment on the other answer, your question seems to be how to scale a vector up so that all the values are integral.</p>

<p>This is not an easy task as you essentially need to find fractional approximations for all the numbers in <code>v1</code>.</p>

<p>Related: <a href=""http://stackoverflow.com/questions/7563669/algorithm-for-finding-the-ratio-of-two-floating-point-numbers"">Algorithm for finding the ratio of two floating-point numbers?</a></p>

<p>There are essentially 2 main approaches to do this depending on what kind of numbers you want:</p>

<p>1) <strong>The easy way:</strong> You could multiply the vector by 2 until everything becomes integral. This is guaranteed to happen since all current systems use binary floating-point. This is essentially the <a href=""http://stackoverflow.com/a/7563720/922184"">first answer</a> in the above question.</p>

<p>There is one major drawback to this approach. If your numbers are like:</p>

<pre><code>0.3333333333333333
0.1000000000000000
0.2500000000000000
</code></pre>

<p>you will get very ""weird"" (and potentially large) results. (you will not get: <code>20, 6, 15</code> which is the desired answer)</p>

<p>2) <strong>The hard way:</strong> This approach is to use <a href=""http://en.wikipedia.org/wiki/Continued_fraction"" rel=""nofollow"">continued fractions</a> on each element of <code>v1</code> to turn it into an array of fractions. Then multiply every element by the LCM of all the denominators. This is essentially the <a href=""http://stackoverflow.com/a/7563694/922184"">second answer</a> in the above question.</p>

<p>The drawback of this approach is that it's math intensive and complicated. So you're better off just copying the implementation in that answer. The advantage is that it will give better results.</p>
"
"<p>i have some question.
I try this code and recieve ""Segmentation fault"" error:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;cstring&gt;
#include &lt;cctype&gt;

using namespace std;

struct Stack {
    int value;
    Stack *next;
};

void push(Stack* top, int value) {
    Stack *ntop = new Stack;
    ntop-&gt;value = top-&gt;value;
    ntop-&gt;next = top-&gt;next;
    top-&gt;next = ntop;
    top-&gt;value = value;
}

int pop(Stack* top) {
    int val = top-&gt;value;
    top-&gt;value = top-&gt;next-&gt;value;
    top-&gt;next = top-&gt;next-&gt;next;
    return val;
}

int main()
{
    Stack *top;
    top-&gt;next = NULL;
    push(top, 20);
    cout &lt;&lt; pop(top);
}
</code></pre>

<pre>[10:40:46] [~] >> g++ 3.cpp -o 3 && ./3
Segmentation fault</pre>

<p>but if i add <strong>const char* test = """";</strong> before <strong>Stack *top;</strong> it works normal:</p>

<pre><code>int main()
{
    const char* test = """";
    Stack *top;
    top-&gt;next = NULL;
    push(top, 20);
    cout &lt;&lt; pop(top);
}
</code></pre>

<pre>[10:47:33] [~] >> g++ 3.cpp -o 3 && ./3
20</pre>

<p>where my mistake?</p>
","922184","","<p>The problem is here:</p>

<pre><code>Stack *top;
top-&gt;next = NULL;
</code></pre>

<p>You are referencing an uninitialized pointer. That's undefined behavior. So anything can happen and it may not be consistent with surrounding code.</p>

<p>I suppose you forgot to actually allocate something for <code>top</code>.</p>

<pre><code>int main()
{
    Stack *top = new Stack;  //  Allocate

    top-&gt;next = NULL;
    push(top, 20);
    cout &lt;&lt; pop(top);

    delete top;   //  Free

    return 0;
}
</code></pre>

<p>*Though I'd want point out that you'll still have memory leaks inside the code.</p>
"
"<p>I have a for loop in my C code as follows:</p>

<pre><code>for(i=0; i&lt;100000; i++){

    a[i] = simulate(); //  simulate() function simulates some system

}
</code></pre>

<p>We see that computation of each iteration is independent from others (the order of elements in <code>a[]</code> is not important to me). I want to parallelize the computation of this for loop using multi-threading. I am not exactly aware of how to do this in C? I have a 8 processor machine, so I can run 8 threads parallely.</p>
","922184","","<p>There's no portable way to do parallelism in C*. However, the <a href=""http://en.wikipedia.org/wiki/OpenMP"">OpenMP standard</a> is widely supported:</p>

<pre><code>#pragma omp parallel for
for(i=0; i&lt;100000; i++){

    a[i] = simulate(); //  simulate() function simulates some system

}
</code></pre>

<p>Depending on your compiler, there will be a flag that you must set to enable OpenMP support:</p>

<ul>
<li><strong>MSVC:</strong> <code>/openmp</code></li>
<li><strong>GCC:</strong> <code>-fopenmp</code></li>
</ul>

<p>as well as a header if you wish to access certain OpenMP functions:</p>

<pre><code>#include &lt;omp.h&gt;
</code></pre>

<p><strong>EDIT :</strong></p>

<p>*The (very recently approved) C11 standard has support for threads via <code>&lt;threads.h&gt;</code>.</p>
"
"<p>Looking at the SSE operators</p>

<pre><code>CMPORDPS - ordered compare packed singles
CMPUNORDPS - unordered compare packed singles
</code></pre>

<p>What do ordered and unordered mean? I looked for equivalent instructions in the x86 instruction set, and it only seems to have unordered (FUCOM).</p>
","922184","","<p>An <strong>ordered comparison</strong> checks if neither operand is <code>NaN</code>. Conversely, an <strong>unordered comparison</strong> checks if either operand is a <code>NaN</code>.</p>

<p>This page gives some more information on this:</p>

<ul>
<li><a href=""http://csapp.cs.cmu.edu/public/waside/waside-sse.pdf"">http://csapp.cs.cmu.edu/public/waside/waside-sse.pdf</a> (section 5)</li>
</ul>

<p>The idea here is that comparisons with <code>NaN</code> are indeterminate. (can't decide the result) So an ordered/unordered comparison checks if this is (or isn't) the case.</p>

<pre><code>double a = 0.;
double b = 0.;

__m128d x = _mm_set1_pd(a / b);     //  NaN
__m128d y = _mm_set1_pd(1.0);       //  1.0
__m128d z = _mm_set1_pd(1.0);       //  1.0

__m128d c0 = _mm_cmpord_pd(x,y);    //  NaN vs. 1.0
__m128d c1 = _mm_cmpunord_pd(x,y);  //  NaN vs. 1.0
__m128d c2 = _mm_cmpord_pd(y,z);    //  1.0 vs. 1.0
__m128d c3 = _mm_cmpunord_pd(y,z);  //  1.0 vs. 1.0

cout &lt;&lt; _mm_castpd_si128(c0).m128i_i64[0] &lt;&lt; endl;
cout &lt;&lt; _mm_castpd_si128(c1).m128i_i64[0] &lt;&lt; endl;
cout &lt;&lt; _mm_castpd_si128(c2).m128i_i64[0] &lt;&lt; endl;
cout &lt;&lt; _mm_castpd_si128(c3).m128i_i64[0] &lt;&lt; endl;
</code></pre>

<p>Result:</p>

<pre><code>0
-1
-1
0
</code></pre>

<ul>
<li><em>Ordered comparison</em> of <code>NaN</code> and <code>1.0</code> gives <code>false</code>.</li>
<li><em>Unordered comparison</em> of <code>NaN</code> and <code>1.0</code> gives <code>true</code>.</li>
<li><em>Ordered comparison</em> of <code>1.0</code> and <code>1.0</code> gives <code>true</code>.</li>
<li><em>Unordered comparison</em> of <code>1.0</code> and <code>1.0</code> gives <code>false</code>.</li>
</ul>
"
"<pre><code>#include &lt;iostream&gt;
using namespace std;

int main(void)
{
    int *ptr = new int;
    cout &lt;&lt; ""Memory address of ptr:"" &lt;&lt; ptr &lt;&lt; endl;
    cin.get();
    delete ptr;

    return 0;
}
</code></pre>

<p>Every time I run this program, I get the same memory address for <code>ptr</code>.  Why?</p>
","922184","","<p>I'd say it's mostly coincidence. As the memory allocator/OS can give you whatever address it wants.</p>

<p>The addresses you get are obviously not uniformly random (and is highly dependent on other OS factors), so it's often to get the same (virtual) address several times in the row.</p>

<p>So for example, on my machine: Window 7, compiled with VS2010, I get different addresses with different runs:</p>

<pre><code>00134C40
00124C40
00214C40
00034C40
00144C40
001B4C40
</code></pre>
"
"<p>My question here is pretty simple: I want to know if processors try to help exception handling somehow. Would it be possible to completely remove overhead from exception handling and throwing if enough effort is put in designing a processor ""exception-ready""?</p>

<p>Because as far as I know, all exception handling is done via software, and that always adds some overhead. Am I wrong?</p>

<p>-- edit</p>

<p>So, thanks for all the answers below. I appreciate. You have answered my question.</p>

<p>But just to clarify why I asked this: generally, people don't go too deep into optimizing exceptions because they all think ""exceptions are for exceptional circumstances"", and therefore they are no bottleneck.</p>

<p>I don't think exceptions should only be thrown under dramatic circumstances. What I think is, basically, that an exception should be thrown anytime a function cannot comply to what it promised to do.</p>

<p>If I say:</p>

<pre><code>doSomethingImportant();
</code></pre>

<p>And if for <em>whatever</em> reason ""something important"" can't be done, this should throw an exception.</p>

<p>Of course, doSomethingImportant() might not be able to comply because the system ran out of memory (a dramatic problem), but I think we should be able to model simpler ""I can't do that now/this time, sorry"" into our software, embedded into our designs. I'd like to say that I think exceptions can be exceptional, yes, but they <em>are to be expected</em> like normal software flow, not as a ""fatal error"" from which the system has to ""recover"", nomsain?</p>

<p>And while big applications backed by nice data centers will hardly ever bottleneck because of exception handling, please don't forget there's market for embedded devices where resources are counted, and exception handling <em>does</em> have an impact (which is what I'm aiming for).</p>

<p>I personally find exceptions quite expressive, and I'd like to use them in embedded devices with as much ""overhead"" as I would get by returning ""-1"" and checking that with an ""if"".</p>
","922184","","<p>There are generally two types of exception handling:</p>

<ol>
<li>The language exception. (the kind that you throw in C++/Java or any other language)</li>
<li>Hardware exceptions. (signals, seg-faults, misalignment, etc...)</li>
</ol>

<p>I'm assuming you're talking about the first one. As of right now, no I don't think any processor has such support. Although I'm not a hardware designer, here are my arguments for why this is the case, as well as why exception handling may never be implemented in hardware.</p>

<ol>
<li>Different languages have different exception handling protocols. C++ maybe different from Java, C#, etc... Stack unwinding and destructor calls will complicate this process.</li>
<li><strong>Is exception handling even a bottleneck?</strong> The majority of the highly-optimized HPC performance-critical applications don't use exception handling anyway. Most of the OOP-oriented code that relies on exception handling is typically bottlenecked by other factors. (such as branching, cache, memory, etc...)</li>
</ol>

<p>So adding hardware support for exception handling doesn't actually help the right user-base.</p>
"
"<p>In K&amp;R Section 5.10, in their sample implementation of a <code>grep</code>-like function, there are these lines:</p>

<pre><code>while (--argc &gt; 0 &amp;&amp; (*++argv)[0] == '-')
    while (c = *++argv[0])
</code></pre>

<p>Understanding the syntax there was one of the most challenging things for me, and even now a couple weeks after viewing it for the first time, I still have to think very slowly through the syntax to make sense of it.  I compiled the program with this alternate syntax, but I'm not sure that the second line is allowable.  I've just never seen <code>*</code>'s and <code>++</code>'s interleaved like this, but it makes sense to me, it compiles, and it runs.  It also requires no parentheses or brackets, which is maybe part of why it seems more clear to me.  I just read the operators in one direction only (right to left) rather than bouncing back and forth to either side of the variable name.</p>

<pre><code>while (--argc &gt; 0 &amp;&amp; **++argv == '-')
    while (c = *++*argv)
</code></pre>
","922184","","<p>Well for one, that's one way to make anyone reading your code to go <strong><em>huh?!?!?!</em></strong></p>

<p>So, from a readability standpoint, no, you probably shouldn't write code like that. </p>

<p>Nevertheless, it's valid code and breaks down as this:</p>

<pre><code>*(++(*p))
</code></pre>

<p>First, <code>p</code> is dereferenced. Then it is incremented. Then it is dereferenced again.</p>

<hr>

<p>To make thing worse, this line:</p>

<pre><code>while (c = *++*argv)
</code></pre>

<p>has an assignment in the loop-condition. So now you have <strong><em>two</em></strong> side-effects to make your reader's head spin. YAY!!!</p>
"
"<pre><code>long startTime = System.currentTimeMillis();
float resultTime= (System.currentTimeMillis() - startTime) / 1000;
System.out.println(""Result time : "" + resultTime);
</code></pre>

<p>The result is always a rounded value like <em>1.0</em> or <em>2.0</em>.
How can I obtain an exact result like <em>1.234</em>?</p>
","922184","","<p>You're doing integer division. (which rounds down to an integer)</p>

<p>Cast to <code>float</code> before you do the division:</p>

<pre><code>float resultTime= (float)(System.currentTimeMillis() - startTime) / 1000.0f;
</code></pre>
"
"<p>I have N numbers n_1, n_2, ...n_N and associated probabilities p_1, p_2, ..., p_N.
function should return number n_i with probability p_i, where i =1, ..., N.
How model it in c++?<br>
I know it is not a hard problem. But I am new to c++, want to know what function will you use. 
Will you generate uniform random number between 0 and 1 like this:  </p>

<pre><code>((double) rand() / (RAND_MAX+1))
</code></pre>
","922184","","<p>This is very similar to the answer I gave for this question:</p>

<p><a href=""http://stackoverflow.com/questions/8529665/changing-probability-of-getting-a-random-number"">changing probability of getting a random number</a></p>

<p>You can do it like this:</p>

<pre><code>double val = (double)rand() / RAND_MAX;

int random;
if (val &lt; p_1)
    random = n_1;
else if (val &lt; p_1 + p_2)
    random = n_2;
else if (val &lt; p_1 + p_2 + p_3)
    random = n_3;
else
    random = n_4;
</code></pre>

<p>Of course, this approach only makes sense if <code>p_1 + p_2 + p_3 + p_4 == 1.0</code>.</p>

<p>This can easily be generalized to a variable number of outputs and probabilities with a couple of arrays and a simple loop.</p>
"
"<p>I would like to generate uniform random numbers in C++ between 0 and 1, in a way which does not use the standard <code>rand()</code> and <code>srand(time(NULL))</code> method.  The reason for this is that if I run the application more than once within the same second of my clock, the seed will be exactly the same and produce the same output.</p>

<p>I do not want to rely on boost or OS/compiler specifics.  x86 can be assumed.</p>

<p>It seems as though an alternate way to do this is to use TR1 (I do not have C++11) and seeding with <code>/dev/random</code> in some way?</p>

<p>Right now I have this, but it still uses <code>time(NULL)</code> as a seed which will not work well within 1 second runs:</p>

<pre><code>#include &lt;iostream&gt; 
#include &lt;tr1/random&gt; 

int main() 
{ 
  std::tr1::mt19937 eng; 
  eng.seed(time(NULL)); 
  std::tr1::uniform_int&lt;int&gt; unif(1, RAND_MAX); 
  int u = unif(eng); 
  std::cout &lt;&lt; (float)u/RAND_MAX &lt;&lt; std::endl; 
} 
</code></pre>
","922184","","<p>Posting at request of the OP:</p>

<p>This is still somewhat compiler-specific, but will still work on nearly all x86-targeting compilers:</p>

<pre><code>#ifdef _WIN32

//  Windows
#define rdtsc  __rdtsc

#else

//  For everything else
unsigned long long rdtsc(){
    unsigned int lo,hi;
    __asm__ __volatile__ (""rdtsc"" : ""=a"" (lo), ""=d"" (hi));
    return ((unsigned long long)hi &lt;&lt; 32) | lo;
}

#endif

int main() 
{ 
  std::tr1::mt19937 eng; 
  eng.seed( rdtsc() );    //  Seed with rdtsc.
  std::tr1::uniform_int&lt;int&gt; unif(1, RAND_MAX); 
  int u = unif(eng); 
  std::cout &lt;&lt; (float)u/RAND_MAX &lt;&lt; std::endl; 
} 
</code></pre>

<p>The idea here is to seed your random number generator with the <code>rdtsc</code> cycle-counter.</p>

<p>The reason why this works is because the <code>rdtsc</code> cycle-counter iterates at about (often the same) speed as the CPU frequency. Therefore, the chances of two calls to it returning the same value are extremely slim - thereby, making it an excellent seed for a RNG.</p>
"
"<p>If multiplication is slower than addition instead of doing</p>

<pre><code>7 * 8
</code></pre>

<p>Will this theoretically improve performance ?</p>

<pre><code>for(int i =0; i &lt; 8 ; i++){
temp += 7
}
</code></pre>

<p>Or else do i just need to do</p>

<pre><code>7 + 7 + 7 + 7 + 7 + 7 + 7 + 7
</code></pre>
","922184","","<p>Have you tried it and timed it?</p>

<p>On nearly every single modern machine today, there is fast hardware support for multiplication. So unless it's simple multiplication by 2, <strong>no, it will not be faster</strong>.</p>

<p>To give some hard numbers on the current Intel machines:</p>

<pre><code>add/sub   1 cycle latency
mul/imul  3 cycle latency
</code></pre>

<p>Taken from <a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">Agner Fog's manuals</a>.</p>

<p>Although it's actually a lot more complicated than this, the point is still: <em>No, you're not going to get any benefit trying to replace multiplications with additions.</em></p>

<p>In the few cases where it <em>is</em> better (such as multiplication by a power of two - using shifts), the compiler will make that optimization for you, if it knows the value at compile-time.</p>

<p>On x86, the compiler can also play with the <code>lea</code> instruction to do fast multiplication by 3, 5, 10, etc...</p>
"
"<p>I'm wondering if it is feasible to make this loop parallel using openMP.</p>

<p>Of coarse there is the issue with the race conditions.  I'm unsure how to deal with the n in the inner loop being generated by the outerloop, and the race condition with where D=A[n].  Do you think it is practical to try and make this parallel?</p>

<pre><code>for(n=0; n &lt; 10000000; ++n) {   

    for (n2=0; n2&lt; 100; ++n2) {
        A[n]=A[n]+B[n2][n+C[n2]+200];

        }

    D=D+A[n];

}
</code></pre>
","922184","","<p>Yes, this is indeed parallelizable assuming none of the pointers are aliased.</p>

<pre><code>int D = 0;  //  Or whatever the type is.

#pragma omp parallel for reduction(+:D) private(n2)
for (n=0; n &lt; 10000000; ++n) {   

    for (n2 = 0; n2 &lt; 100; ++n2) {
        A[n] = A[n] + B[n2][n + C[n2] + 200];
    }

    D += A[n];
}
</code></pre>

<p>It could actually be optimized somewhat as follows:</p>

<pre><code>int D = 0;  //  Or whatever the type is.

#pragma omp parallel for reduction(+:D) private(n2)
for (n=0; n &lt; 10000000; ++n) {   

    int tmp = A[n]
    for (n2 = 0; n2 &lt; 100; ++n2) {
        tmp += B[n2][n + C[n2] + 200];
    }

    A[n] = tmp;
    D += tmp;
}
</code></pre>
"
"<p>I was reading <a href=""http://stackoverflow.com/questions/8635686/swap-three-numbers-in-single-statement"">this</a> question and then I made the following.</p>

<pre><code>a = b + (c - (b = c)) + (a - (c = a))
</code></pre>

<p>I tried that in C and Java. It works with java , but not C.</p>

<p>Of course, it depends on how the compiler evaluate such expressions and after googling about that, I failed to find the answer.</p>
","922184","","<p>The reason why it doesn't work in C is because C doesn't specify exactly when the <code>c = a</code> will occur. It can occur before or after the two other times it is referenced in that statement.</p>

<p>So depending on when the compiler decides to perform the assignment <code>c = a</code>, the value of the expression will vary. It's not defined.</p>

<p>i.e. If <code>b = c</code>  is evaluated before <code>c = a</code> then, <code>b</code> will take the original value of <code>c</code>. If it is evaluated after, then it will take the value of <code>a</code>.</p>
"
"<p>Seemingly trivial problem in assembly: I want to copy the whole XMM0 register to XMM3. I've tried</p>

<pre><code>movdq xmm3, xmm0
</code></pre>

<p>but MOVDQ cannot be used to move values between two XMM registers. What should I do instead?</p>
","922184","","<p>It's <code>movapd</code>, <code>movaps</code>, or <code>movdqa</code></p>

<pre><code>movaps xmm3, xmm0
</code></pre>

<p>They all do the same thing, but there's a catch:</p>

<ul>
<li><code>movapd</code> and <code>movaps</code> operate in the floating-point domain.</li>
<li><code>movdqa</code> operates in the integer domain</li>
</ul>

<p>Use the appropriate one according to your datatype to avoid domain-changing stalls.</p>

<p>Also, there's no reason to use <code>movapd</code>. Always use <code>movaps</code> instead because <code>movapd</code> takes an extra byte to encode.</p>
"
"<p>OK, so say I have a signed char with value -103:</p>

<pre><code>char s_char = -103;
</code></pre>

<p>How does the computer store this char in bits? Is the first bit 0 because the char is negative? If so, would the computer store the char as 01100101, because 1100101 (base 2) in base 10 is 103?</p>

<p>And a second question: how can I access or test a single bit in the signed char? Would</p>

<pre><code>s_char &amp; (0x80 &gt;&gt; pos)
</code></pre>

<p>give me the value of the bit at position pos counting from the left?</p>
","922184","","<p><code>char</code> is just an integer. 8-bit integers in most cases. So <code>-103</code> is just:</p>

<pre><code>10011001
</code></pre>

<p>To access a single bit in a <code>char</code>, you can do it the same way as any other integer:</p>

<pre><code>char s_char = -103;

s_char &amp; (1 &lt;&lt; n)
</code></pre>

<p>will get you the nth bit from the bottom.</p>
"
"<p>I'm keen to know exactly how the classes will be arranged in memory esp. with inheritance and virtual functions. </p>

<p>I know that this is not defined by the c++ language standard. However, is there any easy way to find out how your specific compiler will implement these say by writing some test code? </p>

<p>EDIT:- Using some of the answers below :- </p>

<pre><code>#include &lt;iostream&gt;

using namespace std;

class A {
  public:
    int a;
    virtual void func() {}
};

class B : public A {
  public:
    int b;
    virtual void func() {}
};

class C {
  public:
    int c;
    virtual void func() {}
};

class D : public A, public C {
  public:
    int d;
    virtual void func() {}
};

class E : public C, public A {
  public:
    int e;
    virtual void func() {}
};

class F : public A {
  public:
    int f;
    virtual void func() {}
};

class G : public B, public F {
  public:
    int g;
    virtual void func() {}
};

int main() {
  A a; B b; C c; D d; E e; F f; G g;
  cout&lt;&lt;""A: ""&lt;&lt;(size_t)&amp;a.a-(size_t)&amp;a&lt;&lt;""\n"";
  cout&lt;&lt;""B: ""&lt;&lt;(size_t)&amp;b.a-(size_t)&amp;b&lt;&lt;"" ""&lt;&lt;(size_t)&amp;b.b-(size_t)&amp;b&lt;&lt;""\n"";
  cout&lt;&lt;""C: ""&lt;&lt;(size_t)&amp;c.c-(size_t)&amp;c&lt;&lt;""\n"";
  cout&lt;&lt;""D: ""&lt;&lt;(size_t)&amp;d.a-(size_t)&amp;d&lt;&lt;"" ""&lt;&lt;(size_t)&amp;d.c-(size_t)&amp;d&lt;&lt;"" ""&lt;&lt;(size_t)&amp;d.d-    (size_t)&amp;d&lt;&lt;""\n"";
  cout&lt;&lt;""E: ""&lt;&lt;(size_t)&amp;e.a-(size_t)&amp;e&lt;&lt;"" ""&lt;&lt;(size_t)&amp;e.c-(size_t)&amp;e&lt;&lt;"" ""&lt;&lt;(size_t)&amp;e.e-    (size_t)&amp;e&lt;&lt;""\n"";
  cout&lt;&lt;""F: ""&lt;&lt;(size_t)&amp;f.a-(size_t)&amp;f&lt;&lt;"" ""&lt;&lt;(size_t)&amp;f.f-(size_t)&amp;f&lt;&lt;""\n"";
  cout&lt;&lt;""G: ""&lt;&lt;(size_t)&amp;g.B::a-(size_t)&amp;g&lt;&lt;"" ""&lt;&lt;(size_t)&amp;g.F::a-(size_t)&amp;g&lt;&lt;"" ""    &lt;&lt;(size_t)&amp;g.b-(size_t)&amp;g&lt;&lt;"" ""&lt;&lt;(size_t)&amp;g.f-(size_t)&amp;g&lt;&lt;"" ""&lt;&lt;(size_t)&amp;g.g-(size_t)&amp;g&lt;&lt;""\n"";
}
</code></pre>

<p>And the output is :- </p>

<pre><code>A: 8
B: 8 12
C: 8
D: 8 24 28
E: 24 8 28
F: 8 12
G: 8 24 12 28 32
</code></pre>

<p>So all classes have got a v-ptr at loc 0 of size 8. 
D has another v-ptr at location 16. Similarly for E. 
G also seems to have a v-ptr at 16 although from my (limited) understanding I would have guessed it to have more. </p>
","922184","","<p>One way is to print out the offsets of all the members:</p>

<pre><code>class Parent{
public:
    int a;
    int b;

    virtual void foo(){
        cout &lt;&lt; ""parent"" &lt;&lt; endl;
    }
};

class Child : public Parent{
public:
    int c;
    int d;

    virtual void foo(){
        cout &lt;&lt; ""child"" &lt;&lt; endl;
    }
};

int main(){

    Parent p;
    Child c;

    p.foo();
    c.foo();

    cout &lt;&lt; ""Parent Offset a = "" &lt;&lt; (size_t)&amp;p.a - (size_t)&amp;p &lt;&lt; endl;
    cout &lt;&lt; ""Parent Offset b = "" &lt;&lt; (size_t)&amp;p.b - (size_t)&amp;p &lt;&lt; endl;

    cout &lt;&lt; ""Child Offset a = "" &lt;&lt; (size_t)&amp;c.a - (size_t)&amp;c &lt;&lt; endl;
    cout &lt;&lt; ""Child Offset b = "" &lt;&lt; (size_t)&amp;c.b - (size_t)&amp;c &lt;&lt; endl;
    cout &lt;&lt; ""Child Offset c = "" &lt;&lt; (size_t)&amp;c.c - (size_t)&amp;c &lt;&lt; endl;
    cout &lt;&lt; ""Child Offset d = "" &lt;&lt; (size_t)&amp;c.d - (size_t)&amp;c &lt;&lt; endl;

    system(""pause"");
}
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>parent
child
Parent Offset a = 8
Parent Offset b = 12
Child Offset a = 8
Child Offset b = 12
Child Offset c = 16
Child Offset d = 20
</code></pre>

<p>So you can see all the offsets here. You'll notice that there's nothing at offset 0, as that is presumably where the pointer to the <a href=""http://en.wikipedia.org/wiki/Virtual_method_table"" rel=""nofollow"">vtable</a> goes.</p>

<p>Also notice that the inherited members have the same offsets in both Child and Parent.</p>
"
"<p>Being executed on modern processor (AMD Phenom II 1090T), how many clock ticks does the following code consume more likely : 3 or 11?  </p>

<pre><code>label:  mov (%rsi), %rax
        adc %rax, (%rdx)
        lea 8(%rdx), %rdx
        lea 8(%rsi), %rsi
        dec %ecx
        jnz label
</code></pre>

<p>The problem is, when I execute many iterations of such code, results vary near 3 OR 11 ticks per iteration from time to time. And I can't decide ""who is who"".</p>

<p><strong>UPD</strong>
According to <a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">Table of instruction latencies (PDF)</a>, my piece of code takes at least 10 clock cycles on AMD K10 microarchitecture. Therefore, impossible 3 ticks per iteration are caused by bugs in measurement.</p>

<p><strong>SOLVED</strong>
@Atom noticed, that cycle frequency isn't constant in <em>modern processors</em>. When I disabled in BIOS three options - <code>Core Performance Boost</code>, <code>AMD C1E Support</code> and <code>AMD K8 Cool&amp;Quiet Control</code>, consumption of my ""six instructions"" stabilized on <strong>3 clock ticks</strong> :-)</p>
","922184","","<p>I won't try to answer with certainty how many cycles (3 or 10) it will take to run each iteration, but I'll explain how it <em>might</em> be possible to get 3 cycles per iteration. </p>

<p>(Note that this is for processors in general and I make no references specific to AMD processors.)</p>

<p>Key Concepts:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Out-of-order_execution"">Out of Order Execution</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Register_renaming"">Register Renaming</a></li>
</ul>

<p>Most modern (non-embedded) processors today are both super-scalar and out-of-order. Not only can execute multiple (independent) instructions in parallel, but they can re-order instructions to break dependencies and such.</p>

<p>Let's break down your example:</p>

<pre><code>label:
    mov (%rsi), %rax
    adc %rax, (%rdx)
    lea 8(%rdx), %rdx
    lea 8(%rsi), %rsi
    dec %ecx
    jnz label
</code></pre>

<p>The first thing to notice is that the last 3 instructions before the branch are all independent:</p>

<pre><code>    lea 8(%rdx), %rdx
    lea 8(%rsi), %rsi
    dec %ecx
</code></pre>

<p>So it's possible for a processor to execute all 3 of these in parallel.</p>

<p>Another thing is this:</p>

<pre><code>adc %rax, (%rdx)
lea 8(%rdx), %rdx
</code></pre>

<p>There seems to be a dependency on <code>rdx</code> that prevents the two from running in parallel. But in reality, this is <em>false dependency</em> because the second instruction doesn't actually 
depend on the output of the first instruction. Modern processors are able to rename the <code>rdx</code> register to allow these two instructions to be re-ordered or done in parallel.</p>

<p>Same applies to the <code>rsi</code> register between:</p>

<pre><code>mov (%rsi), %rax
lea 8(%rsi), %rsi
</code></pre>

<hr>

<p>So in the end, 3 cycles is (potentially) achievable as follows (this is just one of several possible orderings):</p>

<pre><code>1:   mov (%rsi), %rax        lea 8(%rdx), %rdx        lea 8(%rsi), %rsi
2:   adc %rax, (%rdx)        dec %ecx
3:   jnz label
</code></pre>

<p>*Of course, I'm over-simplifying things for simplicity. In reality the latencies are probably longer and there's overlap between different iterations of the loop.</p>

<p>In any case, this could explain how it's possible to get 3 cycles. As for why you sometimes get 10 cycles, there could be a ton of reasons for that: branch misprediction, some random pipeline bubble...</p>
"
"<p>I have a system where I specify on the command line the verbosity level. In my functions I check against what was specified to determine if I enter a code block or not: </p>

<pre><code>#ifdef DEBUG
if (verbose_get_bit(verbose_level_1)) {
    // arbitrary debugging/printing style code generally goes in here, e.g.:
    printf(""I am printing this because it was specified and I am compiling debug build\n"");
}
#endif
</code></pre>

<p>I'd like to make this less tedious to set up, so here's what I have so far: </p>

<pre><code>// from ""Verbose.h""
bool verbose_get_bit(verbose_group_name name); // verbose_group_name is an enum
#ifdef DEBUG
#define IF_VERBOSE_BIT_D(x) if (verbose_get_bit(x))
#else // not debug: desired behavior is the entire block that follows gets optimized out
#define IF_VERBOSE_BIT_D(x) if (0)
#endif // not debug
</code></pre>

<p>Now, I can do this: </p>

<pre><code>IF_VERBOSE_BIT_D(verbose_GL_debug) {
    printf(""I don't want the release build to execute any of this code"");
    glBegin(GL_LINES);
    // ... and so on
}
</code></pre>

<p>I like this because it looks like an if-statement, it functions as an if-statement, it's clear that it's a macro, and it does not get run in the release build. </p>

<p>I'd be reasonably sure that the code will get optimized out since it will be wrapped in a <code>if(false)</code> block but I would prefer it if there was some way I can get the preprocessor to actually throw the entire block away. Can it be done?</p>
","922184","","<p>I can't think of a way to do it without wrapping the entire block in a macro.</p>

<p>But this might work for your purposes:</p>

<pre><code>#if DEBUG
#define IF_VERBOSE_BIT_D(x) {x}
#else
#define IF_VERBOSE_BIT_D(x)
#endif

IF_VERBOSE_BIT_D(
    cout &lt;&lt; ""this is"" &lt;&lt; endl;
    cout &lt;&lt; ""in verbose"" &lt;&lt; endl;
    printf(""Code = %d\n"", 1);
)
</code></pre>

<p>Indeed the compiler should be able to optimize out an <code>if (0)</code>, but I often do something similar to this when the code inside the block will not compile at all when not in debug mode.</p>
"
"<p>I found a question somewhere ... here it is and its answer with explanation.</p>

<pre><code>main()
{
char *p=""hai friends"",*p1;
p1=p;
while(*p!='\0') ++*p++;
printf(""%s   %s"",p,p1);
}

 Answer:
 ibj!gsjfoet

 Explanation:
++*p++ will be parse in the given order
</code></pre>

<p>*p that is value at the location currently pointed by p will be taken </p>

<p>++*p the retrieved value will be incremented </p>

<p>when ; is encountered the location will be incremented that is p++ will be executed</p>

<p>Hence, in the while loop initial value pointed by p is ‘h’, which is changed to ‘i’ by executing ++*p and pointer moves to point, ‘a’ which is similarly changed to ‘b’ and so on. Similarly blank space is converted to ‘!’. Thus, we obtain value in p becomes “ibj!gsjfoet” and since p reaches ‘\0’ and p1 points to p thus p1 doesnot print anything.</p>

<p>I found something wrong with explanation on p1.I think p1 should print ""hai friends"" and output of p is fine as given.</p>

<p>but when I tried to run the same code on gcc compiler,its giving <strong>segmentatiion fault</strong></p>

<p>here is the exact code which I tried to run ..</p>

<pre><code> #include&lt;stdio.h&gt;
 int main()
 {
 char *p=""hai friends"",*p1;
 p1=p;
 while(*p !='\0') ++*p++;
 printf(""%s   %s"",p,p1);
 return 0;
 }
</code></pre>

<p>If possible edit the title ,I could not find a suitable title which would explain the situation more clearly.</p>

<p><strong>EDIT :</strong></p>

<p>I tried to run the modified code as suggested by <strong>Mysticial</strong> ,But what I think output should be -</p>

<pre><code>ibj!gsjfoet    hai friends
</code></pre>

<p>because I am incrementing only p0 but p1 should be as its initial place i.e. at the starting address of string.Please if anyone could explain it where I am getting it wrong ???</p>
","922184","","<p>Well for one, code like this: <code>++*p++</code> should be avoided because it's generally hard to read.</p>

<p>Secondly, the problem is that you are <strong><em>modifying a string literal</em></strong>. That's undefined behavior. Don't do it.</p>

<p>Instead, change your declaration to this:</p>

<pre><code>char p[] = ""hai friends"";
char *p1;
</code></pre>

<p>and modify you code as such:</p>

<pre><code>int main()
{

    char p[] = ""hai friends"";
    char *p0,*p1;
    p0 = p;
    p1 = p;
    while(*p0 !='\0') ++*p0++;
    printf(""%s   %s"",p0,p1);
    return 0;

}
</code></pre>
"
"<p>I know you can just do: <code>&amp;theVector[0]</code>, but is this standard? Is this behavior <em>always</em> guaranteed?</p>

<p>If not, is there a better, less 'hackish' way to do this?</p>
","922184","","<p>Yes, that behavior is guaranteed. Although I can't quote it, the standard guarantees that vector elements are stored consecutively in memory to allow this.</p>

<p><strong>There is one exception though:</strong></p>

<p>It will not work for <code>vector&lt;bool&gt;</code> because of a template specialization.</p>

<p><a href=""http://en.wikipedia.org/wiki/Sequence_container_%28C%2B%2B%29#Specialization_for_bool"">http://en.wikipedia.org/wiki/Sequence_container_%28C%2B%2B%29#Specialization_for_bool</a></p>

<p>This specialization attempts to save memory by packing <code>bools</code> together in a bit-field. However, it breaks some semantics and as such, <code>&amp;theVector[0]</code> on a <code>vector&lt;bool&gt;</code> will not work.</p>

<p>In any case, <code>vector&lt;bool&gt;</code> is widely <a href=""http://stackoverflow.com/questions/670308/alternative-to-vectorbool"">considered to be a mistake</a> so the alternative is to use <code>std::deque&lt;bool&gt;</code> instead.</p>
"
"<p>I want to do this:</p>

<pre><code>omp_set_nested(1);
#pragma omp parallel for private(j)
for (i = 0; i &lt; n; ++i) {
    #pragma omp parallel for
    for (j = 0; j &lt; m; ++j) {
    /* do smth */
    }
}
</code></pre>

<p>It means, if I have 8 threads, and first loop uses only 4 threads, I want internal loop to use other 4 threads too. How can I do this?</p>
","922184","","<p>You can specify the number of threads that you want in a region.</p>

<p>So if you did this:</p>

<pre><code>omp_set_nested(1);
#pragma omp parallel for private(j) num_threads(2)
for (i = 0; i &lt; n; ++i) {
    #pragma omp parallel for num_threads(4)
    for (j = 0; j &lt; m; ++j) {
        /* do smth */
    }
}
</code></pre>

<p>Then the outer-loop will have 2 threads. And then each of those 2 threads will spawn 4 threads for the inner loop. (for a total of 8)</p>

<p>Your description is somewhat confusing since you want each loop to use 4 threads. Don't forget that it's nested, so they multiply.</p>
"
"<p>Can anyone tell me what's wrong with this code? I'm getting a seg fault. I'm trying to read just the first line of a file into a newly-created file.</p>

<pre><code>char *buffer;

int main(int argc, char *argv[])
{
  FILE *source = fopen(argv[0], ""r"");
  FILE *destination = fopen(""destination"", ""w"");

  fgets(buffer, 500, source);
  fwrite(buffer, 1, sizeof(buffer), destination);

}
</code></pre>
","922184","","<p>You haven't allocated anything for <code>buffer</code>.</p>

<p>Change:</p>

<pre><code>char *buffer;
</code></pre>

<p>to</p>

<pre><code>char buffer[500];
</code></pre>

<p>As your code is right now, <code>buffer</code> is just an uninitialized pointer. Attempting to dereference it will cause undefined behavior. (and seg-fault in your case)</p>

<hr>

<p>Alternatively, you can dynamically allocate memory for <code>buffer</code>:</p>

<pre><code>buffer = (char*)malloc(500 * sizeof(char));
</code></pre>

<p>but you should remember to free the memory later on:</p>

<pre><code>free(buffer);
</code></pre>

<p>If you go with this latter method, the code will look like this:</p>

<pre><code>char *buffer;

int main(int argc, char *argv[])
{
  FILE *source = fopen(argv[0], ""r"");
  FILE *destination = fopen(""destination"", ""w"");

  //  Allocate
  buffer = (char*)malloc(500 * sizeof(char));

  fgets(buffer, 500, source);
  fwrite(buffer, 1, 500 * sizeof(char), destination); //  Fixed here

  //  Free memory
  free(buffer);

  //  Don't forget return value
  return 0;
}
</code></pre>
"
"<p>I'm new to C++. Only been programming for 2 days so this will probably look messy. The purpose of the program is that you enter a word, and then the program randomizes the placement of the letters in the word.</p>

<p>I have three questions.</p>

<ol>
<li>Why, if the same string is entered twice, will the same ""random"" numbers be output?</li>
<li>How can I make sure no random number is picked twice. I already tried an IF statement nested inside the FOR statement but it just made things worse.</li>
<li>What will make this work?</li>
</ol>

<p>The code:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;string&gt;
#include &lt;cstdlib&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

using namespace std;

int main () {
    cout &lt;&lt; ""Enter word to be randomized: "";
    char rstring[30]; 
    char rstring2[30]; 
    cin &gt;&gt; rstring;
    strcpy(rstring2, rstring);
    int length;
    length = strlen(rstring);

    int max=length;
    int min=0;
    int randint;

    for (int rdm=0; rdm&lt;length; rdm++) {
        randint=rand()%(max-min)+min;
        cout &lt;&lt; rstring[rdm]; //This is temporary. Just a visualization of what I'm doing.
        cout &lt;&lt; randint &lt;&lt; endl; //Temporary as well.
        rstring2[randint]=rstring[rdm];
    }

    cout &lt;&lt; endl &lt;&lt; rstring2 &lt;&lt; endl;
    return 0;
}
</code></pre>

<p>If you compile and run this you will notice that the same random numbers are output for the same text. Like ""hello"" outputs 24330. Why is this random generator generating nonrandom numbers?</p>
","922184","","<p>You need to <a href=""http://www.cplusplus.com/reference/clibrary/cstdlib/srand/"">seed your random number generator</a> to get different results with each run. Otherwise, (as you have noticed) you will get the same random numbers with each run.</p>

<p>Put this at the start of the program:</p>

<pre><code>srand(time(NULL));
</code></pre>

<p>This will seed the random number generator with time - which will likely be different between runs.</p>

<p>Note that you'll also need <code>#include &lt;time.h&gt;</code> to access the <code>time()</code> function.</p>
"
"<p>I just started learning C and copied this directly from a book. Can someone tell me why this doesn't work?</p>

<pre><code>#include &lt;stdio.h&gt;

int main (void)
{
    int     integerVar = 100;
    float   floatingVar = 331.79;
    double  doubleVar = 8.44e+11;
    char    charVar = ""W"";

    _Bool   boolVar = 0;

    printf (""integerVar = %i\n"", integerVar);
    printf (""floatingVar = %f\n"", floatingVar);
    printf (""doubleVar = %e\n"", doubleVar);
    printf (""doubleVar = %g\n"", doubleVar);
    printf (""charVar = %c\n"", charVar);

    printf (""boolVar = %i\n"", boolVar);

    return 0;
}
</code></pre>

<p>I get this error:</p>

<pre><code>datatypes.c: In function ‘main’:
datatypes.c:8: warning: initialization makes integer from pointer without a cast
</code></pre>
","922184","","<p>The problem here:</p>

<pre><code>char    charVar = ""W"";
</code></pre>

<p>you probably meant:</p>

<pre><code>char    charVar = 'W';
</code></pre>

<p><code>""W""</code> is a string. <code>'W'</code> is a char. The latter is what you want.</p>
"
"<p>On my platform, <code>unsigned long long</code> is 64 bits (8 bytes). Suppose I have two such variables:</p>

<pre><code>unsigned long long partialSize;
unsigned long long totalSize;
//somehow determine partialSize and totalSize
</code></pre>

<p>How can I reliably determine how many percentages (rounded to a nearby integer) <code>partialSize</code> is of <code>totalSize</code>? (If possible, it would be nice if I wouldn’t have to assume that the former is less than the latter, but if I really have to make this assumption, it’s fine. But we can, of course, assume that both are non-negative.)</p>

<p>For example, is the following code completely bulletproof? My fear is that it contains some kind of rounding, casting, or conversion errors that could cause the ratio to go out of whack under some conditions.</p>

<pre><code>unsigned long long ratioPercentage
    = (unsigned long long)( ((double)partialSize)/((double)totalSize) * 100.0 );
</code></pre>
","922184","","<p>Note that your formula isn't correct as it omits the <code>+0.5</code> needed to get round-to-nearest.</p>

<p>So I'll proceed assuming this corrected formula:</p>

<pre><code>(unsigned long long)( ((double)partialSize)/((double)totalSize) * 100.0 + 0.5);
</code></pre>

<p>As I've mentioned in the comments, the straight-forward method, although simple, is not guaranteed to correctly rounded results. So your intuition is right in that it is not bullet-proof.</p>

<p>In the vast majority of cases, it will still be correct, but there will be a small set of borderline cases where it won't be correctly rounded. Whether or not those matter is up to you. But the straight-forward method is usually sufficient for most purposes.</p>

<p><strong>Why it may fail:</strong></p>

<p>There are 4 levels of rounding. (corrected from the 2 that I mentioned in the comments)</p>

<ol>
<li>The casts 64-bits -> 53-bits</li>
<li>The division</li>
<li>The multiply by 100.</li>
<li>The final cast.</li>
</ol>

<p>Whenever you have multiple sources of rounding, you suffer from the usual sources of floating-point error.</p>

<p><strong>Counter Examples:</strong></p>

<p>Although rare, I'll list a few examples where the straight-forward formula will give an incorrectly rounded result:</p>

<pre><code> 850536266682995018 /  3335436339933313800  //  Correct: 25%  Formula: 26%
3552239702028979196 / 10006309019799941400  //  Correct: 35%  Formula: 36%
1680850982666015624 /  2384185791015625000  //  Correct: 70%  Formula: 71%
</code></pre>

<p><strong>Solution:</strong></p>

<p>I can't think of a clean 100% bullet-proof solution to this other than to use <a href=""http://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic"" rel=""nofollow"">arbitrary precision arithmetic</a>.</p>

<p><em><strong>But in the end, do you really need it to always be perfectly rounded?</em></strong></p>

<hr>

<p><strong>EDIT :</strong></p>

<p>For smaller numbers, here's a very simple solution that rounds up on <code>0.5</code>:</p>

<pre><code>return (x * 100 + y/2) / y;
</code></pre>

<p>This will work as long as <code>x * 100 + y/2</code> doesn't overflow.</p>

<p>@Daniel Fischer answer has a more comprehensive solution for the other rounding behaviors. Though it shouldn't be too hard to modify this one to get round-to-even.</p>
"
"<p>I was playing with the <code>time.h</code> file in C that helps us with time/day functions.</p>

<p>I came across:</p>

<pre><code>struct tm * _Cdecl localtime(const time_t *__timer);
</code></pre>

<p>...which seems to return a pointer to tm struct. I have found that return by address is mostly used to return new memory allocations.</p>

<p>If this is so, how does the above return actually work (the return address of a <code>struct tm</code>). Is the returned object defined somewhere?</p>

<p>Thanks</p>
","922184","","<p>The pointer returned by <code>localtime</code> (and some other functions) are actually pointers to statically allocated memory. <strong>So you do not need to freed. Furthermore, you should not free it.</strong></p>

<p><a href=""http://www.cplusplus.com/reference/clibrary/ctime/localtime/"">http://www.cplusplus.com/reference/clibrary/ctime/localtime/</a></p>

<blockquote>
  <p>This structure is statically allocated and shared by the functions
  gmtime and localtime. Each time either one of these functions is
  called the content of this structure is overwritten.</p>
</blockquote>

<p><strong>EDIT :</strong> Appending a few things mentioned in the comments.</p>

<p>A direct result of this shared data-structure is that <code>localtime</code> and similar functions are not thread-safe. The thread-safe solution varies with different platforms. <a href=""http://linux.die.net/man/3/localtime_r""><code>localtime_r</code> for POSIX</a> and <a href=""http://msdn.microsoft.com/en-us/library/a442x3ye%28v=vs.80%29.aspx""><code>localtime_s</code> for MSVC</a>.</p>
"
"<p>But the thing is, there are exactly the amount of initializers in the char array that I declared.</p>

<pre><code>char dash[9][9]={
        {""1"",""2"",""3"",""4"",""5"",""6"",""7"",""8"",""9""},
        {""a"",""b"",""c"",""d"",""e"",""f"",""g"",""h"",""i""},
        {""q"",""w"",""e"",""r"",""t"",""y"",""u"",""i"",""o""},
        {""9"",""8"",""7"",""6"",""5"",""4"",""3"",""2"",""1""},
        {""i"",""h"",""g"",""f"",""e"",""d"",""c"",""b"",""a""},
        {""o"",""i"",""u"",""y"",""t"",""r"",""e"",""w"",""q""},
        {""z"",""x"",""y"",""w"",""v"",""u"",""t"",""s"",""r""},
        {""a"",""l"",""l"",""s"",""t"",""a"",""r"",""p"",""y""},
        {""m"",""o"",""n"",""d"",""o"",""l"",""o"",""r"",""i""}
    };
</code></pre>

<p>There are nine rows of nine columns. What's my problem? I checked other forums and this one for answers but found nothing that helped.</p>
","922184","","<p>You need to change all your double-quotes <code>""""</code> to single quotes <code>''</code>.</p>

<p>Otherwise, they are strings instead of <code>char</code>s.</p>

<p>In this case, a simple find-and-replace should do the trick.</p>
"
"<p>The program is very simple , it gives the greatest common divisor as the output.I have verified my algorithm.The compiler issues no error ,but still it wont produce any output.                                                                  </p>

<pre><code>#include&lt;conio.h&gt;
#include &lt;stdio.h&gt;
int gcd(int ,int );
int main()
{
    int a,b,j;
    printf(""enter two numbers"");
    scanf(""%d\n"",&amp;a);
    scanf(""%d\n"",&amp;b);
    j=gcd(a,b);
    printf(""gcd is %d"",j);
    getch();
    return 0;
}
int gcd(int x, int y)
{
    int temp,c;
    if(x&lt;y)
    {
           temp=x;
           x=y;
           y=temp;
           }
    if(y&lt;=x&amp;&amp;(x%y==0))
    return y;
    else
    {   temp=x%y;
        c=gcd(y,temp);
        return c;

        }
}
</code></pre>
","922184","","<p>This could be due to buffering of the output. Add <code>\n</code> to your <code>printfs</code> and see if it fixes it:</p>

<pre><code>printf(""enter two numbers\n"");
printf(""gcd is %d\n"",j);
</code></pre>

<p>Alternatively, you can add calls to <code>fflush(stdout)</code> to flush the output buffer:</p>

<pre><code>printf(""enter two numbers"");
fflush(stdout);

printf(""gcd is %d"",j);
fflush(stdout);
</code></pre>

<hr>

<p>Other than that, it (almost) works as intended on my setup:</p>

<pre><code>enter two numbers
4783780
354340
1
gcd is 20
</code></pre>

<p>The only thing is that the <code>\n</code> forces it to read an extra character. (which I chose to be <code>1</code>)</p>
"
"<p>GCC keeps telling me: </p>

<blockquote>
  <p>expected ‘)’ before ‘;’ token,<br>
  expected primary-expression before ‘)’ token<br>
  expected ‘;’ before ‘)’ token</p>
</blockquote>

<p>And I could not find the problem. Here is the function that have the problem:</p>

<pre><code>void prim(){
    prepararEstructuras();
    int min,k;  
    for(int i=1;i&lt;nnodos;i++){
        min = menorCoste[1];
        k = 1;
        for(int j=2;i&lt;nnodos;j++)
            if(menorCoste[j] &lt; min){
                min = menorCoste[j];
                k = j;
            }
        solucion[k][masCercano[k]] = G[k][masCercano[k]];
        menorCoste[k] = infinito;
        for(int j=1;j&lt;nnodos;j++)
            if(G[k][j] &lt; menorCoste[j] &amp;&amp; menorCoste[j]!=infinito){
                menorCoste[j] = G[k][j];
                masCercano[j] = k;
            }                   
    }
}
</code></pre>

<p>Here is the line that cause the problem:</p>

<pre><code>if(G[k][j] &lt; menorCoste[j] &amp;&amp; menorCoste[j]!=infinito){
</code></pre>

<p>And here are my variables:</p>

<pre><code>#define MAX_NODOS 20000
#define infinito 10000;

int nnodos;
int nAristas;
int G[MAX_NODOS][MAX_NODOS]; 
int solucion[MAX_NODOS][MAX_NODOS];
int menorCoste[MAX_NODOS];
int masCercano[MAX_NODOS];
</code></pre>
","922184","","<p>You have an extra semicolon in your macro.</p>

<pre><code>#define infinito 10000;
                      ^
</code></pre>

<p>Get rid of it.</p>

<p>As it is, your line gets expanded to this:</p>

<pre><code>if(G[k][j] &lt; menorCoste[j] &amp;&amp; menorCoste[j]!=10000;){
                                                  ^ does not belong here
</code></pre>

<p>Alternatively, don't use macros at all:</p>

<pre><code>const int MAX_NODOS = 20000;
const int infinito = 10000;
</code></pre>
"
"<p>I have a process that get killed immediately after executing the program. This is the code of the compiled executable, and it is a small program that reads several graphs represented by numbers from standard input (a descriptive file usually) and finds the minimum spanning tree for every graph using the Prim's algorithm (it does not show the results yet, it just find the solution).</p>

<pre><code>#include &lt;stdlib.h&gt;  
#include &lt;iostream&gt;  

using namespace std;

const int MAX_NODOS = 20000;
const int infinito = 10000;

int nnodos;
int nAristas;
int G[MAX_NODOS][MAX_NODOS]; 
int solucion[MAX_NODOS][MAX_NODOS];
int menorCoste[MAX_NODOS];
int masCercano[MAX_NODOS];



void leeGrafo(){
    if (nnodos&lt;0 || nnodos&gt;MAX_NODOS) {
        cerr &lt;&lt; ""Numero de nodos ("" &lt;&lt; nnodos &lt;&lt; "") no valido\n"";
        exit(0);
    }  
    for (int i=0; i&lt;nnodos ; i++)
        for (int j=0; j&lt;nnodos ; j++)
            G[i][j] = infinito; 
    int A,B,P;
    for(int i=0;i&lt;nAristas;i++){
        cin &gt;&gt; A &gt;&gt; B &gt;&gt; P; 
        G[A][B] = P;
        G[B][A] = P;
    }   
}


void prepararEstructuras(){
    // Grafo de salida
    for(int i=0;i&lt;nnodos;i++)
        for(int j=0;j&lt;nnodos;j++)
            solucion[i][j] = infinito;
    // el mas cercaano 
    for(int i=1;i&lt;nnodos;i++){
        masCercano[i]=0;
        // menor coste
        menorCoste[i]=G[0][i];
    }           
}

void prim(){
    prepararEstructuras();
    int min,k;  
    for(int i=1;i&lt;nnodos;i++){
        min = menorCoste[1];
        k = 1;
        for(int j=2;i&lt;nnodos;j++){
            if(menorCoste[j] &lt; min){
                min = menorCoste[j];
                k = j;
            }
        }
        solucion[k][masCercano[k]] = G[k][masCercano[k]];
        menorCoste[k] = infinito;
        for(int j=1;j&lt;nnodos;j++){
            if(G[k][j] &lt; menorCoste[j] &amp;&amp; menorCoste[j]!=infinito){
                menorCoste[j] = G[k][j];
                masCercano[j] = k;
            }       
        }           
    }
}

void output(){
    for(int i=0;i&lt;nnodos;i++){
        for(int j=0;j&lt;nnodos;j++)
            cout &lt;&lt; G[i][j] &lt;&lt; ' ';
        cout &lt;&lt; endl;
    }
}

int main (){
    while(true){
        cin &gt;&gt; nnodos;
        cin &gt;&gt; nAristas;
        if((nnodos==0)&amp;&amp;(nAristas==0)) break;
        else{
            leeGrafo();
            output();
            prim(); 
        }
    }   
}
</code></pre>

<p>I have learned that i must use strace to find what is going on, and this is what i get :</p>

<pre><code>execve(""./412"", [""./412""], [/* 38 vars */] &lt;unfinished ...&gt;
+++ killed by SIGKILL +++
Killed
</code></pre>

<p>I am runing ubuntu and this is the first time i get this type of errors. The program is supposed to stop after reading two zeros in a row from the input wich i can guarantee that i have in my graphs descriptive file. Also the problem happens even if i execute the program without doing an input redirection to my graphs file. </p>
","922184","","<p>Although I'm not 100% sure that this is the problem, take a look at the sizes of your global arrays:</p>

<pre><code>const int MAX_NODOS = 20000;

int G[MAX_NODOS][MAX_NODOS]; 
int solucion[MAX_NODOS][MAX_NODOS];
</code></pre>

<p>Assuming <code>int</code> is 4 bytes, you'll need:</p>

<pre><code>20000 * 20000 * 4 bytes * 2 = ~3.2 GB
</code></pre>

<p>For one, you might not even have that much memory. Secondly, if you're on 32-bit, it's likely that the OS will not allow a single process to have that much memory at all.</p>

<p>Assuming you're on 64-bit (and assuming you have enough memory), the solution would be to allocate it all at run-time.</p>
"
"<p>I am refreshing my C skills and am having a little bit of difficulty with a simple program I am working on. Here it is:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;ctype.h&gt; // for isdigit()
#include &lt;stdlib.h&gt; // for atoi()

int main (int argc, const char * argv[])
{
    // first read in # of file events to follow, if not an int,
    // complain &amp; abort
    char *input;
    input = malloc(2); // input[0] holds the character
                       // input[1] holds the terminator

    int numLines = 0;
    scanf(""%c"", &amp;input);
    if (isdigit((int)input)) {
        numLines = atoi(input);
    } else {
        printf(""First line of input must be int type! Aborting...\n"");
        return 1;
    }
    //...
}
</code></pre>

<p>The problem is, then even when I enter a number (i.e. 2) it still outputs the aborting message and exits:</p>

<pre><code>2
First line of input must be int type! Aborting...
</code></pre>

<p>I am having a hard time figuring out why it behaves like it is and what I should do to fix the problem. Shouldn't the '%c' specifier tell the compiler to take in the input as an ANSI character and then isdigit() should properly interpret that to be an integer?</p>

<p>Thanks in advance!</p>
","922184","","<p>Change this:</p>

<pre><code>scanf(""%c"", &amp;input);
if (isdigit((int)input)) {
</code></pre>

<p>to this:</p>

<pre><code>scanf(""%c"", input);
if (isdigit(input[0])) {
</code></pre>

<p>As it is right now, you are overwriting the pointer itself, rather writing to the allocated memory.</p>

<p>Also, you need to null-terminate:</p>

<pre><code>input[1] = '\0';
</code></pre>

<hr>

<p>Furthermore, it's not necessary to allocate memory for this. You can get away with just:</p>

<pre><code>char input[] = "" "";
scanf(""%c"", input);
if (isdigit(input[0])) {
    numLines = atoi(input);
</code></pre>

<p>or alternatively:</p>

<pre><code>char input;
scanf(""%c"", &amp;input);
if (isdigit(input)) {
    numLines = input - '0';
</code></pre>
"
"<p>I need to pass some values to the <code>fseek()</code> method in C which are greater than the maximum value of the signed long type (2147483647). But if I do like below the value of the result is -1 which is not success. Is there anyway that I can do this? </p>

<pre><code>//fp is the pointer to fopen method
unsigned long long index=2147483648;
int status = fseek(fp, index, SEEK_SET);
</code></pre>
","922184","","<p>You need to use the 64-bit version of <code>fseek()</code>:</p>

<ul>
<li>Windows: <a href=""http://msdn.microsoft.com/en-us/library/75yw9bf3.aspx"" rel=""nofollow""><code>_fseeki64()</code></a></li>
<li>Linux: <a href=""http://linux.die.net/man/3/fseeko"" rel=""nofollow""><code>fseeko()</code></a> with <code>#define _FILE_OFFSET_BITS 64</code> or <code>-D_FILE_OFFSET_BITS=64</code></li>
</ul>

<p>And for <code>lseek()</code>:</p>

<ul>
<li>Windows: <a href=""http://msdn.microsoft.com/en-us/library/1yee101t.aspx"" rel=""nofollow""><code>_lseeki64()</code></a></li>
<li>Linux: <a href=""http://linux.die.net/man/2/lseek"" rel=""nofollow""><code>lseek()</code></a> with <code>#define _FILE_OFFSET_BITS 64</code> or <code>-D_FILE_OFFSET_BITS=64</code></li>
</ul>

<p>There's also <a href=""http://linux.die.net/man/3/lseek64"" rel=""nofollow""><code>lseek64()</code></a>, but as mentioned by @R.. (see comments), it should not be used.</p>
"
"<p>How can I be sure the data that is written by multiple CPU cores during a mutex lock is synchronized across all L1 caches of all cores ? I am not talking about the variable that represents the lock, I am talking about the memory locations that are involved during the lock.</p>

<p>This is for Linux, x86_64, and my code is:</p>

<pre><code>#include &lt;sys/types.h&gt;
#include ""dlog.h""

uint *dlog_line;
volatile int dlog_lock;

char *dlog_get_new_line(void) {
    uint val;

    while(!__sync_bool_compare_and_swap(&amp;dlog_lock, 0, 1)) {
        val=*dlog_line;
        if (val==DT_DLOG_MAX_LINES) val=0;
        *dlog_line=val;
    }

    dlog_lock = 0;
}
</code></pre>

<p>Here, inside dlog_get_new_line() function, I use gcc builtin function so there shouldn't be any problem with aquiring the lock. But how can I ensure that when the lock is released, the value pointed by *dlog_line propagates into all the L1 cache of all the other CPU cores in the system?</p>

<p>I do not use pthreads, each process runs on different cpu core.</p>
","922184","","<p>What you're interested in is called <a href=""http://en.wikipedia.org/wiki/Cache_coherence"" rel=""nofollow"">cache coherence</a>. <strong>This is done automatically by the hardware.</strong></p>

<p>So in short, you don't have to do anything if you are correctly using <code>__sync_bool_compare_and_swap()</code> (or any other locking intrinsic).</p>

<p>As an oversimplfied explanation, the thread will not return from the call to <code>__sync_bool_compare_and_swap()</code> until all the other processors are able to see the new value or are aware that their local copy is out-of-date.</p>

<hr>

<p>If you're interested in what happens underneath (in the hardware), there are various cache coherence algorithms that are used to ensure that a core doesn't read an outdated copy of data.</p>

<p>Here's a partial list of commonly taught protocols:</p>

<ol>
<li><a href=""http://en.wikipedia.org/wiki/MSI_protocol"" rel=""nofollow"">MSI</a></li>
<li><a href=""http://en.wikipedia.org/wiki/MESI_protocol"" rel=""nofollow"">MESI</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Firefly_protocol"" rel=""nofollow"">Firefly</a></li>
</ol>

<p>Modern hardware will typically have much more complicated algorithms for it.</p>
"
"<p>Here is my code </p>

<pre><code>#import &lt;stdio.h&gt;
#import &lt;string.h&gt;

int main(int argc, const char *argv[])
{
    char *str = ""First string"";
    char *str2 = ""Second string"";

    strcpy(str, str2);
    return 0;
}
</code></pre>

<p>It compiles just fine without any warning or errors, but when I run the app I get that error </p>

<pre><code>Bus error: 10
</code></pre>

<p>What I miss ?</p>
","922184","","<p>For one, you can't modify string literals. It's undefined behavior.</p>

<p>To fix that you can make <code>str</code> a local array:</p>

<pre><code>char str[] = ""First string"";
</code></pre>

<p>Now, you will have a second problem, is that <code>str</code> isn't large enough to hold <code>str2</code>. So you will need to increase the length of it. Otherwise, you will overrun <code>str</code> - which is also undefined behavior.</p>

<p>To get around this second problem, you either need to make <code>str</code> at least as long as <code>str2</code>. Or allocate it dynamically:</p>

<pre><code>char *str2 = ""Second string"";
char *str = malloc(strlen(str2) + 1);  //  Allocate memory
//  Maybe check for NULL.

strcpy(str, str2);

//  Always remember to free it.
free(str);
</code></pre>

<p>There are other more elegant ways to do this involving VLAs (in C99) and stack allocation, but I won't go into those as their use is somewhat questionable.</p>

<hr>

<p>As @SangeethSaravanaraj pointed out in the comments, everyone missed the <code>#import</code>. It should be <code>#include</code>:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
</code></pre>
"
"<p>I just started to play C and I bump into this problem. Here's my code:</p>

<pre><code>#include&lt;stdio.h&gt;
#include&lt;conio.h&gt;

struct person {
    int i;
    char name[100];
};

int main() {
    struct person p[2];

    clrscr();
    for(int i=0;i&lt;2;i++) {
        printf(""Enter i:\n"");
        scanf(""%d"",&amp;p[i].i);

        printf(""Enter name:\n"");
        gets(p[i].name);
    }
    for(int j=0;j&lt;2;j++) {
        printf(""ID: %d, Name: %c\n"", p[j].i,p[j].name);
    }
    getch();
    return 0;
}
</code></pre>

<p>Here's a sample ouput:</p>

<p><img src=""http://i.stack.imgur.com/GUuem.png"" alt=""enter image description here""></p>

<p>The problem is, all char members are not being asked for a value.</p>

<p>UPDATE:</p>

<p>btw, I am using Turbo C++ version 3 compiler.</p>
","922184","","<p>Two things:</p>

<ol>
<li>You need to clear the input buffer to keep it from eating the newline.</li>
<li>Secondly, you need to change the format string to <code>%s</code>.</li>
</ol>

<p>Here's the corrected code:</p>

<pre><code>int main() {
    struct person p[2];

    for(int i=0;i&lt;2;i++) {
        printf(""Enter i:\n"");

        scanf(""%d"",&amp;p[i].i);

        //  Flush input buffer
        int ch;
        while ((ch = getchar()) != '\n' &amp;&amp; ch != EOF);


        printf(""Enter name:\n"");
        gets(p[i].name);
    }
    for(int j=0;j&lt;2;j++) {
        printf(""ID: %d, Name: %s\n"", p[j].i,p[j].name);
    }
    getch();
    return 0;
}
</code></pre>

<p><code>%c</code> expects a <code>char</code>, but you're trying to pass in a string. It's undefined behavior to have mismatching types.</p>

<p>Output:</p>

<pre><code>Enter i:
1
Enter name:
asdf
Enter i:
2
Enter name:
zxcv
ID: 1, Name: asdf
ID: 2, Name: zxcv
</code></pre>
"
"<p>I came across code similar to the following today and I am curious as to what is actually happening:</p>

<pre><code>#pragma pack(1)
__align(2) static unsigned char multi_array[7][24] = { 0 };
__align(2) static unsigned char another_multi_array[7][24] = { 0 };
#pragma pack()
</code></pre>

<p>When searching for a reference to the __align keyword in the Keil compiler, I came across this:</p>

<blockquote>
  <p><strong>Overalignment of execution regions and input sections</strong>  There are situations when you want to overalign code and data sections... If you have access to the original source code, you can do this at compile time with the __align(n) keyword...</p>
</blockquote>

<p>I do not understand what is meant by ""overaligning code and data sections"".  Can someone help to clarify how this overalignment occurrs?</p>
","922184","","<p>Overalignment is when the data is aligned to more than its default alignment. For example, a 4-byte <code>int</code> usually has a default alignment of 4 bytes. (meaning the address will be divisible by 4)</p>

<p>The default alignment of a datatype is quite-often (but not always) the size of the datatype.</p>

<p>Overalignment allows you to increase this alignment to something greater than the default.</p>

<hr>

<p><strong>As for why you would want to do this:</strong></p>

<p>One reason for this is to be able access the data with a larger datatype (that has a larger alignment).</p>

<p>For example:</p>

<pre><code>char buffer[16];

int *ptr = (int*)&amp;buffer;

ptr[0] = 1;
ptr[1] = 2;
</code></pre>

<p>By default, buffer will only be aligned to 1 byte. However, <code>int</code> requires a 4-byte alignment. If <code>buffer</code> isn't aligned to 4 bytes, you will get a misalignment exception. (AFAIK, ARM doesn't allow misaligned memory access... x86/64 usually does, but with performance penalty)</p>

<p><code>__align()</code> will let you force the alignment higher to make it work:</p>

<pre><code> __align(4) char buffer[16];
</code></pre>

<hr>

<p>A similar situation appears when using SIMD instructions. You will be accessing smaller datatype with a large SIMD datatype - which will likely require a larger alignment.</p>
"
"<p>I am newbie in java but I think I have done well teaching myself in these few weeks. But now I am stuck at this loop.</p>

<p>Here is a method from one of my class. To help me debug, I have added ""myString"" string and ""syntax"" list inside this method to demonstrate what is happening and to keep it simple, at least for now.</p>

<pre><code>public void getIndex(){
    String myString = ""2 2 + 3 5"";
    String[] syntax = myString.split("" "");

    for (int index = 0; index &lt; syntax.length; index++){
        System.out.println(""current index is: "" + index);
        System.out.println(""It has: "" + syntax[index]);
        // these print statements are made to help me debug
        if (syntax[index] == ""+""){
            indexNeeded = index;
            break;
        }
    }
    System.out.println(""Index Needed: "" + indexNeeded);   
</code></pre>

<p>As you can see inside the loop, I want to break the ""for loop"" when the element of the list, ""syntax"" is ""+"".
(I am showing ""+"" here but it can be anything in the actual program.)</p>

<p>Here is the output, when run this method:</p>

<pre><code>current index is: 0
It has: 2
current index is: 1
It has: 2
current index is: 2
It has: +
current index is: 3
It has: 3
current index is: 4
It has: 5
Index Needed: 0
</code></pre>

<p><strong>The loop should have stopped when it found ""+"" but it seems that ""if statement"" is not working at all, and hence ""indexNeeded"" hasn't changed.</strong></p>

<p>It's a simple method but what am I doing wrong here?</p>
","922184","","<p>You're trying to compare strings with <code>==</code>. That doesn't work, you need to use <code>.equals()</code>:</p>

<p>change:</p>

<pre><code>syntax[index] == ""+""
</code></pre>

<p>to</p>

<pre><code>syntax[index].equals(""+"")
</code></pre>

<p><code>==</code> only returns true when both objects refer to the same instance. <code>equals()</code> will return true when the contents of the string are the same. This is what you want.</p>
"
"<p>What is the most accurate way I can do a multiply-and-divide operation for 64-bit integers that works in both 32-bit and 64-bit programs (in Visual C++)? (In case of overflow, I need the result mod 2<sup>64</sup>.)</p>

<p>(I'm looking for something like <a href=""http://www.codeproject.com/KB/recipes/MulDiv64.aspx"">MulDiv64</a>, except that this one uses inline assembly, which only works in 32-bit programs.)</p>

<p>Obviously, casting to <code>double</code> and back is possible, but I'm wondering if there's a more accurate way that isn't too complicated. (i.e. I'm not looking for arbitrary-precision arithmetic libraries here!)</p>
","922184","","<p><strong>Since this is tagged Visual C++ I'll give a solution that abuses MSVC-specific intrinsics.</strong></p>

<p>This example is fairly complicated. It's a highly simplified version of the same algorithm that is used by GMP and <code>java.math.BigInteger</code> for large division.</p>

<p>Although I have a simpler algorithm in mind, it's probably about 30x slower.</p>

<p><strong>This solution has the following constraints/behavior:</strong></p>

<ul>
<li>It requires x64. It will not compile on x86.</li>
<li>The quotient is not zero.</li>
<li>The quotient saturates if it overflows 64-bits.</li>
</ul>

<p>Note that this is for the unsigned integer case. It's trivial to build a wrapper around this to make it work for signed cases as well. This example should also produce correctly truncated results.</p>

<p><strong>This code is not fully tested.</strong> However, it has passed all the tests cases that I've thrown at it.<br>(Even cases that I've intentionally constructed to try to break the algorithm.)</p>

<pre><code>#include &lt;intrin.h&gt;

uint64_t muldiv2(uint64_t a, uint64_t b, uint64_t c){
    //  Normalize divisor
    unsigned long shift;
    _BitScanReverse64(&amp;shift,c);
    shift = 63 - shift;

    c &lt;&lt;= shift;

    //  Multiply
    a = _umul128(a,b,&amp;b);
    if (((b &lt;&lt; shift) &gt;&gt; shift) != b){
        cout &lt;&lt; ""Overflow"" &lt;&lt; endl;
        return 0xffffffffffffffff;
    }
    b = __shiftleft128(a,b,shift);
    a &lt;&lt;= shift;


    uint32_t div;
    uint32_t q0,q1;
    uint64_t t0,t1;

    //  1st Reduction
    div = (uint32_t)(c &gt;&gt; 32);
    t0 = b / div;
    if (t0 &gt; 0xffffffff)
        t0 = 0xffffffff;
    q1 = (uint32_t)t0;
    while (1){
        t0 = _umul128(c,(uint64_t)q1 &lt;&lt; 32,&amp;t1);
        if (t1 &lt; b || (t1 == b &amp;&amp; t0 &lt;= a))
            break;
        q1--;
//        cout &lt;&lt; ""correction 0"" &lt;&lt; endl;
    }
    b -= t1;
    if (t0 &gt; a) b--;
    a -= t0;

    if (b &gt; 0xffffffff){
        cout &lt;&lt; ""Overflow"" &lt;&lt; endl;
        return 0xffffffffffffffff;
    }

    //  2nd reduction
    t0 = ((b &lt;&lt; 32) | (a &gt;&gt; 32)) / div;
    if (t0 &gt; 0xffffffff)
        t0 = 0xffffffff;
    q0 = (uint32_t)t0;

    while (1){
        t0 = _umul128(c,q0,&amp;t1);
        if (t1 &lt; b || (t1 == b &amp;&amp; t0 &lt;= a))
            break;
        q0--;
//        cout &lt;&lt; ""correction 1"" &lt;&lt; endl;
    }

//    //  (a - t0) gives the modulus.
//    a -= t0;

    return ((uint64_t)q1 &lt;&lt; 32) | q0;
}
</code></pre>

<p>Note that if you don't need a perfectly truncated result, you can remove the last loop completely. If you do this, the answer will be no more than 2 larger than the correct quotient.</p>

<p><strong>Test Cases:</strong></p>

<pre><code>cout &lt;&lt; muldiv2(4984198405165151231,6132198419878046132,9156498145135109843) &lt;&lt; endl;
cout &lt;&lt; muldiv2(11540173641653250113, 10150593219136339683, 13592284235543989460) &lt;&lt; endl;
cout &lt;&lt; muldiv2(449033535071450778, 3155170653582908051, 4945421831474875872) &lt;&lt; endl;
cout &lt;&lt; muldiv2(303601908757, 829267376026, 659820219978) &lt;&lt; endl;
cout &lt;&lt; muldiv2(449033535071450778, 829267376026, 659820219978) &lt;&lt; endl;
cout &lt;&lt; muldiv2(1234568, 829267376026, 1) &lt;&lt; endl;
cout &lt;&lt; muldiv2(6991754535226557229, 7798003721120799096, 4923601287520449332) &lt;&lt; endl;
cout &lt;&lt; muldiv2(9223372036854775808, 2147483648, 18446744073709551615) &lt;&lt; endl;
cout &lt;&lt; muldiv2(9223372032559808512, 9223372036854775807, 9223372036854775807) &lt;&lt; endl;
cout &lt;&lt; muldiv2(9223372032559808512, 9223372036854775807, 12) &lt;&lt; endl;
cout &lt;&lt; muldiv2(18446744073709551615, 18446744073709551615, 9223372036854775808) &lt;&lt; endl;
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>3337967539561099935
8618095846487663363
286482625873293138
381569328444
564348969767547451
1023786965885666768
11073546515850664288
1073741824
9223372032559808512
Overflow
18446744073709551615
Overflow
18446744073709551615
</code></pre>
"
"<p>I'm new at Java, I study on strings and i want a string to be reversed. Here is my code</p>

<pre><code>String myStr = ""abcdef""; String reversed = """";
for(int j=myStr.length()-1;j&gt;=0;j--) {
    myStr.charAt(j) += reversed;
}
</code></pre>

<p>But it gives me an error message:</p>

<pre><code>****.java:14: error: unexpected type
required: variable
found:    value
</code></pre>

<p>But when I print it by <code>System.out.print(reversed)</code>, it prints <code>reversed</code> correctly. What is the difference between variable and value? Why it can give me correct answer in spite of giving me an error message? I'll appreciate your answers, thanks</p>
","922184","","<p>The problem is here:</p>

<pre><code>myStr.charAt(j) += reversed;
</code></pre>

<p>The left-hand-side is a value. Not a variable. That's why you can't to a <code>+=</code> to it.</p>

<hr>

<p>Although it defeats the purpose of learning how do it the hard way, you can do it like this:</p>

<pre><code>myStr = new StringBuffer(myStr).reverse().toString();
</code></pre>
"
"<p>Suppose I have a vector of ints,</p>

<pre><code>std::vector&lt;int&gt; numbers;
</code></pre>

<p>that is populated with a bunch of values, then I say do this (where an entry exists at 43)</p>

<pre><code>int *oneNumber = &amp;numbers[43];
</code></pre>

<p>Is oneNumber guaranteed to always be pointing at the int at index 43, even if say I resize numbers to something like numbers.resize(46)?</p>

<p>I'm not 100% sure what expected behaviour is here, I know vectors are guaranteed to be contiguous but not sure if that continuity would also mean all the indices in the vector will remain in the same place throughout its life.</p>
","922184","","<blockquote>
  <p>Is oneNumber guaranteed to always be pointing at the int at index 43</p>
</blockquote>

<p>Yes, this is guaranteed by the standard.</p>

<blockquote>
  <p>even if say I resize numbers to something like numbers.resize(46)?</p>
</blockquote>

<p>No. Once you resize, add, or remove anything to the vector, all addresses and iterators to it are invalidated. This is because the vector may need to be reallocated with new memory locations.</p>
"
"<p>gcc 4.6.2 c89</p>

<p>Allocating memory for a 2D array and filling with characters.</p>

<p>However, I don't seem to be filling as when I print nothing is displayed.</p>

<p>Am I doing something wrong here?</p>

<pre><code>char **attributes = NULL;

/* TODO: Check for memory being allocated */
attributes = malloc(3 * sizeof(char*));
int i = 0;
int k = 0;

for(i = 0; i &lt; 3; i++) {
    for(k = 0; k &lt; 5; k++) {
        sdp_attributes[i] = malloc(5 * sizeof(char));
        sdp_attributes[i][k] = k;
    }
}

for(i = 0; i &lt; 3; i++) {
    for(k = 0; k &lt; 5; k++) {
        printf(""attributes[i][k] [ %c ]\n"", attributes[i][k]);
    }
}
</code></pre>

<p>Many thanks for any advice,</p>
","922184","","<p>Two major issues:</p>

<p><strong>First Issue:</strong></p>

<pre><code>for(i = 0; i &lt; 3; i++) {
    for(k = 0; k &lt; 5; k++) {
        sdp_attributes[i] = malloc(5 * sizeof(char));
</code></pre>

<p>You are reallocating <code>sdp_attributes[i]</code> at each iteration of the inner loop - thereby overwriting it each time. You probably wanted this instead:</p>

<pre><code>for(i = 0; i &lt; 3; i++) {
    sdp_attributes[i] = malloc(5 * sizeof(char));
    for(k = 0; k &lt; 5; k++) {
</code></pre>

<p><strong>Second Issue:</strong></p>

<pre><code>sdp_attributes[i][k] = k;
</code></pre>

<p>You are basically writing the lower ascii characters. Most of them are not printable.
Something like this might do what you want:</p>

<pre><code>sdp_attributes[i][k] = k + '0';
</code></pre>
"
"<p>I have a macro for calculating array sizes in my C code:</p>

<pre><code>#define sizearray(a)  (sizeof(a) / sizeof((a)[0]))
</code></pre>

<p>When I test it, it works fine for statically defined arrays, but not so for dynamically defined arrays (see below). Not sure I understand why this is the case. Is there any way of calculating the size of an array allocated on the heap?</p>

<pre><code>/* test sizearray macro */
void testSIZEARRAY(void)
{
    /* test case for statically defined array */
    int a[5] = {0,0,0,0,0};

    assert(sizearray(a) == 5);

    /* test case for dynamically defined array */
    int *b;

    b = calloc(5, sizeof(int));

    assert(sizearray(b) == 5);

    free(b);
}
</code></pre>
","922184","","<p>The answer is no, there is no standard way to get the size of a dynamically allocated array.<br>For all practical purposes, you have to keep track it yourself.</p>

<p>However, there are some compiler-specific methods that do that:</p>

<p><strong>Windows (Visual Studio):</strong> <a href=""http://msdn.microsoft.com/en-us/library/z2s077bc%28v=vs.71%29.aspx"" rel=""nofollow"">_msize()</a></p>

<p><strike><strong>GCC:</strong> msize()</strike> Can't find it in the GCC docs...</p>
"
"<p>I'd like to implement search using C generics</p>

<pre><code>int lsearchGeneric(void *key, void *base, int n, int elemSize)
{
    int i =0;

    for(; i &lt; n; i++)   {
        void *elemAddr = (char*) base + i * elemSize;           
        if(memcmp(key, elemAddr , elemSize) == 0) {
            return i;
        }
    }

    return -1;
}
</code></pre>

<p>This function is called with </p>

<pre><code>char *key = strdup(""w"");
char *base = strdup(""two"");

int result = lsearchGeneric (&amp;key, base, 3, sizeof(char));
printf(""Position: %d\n"", result); // prints -1
</code></pre>

<p>I wonder what am i missing here. Instead of -1, i would expect 1, as ""w"" is the second letter in ""two""</p>

<p>For those (you know who you are) who wonder whether this is homework - the answer is ""no it is not. I am following Programming paradigms lecture from iTunesU""</p>
","922184","","<p>Looks like you have an extra <code>&amp;</code> in your function call:</p>

<pre><code>int result = lsearchGeneric (&amp;key, base, 3, sizeof(char));
                             ^
                        does not belong here!
</code></pre>

<p>You're passing the address of the pointer rather than the pointer itself. The giveaway here is that you weren't consistent with the two operands: You passed <code>&amp;key</code> and <code>base</code>, one with and the other without the <code>&amp;</code>.</p>

<p><strong>Small Note:</strong></p>

<p>This ""generic"" might not work properly with <a href=""http://en.wikipedia.org/wiki/Data_structure_alignment#Data_structure_padding"" rel=""nofollow"">structs that have padding</a>. As the padding values are unspecified and may be different with otherwise identical structs.</p>
"
"<p>I dont know how to handle <code>new BigDecimal(""0E30"")</code>. Its value is <code>0</code> but it doesn't compare to <code>BigDecimal.ZERO</code>. See below:</p>

<pre><code>System.out.println(new BigDecimal(""0E30"").add(BigDecimal.ONE));     // ---&gt; 1
System.out.println(new BigDecimal(""0E30"").equals(BigDecimal.ZERO)); // ---&gt; false
</code></pre>

<p>Could someone help me to make the comparison true (I know I can get a workaround by converting the <code>BigDecimal</code>s to <code>double</code>, but I would like to know what is going on)? 
I am using JRE 1.6.3.
thanks</p>
","922184","","<p>From the <a href=""http://docs.oracle.com/javase/1.4.2/docs/api/java/math/BigDecimal.html#equals%28java.lang.Object%29"" rel=""nofollow"">docs</a> (emphasis is mine):</p>

<blockquote>
  <p>Compares this BigDecimal with the specified Object for equality.
  Unlike compareTo, this method considers two BigDecimals equal only if
  they are <strong>equal in value and <em>scale</em></strong> (thus 2.0 is not equal to 2.00 when
  compared by this method).</p>
</blockquote>

<p><strong>In this case, the scale doesn't match</strong>. So instead, you should use <code>compareTo()</code>.</p>

<p><code>BigDecimal</code> is one of the cases where <code>equals()</code> is inconsistent with <code>compareTo()</code>:</p>

<blockquote>
  <p>Note: care should be exercised if BigDecimals are to be used as keys
  in a SortedMap or elements in a SortedSet, as BigDecimal's natural
  <strong>ordering is inconsistent with equals</strong>. See Comparable, SortedMap or
  SortedSet for more information.</p>
</blockquote>
"
"<p>Here is a program I'm trying to run straight from section 1.9 of ""The C Programming Language"".</p>

<pre><code>#include &lt;stdio.h&gt;
#define MAXLINE 1000

int getline(char line[], int maxline);
void copy(char to[], char from[]);

main()
{
    int len;
    int max;
    char line[MAXLINE];
    char longest[MAXLINE];

    max = 0;
    while ((len = getline(line, MAXLINE)) &gt; 0)
        if (len &gt; max) {
        max = len;
        copy(longest, line);
        }
    if (max &gt; 0)
        printf(""%s"", longest);
return 0;
}


int getline(char s[], int lim)
{
    int c, i;

    for (i=0; i&lt;lim-1 &amp;&amp; (c=getchar()) !=EOF &amp;&amp; c != '\n'; ++i)
        s[i] = c;
    if (c == '\n') {
        s[i] = c;
        ++i;
    }
    s[i] = '\0';
    return i;
}


void copy(char to[], char from[])
{
    int i;

    i = 0;
    while ((to[i] = from[i]) != '\0')
        ++i;
}
</code></pre>

<p>Here is the error I get when I try to compile the program using Ubuntu 11.10:</p>

<pre><code>cc     word.c   -o word
word.c:4:5: error: conflicting types for ‘getline’
/usr/include/stdio.h:671:20: note: previous declaration of ‘getline’ was here
word.c:26:5: error: conflicting types for ‘getline’
/usr/include/stdio.h:671:20: note: previous declaration of ‘getline’ was here
make: *** [word] Error 1
</code></pre>

<p>Just to make sure it wasn't a problem with the print in the book, I referenced this set of answers to back of chapter exercises from the book (http://users.powernet.co.uk/eton/kandr2/krx1.html) and I get a similar error when I try to run exercises 18, 19, 20, 21, etc., from that link.  It's really hard to learn when I can't run the programs to see how they output. This issue started when introducing character arrays and function calls in one program. I'd appreciate any advice on this issue.</p>
","922184","","<p>The problem is that <code>getline()</code> is a standard library function. (defined in <code>stdio.h</code>) Your function has the same name and is thus clashing with it.</p>

<p>The solution is to simply change the name.</p>
"
"<p>I have:</p>

<pre><code>class first{
   private:
   int *array;

   public:
   first(int x){
     array = new int[x][10];
   }
</code></pre>

<p>I want to call this class by:</p>

<pre><code>first class1 = new first(10);
</code></pre>

<p>Why it doesn't work ? How to inintialize array by size from constructor ??</p>
","922184","","<p>Just this is enough:</p>

<pre><code>first class1(10);
</code></pre>

<p><code>new</code> is for when you're allocating a pointer.</p>

<pre><code>first *class1 = new first(10);
</code></pre>

<hr>

<p>Furthermore, you have an incompatibility here:</p>

<pre><code>array = new int[x][10];
</code></pre>

<p><code>array</code> is an <code>int*</code>, but <code>new int[x][10]</code> is a 2D array. I'm not sure which one you want.</p>

<p><strong>For the 1D array:</strong></p>

<pre><code>int *array;
array = new int[x];
</code></pre>

<p><strong>For the 2D array:</strong></p>

<pre><code>int (*array)[10];
array = new int[x][10];
</code></pre>

<p>That said, you might be better off using <a href=""http://www.cplusplus.com/reference/stl/vector/"" rel=""nofollow""><code>std::vector</code></a>.</p>

<hr>

<p><strong>Side Note:</strong> Since you have memory allocation in the constructor, you should also <a href=""http://stackoverflow.com/questions/4172722/what-is-the-rule-of-three"">implement a destructor, copy-constructor, and copy-assignment operator</a>.</p>
"
"<p>For example:</p>

<pre><code>; Method 1
.data
val1 DWORD 10000h
.code
add eax,val1
</code></pre>

<p>v.s:</p>

<pre><code>; Method 2
.code
add eax,10000h
</code></pre>

<p>Which method would execute faster after being compiled (assembled)? 
I'm thinking method 2 would produce faster code because the CPU won't have to read value from main memory before adding up to eax register. I'm not so clear in my answer, could somebody help? </p>
","922184","","<p><strong>In all likelihood, it will be situation dependent and the difference may not even be noticeable.</strong></p>

<p>Factors such as <a href=""http://en.wikipedia.org/wiki/Out-of-order_execution"" rel=""nofollow"">out-of-order execution</a> will likely hide any sort of inherent ""slowness"" of either version unless there actually is a bottleneck.</p>

<p>That said, if we had to pick which is faster, then you are correct that the second case is likely to be faster.</p>

<p>If we look at <a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">Agner Fog's tables</a> for all the current x86 processors:</p>

<p><strong>Core 2:</strong></p>

<pre><code>add/sub    r, r/i    Latency = 1        , 1/Throughput = 0.33
add/sub    r, m      Latency = unknown  , 1/Throughput = 1
</code></pre>

<p><strong>Nehalem:</strong></p>

<pre><code>add/sub    r, r/i    Latency = 1        , 1/Throughput = 0.33
add/sub    r, m      Latency = unknown  , 1/Throughput = 1
</code></pre>

<p><strong>Sandy Bridge:</strong></p>

<pre><code>add/sub    r, r/i    Latency = 1        , 1/Throughput = 0.33
add/sub    r, m      Latency = unknown  , 1/Throughput = 0.5
</code></pre>

<p><strong>K10:</strong></p>

<pre><code>add/sub    r, r/i    Latency = 1        , 1/Throughput = 0.33
add/sub    r, m      Latency = unknown  , 1/Throughput = 0.5
</code></pre>

<p>In all cases, the memory operand version has less throughput. The latency is unknown in all cases, but almost certain to be more than 1 cycle. So it's worse in all factors.</p>

<p>The memory operand versions use all the same execution ports as the immediate version + it also needs a memory read port. This can only make the situation worse. In fact, this is why the throughputs are lower with the memory operand - the memory ports can only sustain 1 or 2 reads/cycle whereas the adder can sustain a full 3/cycle.</p>

<p>Furthermore this assumes that the data is in L1 cache. If it isn't, then the memory operand version will be <strong>MUCH</strong> slower.</p>

<hr>

<p><strong>Taking this one step further</strong>, we can examine the size of the encoded instructions:</p>

<pre><code>add eax,val1    -&gt;   03 05 14 00 00 00
add eax,10000h  -&gt;   05 00 00 01 00
</code></pre>

<p>The encoding for the first one may be slightly different depending on the address of <code>val1</code>. The examples I've shown here are from my particular test case.</p>

<p>So the memory access version needs an extra byte to encode - which means a slightly larger code-size - and potentially more i-cache misses at the extreme.</p>

<hr>

<p>So in conclusion, if there is a performance difference between the versions, it is likely that the immediate will be faster because:</p>

<ol>
<li>It has lower latency.</li>
<li>It has higher throughput.</li>
<li>It has a shorter encoding.</li>
<li>It does not need to access the data-cache - which could potentially be a cache-miss.</li>
</ol>
"
"<p>I am in the midst of solving a simple combination problem whose solution is 2^(n-1).</p>

<p>The only problem is 1 &lt;= n &lt;= 2^31 -1 (max value for signed 32 bit integer)</p>

<p>I tried using Java's BigInteger class but It times out for numbers 2^31/10^4 and greater, so that clearly doesn't work out.</p>

<p>Furthermore, I am limited to using only built-in classes for Java or C++.</p>

<p>Knowing I require speed, I chose to build a class in C++ which does arithmetic on strings.</p>

<p>Now, when I do multiplication, my program multiplies similarly to how we multiply on paper for efficiency (as opposed to repeatedly adding the strings).</p>

<p>But even with that in place, I can't multiply 2 by itself 2^31 - 1 times, it is just not efficient enough.</p>

<p>So I started reading texts on the problem and I came to the solution of...</p>

<p><code>2^n = 2^(n/2) * 2^(n/2) * 2^(n%2)</code> (where / denotes integer division and % denotes modulus)</p>

<p>This means I can solve exponentiation in a logarithmic number of multiplications. But to me, I can't get around how to apply this method to my code? How do I choose a lower bound and what is the most efficient way to keep track of the various numbers that I need for my final multiplication?</p>

<p>If anyone has any knowledge on how to solve this problem, please elaborate (example code is appreciated).</p>

<p><strong>UPDATE</strong></p>

<p>Thanks to everyone for all your help! Clearly this problem is meant to be solved in a realistic way, but I did manage to outperform <code>java.math.BigInteger</code> with a power function that only performs ceil(log2(n)) iterations.</p>

<p>If anyone is interested in the code I've produced, here it is...</p>

<pre><code>using namespace std;

bool m_greater_or_equal (string &amp; a, string &amp; b){ //is a greater than or equal to b?
    if (a.length()!=b.length()){
        return a.length()&gt;b.length();
    }
    for (int i = 0;i&lt;a.length();i++){
        if (a[i]!=b[i]){
            return a[i]&gt;b[i];
        }
    }
    return true;
}

string add (string&amp; a, string&amp; b){
    if (!m_greater_or_equal(a,b)) return add(b,a);
    string x = string(a.rbegin(),a.rend());
    string y = string(b.rbegin(),b.rend());
    string result = """";
for (int i = 0;i&lt;x.length()-y.length()+1;i++){
    y.push_back('0');
}

int carry = 0;
for (int i =0;i&lt;x.length();i++){
    char c = x[i]+y[i]+carry-'0'-'0';
    carry = c/10;
    c%=10;
    result.push_back(c+'0');
}
if (carry==1) result.push_back('1');
return string(result.rbegin(),result.rend());

}

string multiply (string&amp;a, string&amp;b){
    string row = b, tmp;
    string result = ""0"";

    for (int i = a.length()-1;i&gt;=0;i--){

        for (int j= 0;j&lt;(a[i]-'0');j++){
            tmp = add(result,row);
            result = tmp;
        }
        row.push_back('0');
    }
    return result;
}

int counter = 0;

string m_pow (string&amp;a, int exp){
    counter++;
    if(exp==1){
        return a;
    }
    if (exp==0){
        return ""1"";
    }
    string p = m_pow(a,exp/2);
    string res;
    if (exp%2==0){
        res = ""1"";  //a^exp%2 is a^0 = 1
    } else {
        res = a;   //a^exp%2 is a^1 = a
    }
    string x = multiply(p,p);
    return multiply(x,res);
    //return multiply(multiply(p,p),res); Doesn't work because multiply(p,p) is not const

}

int main(){


    string x =""2"";

    cout&lt;&lt;m_pow(x,5000)&lt;&lt;endl&lt;&lt;endl;
    cout&lt;&lt;counter&lt;&lt;endl;

    return 0;
}
</code></pre>
","922184","","<p>As mentioned by @Oli's answer, this is not a question of computing <code>2^n</code> as that's trivially just a <code>1</code> followed by <code>0</code>s in binary.</p>

<p>But since you want to print them out in decimal, this becomes a question of how to convert from binary to decimal for very large numbers.</p>

<p><strong>My answer to that is that it's not realistic.</strong> (I hope this question just stems from curiosity.)</p>

<p>You mention trying to compute <code>2^(2^31 - 1)</code> and printing that out in decimal. That number is <strong>646,456,993 digits long</strong>.</p>

<ul>
<li>Java <strong>BigInteger</strong> can't do it. It's meant for small numbers and uses <code>O(n^2)</code> algorithms.</li>
<li>As mentioned in the comments, there are no built-in BigNum libraries in C++.</li>
<li>Even <strong>Mathematica</strong> can't handle it:  <code>General::ovfl : Overflow occurred in computation.</code></li>
<li>Your best bet is to use the <a href=""http://gmplib.org/"" rel=""nofollow"">GMP</a> library.</li>
</ul>

<hr>

<p><strong>If you're just interested in seeing part of the answer:</strong></p>

<pre><code>2^(2^31 - 1) = 2^2147483647 = 

880806525841981676603746574895920 ... 7925005662562914027527972323328

(total: 646,456,993 digits)
</code></pre>

<p>This was done using a close-sourced library and took roughly 37 seconds and 3.2 GB of memory on a Core i7 2600K @ 4.4 GHz including the time needed to write all 646 million digits to a massive text file.<br>
(It took notepad longer to open the file than needed to compute it.)</p>

<hr>

<p>Now to answer your question of how to actually compute such a power in the general case, @dasblinkenlight has the answer to that which is a variant of <a href=""http://en.wikipedia.org/wiki/Exponentiation_by_squaring"" rel=""nofollow"">Exponentiation by Squaring</a>.</p>

<p>Converting from binary to decimal for large numbers is a much harder task. The standard algorithm here is <a href=""http://gmplib.org/manual/Binary-to-Radix.html#Binary-to-Radix"" rel=""nofollow"">Divide-and-Conquer conversion</a>.</p>

<p>I do not recommend you try to implement the latter - as it's far beyond the scope of starting programmers. (and is also somewhat math-intensive)</p>
"
"<p>i created a dynamic array ,and i need to initialize all the members to 0 .
How can this be done in C?</p>

<pre><code>   int* array;
    array = (int*) malloc(n*sizeof(int));
</code></pre>
","922184","","<p>In this case you would use <code>calloc()</code>:</p>

<pre><code>array = (int*) calloc(n, sizeof(int));
</code></pre>

<p><strike>It's safe to assume that all systems now have all zero bits as the representation for zero.</strike></p>

<p>§6.2.6.2 guarantees this to work:</p>

<blockquote>
  <p>For any integer type, the object representation where all the bits are
  zero shall be a representation of the value zero in that type.</p>
</blockquote>

<p>It's also possible to do a combination of <code>malloc()</code> + <code>memset()</code>, but for reasons discussed in the <a href=""http://stackoverflow.com/questions/8029584/why-does-malloc-initialize-the-values-to-0-in-gcc/8029624#8029624"">comments of this answer</a>, it is likely to be more efficient to use <code>calloc()</code>.</p>
"
"<p>I am somewhat curious about creating a macro to generate a bit mask for a device register, up to 64bits.  Such that <code>BIT_MASK(31)</code> produces <code>0xffffffff</code>.</p>

<p>However, several C examples do not work as thought, as I get <code>0x7fffffff</code> instead.  It is as-if the compiler is assuming I want signed output, not unsigned.  So I tried <code>32</code>, and noticed that the value wraps back around to 0.  This is because of C standards stating that if the shift value is greater than or equal to the number of bits in the operand to be shifted, then the result is undefined.  That makes sense.</p>

<p>But, given the following program, <code>bits2.c</code>:</p>

<pre><code>#include &lt;stdio.h&gt;

#define BIT_MASK(foo) ((unsigned int)(1 &lt;&lt; foo) - 1)

int main()
{
    unsigned int foo;
    char *s = ""32"";

    foo = atoi(s);
    printf(""%d %.8x\n"", foo, BIT_MASK(foo));

    foo = 32;
    printf(""%d %.8x\n"", foo, BIT_MASK(foo));

    return (0);
}
</code></pre>

<p><br/>If I compile with <code>gcc -O2 bits2.c -o bits2</code>, and run it on a Linux/x86_64 machine, I get the following:</p>

<pre><code>32 00000000
32 ffffffff
</code></pre>

<p><br/>If I take the same code and compile it on a Linux/MIPS (big-endian) machine, I get this:</p>

<pre><code>32 00000000
32 00000000
</code></pre>

<p><br/>On the x86_64 machine, if I use <code>gcc -O0 bits2.c -o bits2</code>, then I get:</p>

<pre><code>32 00000000
32 00000000
</code></pre>

<p><br/>If I tweak <code>BIT_MASK</code> to <code>((unsigned int)(1UL &lt;&lt; foo) - 1)</code>, then the output is <code>32 00000000</code> for both forms, regardless of gcc's optimization level.</p>

<p>So it appears that on x86_64, gcc is optimizing something incorrectly OR the undefined nature of left-shifting 32 bits on a 32-bit number is being determined by the hardware of each platform.</p>

<p><br/><br/><br/>
Given all of the above, is it possible to programatically create a C macro that creates a bit mask from either a single bit or a range of bits?</p>

<p>I.e.:</p>

<pre><code>BIT_MASK(6) = 0x40
BIT_FIELD_MASK(8, 12) = 0x1f00
</code></pre>

<p>Assume <code>BIT_MASK</code> and <code>BIT_FIELD_MASK</code> operate from a 0-index (0-31).  <code>BIT_FIELD_MASK</code> is to create a mask from a bit range, i.e., <code>8:12</code>.</p>
","922184","","<p>Shifting by more than or equal to the size of the integer type is <strong><em>undefined behavior</em></strong>.
<br>
So no, it's not a GCC bug.</p>

<p>In this case, the literal <code>1</code> is of type <code>int</code> which is 32-bits in both systems that you used. So shifting by 32 will invoke this undefined behavior.</p>

<hr>

<p>In the first case, the compiler is not able to resolve the shift-amount to 32. So it likely just issues the normal shift-instruction. (which in x86 uses only the bottom 5-bits) So you get:</p>

<pre><code>(unsigned int)(1 &lt;&lt; 0) - 1
</code></pre>

<p>which is zero.</p>

<p>In the second case, GCC is able to resolve the shift-amount to 32. <strong>Since it is undefined behavior</strong>, it (apparently) just replaces the entire result with 0:</p>

<pre><code>(unsigned int)(0) - 1
</code></pre>

<p>so you get <code>ffffffff</code>.</p>

<hr>

<p>So this is a case of where GCC is using undefined behavior as an opportunity to optimize.
<br>(Though personally, I'd prefer that it emits a warning instead.)</p>

<p>Related: <a href=""http://stackoverflow.com/questions/7682477/gcc-fail-or-undefined-behavior"">GCC Fail? Or Undefined Behavior?</a></p>
"
"<p>My program during calculation can generate <code>nan</code> or <code>-nan</code> values.
I check if the values are <code>nan</code>/<code>-nan</code> using <code>isnan</code> method.</p>

<p>I also have to distinguish if the nan value is positive or negative (<code>nan</code> or <code>-nan</code>). How can I do this?</p>

<p>Added:I need crossplatform solution for WIN and for Unix/Linux</p>
","922184","","<p>Nearly all systems today use either IEEE single or double precision floating-point. So in that case you could (bitwise) convert it to an integer and read the sign-bit.</p>

<p>Here's one approach that uses unions. Although it's not fully standard-compliant, it should still work on nearly all systems.</p>

<pre><code>union{
    double f;
    uint64_t i;
} x;

x.f = ... //  Your floating-point value (can be NaN)

//  Check the sign bit.
if ((x.i &amp; 0x8000000000000000ull) == 0){
    //  positive
}else{
    //  negative
}
</code></pre>
"
"<p>I'm trying to make a class that has a simple integer with in it. Of course, it uses header files and whatnot.</p>

<p>Here's the code:</p>

<p>class.h</p>

<pre><code> class consolBuf
{
private:
    int buffersize1 = 10; //Data member initializer is not allowed
    int buffersize2 = 10;
    static char screenBuffer[10][10]; //screenBuffer
public:
    consolBuf(void);
    ~consolBuf(void);
    void draw();
    void write(int x, int y);
    char get(int x, int y);
};
</code></pre>

<p>For some reason some reson Visual Studio keeps complaining that I can't declare a integer in the class.h. I've searched everywhere and I can't find an answer. Is there something I'm missing?</p>
","922184","","<p>Indeed you can't initialize members like that. If you wanted to initialize those as default values for each instance, you would do that in the constructor:</p>

<pre><code>consolBuf::consolBuf()
    : buffersize1(10)
    , buffersize2(10)
{

}
</code></pre>
"
"<p><strong>I have the following header functions:</strong></p>

<pre><code>float computeDistance3(Vector3f&amp; vec_a, Vector3f&amp; vec_b);

float computeDotProduct3(Vector3f&amp; vecta, Vector3f&amp; vectb);

float computeGeoDotProd3(Vector3f&amp; vecta, Vector3f&amp; vectb);
</code></pre>

<p><strong>With the following definitions</strong></p>

<pre><code>float computeDistance3(Vector3f&amp; vec_a, Vector3f&amp; vec_b) {
    float x = vec_a.x - vec_b.x;
    float y = vec_a.y - vec_b.y;
    float z = vec_a.z - vec_b.z;

    return sqrt((x * x) + (y * y) + (z * z));
}

float computeDotProduct3(Vector3f&amp; vec_a, Vector3f vec_b) {
    return (vec_a.x * vec_b.x) 
         + (vec_a.y * vec_b.y) 
         + (vec_a.z * vec_b.z);
}

float computeGeoDotProd3(Vector3f&amp; vecta, Vector3f&amp; vectb) {
    float amag, bmag, dotProd;

    amag = vecta.computeMagnitude();
    bmag = vectb.computeMagnitude();

    dotProd = computeDotProduct3(vecta, vectb);

    bool notZero = (amag != 0.0f &amp;&amp; bmag != 0.0f) &amp;&amp; dotProd != 0.0f;

    if (notZero) {
        return cosf(dotProd / (amag * bmag));
    } else {
        return -1.0f;   
    }

}
</code></pre>

<p>I know that their signatures are the same. Is this confusing the compiler? I'm guessing so, because when I compile the code, I get this:</p>

<pre><code>vector3f.cpp: In function ‘float computeGeoDotProd(Vector3f&amp;, Vector3f&amp;)’:                                                                                                  
vector3f.cpp:139:43: error: call of overloaded ‘computeDotProduct3(Vector3f&amp;, Vector3f&amp;)’ is ambiguous                                                                      
vector3f.cpp:139:43: note: candidates are:                                                                                                                                  
vector3f.h:31:7: note: float computeDotProduct3(Vector3f&amp;, Vector3f&amp;)                                                                                                       
vector3f.cpp:127:7: note: float computeDotProduct3(Vector3f&amp;, Vector3f)   
</code></pre>

<p><strong>Question</strong></p>

<p>What is the solution to unconfusing the compiler?</p>
","922184","","<p>You're missing an <code>&amp;</code> in the definition:</p>

<pre><code>float computeDotProduct3(Vector3f&amp; vec_a, Vector3f vec_b) {
</code></pre>

<p>should be:</p>

<pre><code>float computeDotProduct3(Vector3f&amp; vec_a, Vector3f&amp; vec_b) {
</code></pre>

<p>So you end up with two different (overloaded) function prototypes that differ only by the reference <code>&amp;</code> - hence ambiguous.</p>
"
"<p>I was reading this website </p>

<blockquote>
  <p><a href=""http://www.cplusplus.com/reference/clibrary/cstring/strcmp/"" rel=""nofollow"">http://www.cplusplus.com/reference/clibrary/cstring/strcmp/</a></p>
</blockquote>

<p>which is a C++ website.But, it uses printf to display things. However, i thought in c++, we use cout to display things. Can we mix c and C++ code as they have done here.</p>
","922184","","<p>Technically speaking, yes you <strong><em>can</em></strong> mix C and C++ code. C++ is a near super-set of C and has all of the C libraries (save for a few slight differences).</p>

<p>However, whether or not you <strong><em>should</em></strong> mix C and C++ is another story. Generally speaking, if you write in C++, you should stick to C++ constructs.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/1704407/what-is-the-difference-between-char-s-and-char-s-in-c"">What is the difference between char s[] and char *s in C?</a>  </p>
</blockquote>



<p>I initialize a <code>char</code> pointer: </p>

<pre><code>char *a=""test"";
</code></pre>

<p>I have read at some places that this is considered <strong><em>read-only</em></strong> and that it's dangerous. </p>

<p>Does that imply that the <code>""test""</code> is not allocated space in the heap? Does that mean that the string ""test"" can be written over later in the program?</p>

<p><strong>---Expanding my question---</strong></p>

<p>If I have initiliazed <code>a</code> as above and then I do a bunch of other initializations like:</p>

<pre><code>int b=20;
char c[]=""blahblahblah"";
</code></pre>

<p>Can ""test"" in memory get overwritten with ""20"" or ""blah""? Or does that scenario have no ground?</p>
","922184","","<p>This is dangerous because the string is not-modifiable. Attempting to do so results in <strong><em>undefined behavior</em></strong>.</p>

<p><strong>So it's preferred to do:</strong></p>

<pre><code>const char *a = ""test"";
</code></pre>

<p>You are correct that <code>""test""</code> in this case is not allocated on the heap or the stack* and instead lies in static memory that is not-modifiable.</p>

<p>*The standard says nothing about the stack or heap, though that's how it's usually implemented.</p>

<p><strong>On the other hand:</strong></p>

<pre><code>char a[] = ""test"";
</code></pre>

<p>Is safe to modify since it's just short-form for:</p>

<pre><code>char a[] = {'t','e','s','t','\0'};
</code></pre>

<p>which is an ordinary modifiable array.</p>
"
"<p>I have been trying to execute the following code. Though the task is trivial, I am getting a segmentation fault.</p>

<p>The aim of the code snippet betlow is to create a multi dimensional array of maximum row size 4 and column size 33. Then after creation, it should set the contents of all the rows as 0, followed by a <code>'\0'</code> character. Then in the end, it should display the output on the <code>stdout</code>.</p>

<p>Although I am not new to programming, I keep on getting similar errors, so if possible please explain me how can I avoid such mistakes in the future.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

int main(int argc, char* argv[])
{
        int i,j,k,x,y;
        char** arr;
        arr = (char**) malloc(4 * sizeof(char*));
        for ( i = 0; i &lt; 4; i++) {
                arr[i] = (char*) malloc(9 * sizeof(char));
                memset(arr,0,8);
                arr[i][8] = '\0';
        }
        for ( j = 0; j&lt;4; j++) {
                puts(arr[j]);
        }
        return 0;
}
</code></pre>
","922184","","<p>You're <code>memset</code>ing the wrong pointer.</p>

<p>Instead of:</p>

<pre><code>memset(arr,0,8);
</code></pre>

<p>you want:</p>

<pre><code>memset(arr[i],0,8);
</code></pre>

<p>So you're off by one level of indirection.</p>

<hr>

<p>As pointed out in the comments, here are some optimizations:</p>

<pre><code>for ( i = 0; i &lt; 4; i++) {
    arr[i] = (char*) malloc(9 * sizeof(char));
    memset(arr[i],0,9);
}
</code></pre>

<p>or</p>

<pre><code>for ( i = 0; i &lt; 4; i++) {
    arr[i] = (char*) calloc(9, sizeof(char));
}
</code></pre>

<p>Note that the cast to <code>char*</code> isn't necessary in C.</p>

<hr>

<p>If you wanted to the character <code>'0'</code> instead of the null-character, then you should go with this:</p>

<pre><code>for ( i = 0; i &lt; 4; i++) {
    arr[i] = (char*) malloc(8 * sizeof(char));
    memset(arr[i],'0',8);
    arr[i][8] = '\0';
}
</code></pre>
"
"<p>I'm facing k&amp;r exercise 1.24, that states: ""Write a program to check a C program for rudimentary syntax errors like unmatched parentheses, brackets and braces"".</p>

<p>I'm not sure about how to deal with square brackets.</p>

<p>Are nested square brackets possible in ANSI C syntax ?
I haven't yet seen them so far, but I'm only at Chapter 1.</p>
","922184","","<p>Yes it is possible:</p>

<pre><code>int index[] = {0,3,1,3};
int data[] = {9,10,22,34};

data[index[0]] = 0;
data[index[1]] = 1;
data[index[2]] = 2;
data[index[3]] = 3;
</code></pre>
"
"<p>I've run across some code like this:</p>

<pre><code>line += addr &amp; 0x3fULL;
</code></pre>

<p>Obviously, 'U' and 'L' are not hex digits.  I'm guessing that the 'ULL' at the end of that hex numeric literal means ""Unsigned Long Long""  - am I correct?  (this sort of thing is very difficult to google) if so then this is some sort of suffix modifier on the number?</p>
","922184","","<p>Yes that's correct.</p>

<ul>
<li><code>0x</code> makes it a hexadecimal literal.</li>
<li><code>ULL</code> makes it type <code>unsigned long long</code>.</li>
</ul>
"
"<p>The code below move the an element to top of an array</p>

<pre><code>for ( i = j; i &gt; 0; i-- ) {
  myBlk *tmp = blks[i];
  blks[i] = blks[i-1];
  blks[i-1] = tmp;
  delete tmp;
}
</code></pre>

<p>as the execution reaches <code>delete tmp</code>, I get:</p>

<pre><code>*** glibc detected *** double free or corruption (out): 0x00007fffd556ad10 ***
</code></pre>

<p>If I remove that statement, there is no problem. But I don't want memory to leak...</p>
","922184","","<p>Promoting comment to answer.</p>

<p>It seems that you are confusing a memory allocation with a pointer copy. In your loop, you are not doing any memory allocation. You are just copying a pointer - which does not allocate memory.</p>

<p>So you should get rid of the <code>delete</code>:</p>

<pre><code>for ( i = j; i &gt; 0; i-- ) {
  myBlk *tmp = blks[i];
  blks[i] = blks[i-1];
  blks[i-1] = tmp;
}
</code></pre>

<p><code>delete</code> is only called when there is memory allocation - which you have none of. (none inside the loop at least)</p>
"
"<pre><code>#define MAX_SIZE 8

enum my_enum
{
    VAL1 = 0;
    VAL2,
    VAL3,
    VAL4,
    VAL_MAX
};

struct my_struct
{
  enum my_enum e;
  int  w[MAX_SIZE];
};
</code></pre>

<p>Can a layout in such structure cause alignment issues on a target platform? I understand it much depends on a platform, but generally C compiler is allowed to do padding of structures, so for example on 32 bit machine, where 'int' is 32 bit long:</p>

<pre><code>struct my_struct
{
    int w[MAX_SIZE];
}
</code></pre>

<p>is aligned (as fas as I understand) so compiler probably won't be doing anything else with its layout, but adding 'enum my_enum' in the structure can poptentially get the structure un-aligned on such machine.  Should I be doing anything special to avoid this and should I be avoiding it at all ?</p>

<p>Would be very thankful for clarifications!</p>

<p>Mark</p>
","922184","","<p>The answer is no, you don't have to do anything. If adding a field will break alignment, the compiler will apply padding in the appropriate places to realign it.</p>

<p>In your case, <code>enum</code>s are likely to be implemented as an <code>int</code> so you wouldn't have this problem in the first place.</p>

<p>A better example would be:</p>

<pre><code>struct my_struct
{
  char ch;
  int  w[MAX_SIZE];
};
</code></pre>

<p>In this case, the compiler will likely place 3 bytes of padding after <code>ch</code> to keep <code>w</code> aligned to 4 bytes.</p>
"
"<p>I have the following assembly code on Windows and I want to make sure that I understand correctly.
<code>edi</code> contains some address i.e. <code>0x6090F454</code></p>

<p>In this case, what should <code>eax</code> have after the first <code>mov</code> instruction?</p>

<pre><code>775672f3  mov eax,dword ptr [edi]

775672f5  mov dword ptr [ebp-50h],0 
775672fc  mov dword ptr [ebp-48h],0 

77567303  cmp eax,0FFFFFFFFh 
</code></pre>

<p>It seems to me that <code>eax</code> must have the value but I am not so sure about that.
For your information, C++ code for the above assembly is</p>

<pre><code>if (sem-&gt;num != INVALID_FLAG) {
    ....
}
</code></pre>

<p>Also, here is what's store in edi.</p>

<pre><code>0:024&gt; dd edi
6090f454  0c0e8fe0 ffffffff 00000000 00000000
</code></pre>

<p>Thank you in advance.</p>
","922184","","<p>The line:</p>

<pre><code>mov eax,dword ptr [edi]
</code></pre>

<p>will simply load whatever is stored at the address <code>edi</code>. So it's a simple data load.</p>

<p>Since you don't show what is at address <code>edi</code> (<code>0x6090F434</code>), we can't tell you exactly what <code>eax</code> will be.</p>

<p>Based on the C++ code that is given, it looks like <code>edi</code> is the address of the <code>num</code> field. So it's reading <code>num</code> into a register, then comparing it against <code>0xFFFFFFFF</code> which is the <code>INVALID_FLAG</code> constant.</p>
"
"<p>I was looking over some mock <a href=""https://en.wikipedia.org/wiki/Oracle_Certification_Program"" rel=""nofollow"">OCJP</a> questions. I came across a really baffling syntax. Here it is:</p>

<pre><code>class OddStuff {
    public static void main(String[] args) {
        boolean b = false;
        System.out.println((b != b));// False
        System.out.println((b =! b));// True
    }
}
</code></pre>

<p>Why does the output change between <code>!=</code> and <code>=!</code>?</p>
","922184","","<p>The question is just playing with you with confusing spacing.</p>

<p><code>b != b</code> is the usual <code>!=</code> (not equals) comparison.</p>

<p>On the other hand:</p>

<p><code>b =! b</code> is better written as <code>b = !b</code> which is parsed as:</p>

<pre><code>b = (!b)
</code></pre>

<p>Thus it's two operators.</p>

<ol>
<li>First invert <code>b</code>.</li>
<li>Then assign it back to <code>b</code>.</li>
</ol>

<p>The assignment operator returns the assigned value. Therefore, <code>(b =! b)</code> evaluates to true - which is what you print out.</p>
"
"<p>The code below does not print anything - </p>

<pre><code>int main() {

        char *input = ""This is a string"";
        find_length(input);
        return 0;

}
void find_length(char *input){

    printf(""%s"", input);
    int length = 0;
    while(input[length]!='\0');
    {
        length++;
        printf(""%i"", length);
    }

}
</code></pre>
","922184","","<p><strong>You have an extra semicolon behind your loop:</strong></p>

<pre><code>while(input[length]!='\0');
                          ^ does not belong here!!!
</code></pre>

<p>So it is stuck in an infinite loop. Get rid of it.</p>

<hr>

<p><strong>Furthermore, there could be stream buffering.</strong> Try adding some <code>\n</code>. Or call <code>fflush(stdout)</code> to flush the output stream.</p>

<pre><code>void find_length(char *input){

    printf(""%s\n"", input);
    int length = 0;
    while(input[length]!='\0')  //  remove ;
    {
        length++;
        printf(""%i\n"", length);
    }

}
</code></pre>
"
"<p><strong>I wrote this simple C program:</strong></p>

<pre class=""lang-c prettyprint-override""><code>int main(){
    int i; int count = 0;
    for(i = 0; i &lt; 2000000000; i++){
        count = count + 1;
    }
}
</code></pre>

<p>I wanted to see how the gcc compiler optimizes this loop (clearly add <em>1</em> 2000000000 times should be ""add <em>2000000000</em> one time""). So:</p>

<p><strong>$ gcc test.c</strong><br>
and then time( ) on a.out:</p>

<pre><code>real 0m7.717s  
user 0m7.710s  
sys 0m0.000s  
</code></pre>

<p><strong>$ gcc -O2 test.c</strong> 
and then time( ) on a.out: </p>

<pre><code>real 0m0.003s  
user 0m0.000s  
sys 0m0.000s  
</code></pre>

<p>Then I disassembled both with <strong>gcc -S</strong>. First one seems quite clear:</p>

<pre><code>    .file ""test.c""  
    .text  
.globl main
    .type   main, @function  
main:
.LFB0:
    .cfi_startproc
    pushq   %rbp
    .cfi_def_cfa_offset 16
    movq    %rsp, %rbp
    .cfi_offset 6, -16
    .cfi_def_cfa_register 6
    movl    $0, -8(%rbp)
    movl    $0, -4(%rbp)
    jmp .L2
.L3:
    addl    $1, -8(%rbp)
    addl    $1, -4(%rbp)
.L2:
    cmpl    $1999999999, -4(%rbp)
    jle .L3
    leave
    .cfi_def_cfa 7, 8
    ret
    .cfi_endproc
.LFE0:
    .size   main, .-main
    .ident  ""GCC: (Ubuntu/Linaro 4.5.2-8ubuntu4) 4.5.2""
    .section    .note.GNU-stack,"""",@progbits
</code></pre>

<p>L3 adds, L2 compare <code>-4(%rbp)</code> with <code>1999999999</code> and loops to L3 if <code>i &lt; 2000000000</code>.</p>

<p><strong>Now the optimized one:</strong></p>

<pre><code>    .file ""test.c""  
    .text
    .p2align 4,,15
.globl main
    .type main, @function
main:
.LFB0:
    .cfi_startproc
    rep
    ret
    .cfi_endproc
.LFE0:
    .size main, .-main
    .ident ""GCC: (Ubuntu/Linaro 4.5.2-8ubuntu4) 4.5.2""
    .section .note.GNU-stack,"""",@progbits
</code></pre>

<p>I can't understand at all what's going on there! I've got little knowledge of assembly, but I expected something like</p>

<pre><code>addl $2000000000, -8(%rbp)
</code></pre>

<p>I even tried with <strong>gcc -c -g -Wa,-a,-ad -O2 test.c</strong> to see the C code together with the assembly it was converted to, but the result was no more clear that the previous one.  </p>

<p><strong>Can someone briefly explain:</strong></p>

<ol>
<li>The <strong>gcc -S -O2</strong> output.</li>
<li>If the loop is optimized as I expected (one sum instead of many sums)?</li>
</ol>
","922184","","<p>The compiler is even smarter than that. :)</p>

<p>In fact, it realizes that you aren't using the result of the loop. So it took out the entire loop completely!</p>

<p>This is called <a href=""http://en.wikipedia.org/wiki/Dead_code_elimination"">Dead Code Elimination</a>.</p>

<p>A better test is to print the result:</p>

<pre><code>#include &lt;stdio.h&gt;
int main(void) {
    int i; int count = 0;
    for(i = 0; i &lt; 2000000000; i++){
        count = count + 1;
    }

    //  Print result to prevent Dead Code Elimination
    printf(""%d\n"", count);
}
</code></pre>

<p><strong>EDIT :</strong> I've added the required <code>#include &lt;stdio.h&gt;</code>; the MSVC assembly listing corresponds to a version without the <code>#include</code>, but it should be the same.</p>

<hr>

<p>I don't have GCC in front of me at the moment, since I'm booted into Windows. But here's the disassembly of the version with the <code>printf()</code> on MSVC:</p>

<p><strong>EDIT : I had the wrong assembly output. Here's the correct one.</strong></p>

<pre><code>; 57   : int main(){

$LN8:
    sub rsp, 40                 ; 00000028H

; 58   : 
; 59   : 
; 60   :     int i; int count = 0;
; 61   :     for(i = 0; i &lt; 2000000000; i++){
; 62   :         count = count + 1;
; 63   :     }
; 64   : 
; 65   :     //  Print result to prevent Dead Code Elimination
; 66   :     printf(""%d\n"",count);

    lea rcx, OFFSET FLAT:??_C@_03PMGGPEJJ@?$CFd?6?$AA@
    mov edx, 2000000000             ; 77359400H
    call    QWORD PTR __imp_printf

; 67   : 
; 68   : 
; 69   : 
; 70   :
; 71   :     return 0;

    xor eax, eax

; 72   : }

    add rsp, 40                 ; 00000028H
    ret 0
</code></pre>

<p>So yes, Visual Studio does this optimization. I'd assume GCC probably does too.</p>

<p>And yes, GCC performs a similar optimization.  Here's an assembly listing for the same program with <code>gcc -S -O2 test.c</code> (gcc 4.5.2, Ubuntu 11.10, x86):</p>

<pre><code>        .file   ""test.c""
        .section        .rodata.str1.1,""aMS"",@progbits,1
.LC0:
        .string ""%d\n""
        .text
        .p2align 4,,15
.globl main
        .type   main, @function
main:
        pushl   %ebp
        movl    %esp, %ebp
        andl    $-16, %esp
        subl    $16, %esp
        movl    $2000000000, 8(%esp)
        movl    $.LC0, 4(%esp)
        movl    $1, (%esp)
        call    __printf_chk
        leave
        ret
        .size   main, .-main
        .ident  ""GCC: (Ubuntu/Linaro 4.5.2-8ubuntu4) 4.5.2""
        .section        .note.GNU-stack,"""",@progbits
</code></pre>
"
"<p>This code gives me a seg fault, but when I change the <code>x--</code> to <code>--x</code> it prints correctly. </p>

<p>Are not they the same????</p>

<pre><code>int main()
{    
    myFunc(5); 
    return 0;
}

void myFunc (int x) {  
    if (x &gt; 0) {
        myFunc(x--);
        printf(""%d, "", x);
    }
    else
        return;
}
</code></pre>
","922184","","<p>No they are not the same.</p>

<p>The difference between <code>x--</code> and <code>--x</code> is whether the returned value is before or after the decrement.</p>

<p>In <code>myFunc(x--)</code>, <code>x--</code> returns the old value. So <code>myFunc()</code> gets called repeatability with the same value -> infinite recursion.</p>

<p>In <code>myFunc(--x)</code>, <code>--x</code> returns the new value. So <code>myFunc()</code> gets called with a decreasing number each time -> no infinite recursion.</p>

<hr>

<p>It will be easier to see this if you moved your <code>printf</code> to the start of the function call:</p>

<pre><code>void myFunc (int x) {  
    printf(""%d, "", x);

    if (x &gt; 0) {
        myFunc(x--);

    }
    else
        return;
}
</code></pre>

<p><strong>Output:</strong> (when called with 10)</p>

<pre><code>10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, ...
</code></pre>
"
"<p>I have a the generator polynomial which has to be converted to binary number to use in my CRC code.Like for example these are the one's that are converted correctly, I want to know how they are done.</p>

<p>These are used for ROHC CRC computation:</p>

<p>The polynomial to be used for the 3 bit CRC is:
C(x) = 1 + x + x^3</p>

<p>this is 0x06
The polynomial to be used for the 7 bit CRC is:
C(x) = 1 + x + x^2 + x^3 + x^6 + x^7</p>

<p>this is 0x79</p>

<p>want to know how 0x06 and 0x79 are derived from those equations.</p>
","922184","","<p>Those appear to be in reversed binary notation.</p>

<p>When representing CRC polynomials, each term maps to one bit. Furthermore, the highest order term is implicit and is omitted.</p>

<p>So breaking down your two examples:</p>

<pre><code>1 + x + x^3                    = 1101
1 + x + x^2 + x^3 + x^6 + x^7  = 11110011
</code></pre>

<p>Chopping off the highest order term:</p>

<pre><code>1101     -&gt; 110      = 0x06
11110011 -&gt; 1111001  = 0x79
</code></pre>
"
"<p>I'm writing some code on an Arduino that needs to run fast and make rough approximations to percentages of integers.</p>

<p>For example, given a number I want to find 90% of it, or 70% or 30% etc. The obvious way to do it is multiply by a floating point eg. x * 0.9; or x * 0.3; But because I need speed, I want to avoid a floating point calculation. If I was just dividing by a power of two, I'd do a bitwise shift, but are there similar techniques for approximating 90%, 80% etc. using integers?</p>
","922184","","<p>You can approximate those percentages with fractions that have a power-of-two denominator.</p>

<p>Here's a simple example with <code>2^16</code>:</p>

<pre><code>90% = 90 / 100 ~ 58982 / 65536
70% = 70 / 100 ~ 45875 / 65536
30% = 30 / 100 ~ 19661 / 65536

 x% =  x / 100 ~ x * 655 / 65536
</code></pre>

<p>The divisions (which are now powers-of-two) can be done with shifts.</p>

<p>Of course, it may take some pre-computation to generate those fractions.</p>
"
"<p>To avoid maintaining complex data structures, I want to allocate blocks with quite large alignment (say some kilobytes, possibly megabytes, always by power of two). This allows me to mask the lower bits of a pointer to easily retrieve the address of the beginning of the block it points in.</p>

<p>I'd like a method to guarantee the allocation of such a block with specified alignment, eg. to allocate 4096 byte blocks with 4096 byte alignment. For the method to work, the alignment will always be the size of the blocks, so memory waste is expected to be a concern in the long run.</p>

<p>I'm using C++ (so C and C++ techniques are fine), and any solution should be portable across common desktop environments. Should there be no portable solution, Linux has highest priority.</p>

<p>I'm aware of <a href=""http://stackoverflow.com/questions/7616719/win32-memory-allocation-with-large-alignment"">Win32 memory allocation with large alignment</a>, but if there is a common C library which does this with one function call, I'd happily use it.</p>

<p><em>Background:</em> I'm experimenting with the Vlist structures described <a href=""http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;sqi=2&amp;ved=0CCAQFjAA&amp;url=http://infoscience.epfl.ch/record/64410/files/techlists.pdf&amp;ei=8osRT5SWItPd8QOfoLX-Aw&amp;usg=AFQjCNEQ9QRIe0bRHOmG1jYBY0z_jwkE7w"" rel=""nofollow"">there</a> (ultimate goal is a sort of Scheme interpreter), and I'm currently implementing garbage collection for those lists. I need the quite large memory blocks as arenas for the garbage collector. Should I change the GC technique, I still need the VList blocks to have 32 byte alignment (I'm performing my experiments on 64bit machines).</p>
","922184","","<p>I'm not aware of a fully portable solution. But <a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_allocate_free_aligned_mem.htm"" rel=""nofollow""><code>_mm_malloc()</code> and <code>_mm_free()</code></a> seem to be <a href=""http://stackoverflow.com/questions/3306294/does-vc-support-mm-malloc"">supported by ICC, GCC, and MSVC</a>.</p>

<p>This was added as part of the aligned memory support for SSE intrinsics.</p>

<hr>

<p>Otherwise, you could implement your own fairly easily:</p>

<pre><code>void* my_malloc(size_t bytes,size_t align){

    void *ptr = malloc(bytes + align + sizeof(intptr_t));

    if (ptr == NULL)
        return NULL;

    //  Get aligned return address
    intptr_t *ret = (intptr_t*)((((intptr_t)ptr + sizeof(intptr_t)) &amp; ~(intptr_t)(align - 1)) + align);

    //  Save the free pointer
    ret[-1] = (intptr_t)ptr;

    return ret;
}

void my_free(void *ptr){
    if (ptr == NULL)
        return;

    //  Get the free pointer
    ptr = (void*)(((intptr_t*)ptr)[-1]);

    free(ptr); 
}
</code></pre>
"
"<p>I am working on a microcontroller project in C. The main.c file includes a header defining all of the registers as structures and chars. Unfortunately they name the registers unmeaning-full names like PORTA. Is it possible to rename the structures and variable defined in the header file to something more meaningful in my main file?</p>

<p>So instead of PORTA I can call it OUT without modifying the header file where it was defined.</p>
","922184","","<p>Promoting comment to answer:</p>

<p>The easiest way I can think of is to just use macros:</p>

<pre><code>#define OUT PORTA
</code></pre>

<p>And these don't need to be in the header.</p>

<p><strong>EDIT :</strong></p>

<p>If the original names are actually names of variables (rather than types), then this is the way to go since the typedef method will not work.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/1453410/declaring-a-c-function-to-return-an-array"">Declaring a C function to return an array</a>  </p>
</blockquote>



<p>I am new to C, and need to your thoughts to help me to return the result array from the following function:</p>

<pre><code>void getBase(int n, int b)
{
    const size_t SIZE = 32;
    char arr[32+1]={0}; int digits=SIZE, i;
    char* ptr = arr;
    while (n &gt; 0)
    {
        int t = n%b;
        n/=b;
        arr[--digits] = numbers[t];
    }
    while ( *ptr == '\0') ptr++;
    // NEED To return a ref to `ptr`
}
</code></pre>

<p>My solution:</p>

<pre><code>void getBase(int n, int b, /*send some  array as a parameter*/ char* str)
{
    const size_t SIZE = 32;
    char arr[32+1]={0}; int digits=SIZE, i;
    char* ptr = arr;
    while (n &gt; 0)
    {
        int t = n%b;
        n/=b;
        arr[--digits] = numbers[t];
    }
    while ( *ptr == '\0') ptr++;

    /* and use strcpy ... perhaps memcpy if non-string )*/
    strcpy(str, ptr);
}
</code></pre>

<p>I need further ideas.... </p>

<p>Thanks.</p>
","922184","","<p>Your solution looks fine.</p>

<p>Instead, you don't even need the local <code>arr</code> array at all. You can just write directly into <code>str</code>:</p>

<p><strong>EDIT : Cleaned up and working version.</strong></p>

<pre><code>const char numbers[] = ""0123456789abcdef"";

void getBase(int n, int b, char* str)
{
    const size_t SIZE = 32;
    int digits=SIZE;
    while (n &gt; 0)
    {
        int t = n%b;
        n/=b;
        str[--digits] = numbers[t];
    }

    int length = SIZE - digits;

    memmove(str,str + digits,length);
    str[length] = '\0';
}
</code></pre>

<p>You just have to make sure that your <code>str</code> is large enough to avoid an array-overrun.</p>

<hr>

<pre><code>int main(){

    char str[33];

    getBase(684719851,10,str);

    printf(str);

    return 0;
}
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>684719851
</code></pre>
"
"<p>I'm still working on routines for arbitrary long integers in C++. So far, I have implemented addition/subtraction and multiplication for 64-bit Intel CPUs.</p>

<p>Everything works fine, but I wondered if I can speed it a bit by using SSE. I browsed through the SSE docs and processor instruction lists, but I could not find anything I think I can use and here is why:</p>

<ul>
<li><p>SSE has some integer instructions, but most instructions handle floating point. It doesn't look like it was designed for use with integers (e.g. is there an integer compare for less?)</p></li>
<li><p>The SSE idea is SIMD (same instruction, multiple data), so it provides instructions for 2 or 4 independent operations. I, on the other hand, would like to have something like a 128 bit integer add (128 bit input and output). This doesn't seem to exist. (Yet? In AVX2 maybe?)</p></li>
<li><p>The integer additions and subtractions handle neither input nor output carries. So it's very cumbersome (and thus, slow) to do it by hand.</p></li>
</ul>

<p>My question is: is my assessment correct or is there anything I have overlooked? Can long integer routines benefit from SSE?  In particular, can they help me to write a quicker add, sub or mul routine?</p>
","922184","","<p>You are correct. SSE/AVX are not well-suited for arbitrary precision arithmetic.</p>

<p>You've pretty much covered all the reasons:</p>

<ul>
<li>No carry-propagation support.</li>
<li>No 128-bit integer add/sub.</li>
<li>No 64 x 64-bit integer multiply. (low or high...)</li>
<li>AVX only supports 128-bit wide integer SIMD. (AVX2 will have 256-bit)</li>
</ul>

<p>The first three of these are pretty much the deal breakers for bignum arithmetic on SSE.</p>

<hr>

<p>On the other hand, the normal integer instructions (via general-purpose registers) are well suited.</p>

<ul>
<li>Add with carry: <code>adc</code>, <code>sbb</code></li>
<li>64 x 64-bit multiply (high and low)</li>
</ul>

<p>So for the foreseeable future, SSE/AVX (or SIMD in general) is not likely to be helpful.</p>

<p>Many have tried and failed to make SSE useful for bignums... it's not happening anytime soon.</p>

<hr>

<p>There is one exception though. For very large sizes, <a href=""http://numbers.computation.free.fr/Constants/Algorithms/fft.html"">large multiplications can be done using floating-point FFTs</a>. Those are very vectorizable and actually do benefit from SSE/AVX.</p>

<p>Otherwise, SSE/AVX is pretty much limited to mem-copies and other data-movement.</p>

<hr>

<p><strong>EDIT + Disclosure:</strong></p>

<p>I'm actually the author of <a href=""http://www.numberworld.org/y-cruncher/"">y-cruncher</a>. So I do have a bit of experience in this area.</p>
"
"<p>Alright, so I have a huge number <code>f</code>. This number is just over 100 digits long, actually. I know that the factors are of approximately the same size.</p>

<p>If I have limited resources and time, what language and algorithm should I use? I am including the length of time to code the algorithm in the restricted time.</p>

<p>Thoughts?</p>

<p>EDIT: By limited, I mean in the least amount of time possible.</p>
","922184","","<p>The state-of-the-art prime factorization algorithm is the <a href=""http://en.wikipedia.org/wiki/Quadratic_sieve"" rel=""nofollow"">quadratic sieve</a> and its variants. For numbers larger than 100 digits, the <a href=""http://en.wikipedia.org/wiki/Number_field_sieve"" rel=""nofollow"">number sieve</a> becomes more efficient.</p>

<p>There's an open-source implementation of it <a href=""http://www.boo.net/~jasonp/qs.html"" rel=""nofollow"">here</a>. It's able to factor a 100 digit number into two roughly equal primes in only <a href=""http://en.wikipedia.org/wiki/RSA_numbers#RSA-100"" rel=""nofollow"">4 hours on a 2.2 GHz AMD Althon</a>.</p>

<p>So there's the algorithm and a sample implementation. That might be enough to give you ideas or get you started.</p>
"
"<p>Hi to all C coders.</p>

<p>Having looked first for similar questions like mine I couldn't find ones.</p>

<p>How to fetch/compare 4bytes in a portable way (without memcpy/memcmp of course)?</p>

<p>I have never learned C and because of that I am a living proof that without knowing the basics everything becomes a nasty mess afterwards.
Anyway, writing words (already) is no time to say 'start with the alphabet'.</p>

<pre><code>    ulHashPattern = *(unsigned long *)(pbPattern);
        for (a=0; a &lt; ASIZE; a++) bm_bc[a]=cbPattern;
        for (j=0; j &lt; cbPattern-1; j++) bm_bc[pbPattern[j]]=cbPattern-j-1;
        i=0;
        while (i &lt;= cbTarget-cbPattern) {
            if ( *(unsigned long *)&amp;pbTarget[i] == ulHashPattern ) {
</code></pre>

<p>The above fragment works as it must on Windows 32bit compiler. My desire is all such 4vs4 comparisons to work under 64bit Windows and Linux as well.
Many times I need 2,4,8 bytes transfers, in above example I need explicitly 4bytes from some pbTarget offset. <em>Here the actual question: what type should I use instead of <strong>unsigned long</strong>?</em> (I guess something close to UINT16,UINT32,UINT64 will do). <em>In other words, what 3 types I need in order to represent 2,4,8 bytes <strong>ALWAYS</strong> independently from the environment.</em></p>

<p>I believe this basic question causes a lot of troubles, so it should be clarified.</p>

<p>Add-on 2012-Jan-16:</p>

<p>@Richard J. Ross III<br>
I am double-confused! Since I don't know whether Linux uses 1] or 2] i.e. is _STD_USING defined in Linux,
in other words which group is portable the types uint8_t,...,uint64_t or the _CSTD uint8_t,...,_CSTD uint64_t?</p>

<p>1] An excerpt from MVS 10.0 stdint.h</p>

<pre><code>typedef unsigned char uint8_t;
typedef unsigned short uint16_t;
typedef unsigned int uint32_t;
typedef _ULonglong uint64_t;
</code></pre>

<p>2] An excerpt from MVS 10.0 stdint.h</p>

<pre><code> #if defined(_STD_USING)
...
using _CSTD uint8_t; using _CSTD uint16_t;
using _CSTD uint32_t; using _CSTD uint64_t;
...
</code></pre>

<p>With Microsoft C 32bit there is no problem:</p>

<pre><code>; 3401 :           if ( *(_CSTD uint32_t *)&amp;pbTarget[i] == *(_CSTD uint32_t *)(pbPattern) )

  01360 8b 04 19     mov     eax, DWORD PTR [ecx+ebx]
  01363 8b 7c 24 14  mov     edi, DWORD PTR _pbPattern$GSCopy$[esp+1080]
  01367 3b 07        cmp     eax, DWORD PTR [edi]
  01369 75 2c        jne     SHORT $LN80@Railgun_Qu@6
</code></pre>

<p>But when 64bit is the targeted code, that is what happens:</p>

<pre><code>D:\_KAZE_Simplicius_Simplicissimus_Septupleton_r2-_strstr_SHORT-SHOWDOWN_r7&gt;cl /Ox /Tcstrstr_SHORT-SHOWDOWN.c /Fastrstr_SHORT-SHOWDOWN /w /FAcs
Microsoft (R) C/C++ Optimizing Compiler Version 15.00.30729.01 for x64
Copyright (C) Microsoft Corporation.  All rights reserved.

strstr_SHORT-SHOWDOWN.c
strstr_SHORT-SHOWDOWN.c(1925) : fatal error C1083: Cannot open include file: 'stdint.h': No such file or directory

D:\_KAZE_Simplicius_Simplicissimus_Septupleton_r2-_strstr_SHORT-SHOWDOWN_r7&gt;
</code></pre>

<p>How about Linux' stdint.h, is it always presented?</p>

<p>I didn't give up and commented it: <code>//#include &lt;stdint.h&gt;</code>, then compilation went ok:</p>

<pre><code>; 3401 :           if ( !memcmp(&amp;pbTarget[i], &amp;ulHashPattern, 4) ) 
  01766 49 63 c4     movsxd  rax, r12d
  01769 42 39 2c 10  cmp     DWORD PTR [rax+r10], ebp
  0176d 75 38        jne     SHORT $LN1@Railgun_Qu@6

; 3401 :           if ( *(unsigned long *)&amp;pbTarget[i] == ulHashPattern ) 
  01766 49 63 c4     movsxd  rax, r12d
  01769 42 39 2c 10  cmp     DWORD PTR [rax+r10], ebp
  0176d 75 38        jne     SHORT $LN1@Railgun_Qu@6
</code></pre>

<p>This very 'unsigned long *' troubles me since gcc -m64 will fetch a QWORD not DWORD, right?</p>

<p>@Mysticial<br>
Just wanted to show the three different translations done by Microsoft CL 32bit v16:<br>
1]</p>

<pre><code>; 3400 :           if ( !memcmp(&amp;pbTarget[i], pbPattern, 4) )
  01360 8b 04 19     mov     eax, DWORD PTR [ecx+ebx]
  01363 8b 7c 24 14  mov     edi, DWORD PTR _pbPattern$GSCopy$[esp+1080]
  01367 3b 07        cmp     eax, DWORD PTR [edi]
  01369 75 2c        jne     SHORT $LN84@Railgun_Qu@6
</code></pre>

<p>2]  </p>

<pre><code>; 3400 :           if ( !memcmp(&amp;pbTarget[i], &amp;ulHashPattern, 4) )
  01350 8b 44 24 14  mov     eax, DWORD PTR _ulHashPattern$[esp+1076]
  01354 39 04 2a     cmp     DWORD PTR [edx+ebp], eax
  01357 75 2e        jne     SHORT $LN83@Railgun_Qu@6
</code></pre>

<p>3]  </p>

<pre><code>; 3401 :           if ( *(uint32_t *)&amp;pbTarget[i] == ulHashPattern )
  01350 8b 44 24 14  mov     eax, DWORD PTR _ulHashPattern$[esp+1076]
  01354 39 04 2a     cmp     DWORD PTR [edx+ebp], eax
  01357 75 2e        jne     SHORT $LN79@Railgun_Qu@6
</code></pre>

<p>The initial goal was to extract (with a single mov instruction respectively *(uint32_t *)&amp;pbTarget[i]) and compare 4bytes versus a register variable 4bytes in length i.e. one RAM access one comparision in a single instruction.
Nastily I managed only to reduce the memcmp()'s 3 RAM accesses (applied on pbPattern which points to 4 or more bytes) down to 2, thankfully to the inlining.
Now if I want to use memcmp() on first 4bytes of pbPattern (as in 2]) ulHashPattern should be not of type register, whereas 3] needs not such a restriction.</p>

<pre><code>; 3400 :           if ( !memcmp(&amp;pbTarget[i], &amp;ulHashPattern, 4) )
</code></pre>

<p>The line above gives an error (ulHashPattern is defined as: register unsigned long ulHashPattern; ):</p>

<pre><code>strstr_SHORT-SHOWDOWN.c(3400) : error C2103: '&amp;' on register variable
</code></pre>

<p>Yes, you are right: memcmp() saves the situation (but with a limitation) - the fragment 2] is identical to 3] mine dirty style.
Obviously my inclination not to use a function when it might be manually coded is a thing of the past but I like it.  </p>

<p>Still I am not fully happy from the compilers, I have defined ulHashPattern as a register variable but it is loaded each time from RAM?! Maybe I miss something but this very (mov eax, DWORD PTR _ulHashPattern$[esp+1076]) line degrades performance - an ugly code in my view.</p>
","922184","","<p>To be strictly pedantic, the only type you can use is <code>char</code>. This is because you are <a href=""http://stackoverflow.com/questions/98650/what-is-the-strict-aliasing-rule"">violating strict-aliasing</a> with the following type-puns:</p>

<pre><code>*(unsigned long *)(pbPattern);
*(unsigned long *)&amp;pbTarget[i]
</code></pre>

<p><code>char*</code> is the sole exception to this rule as you can alias any data-type with <code>char*</code>.</p>

<p>If you turn up your warnings on GCC, you should be getting strict-aliasing warning with your code-snippet. (AFAIK, MSVC doesn't warn about strict-aliasing.)</p>

<hr>

<p>I can't quite tell exactly what you are trying to do in that code-snippet, but the idea still holds, you should not be using <code>unsigned long</code> or any other data-type to load and compare larger chunks of data that are of different types.</p>

<p>In all reality, you really should be using <code>memcmp()</code>, as it's straight-forward and will let you bypass the inefficiencies of forcing everything down to a <code>char*</code>.</p>

<p>Is there a reason you can't use <code>memcmp()</code>?</p>

<hr>

<p>If you're OK with violating strict-aliasing, you can use the fixed integer types (such as <code>uint32_t</code>) defined in <code>&lt;stdint.h&gt;</code>. However, be aware that these are fixed to the # of bits rather than the # of bytes.</p>
"
"<p>The code below should take the input, store it then display LEDs that give the number as a display. However it gives random LEDs, not the correct one. I've checked a few things but I can't see what's wrong, can you help?</p>

<pre><code>#include &lt;stdio.h&gt;

int main( void )
{
   /* Declare a data variable for each pixel. */
   int a1, a2, a3, a4, a5 =0;
   int b1, b2, b3, b4, b5 =0;
   int c1, c2, c3, c4, c5 =0;
   int d1, d2, d3, d4, d5 =0;
   int e1, e2, e3, e4, e5 =0;
   int f1, f2, f3, f4, f5 =0;
   int g1, g2, g3, g4, g5 =0;
   int h1, h2, h3, h4, h5 =0;
   int i1, i2, i3, i4, i5 =0;
   int j1, j2, j3, j4, j5 =0;
   int k1, k2, k3, k4, k5 =0;
   int l1, l2, l3, l4, l5 =0;


   /* Collect the data from stdin and store in a string */

      char str[6];
      scanf(""%s"", str);
      int a = str[0] - '0';
      int b = str[1] - '0';
      int c = str[2] - '0';
      int d = str[3] - '0';

   /* Change the pixels to store the shape of the numbers to be displayed */   

      switch ( a ) {
      case 0:
        a1, b1, c1, a2, c2, a3, c3, a4, c4, a5, b5, c5 = 1;
        break;
      case 1:
        c1, c2, c3, c4, c5 = 1;
        break;
      case 2:
        a1, b1, c1, c2, a3, b3, c3, a4, a5, b5, c5 = 1;
        break;
      case 3:
        a1, b1, c1, c2, a3, b3, c3, c4, a5, b5, c5 = 1;
        break;
      case 4:
        a1, c1, a2, c2, a3, b3, c3, b4, b5 = 1;
        break;
      case 5:
        a1, b1, c1, a2, a3, b3, c3, c4, a5, b5, c5 = 1;
        break;
      case 6:
        a1, b1, c1, a2, a3, b3, c3, a4, c4, a5, b5, c5 = 1;
        break;
      case 7:
        a1, b1, c1, c2, c3, c4, c5 = 1;
        break;
      case 8:
        a1, b1, c1, a2, c2, a3, b3, c3, a4, c4, a5, b5, c5 = 1;
        break;
      case 9:
        a1, b1, c1, a2, c2, a3, b3, c3, c4, c5 = 1;
        break; 
      default:
        printf(""Please input a valid number"");
        return 0;
          break;
}

switch ( b ) {
      case 0:
        d1, e1, f1, d2, f2, d3, f3, d4, f4, d5, e5, f5 = 1;
        break;
      case 1:
        f1, f2, f3, f4, f5 = 1;
        break;
      case 2:
        d1, e1, f1, f2, d3, e3, f3, d4, d5, e5, f5 = 1;
        break;
      case 3:
        d1, e1, f1, f2, d3, e3, f3, f4, d5, e5, f5 = 1;
        break;
      case 4:
        d1, f1, d2, f2, d3, e3, f3, e4, e5 = 1;
        break;
      case 5:
        d1, e1, f1, d2, d3, e3, f3, f4, d5, e5, f5 = 1;
        break;
      case 6:
        d1, e1, f1, d2, d3, e3, f3, d4, f4, d5, e5, f5 = 1;
        break;
      case 7:
        d1, e1, f1, f2, f3, f4, f5 = 1;
        break;
      case 8:
        d1, e1, f1, d2, f2, d3, e3, f3, d4, f4, d5, e5, f5 = 1;
        break;
      case 9:
        d1, e1, f1, d2, f2, d3, e3, f3, f4, f5 = 1;
        break; 
      default:
        printf(""Please input a valid number"");
        return 0;
          break;
}

switch ( c ) {
      case 0:
        g1, h1, i1, g2, i2, g3, i3, g4, i4, g5, h5, i5 = 1;
        break;
      case 1:
        i1, i2, i3, i4, i5 = 1;
        break;
      case 2:
        g1, h1, i1, i2, g3, h3, i3, g4, g5, h5, i5 = 1;
        break;
      case 3:
        g1, h1, i1, i2, g3, h3, i3, i4, g5, h5, i5 = 1;
        break;
      case 4:
        g1, i1, g2, i2, g3, h3, i3, h4, h5 = 1;
        break;
      case 5:
        g1, h1, i1, g2, g3, h3, i3, i4, g5, h5, i5 = 1;
        break;
      case 6:
        g1, h1, i1, g2, g3, h3, i3, g4, i4, g5, h5, i5 = 1;
        break;
      case 7:
        g1, h1, i1, i2, i3, i4, i5 = 1;
        break;
      case 8:
        g1, h1, i1, g2, i2, g3, h3, i3, g4, i4, g5, h5, i5 = 1;
        break;
      case 9:
        g1, h1, i1, g2, i2, g3, h3, i3, i4, i5 = 1;
        break; 
      default:
        printf(""Please input a valid number"");
        return 0;
          break;
}

switch ( d ) {
      case 0:
        j1, k1, l1, j2, l2, j3, l3, j4, l4, j5, k5, l5 = 1;
        break;
      case 1:
        l1, l2, l3, l4, l5 = 1;
        break;
      case 2:
        j1, k1, l1, l2, j3, k3, l3, j4, j5, k5, l5 = 1;
        break;
      case 3:
        j1, k1, l1, l2, j3, k3, l3, l4, j5, k5, l5 = 1;
        break;
      case 4:
        j1, l1, j2, l2, j3, k3, l3, k4, k5 = 1;
        break;
      case 5:
        j1, k1, l1, j2, j3, k3, l3, l4, j5, k5, l5 = 1;
        break;
      case 6:
        j1, k1, l1, j2, j3, k3, l3, j4, l4, j5, k5, l5 = 1;
        break;
      case 7:
        j1, k1, l1, l2, l3, l4, l5 = 1;
        break;
      case 8:
        j1, k1, l1, j2, l2, j3, k3, l3, j4, l4, j5, k5, l5 = 1;
        break;
      case 9:
        j1, k1, l1, j2, l2, j3, k3, l3, l4, l5 = 1;
        break; 
      default:
        printf(""Please input a valid number"");
        return 0;
          break;
}

      /* Display the pixels in the correct order */

         if (a1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (b1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (c1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (d1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (e1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (f1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (g1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (h1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (i1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (j1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (k1 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (l1 == 1 )
            printf(""O\n"");
         else
            printf("" \n"");

         if (a2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (b2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (c2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (d2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (e2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (f2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (g2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (h2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (i2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (j2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (k2 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (l2 == 1 )
            printf(""O\n"");
         else
            printf("" \n"");

         if (a3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (b3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (c3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (d3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (e3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (f3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (g3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (h3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (i3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (j3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (k3 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (l3 == 1 )
            printf(""O\n"");
         else
            printf("" \n"");

         if (a4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (b4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (c4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (d4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (e4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (f4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (g4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (h4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (i4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (j4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (k4 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (l4 == 1 )
            printf(""O\n"");
         else
            printf("" \n"");

         if (a5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (b5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (c5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (d5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (e5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (f5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (g5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (h5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (i5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (j5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (k5 == 1 )
            printf(""O"");
         else
            printf("" "");

         if (l5 == 1 )
            printf(""O"");
         else
            printf("" "");
}
</code></pre>
","922184","","<p>For each of these things:</p>

<pre><code>c1, c2, c3, c4, c5 = 1;
</code></pre>

<p>If you're trying to set them all to 1. You need to do it like this:</p>

<pre><code>c1 = 1;
c2 = 1;
c3 = 1;
c4 = 1;
c5 = 1;
</code></pre>

<p>or alternatively:</p>

<pre><code>c1 = c2 = c3 = c4 = c5 = 1;
</code></pre>

<p>In other words, you need to set each one individually.</p>

<p><strong>That said, you should be using arrays to do this instead.</strong></p>
"
"<pre><code>void openUpNow(FILE *x, FILE *y)
{
    x = fopen(""xwhatever"", ""r"");
    y = fopen(""ywhatever"", ""r"");
}

int _tmain(int argc,  _TCHAR* argv[ ])
{   
    FILE *x, *y;

    openUpNow(x, y);
}
</code></pre>

<p>warning C4700: uninitialized local variable 'x' used</p>

<p>warning C4700: uninitialized local variable 'y' used</p>

<p>Remedy?</p>
","922184","","<p>I don't think that's what you want to do anyway.</p>

<p>Assuming you want <code>openUpNow()</code> to open the files into <code>x</code> and <code>y</code> you should use:</p>

<pre><code>void openUpNow(FILE **x, FILE **y)
{
    *x = fopen(""xwhatever"", ""r"");
    *y = fopen(""ywhatever"", ""r"");
}

int _tmain(int argc,  _TCHAR* argv[ ])
{   
    FILE *x, *y;

    openUpNow(&amp;x, &amp;y);

    //  do stuff


}
</code></pre>

<p>In other words, you need to pass the address of the pointers <code>x</code> and <code>y</code> into the function.</p>

<p>As your code is right now, the call to <code>openUpNow()</code> doesn't do anything (and leaks the file-handles) since pointers are passed by value.</p>
"
"<p>I'm new to C so please correct any mistakes I have.</p>

<p>Here's some code that's sort of like the code I have</p>

<pre><code>//typdef stuff for apple, *apple_t here
apple_t get() {
    apple a;
    a.num = 0;

    apple_t ap = &amp;a;
    printf(""set num to %d\n"", ap-&gt;num);
    return ap;
}

// ap above is placed into read(ap)
void read(apple_t ap) {
    printf(""num: %d\n"", ap-&gt;num);
}
</code></pre>

<p>Why is it that for the ""set"" print ap->num == 0, but when I do the printf in read function
I get some junk number like -1218550893?  What's going on? Is the integer set being freed?  What is C doing? And how do you fix this?</p>
","922184","","<p>You are returning the address of a local variable.</p>

<p>In this case the variable <code>a</code> is a local variable. It is lost after the function ends.</p>

<p>There are two options to fix this:</p>

<ol>
<li>Return it by value. Don't return its address.</li>
<li>Allocate memory for it using <code>malloc()</code>. But you must be sure to <code>free()</code> it later.</li>
</ol>
"
"<p>In general I know why you get this error, but I'm a little confused in this particular instance...</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

char* mystrncpy(char* dst, const char* src, size_t n) {
    char* temp = dst;

    while (n-- &gt; 0 &amp;&amp; (*temp = *src)) {
        temp++;
        src++;
    }

    return dst;
}

int main() {
    const char* str = ""Hello World!"";
    char buf[50];
    memset(buf, 0, sizeof(buf));
    mystrncpy(buf, str, sizeof(buf));
    printf(""%s\n"", buf);
}
</code></pre>

<p>The code above works great, but if I remove the extra set of brackets changing the while loop to:</p>

<pre><code>while (n-- &gt; 0 &amp;&amp; *temp = *src)
</code></pre>

<p>Then I get the error.  I guess it's something about operator precedence but I'm a little baffled.  Can someone explain what that while loop alteration does to make this compiler error appear?</p>
","922184","","<p>Yes, it's about precedence.</p>

<p><code>=</code> has lower precedence than <code>&amp;&amp;</code>. Therefore, the latter case parses as:</p>

<pre><code>while ((n-- &gt; 0 &amp;&amp; *temp) = *src)
</code></pre>

<p>And of course <code>(n-- &gt; 0 &amp;&amp; *temp)</code> is not an l-value.</p>

<p><strike>Are you sure you didn't intend to use <code>==</code> instead of <code>=</code>?</strike></p>
"
"<p>Is that a valid expression? If so, can you rewrite it so that it makes more sense? For example, is it the same as <code>(4 &gt; y &amp;&amp; y &gt; 1)</code>? How do you evaluate chained logical operators?</p>
","922184","","<p>The statement <code>(4 &gt; y &gt; 1)</code> is parsed as this:</p>

<pre><code>((4 &gt; y) &gt; 1)
</code></pre>

<p>The comparison operators <code>&lt;</code> and <code>&gt;</code> <a href=""http://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B#Operator_precedence"">evaluate left-to-right</a>.</p>

<p>The <code>4 &gt; y</code> returns either <code>0</code> or <code>1</code> depending on if it's true or not.</p>

<p>Then the result is compared to 1.</p>

<p>In this case, since <code>0</code> or <code>1</code> is never more than <code>1</code>, the <strong>whole statement will always return false</strong>.</p>

<hr>

<p><strong>There is one exception though:</strong></p>

<p>If <code>y</code> is a class and the <code>&gt;</code> operator has been overloaded to do something unusual. Then anything goes.</p>

<p>For example, this will fail to compile:</p>

<pre><code>class mytype{
};

mytype operator&gt;(int x,const mytype &amp;y){
    return mytype();
}

int main(){

    mytype y;

    cout &lt;&lt; (4 &gt; y &gt; 1) &lt;&lt; endl;

    return 0;
}
</code></pre>
"
"<p>I'm looking to for a reasonably efficient way of determining if a floating point value (<code>double</code>)  can be exactly represented by an integer data type (<code>long</code>, 64 bit).</p>

<p>My initial thought was to check the exponent to see if it was <code>0</code> (or more precisely <code>127</code>).  But that won't work because <code>2.0</code> would be e=1 m=1...</p>

<p>So basically, I am stuck.  I have a feeling that I can do this with bit masks, but I'm just not getting my head around how to do that at this point.</p>

<p>So how can I check to see if a double is exactly representable as a long?</p>

<p>Thanks</p>
","922184","","<p>Here's one method that could work in most cases. I'm not sure if/how it will break if you give it <code>NaN</code>, <code>INF</code>, very large (overflow) numbers...
<br>(Though I think they will all return false - not exactly representable.)</p>

<p>You could:</p>

<ol>
<li>Cast it to an integer.</li>
<li>Cast it back to a floating-point.</li>
<li>Compare with original value.</li>
</ol>

<p>Something like this:</p>

<pre><code>double val = ... ;  //  Value

if ((double)(long long)val == val){
    //  Exactly representable
}
</code></pre>

<p><code>floor()</code> and <code>ceil()</code> are also fair game (though they may fail if the value overflows an integer):</p>

<pre><code>floor(val) == val
ceil(val) == val
</code></pre>

<hr>

<p><strong>And here's a messy bit-mask solution:</strong><br>
(<strong>Warning:</strong> Not fully tested. And it uses union type-punning. So it's not completely compliant.)</p>

<pre><code>int representable(double x){

    //  Warning!!! Not fully C-compliant!
    union{
        double f;
        uint64_t i;
    } val;

    val.f = x;

    uint64_t exp = val.i &amp; 0x7ff0000000000000ull;
    uint64_t man = val.i &amp; 0x000fffffffffffffull;
    man |= 0x0010000000000000ull;  //  Implicit leading 1-bit.

    int shift = (exp &gt;&gt; 52) - 1075;

    //  Out of range
    if (shift &lt; -63 || shift &gt; 63)
        return 0;

    //  Test mantissa
    if (shift &lt; 0){
        shift = -shift;
        return ((man &gt;&gt; shift) &lt;&lt; shift) == man;
    }else{
        return ((man &lt;&lt; shift) &gt;&gt; shift) == man;
    }
}
</code></pre>
"
"<p>Teaching myself C and finding that when I do an equation for a temp conversion it won't work unless I change the fraction to a decimal. ie,</p>

<p><code>tempC=(.555*(tempF-32))</code>  will work but <code>tempC=((5/9)*(tempF-32))</code>  won't work. </p>

<p>Why?<br>
According to C Primer Plus it should work as I'm using floats for both tempC and tempF.</p>
","922184","","<p>It looks like you have integer division in the second case:</p>

<pre><code>tempC=((5/9)*(tempF-32))
</code></pre>

<p>The <code>5 / 9</code> will get truncated to zero.</p>

<p>To fix that, you need to make one of them a floating-point type:</p>

<pre><code>tempC=((5./9.)*(tempF-32))
</code></pre>
"
"<p>why is the Double.parseDouble making <code>9999999999999999</code> to <code>10000000000000000</code> ?
For Example :</p>

<pre><code>Double d =Double.parseDouble(""9999999999999999"");
String b= new DecimalFormat(""#.##"").format(d);
System.out.println(b);
</code></pre>

<p>IS Printing </p>

<pre><code>10000000000000000
</code></pre>

<p>instead it has to show <code>9999999999999999</code> or <code>9999999999999999.00</code></p>

<p>Any sort of help is greatly appreciated.</p>
","922184","","<p>The number <code>9999999999999999</code> is just above the precision limit of double-precision floating-point. In other words, the 53-bit mantissa is not able to hold <code>9999999999999999</code>.</p>

<p>So the result is that it is rounded to the nearest double-precision value - which is <code>10000000000000000</code>.</p>

<pre><code> 9999999999999999 = 0x2386f26fc0ffff  // 54 significant bits needed
10000000000000000 = 0x2386f26fc10000  // 38 significant bits needed
</code></pre>
"
"<p>The following is a simple loop in C++. The timer is using QueryPerformanceCounter() and is quite accurate. I found Java to take 60% of the time C++ takes and this can't be?! What am I doing wrong here? Even strict aliasing (which is not included in the code here) doesn't help at all...</p>

<pre><code>long long var = 0;
std::array&lt;int, 1024&gt; arr;
int* arrPtr = arr.data();
CHighPrecisionTimer timer;

for(int i = 0; i &lt; 1024; i++) arrPtr[i] = i;

timer.Start();

for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
    for(int x = 0; x &lt; 1024; x++){
        var += arrPtr[x];
    }
}

timer.Stop();

printf(""Unrestricted: %lld us, Value = %lld\n"", (Int64)timer.GetElapsed().GetMicros(), var);
</code></pre>

<p>This C++ runs through in about 9.5 seconds. I am using the Intel Compiler 12.1 with host processor optimization (specifically for mine) and everything maxed. So this is Intel Compiler at its best! Auto-Parallelization funnily consumes 70% CPU instead of 25% but doesn't get the job done any faster ;)...</p>

<p>Now I use the following Java code for comparison:</p>

<pre><code>    long var = 0;
    int[] arr = new int[1024];

    for(int i = 0; i &lt; 1024; i++) arr[i] = i;

    for(int i = 0; i &lt; 1024 * 1024; i++){
        for(int x = 0; x &lt; 1024; x++){
            var += arr[x];
        }
    }

    long nanos = System.nanoTime();

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
        for(int x = 0; x &lt; 1024; x++){
            var += arr[x];
        }
    }

    nanos = (System.nanoTime() - nanos) / 1000;

    System.out.print(""Value: "" + var + "", Time: "" + nanos);
</code></pre>

<p>The Java code is invoked with aggressive optimization and the server VM (no debug). It runs in about 7 seconds on my machine (only uses one thread).</p>

<p>Is this a failure of the Intel Compiler or am I just too dumb again?</p>

<p>[EDIT]: Ok now heres the thing... Seems more like a bug in the Intel compiler ^^. 
[Please note that I am running on the Intel Quadcore Q6600, which is rather old. And it might be that the Intel Compiler performs way better on recent CPUs, like Core i7]</p>

<pre><code>Intel x86 (without vectorization): 3 seconds
MSVC x64: 5 seconds
Java x86/x64 (Oracle Java 7): 7 seconds
Intel x64 (with vectorization): 9.5 seconds
Intel x86 (with vectorization): 9.5 seconds
Intel x64 (without vectorization): 12 seconds
MSVC x86: 15 seconds (uhh)
</code></pre>

<p>[EDIT]: Another nice case ;). Consider the following trivial lambda expression</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;tchar.h&gt;
#include &lt;Windows.h&gt;
#include &lt;vector&gt;
#include &lt;boost/function.hpp&gt;
#include &lt;boost/lambda/bind.hpp&gt;
#include &lt;boost/typeof/typeof.hpp&gt;

template&lt;class TValue&gt;
struct ArrayList
{
private:
    std::vector&lt;TValue&gt; m_Entries;
public:

    template&lt;class TCallback&gt;
    void Foreach(TCallback inCallback)
    {
        for(int i = 0, size = m_Entries.size(); i &lt; size; i++)
        {
            inCallback(i);
        }
    }

    void Add(TValue inValue)
    {
        m_Entries.push_back(inValue);
    }
};

int _tmain(int argc, _TCHAR* argv[])
{
    auto t = [&amp;]() {};


    ArrayList&lt;int&gt; arr;
    int res = 0;

    for(int i = 0; i &lt; 100; i++)
    {
        arr.Add(i);
    }

    long long freq, t1, t2;

    QueryPerformanceFrequency((LARGE_INTEGER*)&amp;freq);
    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t1);

    for(int i = 0; i &lt; 1000 * 1000 * 10; i++)
    {
        arr.Foreach([&amp;](int v) {
            res += i;
        });
    }

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t2);

    printf(""Time: %lld\n"", ((t2-t1) * 1000000) / freq);

    if(res == 4950)
        return -1;

    return 0;
}
</code></pre>

<p>Intel compiler shines again:</p>

<pre><code>MSVC x86/x64: 12 milli seconds
Intel x86/x64: 1 second
</code></pre>

<p>Uhm?! Well, I guess 90 times slower is not a bad thing...</p>

<p>I am not really sure anymore that this applies:
<em>Okay and based on an answer to this thread: The intel compiler is known (and I knew that too but I just didn't think about that they could drop support for their processors) to have terrible performance on processors which are not ""known"" to the compiler, like AMD processors, and maybe even outdated Intel processors like mine... So if someone with a recent Intel processor could try this out it would be nice ;).</em> </p>

<p>Here is the x64 output of the Intel Compiler:</p>

<pre><code>    std::array&lt;int, 1024&gt; arr;
    int* arrPtr = arr.data();
    QueryPerformanceFrequency((LARGE_INTEGER*)&amp;freq);
000000013F05101D  lea         rcx,[freq]  
000000013F051022  call        qword ptr [__imp_QueryPerformanceFrequency (13F052000h)]  

    for(int i = 0; i &lt; 1024; i++) arrPtr[i] = i;
000000013F051028  mov         eax,4  
000000013F05102D  movd        xmm0,eax  
000000013F051031  xor         eax,eax  
000000013F051033  pshufd      xmm1,xmm0,0  
000000013F051038  movdqa      xmm0,xmmword ptr [__xi_z+28h (13F0521A0h)]  
000000013F051040  movdqa      xmmword ptr arr[rax*4],xmm0  
000000013F051046  paddd       xmm0,xmm1  
000000013F05104A  movdqa      xmmword ptr [rsp+rax*4+60h],xmm0  
000000013F051050  paddd       xmm0,xmm1  
000000013F051054  movdqa      xmmword ptr [rsp+rax*4+70h],xmm0  
000000013F05105A  paddd       xmm0,xmm1  
000000013F05105E  movdqa      xmmword ptr [rsp+rax*4+80h],xmm0  
000000013F051067  add         rax,10h  
000000013F05106B  paddd       xmm0,xmm1  
000000013F05106F  cmp         rax,400h  
000000013F051075  jb          wmain+40h (13F051040h)  

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t1);
000000013F051077  lea         rcx,[t1]  
000000013F05107C  call        qword ptr [__imp_QueryPerformanceCounter (13F052008h)]  
            var += arrPtr[x];
000000013F051082  movdqa      xmm1,xmmword ptr [__xi_z+38h (13F0521B0h)]  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
000000013F05108A  xor         eax,eax  
            var += arrPtr[x];
000000013F05108C  movdqa      xmm0,xmmword ptr [__xi_z+48h (13F0521C0h)]  
    long long var = 0, freq, t1, t2;
000000013F051094  pxor        xmm6,xmm6  
        for(int x = 0; x &lt; 1024; x++){
000000013F051098  xor         r8d,r8d  
            var += arrPtr[x];
000000013F05109B  lea         rdx,[arr]  
000000013F0510A0  xor         ecx,ecx  
000000013F0510A2  movq        xmm2,mmword ptr arr[rcx]  
        for(int x = 0; x &lt; 1024; x++){
000000013F0510A8  add         r8,8  
            var += arrPtr[x];
000000013F0510AC  punpckldq   xmm2,xmm2  
        for(int x = 0; x &lt; 1024; x++){
000000013F0510B0  add         rcx,20h  
            var += arrPtr[x];
000000013F0510B4  movdqa      xmm3,xmm2  
000000013F0510B8  pand        xmm2,xmm0  
000000013F0510BC  movq        xmm4,mmword ptr [rdx+8]  
000000013F0510C1  psrad       xmm3,1Fh  
000000013F0510C6  punpckldq   xmm4,xmm4  
000000013F0510CA  pand        xmm3,xmm1  
000000013F0510CE  por         xmm3,xmm2  
000000013F0510D2  movdqa      xmm5,xmm4  
000000013F0510D6  movq        xmm2,mmword ptr [rdx+10h]  
000000013F0510DB  psrad       xmm5,1Fh  
000000013F0510E0  punpckldq   xmm2,xmm2  
000000013F0510E4  pand        xmm5,xmm1  
000000013F0510E8  paddq       xmm6,xmm3  
000000013F0510EC  pand        xmm4,xmm0  
000000013F0510F0  movdqa      xmm3,xmm2  
000000013F0510F4  por         xmm5,xmm4  
000000013F0510F8  psrad       xmm3,1Fh  
000000013F0510FD  movq        xmm4,mmword ptr [rdx+18h]  
000000013F051102  pand        xmm3,xmm1  
000000013F051106  punpckldq   xmm4,xmm4  
000000013F05110A  pand        xmm2,xmm0  
000000013F05110E  por         xmm3,xmm2  
000000013F051112  movdqa      xmm2,xmm4  
000000013F051116  paddq       xmm6,xmm5  
000000013F05111A  psrad       xmm2,1Fh  
000000013F05111F  pand        xmm4,xmm0  
000000013F051123  pand        xmm2,xmm1  
        for(int x = 0; x &lt; 1024; x++){
000000013F051127  add         rdx,20h  
            var += arrPtr[x];
000000013F05112B  paddq       xmm6,xmm3  
000000013F05112F  por         xmm2,xmm4  
        for(int x = 0; x &lt; 1024; x++){
000000013F051133  cmp         r8,400h  
            var += arrPtr[x];
000000013F05113A  paddq       xmm6,xmm2  
        for(int x = 0; x &lt; 1024; x++){
000000013F05113E  jb          wmain+0A2h (13F0510A2h)  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
000000013F051144  inc         eax  
000000013F051146  cmp         eax,0A00000h  
000000013F05114B  jb          wmain+98h (13F051098h)  
        }
    }

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t2);
000000013F051151  lea         rcx,[t2]  
000000013F051156  call        qword ptr [__imp_QueryPerformanceCounter (13F052008h)]  

    printf(""Unrestricted: %lld ms, Value = %lld\n"", ((t2-t1)*1000/freq), var);
000000013F05115C  mov         r9,qword ptr [t2]  
    long long var = 0, freq, t1, t2;
000000013F051161  movdqa      xmm0,xmm6  

    printf(""Unrestricted: %lld ms, Value = %lld\n"", ((t2-t1)*1000/freq), var);
000000013F051165  sub         r9,qword ptr [t1]  
000000013F05116A  lea         rcx,[string ""Unrestricted: %lld ms, Value = %""... (13F0521D0h)]  
000000013F051171  imul        rax,r9,3E8h  
000000013F051178  cqo  
000000013F05117A  mov         r10,qword ptr [freq]  
000000013F05117F  idiv        rax,r10  
    long long var = 0, freq, t1, t2;
000000013F051182  psrldq      xmm0,8  

    printf(""Unrestricted: %lld ms, Value = %lld\n"", ((t2-t1)*1000/freq), var);
000000013F051187  mov         rdx,rax  
    long long var = 0, freq, t1, t2;
000000013F05118A  paddq       xmm6,xmm0  
000000013F05118E  movd        r8,xmm6  

    printf(""Unrestricted: %lld ms, Value = %lld\n"", ((t2-t1)*1000/freq), var);
000000013F051193  call        qword ptr [__imp_printf (13F052108h)]  
</code></pre>

<p>And this one is the assembly of the MSVC x64 build:</p>

<pre><code>int _tmain(int argc, _TCHAR* argv[])
{
000000013FF61000  push        rbx  
000000013FF61002  mov         eax,1050h  
000000013FF61007  call        __chkstk (13FF61950h)  
000000013FF6100C  sub         rsp,rax  
000000013FF6100F  mov         rax,qword ptr [__security_cookie (13FF63000h)]  
000000013FF61016  xor         rax,rsp  
000000013FF61019  mov         qword ptr [rsp+1040h],rax  
    long long var = 0, freq, t1, t2;
    std::array&lt;int, 1024&gt; arr;
    int* arrPtr = arr.data();
    QueryPerformanceFrequency((LARGE_INTEGER*)&amp;freq);
000000013FF61021  lea         rcx,[rsp+28h]  
000000013FF61026  xor         ebx,ebx  
000000013FF61028  call        qword ptr [__imp_QueryPerformanceFrequency (13FF62000h)]  

    for(int i = 0; i &lt; 1024; i++) arrPtr[i] = i;
000000013FF6102E  xor         r11d,r11d  
000000013FF61031  lea         rax,[rsp+40h]  
000000013FF61036  mov         dword ptr [rax],r11d  
000000013FF61039  inc         r11d  
000000013FF6103C  add         rax,4  
000000013FF61040  cmp         r11d,400h  
000000013FF61047  jl          wmain+36h (13FF61036h)  

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t1);
000000013FF61049  lea         rcx,[rsp+20h]  
000000013FF6104E  call        qword ptr [__imp_QueryPerformanceCounter (13FF62008h)]  
000000013FF61054  mov         r11d,0A00000h  
000000013FF6105A  nop         word ptr [rax+rax]  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
        for(int x = 0; x &lt; 1024; x++){
000000013FF61060  xor         edx,edx  
000000013FF61062  xor         r8d,r8d  
000000013FF61065  lea         rcx,[rsp+48h]  
000000013FF6106A  xor         r9d,r9d  
000000013FF6106D  mov         r10d,100h  
000000013FF61073  nop         word ptr [rax+rax]  
            var += arrPtr[x];
000000013FF61080  movsxd      rax,dword ptr [rcx-8]  
000000013FF61084  add         rcx,10h  
000000013FF61088  add         rbx,rax  
000000013FF6108B  movsxd      rax,dword ptr [rcx-14h]  
000000013FF6108F  add         r9,rax  
000000013FF61092  movsxd      rax,dword ptr [rcx-10h]  
000000013FF61096  add         r8,rax  
000000013FF61099  movsxd      rax,dword ptr [rcx-0Ch]  
000000013FF6109D  add         rdx,rax  
000000013FF610A0  dec         r10  
000000013FF610A3  jne         wmain+80h (13FF61080h)  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
        for(int x = 0; x &lt; 1024; x++){
000000013FF610A5  lea         rax,[rdx+r8]  
000000013FF610A9  add         rax,r9  
000000013FF610AC  add         rbx,rax  
000000013FF610AF  dec         r11  
000000013FF610B2  jne         wmain+60h (13FF61060h)  
        }
    }

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t2);
000000013FF610B4  lea         rcx,[rsp+30h]  
000000013FF610B9  call        qword ptr [__imp_QueryPerformanceCounter (13FF62008h)]  

    printf(""Unrestricted: %lld ms, Value = %lld\n"", ((t2-t1)*1000/freq), var);
000000013FF610BF  mov         rax,qword ptr [rsp+30h]  
000000013FF610C4  lea         rcx,[string ""Unrestricted: %lld ms, Value = %""... (13FF621B0h)]  
000000013FF610CB  sub         rax,qword ptr [rsp+20h]  
000000013FF610D0  mov         r8,rbx  
000000013FF610D3  imul        rax,rax,3E8h  
000000013FF610DA  cqo  
000000013FF610DC  idiv        rax,qword ptr [rsp+28h]  
000000013FF610E1  mov         rdx,rax  
000000013FF610E4  call        qword ptr [__imp_printf (13FF62138h)]  

    return 0;
000000013FF610EA  xor         eax,eax  
</code></pre>

<p>Intel Compiler configured without Vectorization, 64-Bit, highest optimizations (this is surprisingly slow, 12 seconds):</p>

<pre><code>000000013FC0102F  lea         rcx,[freq]  

    double var = 0; long long freq, t1, t2;
000000013FC01034  xorps       xmm6,xmm6  
    std::array&lt;double, 1024&gt; arr;
    double* arrPtr = arr.data();
    QueryPerformanceFrequency((LARGE_INTEGER*)&amp;freq);
000000013FC01037  call        qword ptr [__imp_QueryPerformanceFrequency (13FC02000h)]  

    for(int i = 0; i &lt; 1024; i++) arrPtr[i] = i;
000000013FC0103D  mov         eax,2  
000000013FC01042  mov         rdx,100000000h  
000000013FC0104C  movd        xmm0,eax  
000000013FC01050  xor         eax,eax  
000000013FC01052  pshufd      xmm1,xmm0,0  
000000013FC01057  movd        xmm0,rdx  
000000013FC0105C  nop         dword ptr [rax]  
000000013FC01060  cvtdq2pd    xmm2,xmm0  
000000013FC01064  paddd       xmm0,xmm1  
000000013FC01068  cvtdq2pd    xmm3,xmm0  
000000013FC0106C  paddd       xmm0,xmm1  
000000013FC01070  cvtdq2pd    xmm4,xmm0  
000000013FC01074  paddd       xmm0,xmm1  
000000013FC01078  cvtdq2pd    xmm5,xmm0  
000000013FC0107C  movaps      xmmword ptr arr[rax*8],xmm2  
000000013FC01081  paddd       xmm0,xmm1  
000000013FC01085  movaps      xmmword ptr [rsp+rax*8+60h],xmm3  
000000013FC0108A  movaps      xmmword ptr [rsp+rax*8+70h],xmm4  
000000013FC0108F  movaps      xmmword ptr [rsp+rax*8+80h],xmm5  
000000013FC01097  add         rax,8  
000000013FC0109B  cmp         rax,400h  
000000013FC010A1  jb          wmain+60h (13FC01060h)  

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t1);
000000013FC010A3  lea         rcx,[t1]  
000000013FC010A8  call        qword ptr [__imp_QueryPerformanceCounter (13FC02008h)]  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
000000013FC010AE  xor         eax,eax  
        for(int x = 0; x &lt; 1024; x++){
000000013FC010B0  xor         edx,edx  
            var += arrPtr[x];
000000013FC010B2  lea         ecx,[rdx+rdx]  
        for(int x = 0; x &lt; 1024; x++){
000000013FC010B5  inc         edx  
        for(int x = 0; x &lt; 1024; x++){
000000013FC010B7  cmp         edx,200h  
            var += arrPtr[x];
000000013FC010BD  addsd       xmm6,mmword ptr arr[rcx*8]  
000000013FC010C3  addsd       xmm6,mmword ptr [rsp+rcx*8+58h]  
        for(int x = 0; x &lt; 1024; x++){
000000013FC010C9  jb          wmain+0B2h (13FC010B2h)  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
000000013FC010CB  inc         eax  
000000013FC010CD  cmp         eax,0A00000h  
000000013FC010D2  jb          wmain+0B0h (13FC010B0h)  
        }
    }

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t2);
000000013FC010D4  lea         rcx,[t2]  
000000013FC010D9  call        qword ptr [__imp_QueryPerformanceCounter (13FC02008h)]  
</code></pre>

<p>Intel Compiler without vectorization, 32-Bit and highest optimization (this one clearly is the winner now, runs in about 3 seconds and the assembly looks much better):</p>

<pre><code>00B81088  lea         eax,[t1]  
00B8108C  push        eax  
00B8108D  call        dword ptr [__imp__QueryPerformanceCounter@4 (0B82004h)]  
00B81093  xor         eax,eax  
00B81095  pxor        xmm0,xmm0  
00B81099  movaps      xmm1,xmm0  
        for(int x = 0; x &lt; 1024; x++){
00B8109C  xor         edx,edx  
            var += arrPtr[x];
00B8109E  addpd       xmm0,xmmword ptr arr[edx*8]  
00B810A4  addpd       xmm1,xmmword ptr [esp+edx*8+40h]  
00B810AA  addpd       xmm0,xmmword ptr [esp+edx*8+50h]  
00B810B0  addpd       xmm1,xmmword ptr [esp+edx*8+60h]  
        for(int x = 0; x &lt; 1024; x++){
00B810B6  add         edx,8  
00B810B9  cmp         edx,400h  
00B810BF  jb          wmain+9Eh (0B8109Eh)  

    for(int i = 0; i &lt; 1024 * 1024 * 10; i++){
00B810C1  inc         eax  
00B810C2  cmp         eax,0A00000h  
00B810C7  jb          wmain+9Ch (0B8109Ch)  

    double var = 0; long long freq, t1, t2;
00B810C9  addpd       xmm0,xmm1  
        }
    }

    QueryPerformanceCounter((LARGE_INTEGER*)&amp;t2);
00B810CD  lea         eax,[t2]  
00B810D1  push        eax  
00B810D2  movaps      xmmword ptr [esp+4],xmm0  
00B810D7  call        dword ptr [__imp__QueryPerformanceCounter@4 (0B82004h)]  
00B810DD  movaps      xmm0,xmmword ptr [esp]
</code></pre>
","922184","","<p>tl;dr: What you're seeing here seems to be <strong>ICC's failed attempt at vectorizing the loop</strong>.</p>

<p><strong>Let's start with MSVC x64:</strong></p>

<p>Here's the critical loop:</p>

<pre><code>$LL3@main:
movsxd  rax, DWORD PTR [rdx-4]
movsxd  rcx, DWORD PTR [rdx-8]
add rdx, 16
add r10, rax
movsxd  rax, DWORD PTR [rdx-16]
add rbx, rcx
add r9, rax
movsxd  rax, DWORD PTR [rdx-12]
add r8, rax
dec r11
jne SHORT $LL3@main
</code></pre>

<p>What you see here is the standard loop unrolling by the compiler. MSVC is unrolling to 4 iterations, and splitting the <code>var</code> variable across four registers: <code>r10</code>, <code>rbx</code>, <code>r9</code>, and <code>r8</code>. Then at the end of the loop, these 4 registers are summed up back together.</p>

<p>Here's where the 4 sums are recombined:</p>

<pre><code>lea rax, QWORD PTR [r8+r9]
add rax, r10
add rbx, rax
dec rdi
jne SHORT $LL6@main
</code></pre>

<p><strong>Note that MSVC currently does not do automatic vectorization.</strong></p>

<hr>

<p><strong>Now let's look at part of your ICC output:</strong></p>

<pre><code>000000013F0510A2  movq        xmm2,mmword ptr arr[rcx]  
000000013F0510A8  add         r8,8  
000000013F0510AC  punpckldq   xmm2,xmm2  
000000013F0510B0  add         rcx,20h  
000000013F0510B4  movdqa      xmm3,xmm2  
000000013F0510B8  pand        xmm2,xmm0  
000000013F0510BC  movq        xmm4,mmword ptr [rdx+8]  
000000013F0510C1  psrad       xmm3,1Fh  
000000013F0510C6  punpckldq   xmm4,xmm4  
000000013F0510CA  pand        xmm3,xmm1  
000000013F0510CE  por         xmm3,xmm2  
000000013F0510D2  movdqa      xmm5,xmm4  
000000013F0510D6  movq        xmm2,mmword ptr [rdx+10h]  
000000013F0510DB  psrad       xmm5,1Fh  
000000013F0510E0  punpckldq   xmm2,xmm2  
000000013F0510E4  pand        xmm5,xmm1  
000000013F0510E8  paddq       xmm6,xmm3  

...
</code></pre>

<p>What you're seeing here is an attempt by ICC to vectorize this loop. This is done in a similar manner as what MSVC did (splitting into multiple sums), but using SSE registers instead and with two sums per register.</p>

<p><strong>But it turns out that the overhead of vectorization happens to outweigh the benefits of vectorizing.</strong></p>

<p>If we walk these instructions down one-by-one, we can see how ICC tries to vectorize it:</p>

<pre><code>//  Load two ints using a 64-bit load.  {x, y, 0, 0}
movq        xmm2,mmword ptr arr[rcx]  

//  Shuffle the data into this form.
punpckldq   xmm2,xmm2           xmm2 = {x, x, y, y}
movdqa      xmm3,xmm2           xmm3 = {x, x, y, y}

//  Mask out index 1 and 3.
pand        xmm2,xmm0           xmm2 = {x, 0, y, 0}

//  Arithmetic right-shift to copy sign-bit across the word.
psrad       xmm3,1Fh            xmm3 = {sign(x), sign(x), sign(y), sign(y)}

//  Mask out index 0 and 2.
pand        xmm3,xmm1           xmm3 = {0, sign(x), 0, sign(y)}

//  Combine to get sign-extended values.
por         xmm3,xmm2           xmm3 = {x, sign(x), y, sign(y)}
                                xmm3 = {x, y}

//  Add to accumulator...
paddq       xmm6,xmm3
</code></pre>

<p>So it's doing some very messy unpacking just to vectorize. The mess comes from needing to sign-extend the 32-bit integers to 64-bit using only SSE instructions.</p>

<p>SSE4.1 actually provides the <code>PMOVSXDQ</code> instruction for this purpose. But either the target machine doesn't support SSE4.1, or ICC isn't smart enough to use it in this case.</p>

<p>But the point is:</p>

<p><strong>The Intel compiler is trying to vectorize the loop. But the overhead added seems to outweigh the benefit of vectorizing it in the first place. Hence why it's slower.</strong></p>

<hr>

<h1>EDIT : Update with OP's results on:</h1>

<ul>
<li>ICC x64 no vectorization</li>
<li>ICC x86 with vectorization</li>
</ul>

<p>You changed the data-type to <code>double</code>. So now it's floating-point. There's no more of that ugly sign-fill shifts that were plaguing the integer version.</p>

<p><strong>But since you disabled vectorization for the x64 version, it obviously becomes slower.</strong></p>

<p><strong>ICC x86 with vectorization:</strong></p>

<pre><code>00B8109E  addpd       xmm0,xmmword ptr arr[edx*8]  
00B810A4  addpd       xmm1,xmmword ptr [esp+edx*8+40h]  
00B810AA  addpd       xmm0,xmmword ptr [esp+edx*8+50h]  
00B810B0  addpd       xmm1,xmmword ptr [esp+edx*8+60h]  
00B810B6  add         edx,8  
00B810B9  cmp         edx,400h  
00B810BF  jb          wmain+9Eh (0B8109Eh)  
</code></pre>

<p>Not much here - standard vectorization + 4x loop-unrolling.</p>

<p><strong>ICC x64 with no vectorization:</strong></p>

<pre><code>000000013FC010B2  lea         ecx,[rdx+rdx]  
000000013FC010B5  inc         edx  
000000013FC010B7  cmp         edx,200h  
000000013FC010BD  addsd       xmm6,mmword ptr arr[rcx*8]  
000000013FC010C3  addsd       xmm6,mmword ptr [rsp+rcx*8+58h]  
000000013FC010C9  jb          wmain+0B2h (13FC010B2h)  
</code></pre>

<p>No vectorization + only 2x loop-unrolling.</p>

<p>All things equal, disabling vectorization will hurt performance in this floating-point case.</p>
"
"<p>My problem reduces to finding the number of primes between two given numbers.I could have a range as big as <code>1 to (1000)!</code> and hence I am need of some mathematical optimizations. </p>

<p>Clearly the sieve method would be too slow in this case. Is there any mathematical optimization that can be applied - like for instance, taking a smaller subset of this large space and making inferences about the rest of the numbers.  </p>

<p>P.S: It definitely looks like I might have reached a dead end - but all that I am looking for are some optimizations that could possibly help solve this. And also, I am only looking for a single-threaded approach. </p>

<p>EDIT: One approach I have been thinking and can solve a lot of large prime number related problems - is for someone to maintain a global table of primes and make it available for lookup. Folks at the PrimeGrid project can contribute usefully towards this. </p>
","922184","","<p>Since you want to go as high as <code>1000!</code> (factorial). You will not be able to get exact results with currently known methods on current technology.</p>

<p>The <a href=""http://en.wikipedia.org/wiki/Prime-counting_function"">Prime Counting Function</a> has only been evaluated exactly for a handful of values up to <code>10^24</code>. So no way you'll be able to hit <code>1000!</code>.</p>

<hr>

<p>But since you mention than an approximation may be fine, you can use the <a href=""http://en.wikipedia.org/wiki/Logarithmic_integral_function"">Logarithmic Integral</a> as an approximation to the Prime Counting Function.</p>

<p>This is based on the <a href=""http://en.wikipedia.org/wiki/Prime_number_theorem"">Prime Number Theorem</a> which says that the <strong>Prime Counting Function is asymptotic to the Logarithmic Integral</strong>.</p>
"
"<p>Will the Java Compiler optimize simple repeated math operations like:</p>

<pre><code>if (prevX / width != curX / width) {
    // Do something with prevX / width value
} else {
    // Do something with curX / width value
}
</code></pre>

<p>I know I can just assign the results to a variables before the if statement, and return the variables, but it's kind of cumbersome. If the compiler automatically recognizes that the same calculations are being made and caches the results to temporary variables on its own, I'd rather stick to the above convention.</p>

<p>*Edit - I'm an idiot. I tried to simply/abstract my question too much. It's not at simple as: if (x > y)</p>
","922184","","<p>The answer is yes. This is called <a href=""http://en.wikipedia.org/wiki/Common_subexpression_elimination"">Common Subexpression Elimination</a> and is a standard (and powerful) compiler optimization used in Java, C/C++ and others...</p>

<p><a href=""http://java.sun.com/products/hotspot/docs/whitepaper/Java_Hotspot_v1.4.1/Java_HSpot_WP_v1.4.1_1002_4.html"">This page</a> confirms that the HotSpot JVM will do this optimization.</p>

<hr>

<p>That said, whether or not the compiler/run-time will be able to do this optimization when you expect it to is another story. So I usually prefer to do these optimizations myself if it also enhances readability.</p>

<pre><code>double xw = x / width;
double yw = y / width;

if (xw &gt; yw) {
    return xw;
} else {
    return yw;
}
</code></pre>
"
"<p>How fast does each assembly language instruction take?  Do operations like set, read, move and compare all take the same time to execute?</p>

<p>If not: Is there any way to find out how long. </p>

<p>Is there some name for what I mean, some specific type cpu's speed of executing the different assembly language instructions (move, read, etc.)</p>

<p>I'm just curious and can't seem to find it on google.</p>
","922184","","<p>The key terms you're probably looking are:</p>

<ul>
<li>Instruction Latency</li>
<li>Instruction Throughput</li>
</ul>

<p>These should be easy to google for. But basically, instructions take a certain number of cycles to execute (latency). But you can often execute multiple of them simultaneously (throughput).</p>

<blockquote>
  <p>Do operations like set, read, move and compare all take the same time
  to execute?</p>
</blockquote>

<p>In general no. Different instructions have different latencies and throughputs. For example, an addition is typically much faster than a division.</p>

<hr>

<p>If you're interested in the actual values of different assembly instructions on modern processors, you can take a look at <a href=""http://www.agner.org/optimize/instruction_tables.pdf"" rel=""nofollow"">Agner Fog's tables</a>.</p>

<hr>

<p>That said, there's about a gazzillion other factors that affect the performance of a computer.<br>
Most of which are arguably more important than instruction latencies/throughputs:</p>

<ul>
<li>Cache</li>
<li>Memory</li>
<li>Disk</li>
<li>Bloat (this seems to be a big one... :D)</li>
<li>etc... the list goes on and on...</li>
</ul>
"
"<p>Suppose I have this structures in <code>c++</code>:</p>

<pre><code>class A{
  public:
    B b;
}

class B{
  public:
    C c;
}

class C{
  public:
    double x;
    double y;
    double z;
    double s;
    function Usize(){
      s  = sqrt(pow(x,2) + pow(y,2) + pow(z,2));
    }
}
</code></pre>

<p>Will accessing the the values in <code>c</code> ten times require more memory traffic than creating a direct pointer to c and use it? In code terms (assuming legal values):</p>

<pre><code>double dx = 2*rand()-1;
double dy = 2*rand()-1;
double dz = 2*rand()-1;

a-&gt;b-&gt;c.x *= dx;
a-&gt;b-&gt;c.y *= dy;
a-&gt;b-&gt;c.z *= dz;

if (a-&gt;b-&gt;c.x &gt; 10) a-&gt;b-&gt;c.x -= 10;
else if (a-&gt;b-&gt;c.x &lt;0) a-&gt;b-&gt;c.x += 10;
if (a-&gt;b-&gt;c.y &gt; 10) a-&gt;b-&gt;c.y -= 10;
else if (a-&gt;b-&gt;c.y &lt; 0) a-&gt;b-&gt;c.y += 10;
if (a-&gt;b-&gt;c.z &gt; 10) a-&gt;b-&gt;c.z -= 10;
else if (a-&gt;b-&gt;c.z &lt; 0) a-&gt;b-&gt;c.z += 10;

a-&gt;b-&gt;c-&gt;Usize();
</code></pre>

<p>vs.</p>

<pre><code>double dx = 2*rand()-1;
double dy = 2*rand()-1;
double dz = 2*rand()-1;


C* ac = a-&gt;b-&gt;c
ac.x *= dx;
ac.y *= dy;
ac.z *= dz;

if (ac.x &gt; 10) ac.x -= 10;
else if (ac.x &lt; 0)  ac.x += 10;
if (ac.y &gt; 10) ac.y -= 10;
else if (Ac.y &lt; 0) ac.y += 10;
if (ac.z &gt; 10) ac.z -= 10;
else if (ac.z &lt; 0) ac.z += 10;
</code></pre>

<p>Thanks.</p>
","922184","","<p><strong>Chances are no. There will be no difference.</strong></p>

<p>While it is true that dereference chaining will lead to more memory accesses, modern compilers are able to do exactly what you have done. (That is, transform your first example into your second example.)</p>

<p>This is due to a standard compiler optimization called <a href=""http://en.wikipedia.org/wiki/Common_subexpression_elimination"" rel=""nofollow"">Common Subexpression Elimination</a> (CSE).</p>

<p>The name pretty much says it all. In your first example, <code>a-&gt;b-&gt;c</code> is the common subexpression that will be optimized out by the compiler. It will be evaluated only once, the result saved, and reused for all the instances it is needed.</p>

<hr>

<p>There are a number of situations that could prevent a compiler from making such optimizations.</p>

<ol>
<li>If any relevant variables are declared <code>volatile</code>, then this optimization is not allowed since a <code>volatile</code> variable requires that it be reloaded each time it is used.</li>
<li>If any of the relevant variables are (or potentially) modified, then this optimization is not allowed since it may produce a different result.</li>
</ol>

<hr>

<p>As a side-note though, your second example is also more readable since there's dereference chaining.<br>So if I had to pick which to use, I'd go with the second example anyway.</p>
"
"<p>I am trying to create a vector of bitsets in C++. For this, I have tried the attempt as shown in  the code snippet below:</p>

<pre><code>vector&lt;bitset&lt;8&gt;&gt; bvc;
    while (true) {
        bitset&lt;8&gt; bstemp( (long) xtemp );
        if (bstemp.count == y1) {
            bvc.push_back(bstemp);
        }
        if ( xtemp == 0) {
            break;
        }
        xtemp = (xtemp-1) &amp; ntemp;
    }
</code></pre>

<p>When I try to compile the program, I get the error that reads that <code>bvc</code> was not declared in the scope. It further tells that the template argument 1 and 2 are invalid. (the 1st line). Also, in the line containing <code>bvc.push_back(bstemp)</code>, I am getting an error that reads invalid use of member function.</p>
","922184","","<p>I have a feeling that you're using pre C++11.</p>

<p>Change this:</p>

<pre><code>vector&lt;bitset&lt;8&gt;&gt; bvc;
</code></pre>

<p>to this:</p>

<pre><code>vector&lt;bitset&lt;8&gt; &gt; bvc;
</code></pre>

<p>Otherwise, the <code>&gt;&gt;</code> is parsed as the right-shift operator. This was ""fixed"" in C++11.</p>
"
"<p>Converting a C++ <code>string</code> to a char array is pretty straightorward using the <code>c_str</code> function of string and then doing <code>strcpy</code>. However, how to do the opposite?</p>

<p>I have a char array like: <code>char arr[ ] = ""This is a test"";</code> to be converted back to:
<code>string str = ""This is a test</code>.</p>
","922184","","<p>The <code>string</code> class has a constructor that takes a NULL-terminated C-string:</p>

<pre><code>char arr[ ] = ""This is a test"";

string str(arr);


//  You can also assign directly to a string.
str = ""This is another string"";
</code></pre>
"
"<p>I am searching for an algorithm that allow me to compute <strong><code>(2^n)%d</code></strong> with <strong>n and d 32 or 64 bits integers</strong>.</p>

<p>The problem is that it's impossible to store <code>2^n</code> in memory even with multiprecision libraries, but maybe there exist a trick to compute <code>(2^n)%d</code> only using 32 or 64 bits integers.</p>

<p>Thank you very much.</p>
","922184","","<p>Take a look at the <a href=""http://en.wikipedia.org/wiki/Modular_exponentiation"">Modular Exponentiation algorithm</a>.</p>

<p>The idea is not to compute <code>2^n</code>. Instead, you reduce modulus <code>d</code> multiple times while you are powering up. <a href=""http://en.wikipedia.org/wiki/Modular_exponentiation#Memory-efficient_method"">That keeps the number small.</a></p>

<p>Combine the method with <a href=""http://en.wikipedia.org/wiki/Exponentiation_by_squaring"">Exponentiation by Squaring</a>, and you can compute <code>(2^n)%d</code> in only <code>O(log(n))</code> steps.</p>

<p>Here's a small example: <code>2^130 % 123 = 40</code></p>

<pre><code>2^1   % 123 = 2
2^2   % 123 = 2^2      % 123    = 4
2^4   % 123 = 4^2      % 123    = 16
2^8   % 123 = 16^2     % 123    = 10
2^16  % 123 = 10^2     % 123    = 100
2^32  % 123 = 100^2    % 123    = 37
2^65  % 123 = 37^2 * 2 % 123    = 32
2^130 % 123 = 32^2     % 123    = 40
</code></pre>
"
"<p>How to calculate serie 1 + 1/1! + 1/2! + 1/3! +...+1/n! in C++?
I have an outline:</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;
int main()
{
    int n, i, j, fat;
    float soma = 0.0;
    cin &gt;&gt; n;
    for (i = 1; i &lt;= n; i++)
    {

        fat = 1;
        soma += 1 / fat;
        for (j = 1; j &lt;= n; j++)
        {
            fat *= j;
        }
    }
    cout &lt;&lt; soma &lt;&lt; endl;
    return 0;
}
</code></pre>
","922184","","<p>You have an integer division right here:</p>

<pre><code>soma += 1 / fat;
</code></pre>

<p>change it to this:</p>

<pre><code>soma += 1. / fat;
</code></pre>

<p>Also be aware that your implementation is very vulnerable to integer overflow when <code>n</code> gets large.</p>

<p>Here's the working version. There were 2 more errors:</p>

<pre><code>int main()
{
    int n, i, j, fat;
    float soma = 1.0;   //  Change to 1.0
    cin &gt;&gt; n;
    for (i = 1; i &lt;= n; i++)
    {

        fat = 1;
        for (j = 1; j &lt;= i; j++)
        {
            fat *= j;
        }
        soma += 1. / fat;      //  Move this to after the loop.
    }
    cout &lt;&lt; soma &lt;&lt; endl;
    return 0;
}
</code></pre>

<p>As mentioned in the comments, you don't need to recompute the factorial at each step.</p>
"
"<p>This question refers to the IEEE standard floating point numbers used on C/x86.</p>

<p>Is it possible to represent any numeric (i.e. excluding special values such as NaN) float or double as a decimal string such that converting that string back to a float/double will always yield exactly the original number?</p>

<p>If not, what algorithm tells me whether a given number will suffer a conversion error?</p>

<p>If so, consider this: some decimal fractions, when converted to binary, will not be numerically the same as the original decimal value, but the reverse is not true (because the binary has bounded precision so any decimal expansion is finite and perfect if not truncated), so here's another question...</p>

<p>Is it ever necessary to introduce deliberate errors into the decimal representation in order to trick the <code>atof</code> (or other) function into yielding the exact original number, or will a naive, non-truncating <code>toString</code> function be adequate (assuming exact conversion is possible in general)?</p>
","922184","","<p>According to <a href=""http://discuss.joelonsoftware.com/default.asp?joel.3.653326.31"">this page</a>:</p>

<blockquote>
  <p>Actually, the IEEE754-1985 standard says that 17 decimal digits is
  enough in all cases. However, it seems that the standard is a little
  vague on whether conforming implementations must guarantee lossless
  conversion when 17 digits are used.</p>
</blockquote>

<p>So storing a <code>double</code> as a decimal string with at least 17 digits (correctly rounded) will guarantee that it can be converted back to binary <code>double</code> without any data loss.</p>

<p>In other words, if every single possible double-precision value were to be converted to a decimal string of 17 digits (correctly rounded), they will all map to different values. Thus there is no data-loss.</p>

<hr>

<p>I'm not sure on the minimum cut-off for single-precision though. But I'd suspect that it will be 8 or 9 digits.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/3272424/compute-fast-log-base-2-ceiling"">Compute fast log base 2 ceiling</a>  </p>
</blockquote>



<p>What is the fastest possible way to find out how many binary digits a particular integer has when it is converted from decimal to binary in C/C++? </p>

<p>Ex. 47<sub>(10)</sub> = 101111<sub>(2)</sub></p>

<p>So 47 has 6 digits represented in binary.</p>
","922184","","<p>If you're looking for the ""fastest"" way in terms of performance, you will need to resort to platform-specific methods.</p>

<p>Some architectures actually have an instruction that does that.</p>

<p>On x86, you have the <code>bsr</code> instruction.</p>

<p><strong>In MSVC, it is accessible as:</strong></p>

<pre><code>inline int bitlength(unsigned long x){
    if (x == 0)
        return 0;

    unsigned long index;
    _BitScanReverse(&amp;index,x);
    return (int)(index + 1);
}
</code></pre>

<p><strong>GCC</strong> has the <a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html""><code>__builtin_clz()</code> intrinsic</a> - which does something similar.</p>
"
"<pre><code>#include &lt;stdio.h&gt;
int main(void){
    float a = 1.1;
    double b = 1.1;
    if(a == b){
        printf(""if block"");
    }
    else{
        printf(""else block"");
    }
    return 0;
}
</code></pre>

<p>Prints: else block</p>

<pre><code>#include &lt;stdio.h&gt;
int main(void){
    float a = 1.5;
    double b = 1.5;
    if(a == b){
        printf(""if block"");
    }
    else{
        printf(""else block"");
    }
    return 0;
}
</code></pre>

<p>Prints: if block</p>

<p>What is the logic behind this? </p>

<p>Compiler used: gcc-4.3.4</p>
","922184","","<p>This is because <code>1.1</code> is not exactly representable in binary floating-point. But <code>1.5</code> is.</p>

<p>As a result, the <code>float</code> and <code>double</code> representations will hold slightly different values of <code>1.1</code>.</p>

<p>Here is exactly the difference when written out as binary floating-point:</p>

<pre><code>(float) 1.1 = (0.00011001100110011001101)₂
(double)1.1 = (0.0001100110011001100110011001100110011001100110011010)₂
</code></pre>

<p>Thus, when you compare them (and the <code>float</code> version gets promoted), they will not be equal.</p>
"
"<p>I have some where in my code the next line:
    long long maxCPUTime=4294967296;</p>

<p>(the largest number long type can be is 4294967296 -1 , so I used long long)</p>

<p>the problem is, when I compile ,I get the next error:</p>

<pre><code>error: integer constant is too large for ‘long’ type
</code></pre>

<p>Its as if, eclips doesn't  recognize that I wrote 'long long' and it thinks I wrote 'long'.</p>

<p>(I'm using linux os)</p>

<p>anyone knows why I get this error?</p>
","922184","","<p>Append <code>LL</code> to it:</p>

<pre><code>long long maxCPUTime = 4294967296LL;
</code></pre>

<p>That should solve the problem. (<code>LL</code> is preferred over <code>ll</code> as it's easier to distinguish.)</p>

<p><code>long long</code> wasn't officially added to the standard until C99/C++11.</p>

<p>Normally, integer literals will have the minimum type to hold it. But prior to C99/C++11, <code>long long</code> didn't ""exist"" in the standard. (but most compilers had it as an extension) So therefore (under some compilers) integer literals larger than <code>long</code> don't get the <code>long long</code> type.</p>
"
"<p>I've faced the next one sample:</p>

<pre><code>#include &lt;stdio.h&gt;

// test multiple return                                                                                                                                                             
int foo()
{
    return 1,2,3,4,5,6;
}

// main entry point                                                                                                                                                                 
int main(int argc, char* argv[])
{
    printf(""foo returns: %d\n"", foo());
    return 0;
}
</code></pre>

<p>compile it, then run:</p>

<pre><code>gcc main.cpp -o main
./main
</code></pre>

<p>The results are confusing me:</p>

<pre><code>foo returns: 6
</code></pre>

<p>The question is: why there is no compile time error?</p>
","922184","","<p>In this context:</p>

<pre><code>return 1,2,3,4,5,6;
</code></pre>

<p>is actually the <a href=""http://en.wikipedia.org/wiki/Comma_operator"">comma operator</a>. It evaluates everything between the commas in order (left-to-right), and returns the last one.</p>

<p>That's why it returns and prints <code>6</code>. <strong>So yes, it's valid code.</strong> That's why there's no compiler error. (Although the <code>1,2,3,4,5</code> part doesn't do anything in this case.)</p>

<p>In C and C++, you can't return multiple values. You'd have to use a struct or a class to do that.</p>
"
"<p>Visual C++ can emit <a href=""http://msdn.microsoft.com/en-us/library/c24hdbz6%28v=vs.80%29.aspx"" rel=""nofollow"">C4738 warning</a>:</p>

<blockquote>
  <p>storing 32-bit float result in memory, possible loss of performance</p>
</blockquote>

<p>for cases when a 32-bit <code>float</code> is about to be stored in memory instead of being stored in a register.</p>

<p>The description further says using <code>double</code> resolves the issue. I don't get why the latter is true.</p>

<p>Why is storing <code>float</code> in memory result in performance loss and storing <code>double</code> does not?</p>
","922184","","<p>While I'm not 100% sure of the cause, here's my guess.</p>

<p>When compiling on x86 and SSE2 is not enabled, the compiler must use the x87 FP stack for all floating-point registers. On MSVC, the FP-mode, by default, set to the 53-bit precision rounding. (I think. I'm not 100% sure on this.)</p>

<p>Therefore, all operations done on the FP-stack is at double-precision.</p>

<p>However, when something is cast down to a <code>float</code>, the precision needs to be rounded to single-precision. The only way to do this is to store it to memory via the <code>fstp</code> instruction over a 4-byte memory operand - and reload it.</p>

<hr>

<p>Let's look at the example on the <a href=""http://msdn.microsoft.com/en-us/library/c24hdbz6%28v=vs.80%29.aspx"" rel=""nofollow"">C4738 warning page</a> you linked to:</p>

<pre><code>float func(float f)
{
    return f;
}

int main()
{
    extern float f, f1, f2;
    double d = 0.0;

    f1 = func(d);
    f2 = (float) d;
    f = f1 + f2;   // C4738
    printf_s(""%f\n"", f);
}
</code></pre>

<p>When you call <code>func()</code>, <code>d</code> is probably stored in an x87 register. However, the call to <code>func()</code> requires that the precision be lowered to single-precision. This will cause <code>d</code> to be rounded/stored to memory. Then reloaded and re-promoted to double-precision on the line <code>f = f1 + f2;</code>.</p>

<p>However, if you use <code>double</code> the whole way, the compiler can keep <code>d</code> in register - thus bypassing the overhead of going to and from memory.</p>

<hr>

<p>As for why it could make you run out of registers... I have no idea. It's possible that the semantics of the program may result in having both double-precision and single-precision values of the same value - which, in this case, require an extra register.</p>
"
"<p>I was just wondering how disastrous integer overflow really is. Take the following example program:</p>

<pre><code>#include &lt;iostream&gt;

int main()
{
    int a = 46341;
    int b = a * a;
    std::cout &lt;&lt; ""hello world\n"";
}
</code></pre>

<p>Since <code>a * a</code> overflows on 32 bit platforms, and integer overflow triggers undefined behavior, do I have any guarantees at all that <code>hello world</code> will actually appear on my screen?</p>

<hr>

<p>I removed the ""signed"" part from my question based on the following standard quotes:</p>

<blockquote>
  <p>(§5/5 C++03, §5/4 C++11) If during the evaluation of an expression, the result is not mathematically defined or not in the range of representable values for its type, the behavior is undefined.</p>
  
  <p>(§3.9.1/4) Unsigned integers, declared <code>unsigned</code>, shall obey the laws of arithmetic modulo 2^n where n is the number of bits in the value representation of that particular size of integer. This implies that <strong>unsigned arithmetic does not overflow</strong> because a result that cannot be represented by the resulting unsigned integer type is reduced modulo the number that is one greater than the largest value that can be represented by the resulting unsigned integer type.</p>
</blockquote>
","922184","","<p>As pointed out by @Xeo in the comments (I actually brought it up in the <a href=""http://chat.stackoverflow.com/transcript/message/2470538#2470538"">C++ chat</a> first): 
<br><strong>Undefined behavior really means it and it can hit you when you least expect it.</strong></p>

<p>The best example of this is here: <a href=""http://stackoverflow.com/q/7682477/922184"">GCC Fail? Or Undefined Behavior?</a></p>

<p>On x86, signed integer overflow is just a simple wrap-around. So normally, <em>you'd expect the same thing to happen in C or C++</em>. However, the compiler can intervene - and <strong>use undefined behavior as an opportunity to optimize</strong>.</p>

<p>In the example taken from that question:</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;

int main(){
    int i = 0x10000000;

    int c = 0;
    do{
        c++;
        i += i;
        cout &lt;&lt; i &lt;&lt; endl;
    }while (i &gt; 0);

    cout &lt;&lt; c &lt;&lt; endl;
    return 0;
}
</code></pre>

<p>When compiled with GCC, GCC optimizes out the loop test and makes this an infinite loop.</p>
"
"<p>I have the following code:</p>

<pre><code>/* sample.c */ 
    #include&lt;stdio.h&gt; 
    #include&lt;malloc.h&gt; 
    #include&lt;stdlib.h&gt; 
    #include""hermes.h"" 
    #include&lt;string.h&gt; 

    int main (){
        struct hermes *h ;
        h = ( struct hermes *) malloc ( sizeof ( struct hermes *));

        strcpy ( h-&gt;api-&gt;search_response-&gt;result_code , ""123"" );
            printf(""VALue : %s\n"" , h-&gt;api-&gt;search_response-&gt;result_code );
        return 0; 
    }

/* hermes.h */ 
    struct hermes {

     union  {

          /* search response */
                    struct  {
                            int error_code;
                            char *result_code;
                            char *user_track_id;
                            struct bus_details bd;
                    }*search_response;

        }*api;
    };
</code></pre>

<p>I get a segmentation fault when I try to access the elements. Could anyone tell me what is the right way to access these elements?</p>
","922184","","<p>Your <code>malloc()</code> line isn't correct:</p>

<pre><code>h = ( struct hermes *) malloc ( sizeof ( struct hermes *));
</code></pre>

<p>should be:</p>

<pre><code>h = ( struct hermes *) malloc ( sizeof ( struct hermes));
</code></pre>

<p>Remove the <code>*</code> in the <code>sizeof()</code>. Otherwise, you're only allocating enough for a pointer rather than the struct itself.</p>

<p>Also, the cast isn't necessary in C.</p>
"
"<p>I have written 2 programs. Please go through both the programs and help me in            understanding why variable 'i' and '*ptr' giving different values.</p>

<pre><code>//Program I:
//Assumption: Address of i = 100, address of ptr = 500

int i = 5;
int *ptr = (int *) &amp;i;

*ptr = 99;

cout&lt;&lt;i; // 99
cout&lt;&lt;&amp;i;// 100
cout&lt;&lt;ptr; // 100
cout&lt;&lt;*ptr; // 99
cout&lt;&lt;&amp;ptr; // 500
//END_Program_I===============

//Program II:
//Assumption: Address of i = 100, address of ptr = 500
const int i = 5;
int *ptr = (int *) &amp;i;

*ptr = 99;

cout&lt;&lt;i; // 5
cout&lt;&lt;&amp;i;// 100
cout&lt;&lt;ptr; // 100
cout&lt;&lt;*ptr; // 99
cout&lt;&lt;&amp;ptr; // 500
//END_PROGRAM_II===============
</code></pre>

<p>The confusion is: Why variable i still coming as 5, even though *ptr ==99?</p>
","922184","","<p>In the following three lines, you are modifying a constant:</p>

<pre><code>const int i = 5;
int *ptr = (int *) &amp;i;

*ptr = 99;
</code></pre>

<p><strong>This is undefined behavior. Anything can happen. So don't do it.</strong></p>

<hr>

<p><strong>As for what's happening underneath in this particular case:</strong></p>

<p>Since <code>i</code> is <code>const</code>, the compiler assumes it will not change. Therefore, it simply inlines the <code>5</code> to each place where it is used. That's why printing out <code>i</code> shows the original value of <code>5</code>.</p>
"
"<p>When trying to test the speed of functions, I found that not all parts of my code work in <code>Release</code> mode. The same code works perfectly in <code>Debug</code> mode, though.</p>

<p>I'm using VC++ compiler with <code>/O2</code> optimization.</p>

<p>Here's the cut out part, which doesn't work.</p>

<pre class=""lang-c prettyprint-override""><code>int main()
{
    boost::timer::auto_cpu_timer t;

    for(int i = 0; i &lt; 1000000; i++)
        gcdb(i, 5);
    return 0;
}
</code></pre>

<p>The generated assembly in release mode, the code for the for loop is missing only in this mode.</p>

<pre><code>int main()
{
000000013F8E1280  sub         rsp,88h  
000000013F8E1287  mov         rax,qword ptr [__security_cookie (013F8E7150h)]  
000000013F8E128E  xor         rax,rsp  
000000013F8E1291  mov         qword ptr [rsp+70h],rax  
    boost::timer::auto_cpu_timer t;
000000013F8E1296  lea         rcx,[t]  
000000013F8E129B  mov         edx,6  
000000013F8E12A0  call        boost::timer::auto_cpu_timer::auto_cpu_timer (013F8E2DA0h)  

    for(int i = 0; i &lt; 1000000; i++)
        gcdb(i, 5);
    return 0;
000000013F8E12A5  lea         rcx,[t]  
000000013F8E12AA  call        boost::timer::auto_cpu_timer::~auto_cpu_timer (013F8E2810h)  
000000013F8E12AF  xor         eax,eax  
}
</code></pre>

<p><code>gcdb()</code> is just a function for the finding the GCD of two numbers.</p>

<p>What could be causing this code skipping?</p>
","922184","","<p>What you're seeing here is a compiler optimization known as <a href=""http://en.wikipedia.org/wiki/Dead_code_elimination"">Dead Code Elimination</a>.</p>

<p>When the compiler sees that the result of some code is not needed, it is free to eliminate it. This is a standard optimization employed by all modern compilers.</p>

<p>A work-around to keep the compiler from optimizing it out is to actually use the output in some way:</p>

<pre><code>int main()
{
    boost::timer::auto_cpu_timer t;

    int sum = 0;

    for(int i = 0; i &lt; 1000000; i++)
        sum += gcdb(i, 5);

    cout &lt;&lt; sum &lt;&lt; endl;
    return 0;
}
</code></pre>

<p>Related: <a href=""http://stackoverflow.com/questions/8841865/how-does-gcc-optimize-c-code"">How does GCC optimize C code?</a></p>
"
"<p>why do I get results 6, and then 8 by from the following code? I searched through the posts but cannot find an exact match of my question. Thanks.</p>

<pre><code>#include &lt;stdio.h&gt;

void getSize(const char *str)
{
        printf(""%d\n"", sizeof(str)/sizeof(char));
}

int main()
{
        char str[]=""hello"";
        printf(""%d\n"", sizeof(str)/sizeof(char));
        getSize(str);
}
</code></pre>
","922184","","<p>In your <code>getSize()</code> function, <code>str</code> is a pointer. Therefore <code>sizeof(str)</code> returns the <strong>size of a pointer</strong>. (which is 8 bytes in this case)</p>

<p>In your <code>main()</code> function, <code>str</code> is an array. Therefore <code>sizeof(str)</code> returns the <strong>size of the array</strong>.</p>

<p>This is one of the subtle differences between arrays and pointers.</p>
"
"<p>I have made some research on Stackoverflow about reverse for loops in C++ that use an unsigned integer instead of a signed one. But I still do NOT understand why there is a problem (see <a href=""http://stackoverflow.com/questions/5458204/unsigned-int-reverse-iteration-with-for-loops"">Unsigned int reverse iteration with for loops</a>). Why the following code will yield a segmentation fault?</p>

<pre><code>#include &lt;vector&gt;
#include &lt;iostream&gt;
using namespace std;

int main(void)
{
    vector&lt;double&gt; x(10);

    for (unsigned int i = 9; i &gt;= 0; i--)
    {
        cout &lt;&lt; ""i= "" &lt;&lt; i &lt;&lt; endl;
        x[i] = 1.0;
    }

    cout &lt;&lt; ""x0= "" &lt;&lt; x[0] &lt;&lt; endl;

    return 0;
}
</code></pre>

<p>I understand that the problem is when the index i will be equal to zero, because there is something like an overflow. But I think an unsigned integer is allowed to take the zero value, isn't it? Now if I replace it with a signed integer, there is absolutely no problem.</p>

<p>Does somebody can explain me the mechanism behind that reverse loop with an unsigned integer?</p>

<p>Thank you very much!</p>
","922184","","<p>The problem here is that an unsigned integer is never negative.</p>

<p>Therefore, the loop-test:</p>

<pre><code>i &gt;= 0
</code></pre>

<p>will always be true. Thus you get an infinite loop.</p>

<p>When it drops below zero, it wraps around to the largest value <code>unsigned</code> value.
<br>
<strong>Thus, you will also be accessing <code>x[i]</code> out-of-bounds</strong>.</p>

<p>This is not a problem for signed integers because it will simply go negative and thus fail <code>i &gt;= 0</code>.</p>

<p>Thus, if you want to use unsigned integers, you can try one of the following possibilities:</p>

<pre><code>for (unsigned int i = 9; i-- != 0; )
</code></pre>

<p>and</p>

<pre><code>for (unsigned int i = 9; i != -1; i--)
</code></pre>

<p>These two were suggested by GManNickG and AndreyT from the comments.</p>

<hr>

<p>And here's my original 3 versions:</p>

<pre><code>for (unsigned int i = 9; i != (unsigned)0 - 1; i--)
</code></pre>

<p>or</p>

<pre><code>for (unsigned int i = 9; i != ~(unsigned)0; i--)
</code></pre>

<p>or</p>

<pre><code>for (unsigned int i = 9; i != UINT_MAX; i--)
</code></pre>
"
"<p>I had working on a class and started writing everything in the same .cpp file. However, after a while I could see the class getting bigger and bigger so I decided to split it into a .h and a .cpp file. </p>

<p>gaussian.h file:</p>

<pre><code>class Gaussian{
    private:
        double mean;
        double standardDeviation;
        double variance;
        double precision;
        double precisionMean;
    public:
        Gaussian(double, double);
        ~Gaussian();
        double normalizationConstant(double);
        Gaussian fromPrecisionMean(double, double);
        Gaussian operator * (Gaussian);
        double absoluteDifference (Gaussian);
};
</code></pre>

<p>gaussian.cpp file: </p>

<pre><code>#include ""gaussian.h""
#include &lt;math.h&gt;
#include ""constants.h""
#include &lt;stdlib.h&gt;
#include &lt;iostream&gt;

Gaussian::Gaussian(double mean, double standardDeviation){
    this-&gt;mean = mean;
    this-&gt;standardDeviation = standardDeviation;
    this-&gt;variance = sqrt(standardDeviation);
    this-&gt;precision = 1.0/variance;
    this-&gt;precisionMean = precision*mean;
} 

//Code for the rest of the functions...

double absoluteDifference (Gaussian aux){
    double absolute = abs(this-&gt;precisionMean - aux.precisionMean);
    double square = abs(this-&gt;precision - aux.precision);
    if (absolute &gt; square)
        return absolute;
    else
        return square;
}
</code></pre>

<p>However, I can't get this to compile. I try running:</p>

<pre><code>g++ -I. -c -w gaussian.cpp
</code></pre>

<p>But I get:</p>

<pre><code>gaussian.cpp: In function ‘double absoluteDifference(Gaussian)’:
gaussian.cpp:37:27: error: invalid use of ‘this’ in non-member function
gaussian.h:7:16: error: ‘double Gaussian::precisionMean’ is private
gaussian.cpp:37:53: error: within this context
gaussian.cpp:38:25: error: invalid use of ‘this’ in non-member function
gaussian.h:6:16: error: ‘double Gaussian::precision’ is private
gaussian.cpp:38:47: error: within this context
</code></pre>

<p>Why can't I use this?? I am using it in the fromPrecisionMean function and that compiles. Is it because that function returns a Gaussian? Any extra explanation will be really appreciated, I am trying to learn as much as I can! Thanks! </p>
","922184","","<p>You forgot to declare <code>absoluteDifference</code> as part of the <code>Gaussian</code> class.</p>

<p>Change:</p>

<pre><code>double absoluteDifference (Gaussian aux){
</code></pre>

<p>to this:</p>

<pre><code>double Gaussian::absoluteDifference (Gaussian aux){
</code></pre>

<hr>

<p><strong>Side Note:</strong> It might be better to pass by reference rather than by value:</p>

<pre><code>double Gaussian::absoluteDifference (const Gaussian &amp;aux){
</code></pre>
"
"<p>I searched the question similar to my problem <a href=""http://stackoverflow.com/questions/3533594/sqrt-function-not-working-with-variable-arguments"">Similar problem</a>. But my problem is when using Turbo C compiler v3.0. Should I have to do some additional work for math.h file? please help.</p>

<pre><code>int main (void){
    double result, a;
    clrscr();
    printf(""Enter a # for square root.\n"");
    scanf(""%f"",&amp;a);
    printf(""a = %f\n"",a);
    result = sqrt(a);
    printf(""a = %f  and square root is %f\n"",a, result);
    getch();
    return 0;
    }
</code></pre>

<p>The Output is like this:</p>

<p>Enter a # for square root.</p>

<p><strong>64</strong></p>

<p>a = 0.000000</p>

<p>a = 0.000000 and square root is 0.000000</p>
","922184","","<p>For <code>scanf()</code>, <code>%f</code> is for <code>float</code>. You need to use <code>%lf</code> for <code>double</code>:</p>

<pre><code>printf(""Enter a # for square root.\n"");
scanf(""%lf"",&amp;a);
</code></pre>

<p>This is in contrast to <code>printf()</code> where type-promotion allows <code>%f</code> to be used for both <code>float</code> and <code>double</code>.</p>
"
"<p>I think first 400*400=160000 is first converted to 28928 by starting from 0 and going 160000 time in circular fashion for int type assuming it like:</p>

<p><img src=""http://i.stack.imgur.com/mdpND.jpg"" alt=""enter image description here""> </p>

<p>And then 28928 is divided by 400 floor of which gives 72, and the result varies with the type of variable. Is my assumption correct or there is any other explanation?</p>
","922184","","<p>Assuming you're using a horrifically old enough compiler for where <code>int</code> is only 16 bits. Then yes, your analysis is correct.*</p>

<pre><code>400 * 400 = 160000 

//  Integer overflow wrap-around.
160000 % 2^16 = 28928

//  Integer Division
28928 / 400 = 72 (rounded down)
</code></pre>

<p>Of course, for larger datatypes, this overflow won't happen so you'll get back <code>400</code>.</p>

<p>*This wrap-around behavior is guaranteed <strong>only for <em>unsigned</em> integer types</strong>. For signed integers, it is technically <strong>undefined behavior</strong> in C and C++.</p>

<p>In many cases, signed integers will still exhibit the same wrap-around behavior. <strong>But you just can't count on it.</strong> (So your example with a signed 16-bit integer isn't guaranteed to hold.)</p>

<hr>

<p>Although rare, here are some examples of where signed integer overflow does not wrap around as expected:</p>

<ul>
<li><a href=""http://stackoverflow.com/q/7682477/922184"">GCC Fail? Or Undefined Behavior?</a></li>
<li><a href=""http://stackoverflow.com/q/7124058/922184"">Compiler optimization causing program to run slower</a></li>
</ul>
"
"<p>When working with <code>char</code> buffers in C, sometimes it would be useful and more efficient to able to work with <code>int</code>-sized chunks of data at a time. To do this I can cast my <code>char *</code> to an <code>int *</code> and use that pointer instead. However I'm not entirely confident that this works the way I think it does.</p>

<p>For example, suppose I have <code>char *data</code>, does <code>*(int32_t *)data = -1</code> always overwrite the bytes <code>data[0]</code>, <code>data[1]</code>, <code>data[2]</code> and <code>data[3]</code> and no other bytes?</p>
","922184","","<p>Expanding on my comment.</p>

<p><strong>There are two major issues here:</strong></p>

<ul>
<li>It violates <a href=""http://stackoverflow.com/q/98650/922184"">strict-aliasing</a>.</li>
<li>You might break alignment.</li>
</ul>

<hr>

<p>Violating strict-aliasing is technically <strong>undefined behavior</strong>. You are allowed to alias any datatype with <code>char*</code>, but not the other way around.</p>

<p>You can get around the issue with <code>f[no-]strict-aliasing</code> on GCC.</p>

<hr>

<p>The other issue is alignment. The <code>char</code> pointer might not be properly aligned. Accessing misaligned data may lead to performance degradation or even a hardware exception if the hardware doesn't support misaligned access.</p>

<hr>

<p>If performance isn't an issue, the full-proof way is to <code>memcpy()</code> to an <code>int</code> array buffer.</p>

<p>Once these two issues are resolved, your example with:</p>

<pre><code>*(int32_t *)data = -1
</code></pre>

<p>overwriting <code>data[0]</code>, <code>data[1]</code>, <code>data[2]</code>, and <code>data[3]</code> should work as expected if <code>sizeof(int32_t) == 4</code>. Just pay attention to the endianness...</p>
"
"<p>Look at this sample C code (extracted a test case as an example):</p>

<pre><code>main() {
  unsigned long a, b;
  int c;
  c = 32;
  a = 0xffffffff &lt;&lt; 32;
  b = 0xffffffff &lt;&lt; c;
  printf (""a=%x, b=%x\n"", a, b);
}
</code></pre>

<p>Prints: <code>a=0, b=ffffffff</code> </p>

<p>I cannot understand why b is not zero, just like a. I tested this on Microsoft C and GCC.</p>

<p><strong>Update</strong>: I fixed the stupid typo (should have been &lt;&lt; c and not &lt;&lt; b of course). But my question still stands, e.g. the result is still the same.</p>
","922184","","<p>You never initialized <code>b</code> to anything before you use it here:</p>

<pre><code>b = 0xffffffff &lt;&lt; b;
</code></pre>

<p>So it can be anything. (I think you actually meant to shift by <code>c</code>.)</p>

<hr>

<p>That aside:</p>

<p>The main issue is that shifting by the # of bits in the datatype or more is <strong>undefined behavior</strong>.<br>
So if the literal <code>0xffffffff</code> is a 32-bit integer, then the line:</p>

<pre><code>a = 0xffffffff &lt;&lt; 32;
</code></pre>

<p>is not defined by the standard. (See comments.)</p>

<hr>

<p>You should also be getting a compiler warning:</p>

<pre><code>warning C4293: '&lt;&lt;' : shift count negative or too big, undefined behavior
</code></pre>
"
"<p>What are the disadvantages, if any, of defining large arrays or objects on the stack? Take the following example:</p>

<pre><code>int doStuff() {
   int poolOfObjects[1500];
   // do stuff with the pool
   return 0;
}
</code></pre>

<p>Are there any performance issues with this? I've heard of stack overflow issues, but I'm assuming that this array isn't big enough for that.</p>
","922184","","<p>As you have mentioned, <strong>overrunning the stack is the primary issue</strong>. Even if your particular case isn't very large, consider what will happen if the function is recursive.</p>

<p>Even worse, <strong>if the function is called from a recursive function, it may be inlined</strong> - thus leading to ""surprise"" stackoverflow problems. (I've run into this issue multiple times with the Intel Compiler.)</p>

<hr>

<p>As far as performance issues go, these are better measured than guessed. But having a very large array on the stack could potentially hurt data-locality if it separates other variables.</p>

<p>Other than that, stack allocation is dirt-cheap and faster than heap allocation. On some compilers (like MSVC), using more than 4k stack will make the compiler generate a buffer security check. (But it can be disabled though.)</p>
"
"<p>I am testing performance on integer addition in Java. The way I did that is by summing up billions of integers. The sample file I use for testing is a 1G binary file. My program is as simple as shown in the snippet below.</p>

<pre><code>int result = 0;
FileChannel fileChannel = new FileInputStream(filename).getChannel();
long fileSize = fileChannel.size();
intBuffer = fileChannel.map(MapMode.READ_ONLY, startPosition, fileSize).asIntBuffer();

try {
  while (true) {
    result += intBuffer.get();
  }
} catch (BufferUnderflowException e) {
  System.out.println(""Complete reading"");
}
</code></pre>

<p>As you can see from above, it simply executes two operations in each loop</p>

<ul>
<li>read integer from file</li>
<li>integer addition</li>
</ul>

<p>This program ran about 2 minutes on my machine. I also did another test run without addition, by changing <code>result += intBuffer.get()</code> to <code>result = intBuffer.get()</code> (shown as in following snippet).</p>

<pre><code>int result = 0;
FileChannel fileChannel = new FileInputStream(filename).getChannel();
long fileSize = fileChannel.size();
intBuffer = fileChannel.map(MapMode.READ_ONLY, startPosition, fileSize).asIntBuffer();

try {
  while (true) {
    result = intBuffer.get();
  }
} catch (BufferUnderflowException e) {
  System.out.println(""Complete reading"");
}
</code></pre>

<p>The entire program in this case turned out to complete within 1 second. Compared to its sibling variant above, it seems integer addition dominate the CPU time compared to IO read.</p>

<p>I wrote another benchmark program just for justify my guess, it does the same number of additions as the above example.</p>

<pre><code>int result = random.nextInt();
int other = random.nextInt();
int num = 1073741824 / 4;
while(num-- &gt; 0) {
  result += other;
}
</code></pre>

<p>With the same amount of integer additions plus the integer incremental operations, this program finishes less than 1 second.</p>

<p>My question is</p>

<ul>
<li>What caused the the major timing difference between these runs? Does Java compiler does something to optimize the last one?</li>
</ul>

<p>Any thoughts are appreciated.</p>
","922184","","<p>That's because disk I/O is very slow compared the CPU.</p>

<p>In the first case, you're reading from a file. So you're bound by disk-access.</p>

<p>In the second case, it's all in the CPU.</p>

<hr>

<p>So this has nothing to do with the speed of addition.</p>

<ul>
<li>The first case is limited by the speed of your disk.</li>
<li>The second case is (probably) limited by the speed of the random number generator.</li>
</ul>

<hr>

<p>As for why <code>result = intBuffer.get()</code> seems to be very fast: (pulled from comments)</p>

<p>Two possible reasons I can think of:</p>

<ul>
<li><strong><a href=""http://en.wikipedia.org/wiki/Dead_code_elimination"" rel=""nofollow"">Dead Code Elimination</a></strong> by the JIT is optimizing out all but the last iteration.</li>
<li><strong>I/O buffering:</strong> The OS is buffering the entire file into memory after the first read.*</li>
</ul>

<p>*So subsequent passes will be very fast. It's easy to test for this case by re-ordering the tests or clearing the I/O cache each time</p>
"
"<p>In the book <a href=""http://rads.stackoverflow.com/amzn/click/1584506806"">Game Coding Complete, 3rd Edition,</a> the author mentions a technique to both reduce data structure size <em>and</em> increase access performance. In essence it relies on the fact that you gain performance when member variables are memory aligned. This is an obvious potential optimization that compilers would take advantage of, but by making sure each variable is aligned they end up bloating the size of the data structure.</p>

<p>Or that was his claim at least.</p>

<p>The real performance increase, he states, is by using your brain and ensuring that your structure is properly designed to take take advantage of speed increases while preventing the compiler bloat. He provides the following code snippet:</p>

<pre><code>#pragma pack( push, 1 )

struct SlowStruct
{
    char c;
    __int64 a;
    int b;
    char d;
};

struct FastStruct
{
    __int64 a;
    int b;
    char c;
    char d;  
    char unused[ 2 ]; // fill to 8-byte boundary for array use
};

#pragma pack( pop )
</code></pre>

<p>Using the above <code>struct</code> objects in an unspecified test he reports a performance increase of <code>15.6%</code> (<code>222ms</code> compared to <code>192ms</code>) and a smaller size for the <code>FastStruct</code>. This all makes sense on paper to me, but it fails to hold up under my testing:</p>

<p><img src=""http://i.stack.imgur.com/Gf6yK.png"" alt=""enter image description here""></p>

<p>Same time results <em>and</em> size (counting for the <code>char unused[ 2 ]</code>)!</p>

<p>Now if the <code>#pragma pack( push, 1 )</code> is isolated only to <code>FastStruct</code> (or removed completely) we do see a difference:</p>

<p><img src=""http://i.stack.imgur.com/jblLW.png"" alt=""enter image description here""></p>

<p>So, finally, here lies the question: Do modern compilers (VS2010 specifically) already optimize for the bit alignment, hence the lack of performance increase (but increase the structure size as a side-affect, like Mike Mcshaffry stated)? Or is my test not intensive enough/inconclusive to return any significant results?</p>

<p>For the tests I did a variety of tasks from math operations, column-major multi-dimensional array traversing/checking, matrix operations, etc. on the unaligned <code>__int64</code> member. None of which produced different results for either structure.</p>

<p>In the end, even if their was no performance increase, this is still a useful tidbit to keep in mind for keeping memory usage to a minimum. But I would love it if there was a performance boost (no matter how minor) that I am just not seeing.</p>
","922184","","<h1>It is highly dependent on the hardware.</h1>

<p><strong>Let me demonstrate:</strong></p>

<pre><code>#pragma pack( push, 1 )

struct SlowStruct
{
    char c;
    __int64 a;
    int b;
    char d;
};

struct FastStruct
{
    __int64 a;
    int b;
    char c;
    char d;  
    char unused[ 2 ]; // fill to 8-byte boundary for array use
};

#pragma pack( pop )

int main (void){

    int x = 1000;
    int iterations = 10000000;

    SlowStruct *slow = new SlowStruct[x];
    FastStruct *fast = new FastStruct[x];



    //  Warm the cache.
    memset(slow,0,x * sizeof(SlowStruct));
    clock_t time0 = clock();
    for (int c = 0; c &lt; iterations; c++){
        for (int i = 0; i &lt; x; i++){
            slow[i].a += c;
        }
    }
    clock_t time1 = clock();
    cout &lt;&lt; ""slow = "" &lt;&lt; (double)(time1 - time0) / CLOCKS_PER_SEC &lt;&lt; endl;

    //  Warm the cache.
    memset(fast,0,x * sizeof(FastStruct));
    time1 = clock();
    for (int c = 0; c &lt; iterations; c++){
        for (int i = 0; i &lt; x; i++){
            fast[i].a += c;
        }
    }
    clock_t time2 = clock();
    cout &lt;&lt; ""fast = "" &lt;&lt; (double)(time2 - time1) / CLOCKS_PER_SEC &lt;&lt; endl;



    //  Print to avoid Dead Code Elimination
    __int64 sum = 0;
    for (int c = 0; c &lt; x; c++){
        sum += slow[c].a;
        sum += fast[c].a;
    }
    cout &lt;&lt; ""sum = "" &lt;&lt; sum &lt;&lt; endl;


    return 0;
}
</code></pre>

<hr>

<p><strong>Core i7 920 @ 3.5 GHz</strong></p>

<pre><code>slow = 4.578
fast = 4.434
sum = 99999990000000000
</code></pre>

<p>Okay, not much difference. But it's still consistent over multiple runs.<br><strong>So the alignment makes a small difference on Nehalem Core i7.</strong></p>

<hr>

<p><strong>Intel Xeon X5482 Harpertown @ 3.2 GHz</strong> (Core 2 - generation Xeon)</p>

<pre><code>slow = 22.803
fast = 3.669
sum = 99999990000000000
</code></pre>

<p>Now take a look...</p>

<h1>6.2x faster!!!</h1>

<hr>

<p>Conclusion:</p>

<p><strong>You see the results. You decide whether or not it's worth your time to do these optimizations.</strong></p>

<hr>

<p><strong>EDIT :</strong></p>

<p>Same benchmarks but without the <code>#pragma pack</code>:</p>

<p><strong>Core i7 920 @ 3.5 GHz</strong></p>

<pre><code>slow = 4.49
fast = 4.442
sum = 99999990000000000
</code></pre>

<p><strong>Intel Xeon X5482 Harpertown @ 3.2 GHz</strong></p>

<pre><code>slow = 3.684
fast = 3.717
sum = 99999990000000000
</code></pre>

<ul>
<li>The Core i7 numbers didn't change. Apparently it can handle
misalignment without trouble for this benchmark.</li>
<li>The Core 2 Xeon now shows the same times for both versions. This confirms that misalignment is a problem on the Core 2 architecture. </li>
</ul>

<p>Taken from my comment:</p>

<p>If you leave out the <code>#pragma pack</code>, the compiler will keep everything aligned so you don't see this issue. So this is actually an example of what could happen if you <strong><em>misuse</em></strong> <code>#pragma pack</code>.</p>
"
"<p>I have an application where <code>pthread_join</code> is being the bottleneck. I need help to resolve this problem.</p>

<pre><code>void *calc_corr(void *t) {
         begin = clock();
         // do work
         end = clock();
         duration = (double) (1000*((double)end - (double)begin)/CLOCKS_PER_SEC);
         cout &lt;&lt; ""Time is ""&lt;&lt;duration&lt;&lt;""\t""&lt;&lt;h&lt;&lt;endl;
         pthread_exit(NULL);
}

int main() {
         start_t = clock();

         for (ii=0; ii&lt;16; ii++) 
            pthread_create(&amp;threads.p[ii], NULL, &amp;calc_corr, (void *)ii);

         for (i=0; i&lt;16; i++) 
            pthread_join(threads.p[15-i], NULL);

         stop_t = clock();

         duration2 = (double) (1000*((double)stop_t - (double)start_t)/CLOCKS_PER_SEC);
         cout &lt;&lt; ""\n Time is ""&lt;&lt;duration2&lt;&lt;""\t""&lt;&lt;endl;

         return 0;
}
</code></pre>

<p>The time printed in the thread function is in the range of <strong>40ms - 60ms</strong> where as the time printed in the main function is in the <strong>650ms - 670ms</strong>. The irony is, my serial code runs in <strong>650ms - 670ms</strong> time. what can I do to reduce the time taken by <code>pthread_join</code>?</p>

<p>Thanks in advance!</p>
","922184","","<p>On Linux, <code>clock()</code> measures the combined CPU time. <strong>It does not measure the wall time.</strong></p>

<p>This is explains why you get <code>~640 ms = 16 * 40ms</code>. (as pointed out in the comments)</p>

<p>To measure wall time, you should be using something like:</p>

<ul>
<li><a href=""http://pubs.opengroup.org/onlinepubs/009604599/functions/gettimeofday.html""><code>gettimeofday()</code></a></li>
<li><a href=""http://linux.die.net/man/3/clock_gettime""><code>clock_gettime()</code></a></li>
</ul>
"
"<p>I have the following the code:</p>

<pre><code>int myArray[] = {0, 0, 0, 0, 0, 0};
double EV = 0;
for(short a1 = 1; a1 &lt;= 6; ++a1)
{
    ++myArray[a1-1];
    if(....)
    {
        --myArray[a1-1];
        continue;
    }
    EV = myEVFunc();
    if(EV...)
    {

        for(short a2 = 1; a2 &lt;=6 ; ++a2)
        {
            ++myArray[a2-1];
            if(....)
            {
                --myArray[a2-1];
                continue;
            }
            EV = myEVFunc();
            if(EV...)
            {
                for(short a3 = 1; a3 &lt;= 6; ++a3)
                {
                    ++myArray[a3-1];
                    if(....)
                    {
                        --myArray[a3-1];
                        continue;
                    }
                    EV = myEVFunc();
                }
            }
        }
    }
}
</code></pre>

<p>I am trying to use OpenMP to parallelize the loops. the code compiles fine when i place 
 <code>#pragma omp parallel for</code> in front of the outermost for loop. However it gives incorrect results. I suspect two issues the continue statements inside the loops and the fact that there are shared variables in the nested loops. 
Is it possible to use OpenMP with this code snippet, if so can anyone please give me the correct syntax. Thanks in advance.</p>
","922184","","<p>I'll point out a couple obvious things:</p>

<p>1.) <code>double EV = 0;</code> is declared outside the outer loop. Therefore it will be shared by all the threads. So you'll have a <strong><em>race condition</em></strong> at <code>EV = myEVFunc();</code> and at each access to <code>EV</code>.</p>

<p>The solution to this is to declare it inside the loop. That will make it private to each thread.</p>

<pre><code>#pragma omp parallel for
    for(short a1 = 1; a1 &lt;= 6; ++a1)
    {
        ++myArray[a1-1];
        if(....)
        {
            --myArray[a1-1];
            continue;
        }
        double EV = myEVFunc();
        if(EV...)
        ...
</code></pre>

<p>2.) Another (sorta) issue is that your outer-loop only has 6 iterations. So you won't get more than 6 threads. Furthermore, you could get load-balancing issues with say 4 cores...</p>
"
"<p>I am multiplying constant <code>vector&lt;bool&gt;</code> on different <code>vector&lt;double&gt;</code> many times. I wonder how fast is that, wouldn't it be faster to convert it first to <code>vector&lt;double&gt;</code>, so that sse can be used?</p>

<pre><code>    void applyMask(std::vector&lt;double&gt;&amp; frame, const std::vector&lt;bool&gt;&amp; mask)
    {
        std::transform(frame.begin(), frame.end(), mask.begin(), frame.begin(), [](const double&amp; x, const bool&amp; m)-&gt;double{ return x*m;});
    }
</code></pre>
","922184","","<p>It seems like you're trying to zero parts of a <code>vector&lt;double&gt;</code> using a mask of <code>vector&lt;bool&gt;</code>.</p>

<p><strong>As it stands right now, it's not vectorizable</strong>. Furthermore, the <code>vector&lt;bool&gt;</code> template specialization is going to hinder the compiler's ability to do any sort of auto-vectorization.</p>

<p>So you basically have two options:</p>

<p><strong>The easy way</strong> is to indeed convert the <code>vector&lt;bool&gt;</code> to a <code>vector&lt;double&gt;</code> of corresponding zeros and ones. Then the problem reduces to simply vector-to-vector multiplication of the same datatype, which is completely vectorizable. (even auto-vectorizable)</p>

<p><strong>The harder way</strong> (which might be faster), is to play some hacks with the <a href=""http://msdn.microsoft.com/en-us/library/7c4sw98t.aspx"" rel=""nofollow""><code>_mm_and_pd</code></a> or <a href=""http://msdn.microsoft.com/en-us/library/bb513997.aspx"" rel=""nofollow""><code>_mm_blendv_pd()</code></a> intrinsics/instructions. But that requires a lot more work since you have to manually vectorize the code.</p>

<hr>

<p>I suggest you just go with the easy way. No need to dive into manual vectorization unless you really need to.</p>
"
"<p>Given an unsigned int, I have to implement the following operations :</p>

<ol>
<li>Count the number of bits set to 1</li>
<li>Find the index of the left-most 1 bit</li>
<li>Find the index of the righ-most 1 bit</li>
</ol>

<p>(the operation should not be architecture dependents).</p>

<p>I've done this using bitwise shift, but I have to iterate through almost all the bits(es.32) .
For example, counting 1's:</p>

<pre><code>unsigned int number= ...;
while(number != 0){
    if ((number &amp; 0x01) != 0)
        ++count;
    number &gt;&gt;=1;
}
</code></pre>

<p>The others operation are similar.</p>

<p>So my question is: is there any faster way to do that?</p>
","922184","","<p>If you want the <em>fastest</em> way, you will need to use non-portable methods.</p>

<p><strong>Windows/MSVC:</strong></p>

<ul>
<li><a href=""http://msdn.microsoft.com/en-us/library/wfd9z0bb%28v=vs.80%29.aspx"">_BitScanForward()</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/fbxyd7zd%28v=vs.80%29.aspx"">_BitScanReverse()</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/bb385231.aspx"">__popcnt()</a></li>
</ul>

<p><strong>GCC:</strong></p>

<ul>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"">__builtin_ffs()</a></li>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"">__builtin_ctz()</a></li>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"">__builtin_clz()</a></li>
<li><a href=""http://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html"">__builtin_popcount()</a></li>
</ul>

<p>These typically map directly to native hardware instructions. So it doesn't get much faster than these.</p>

<p>But since there's no C/C++ functionality for them, they're only accessible via compiler intrinsics.</p>
"
"<p>I'm programming in C.</p>

<p>I always saw examples and cases where using a macro is better than using function.</p>

<p>Could someone explain me with an example the disadvantage of a macro compared to a function?</p>
","922184","","<p><strong>Side-effects are a big one.</strong> Here's a typical case:</p>

<pre><code>#define min(a,b) (a &lt; b ? a : b)

min(x++,y)
</code></pre>

<p>gets expanded to:</p>

<pre><code>(x++ &lt; y ? x++ : y)
</code></pre>

<p><code>x</code> gets incremented twice in the same statement. (and undefined behavior)</p>

<hr>

<p><strong>Writing multi-line macros are also a pain:</strong></p>

<pre><code>#define foo(a,b,c)  \
    a += 10;        \
    b += 10;        \
    c += 10;
</code></pre>

<p>They require a <code>\</code> at the end of each line.</p>

<hr>

<p><strong>Macros can't ""return"" anything unless you make it a single expression:</strong></p>

<pre><code>int foo(int *a, int *b){
    side_effect0();
    side_effect1();
    return a[0] + b[0];
}
</code></pre>

<p>Can't do that in a macro unless you use GCC's expression statement. (EDIT: You can use a comma operator though... overlooked that... But it might still be less readable.)</p>

<hr>

<p><strong>Order of Operations:</strong> (courtesy of @ouah)</p>

<pre><code>#define min(a,b) (a &lt; b ? a : b)

min(x &amp; 0xFF, 42)
</code></pre>

<p>gets expanded to:</p>

<pre><code>(x &amp; 0xFF &lt; 42 ? x &amp; 0xFF : 42)
</code></pre>

<p>But <code>&amp;</code> has lower precedence than <code>&lt;</code>. So <code>0xFF &lt; 42</code> gets evaluated first.</p>
"
"<p>After executing <code>gcc -m64 -O test.c -save-temps</code>, I noticed that:
<code>mov     %edi, %edi</code>
appears in the generated assembly. Does this instruction even do anything? It moves <code>%edi</code> into itself, effectively accomplishing nothing. </p>

<p>All optimization levels produce this assembly, though in some cases it is placed differently.</p>

<p>Please let me know if you need me to provide further context. As of posting this question, I don't feel that further context is necessary, but I could be incorrect.</p>

<p>Code of procedure:</p>

<pre><code> subl    $400, %edi
 cmpl    $20, %edi
 ja      .L4
 mov     %edi, %edi
 jmp     *.L11(,%rdi,8)
</code></pre>

<p>This is referencing a jump table for a switch statement.</p>

<p>C Source:</p>

<pre><code>int main()
{

}

int thing(int x)
{

   switch(x)
   {
        case 400:
        return  1;
        break;
        case 404:
        return  2;
        break;
        case 408:
        return  3;
        break;
        case 412:
        return  4;
        break;
        case 416:
        return  5;
        break;
        case 420:
        return  6;
        break;
   }

}
</code></pre>
","922184","","<p>In 64-bit mode, the <code>mov</code> instruction when used on 32-bit registers will zero the upper 32-bits of the destination register.</p>

<p>So:</p>

<pre><code>mov %edi, %edi
</code></pre>

<p>clears the top 32-bits of <code>rdi</code>.</p>

<p><a href=""http://en.wikipedia.org/wiki/MOV_%28x86_instruction%29"">http://en.wikipedia.org/wiki/MOV_%28x86_instruction%29</a> (scroll all the way down)</p>
"
"<p>I wrote the following code to sum the series <code>(-1)^i*(i/(i+1))</code>. But when I run it I get <code>-1</code> for any value of n.</p>

<p>Can some one please point out what I am doing wrong? Thank you in advance!</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;

int main()
{
    int sum = 0;
    int i = 1.0;
    int n = 5.0;

    for(i=1;i&lt;=n;i++)
        sum = (-1)^i*(i/(i+1));

    cout &lt;&lt; ""Sum"" &lt;&lt;"" = ""&lt;&lt; sum &lt;&lt; endl;
    return 0;
}
</code></pre>
","922184","","<p><strong>Problem #1:</strong> The C++ <code>^</code> operator isn't the math power operator. It's a bitwise XOR.</p>

<p>You should use <code>pow()</code> instead.</p>

<p><strong>Problem #2:</strong> 
You are storing floating-point types into an integer type. So the following will result in <a href=""http://mathworld.wolfram.com/IntegerDivision.html"" rel=""nofollow"">integer division (truncated division)</a>:</p>

<pre><code>i/(i+1)
</code></pre>

<p><strong>Problem #3:</strong> 
You are not actually summing anything up:</p>

<pre><code>sum = ...
</code></pre>

<p>should be:</p>

<pre><code>sum += ...
</code></pre>

<hr>

<p>A corrected version of the code is as follows:</p>

<pre><code>double sum = 0;
int i = 1;
int n = 5;

for(i = 1; i &lt;= n; i++)
    sum += pow(-1.,(double)i) * ((double)i / (i + 1));
</code></pre>

<hr>

<p>Although you really don't need to use <code>pow</code> in this case. A simple test for odd/even will do.</p>

<pre><code>double sum = 0;
int i = 1;
int n = 5;

for(i = 1; i &lt;= n; i++){
    double val = (double)i / (i + 1);
    if (i % 2 != 0){
        val *= -1.;
    }
    sum += val;
}
</code></pre>
"
"<p>This may be a stupid question but I was going through the K&amp;R book to practice C a bit noticed that you don't need to specify a return type for the functions. I thought C was a strongly typed language. How is this possible ? Is this something like type inference ? Maybe they let something like this because of implicit conversion but a bit confused to see this..</p>

<p>Eg:</p>

<pre><code>#include&lt;stdio.h&gt;

int main()
{
    int c = funct();
}

funct()
{
    return 3;
}
</code></pre>
","922184","","<p>If the return type is omitted, it defaults to <code>int</code>.</p>

<p>So <code>funct()</code> returns a type <code>int</code>. That's why the code compiles.</p>

<p>This is depreciated though, modern compilers will warn you if you omit the return type. (It is not allowed at all in C99 and C++.)</p>

<p><strong>EDIT :</strong>
In addition to that, in your example, you don't declare the <code>funct()</code> function before you call it.</p>

<p><a href=""http://en.wikipedia.org/wiki/Function_prototype#Uses"" rel=""nofollow"">From Wikipedia</a>:</p>

<blockquote>
  <p>In C, if a function is not previously declared and its name occurs in
  an expression followed by a left parenthesis, it is implicitly
  declared as a function that returns an int and nothing is assumed
  about its arguments.</p>
</blockquote>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/1011455/is-it-possible-to-modify-a-string-of-char-in-c"">Is it possible to modify a string of char in C?</a>  </p>
</blockquote>



<pre><code>char *s = ""anusha"";
</code></pre>

<p>Is this like a constant pointer? When i tried to change the character in location 3 by writing <code>s[3]='k'</code>, it gave me a segmentation fault. So i am assuming it is like pointing to a constant array or s is a constant pointer? Which among the two? Please clarify.</p>
","922184","","<p>That is correct, you are not allowed to modify string literals.</p>

<p>However, it's legal to do this:</p>

<pre><code>char s[] = ""anusha"";
s[3] = 'k'
</code></pre>

<p>The difference here being that it is stored as a local array that can be modified.</p>
"
"<p>I have a program in C++ (compiled using g++). I'm trying to apply two doubles as operands to the modulus function, but I get the following error:</p>

<blockquote>
  <blockquote>
    <p>error: invalid operands of types 'double' and 'double' to binary 'operator%'</p>
  </blockquote>
</blockquote>

<p>Here's the code:</p>

<pre><code>int main() {
    double x = 6.3;
    double y = 2;
    double z = x % y;
}
</code></pre>
","922184","","<p>The <code>%</code> operator is for integers.  You're looking for the <a href=""http://en.cppreference.com/w/cpp/numeric/math/fmod""><code>fmod()</code> function</a>.</p>

<pre><code>#include &lt;math.h&gt;

int main() {
    double x = 6.3;
    double y = 2.0;
    double z = fmod(x,y);
    return 0;
}
</code></pre>
"
"<pre><code>void swap(int &amp;first, int &amp;second){
    int temp = first;
    first = second;
    second = temp;
}
</code></pre>

<p>//////</p>

<pre><code>int a=3,b=2;
swap(a,b);
</code></pre>

<p>In the above example, the C compiler complaints that ""void swap(int &amp;first, int &amp;second)"" has a syntax error like missing ""&amp;"" before ""( / {"". I don't understand why? Doesn't C support this feature. Please clarify. Thanks.</p>
","922184","","<p>C doesn't support passing by reference. So you will need to use pointers to do what you are trying to achieve:</p>

<pre><code>void swap(int *first, int *second){
    int temp = *first;
    *first = *second;
    *second = temp;
}


int a=3,b=2;
swap(&amp;a,&amp;b);
</code></pre>

<hr>

<p><strong>I do <em>NOT</em> recommend this:</strong> But I'll add it for completeness.</p>

<p>You can use a macro if your parameters have no side-effects.</p>

<pre><code>#define swap(a,b){   \
    int _temp = (a); \
    (a) = _b;        \
    (b) = _temp;     \
}
</code></pre>
"
"<p>I saw some code that was something like this</p>

<pre><code>int *func2(int *var) {
    //Do some actual work
    return var;
}

int *func1(int *var) {
    return func2(var);
}

int main() {
    int var;
    var = func1(&amp;var);
    return 0;
}
</code></pre>

<p>This seems like an incredible waste to me but I figured the intermediate function might have previously had two function that it could call or there are some plans for expansion in the future. I was just wondering if compilers like gcc can detect this sort of thing and eliminate the useless function in the actual program or if this sort of thing actually wastes CPU cycles at runtime?</p>
","922184","","<p>In most cases, if you turn up the compiler optimizations high enough, such trivial functions will be <a href=""http://en.wikipedia.org/wiki/Inline_expansion"" rel=""nofollow"">inlined</a>. Thus there is no overhead.</p>

<p>So the answer to your question is: <strong>Yes, the compiler is usually smart enough to eliminate the call.</strong><br>
So don't worry about it unless you need to.</p>

<p>You can also use the <code>inline</code> keyword to make it more explicit: (although the compiler is still free to ignore it)</p>

<pre><code>inline int *func1(int *var) {
    return func2(var);
}
</code></pre>
"
"<p>I am weak in mathematics and always get stuck with the problems which require answer modulo some prime no. </p>

<p>eg: (500!/20!) mod 1000000007 </p>

<p>I am familiar with BigIntegers but calculating modulo after calculating factorial of 500(even after using DP) seems to take a load of time. </p>

<p>I'd like to know if there's a particular way of approaching/dealing with these kind of problems. </p>

<p>Here is one such problem which I am trying to solve at the moment:
<a href=""http://www.codechef.com/FEB12/problems/WCOUNT"">http://www.codechef.com/FEB12/problems/WCOUNT</a></p>

<p>It would really be helpful if someone could direct me to a tutorial or an approach to handle these coding problems.
I am familiar with Java and C++.</p>
","922184","","<p>The key to these large-number modulus tasks is not to compute the full result before performing the modulus. <strong>You should reduce the modulus in the intermediate steps to keep the number small:</strong></p>

<pre><code>500! / 20! = 21 * 22 * 23 * ... * 500

21 * 22 * 23 * 24 * 25 * 26 * 27 = 4475671200

4475671200 mod 1000000007 = 475671172
475671172 * 28 mod 1000000007 = 318792725
318792725 * 29 mod 1000000007 = 244988962
244988962 * 30 mod 1000000007 = 349668811

...

 31768431 * 500 mod 1000000007 = 884215395

500! / 20! mod 1000000007 = 884215395
</code></pre>

<p>You don't need to reduce modulus at every single step. Just do it often enough to keep the number from getting too large.</p>
"
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/5117132/integer-wrapper-objects-share-the-same-instances-only-within-the-value-127"">Integer wrapper objects share the same instances only within the value 127?</a><br>
  <a href=""http://stackoverflow.com/questions/8427416/why-is-true-for-some-integer-objects"">Why is == true for some Integer objects?</a>  </p>
</blockquote>



<pre><code>class One
{
    public static void main(String[] args) 
    {
           Integer i1 = 10;
           Integer i2 = 10;

        if (i1 == i2) 
        {
            System.out.println(""In if "");
        } 
        else
        {
            System.out.println(""in else"");
        }
    }
}
</code></pre>

<p>The output of the above program is <code>In if</code>
but if the values of i1 and i2 are changed to 1000 then output is In else.</p>

<p>I know that autoboxing is taking place here but unable to understand the  reasons of the output.
Thank You!</p>
","922184","","<p><code>==</code> only returns true if both operands refer to the same instance.</p>

<p>In the second case, they return false because they aren't the same instance. (the same reason why you can't compare strings with <code>==</code>)</p>

<p>But in the first case, the run-time actually caches <code>Integer</code> objects for small values. Thus, <code>i1</code> and <code>i2</code> point to the same cached object.</p>
"
"<p>Lets assume we have fixed amount of calculation work, without blocking, sleeping, i/o-waiting. The work can be parallelized very well - it consists of 100M small and independent calculation tasks.</p>

<p>What is faster for 4-core CPU - to run 4 threads or... lets say 50? Why second variant should be slover and how much slover?</p>

<p>As i assume: when you run 4 heavy threads on 4-core CPU without another CPU-consuming processes/threads, scheduler is allowed to not move the threads between cores at all; it has no reason to do that in this situation. Core0 (main CPU) will be responsible for executing interruption handler for hardware timer 250 times per second (basic Linux configuration) and other hardware interruption handlers, but another cores may not feel any worries.</p>

<p>What is the cost of context switching? The time for store and restore CPU registers for different context? What about caches, pipelines and various code-prediction things inside CPU? Can we say that each time we switch context, we hurt caches, pipelines and some code-decoding facilities in CPU? So more threads executing on a single core, less work they can do together in comparison to their serial execution?</p>

<p>Question about caches and another hardware optimization in multithreading environment is the interesting question for me now.</p>
","922184","","<p>As @Baile mentions in the comments, this is highly application, system, environment-specific.</p>

<p>And as such, I'm not going to take the hard-line approach of mentioning exactly 1 thread for each core. (or 2 threads/core in the case of Hyperthreading)</p>

<p>As an experienced shared-memory programmer, I have seen from my experience that the optimal # of threads (for a 4 core machine) can range anywhere from 1 to 64+.</p>

<p>Now I will enumerate the situations that can cause this range:</p>

<p><strong>Optimal Threads &lt; # of Cores</strong></p>

<p>In certain tasks that are very fine-grained paralleled (such as small FFTs), the overhead of threading is the dominant performance factor. In some cases, it's it not helpful to parallelize at all. In some cases, you get speedup with 2 threads, but backwards scaling at 4 threads.</p>

<p>Another issue is resource contention. Even if you have a highly parallelizable task that can easily split across 4 cores/threads, you may be bottlenecked by memory bandwidth and cache effects. So often, you find that 2 threads will be just as fast as 4 threads. (as if often the case with very large FFTs)</p>

<p><strong>Optimal Threads = # of Cores</strong></p>

<p>This is the optimal case. No need to explain here - one thread per core. Most embarrassingly parallel applications that are not memory or I/O bound fit right here.</p>

<p><strong>Optimal Threads > # of Cores</strong></p>

<p>This is where it gets interesting... very interesting. Have you heard about load-imbalance? How about over-decomposition and work-stealing?</p>

<p>Many parallelizable applications are irregular - meaning that the tasks do not split into sub-tasks of equal size. So if you may end up splitting a large task into 4 unequal sizes, assign them to 4 threads and run them on 4 cores... the result? Poor parallel performance because 1 thread happened to get 10x more work than the other threads.</p>

<p>A common solution here is to <em>over-decompose</em> the task into many sub-tasks. You can either create threads for each one of them (so now you get <em>threads</em> >> <em>cores</em>). Or you can use some sort of task-scheduler with a fixed number of threads. Not all tasks are suited for both, so quite often, the approach of over-decomposing a task to 8 or 16 threads for a 4-core machine gives optimal results.</p>

<hr>

<p>Although spawning more threads can lead to better load-balance, the overhead builds up. So there's typically an optimal point somewhere. I've seen as high as 64 threads on 4 cores. But as mentioned, it's highly application specific. And you need to experiment.</p>

<hr>

<p><strong>EDIT : Expanding answer to more directly answer the question...</strong></p>

<blockquote>
  <p>What is the cost of context switching? The time for store and restore
  CPU registers for different context?</p>
</blockquote>

<p>This is very dependent on the environment - and is somewhat difficult to measure directly.<br> Short answer: <strong>Very Expensive</strong> <a href=""http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html"">This might be a good read.</a></p>

<blockquote>
  <p>What about caches, pipelines and various code-prediction things inside
  CPU? Can we say that each time we switch context, we hurt caches,
  pipelines and some code-decoding facilities in CPU?</p>
</blockquote>

<p>Short answer: <strong>Yes</strong> When you context switch out, you likely flush your pipeline and mess up all the predictors. Same with caches. The new thread is likely to replace the cache with new data.</p>

<p>There's a catch though. In some applications where the threads share the same data, it's possible that one thread could potentially ""warm"" the cache for another incoming thread or another thread on a different core sharing the same cache. (Although rare, I've seen this happen before on one of my NUMA machines - superlinear speedup: 17.6x across 16 cores!?!?!)</p>

<blockquote>
  <p>So more threads executing on a single core, less work they can do
  together in comparison to their serial execution?</p>
</blockquote>

<p>Depends, depends... Hyperthreading aside, there will definitely be overhead. But I've read a paper where someone used a second thread to prefetch for the main thread... Yes it's crazy...</p>
"
"<p>I'm stuck in a problem in which I need to calculate something like:</p>

<p>((500!)/(20!x20!x20!x20!...)) mod 1000000007 </p>

<p>I understand how to calculate 500!%1000000007 but I am not sure on how to distribute that operator in division. </p>

<p>I am currently trying to write a code which cancels the denominators by its numerator by its factors. But I am not sure if it is a good approach to this.</p>

<p>I just need a mathematical way of solving these kind of problems(mod1000000007) as they are regularly encountered in programming competitions and would help me to prepare for Google Code Jam.</p>
","922184","","<p><strong>Method 1:</strong></p>

<p>Think of how you would compute <code>500! / (20! * 20! * 20! * ...)</code> normally.</p>

<p>Don't multiply everything out and divide at the end. Do your divisions in the middle. Then combine this with the modulus reductions from your previous question.</p>

<p><strong>Method 2:</strong></p>

<p><a href=""http://en.wikipedia.org/wiki/Prime_factor"" rel=""nofollow"">Prime factorize</a> <code>500!</code> and <code>20!</code>. Then subtract out the prime factors of <code>20! * 20! * 20!</code> (or how ever many of them you have) from the prime factors of <code>500!</code>.</p>

<p>Then rebuild the number by multiplying back the remaining factors together. (while taking modulus along the way to keep the number from getting large)</p>

<p><strong>Method 3:</strong></p>

<p>If <code>1000000007</code> (or whatever modulus) is prime, you can do divisions using the <a href=""http://en.wikipedia.org/wiki/Modular_multiplicative_inverse"" rel=""nofollow"">modular inverse</a>.</p>

<p>Compute <code>20! mod 1000000007</code>. Then compute it's modular inverse and multiply it into <code>500! mod 1000000007</code>.</p>
"
"<p>This is really a weird bug to me and it took me long time to figure out what's happening. To simplify things and reproduce, just create a empty win32 console application using VS2005 and use this code in the main method:  </p>

<pre><code>float a = 411.00418f;
float b = 1.0f;
float c = 0.076279849f;
unsigned short result = (unsigned short)( (a-b)/c );
unsigned short result2 = (unsigned short)( (float)((a-b)/c) );
// Debug: 5374, 5375
// Release: 5374, 5374
printf(""%d, %d\n"", result, result2);  
</code></pre>

<p>Why result2 shows different value in debug/release mode?</p>
","922184","","<p>In MSVC, the default floating-point mode is <code>precise (/fp:precise)</code>. Meaning that the optimizer may do certain optimizations to improve accuracy or performance.</p>

<p>Try changing mode to <code>strict (/fp:strict)</code>. This will make the compiler follow the strict floating-point rules on rounding and such.</p>

<p>(EDIT: <code>strict (/fp:strict)</code> doesn't seem to work in this case...)</p>

<p>If you look at the disassembly of the optimized build, you can see that the entire computation has been folded and optimized out.</p>

<pre><code>push    5374                    ; 000014feH
push    5374                    ; 000014feH
push    OFFSET ??_C@_07MHMABKGB@?$CFd?0?5?$CFd?6?$AA@
call    DWORD PTR __imp__printf
add esp, 12                 ; 0000000cH
</code></pre>

<p><strong>EDIT : This looks like a compiler optimizer bug to me.</strong></p>

<p>Under <code>strict (/fp:strict)</code>, the following code produces different results:</p>

<pre><code>float a = 411.00418f;
float b = 1.0f;
float c = 0.076279849f;

unsigned short result1 = (unsigned short)((float)((a-b)/c));

float d = (float)((a-b)/c);
unsigned short result2 = (unsigned short)( d );
</code></pre>

<p>Output:</p>

<pre><code>5374, 5375
</code></pre>

<p>Pulling out the <code>(float)((a-b)/c)</code> into a separate assignment should not affect the results under <code>strict (/fp:strict)</code>.</p>

<hr>

<p><strong>I know one of the guys who work on the MSVC optimizer. I'll send a bug report to him.</strong></p>

<h1>Update:</h1>

<p>Here's their response:</p>

<blockquote>
  <p>Hi Alex, thanks for this bug report. I’ll try to fix this for the
  upcoming VC++ release, but it might not make it.</p>
  
  <p>FWIW, the bug doesn’t reproduce if you throw /arch:SSE2, and since we
  are enabling /arch:SSE2 by default for the next VC++ release
  (https://connect.microsoft.com/VisualStudio/feedback/details/688736/compiler-generates-sse-instructions-without-arch-sse).</p>
  
  <p>So, the default behavior will show that this bug is fixed. But if
  you revert back to the old FP model (throw /arch:IA32) the bug may
  still be present.</p>
  
  <p>Eric</p>
</blockquote>

<p><strong>So they've confirmed this as a bug.</strong></p>
"
"<p>I was trying to figure out how to parallelize a segment of code in OpenMP, where the inside of the for loop is independent from the rest of it.</p>

<p>Basically the project is dealing with particle systems, but I don't think that should relevant to the parallelization of the code. Is it a caching problem where the for loop divides the threads in a way such that the particles are not cached in each core in an efficient manner?</p>

<p><strong>Edit:</strong> As mentioned by an answer below, I'm wondering why I'm not getting speedup.</p>

<pre><code>#pragma omp parallel for
for (unsigned i = 0; i &lt; psize-n_dead; ++i)
{
    s-&gt;particles[i].pos = s-&gt;particles[i].pos + dt * s-&gt;particles[i].vel;
    s-&gt;particles[i].vel = (1 - dt*.1) * s-&gt;particles[i].vel + dt*s-&gt;force;
    //  printf(""%d"", omp_get_thread_num());

}
</code></pre>
","922184","","<p>If you're asking whether it's <strong><em>parallelized</em></strong> correctly, it looks fine. I don't see any data-races or loop-dependencies that could break it.</p>

<p>But I think you're wondering on why you aren't getting any speedup with parallelism.</p>

<p>Since you mentioned that the trip count, <code>psize-n_dead</code> will be on the order of <code>4000</code>. I'd say that's actually pretty small given the amount of work in the loop.</p>

<p>In other words, you don't have much total work to be worth parallelizing. So threading overhead is probably eating up any speedup that you should be gaining. If possible, you should try parallelizing at a higher level.</p>

<hr>

<p>EDIT: You updated your comment to include up to 200000.</p>

<p>For larger values, it's likely that you'll be memory bound in some way. Your loop merely iterates through all the data doing very little work. So using more threads probably won't help much (if at all).</p>
"
"<p>I'm trying to malloc a huge 4d array (192 gig available); but what goes in does not match what comes out (see assert() in code below).
(I made the defined sizes small; but the real numbers are: 20,9000,195,120)</p>

<pre><code>#define SIZE_A 1
#define SIZE_B 3
#define SIZE_C 4
#define SIZE_D 2

#define offSet(a,b,c,d) ( ((size_t) SIZE_A * SIZE_B * SIZE_C * a) + ((size_t) SIZE_B * SIZE_C * b) + ((size_t) SIZE_C * c) + d)

void xall(void)
{
int *aray = (int *) malloc( (size_t) SIZE_A * SIZE_B * SIZE_C *  SIZE_D  * sizeof(int));


int counter = 0;

    for (int a = 0; a &lt; SIZE_A; ++a){
        for (int b = 0; b &lt; SIZE_B; ++b){
            for (int c = 0; c &lt; SIZE_C; ++c) {
                for (int d = 0; d &lt; SIZE_D; ++d){
                    aray[ offSet(a,b,c,d) ] = counter++;

                }}}}


counter = 0;    
    for (int a = 0; a &lt; SIZE_A; ++a){
        for (int b = 0; b &lt; SIZE_B; ++b){
            for (int c = 0; c &lt; SIZE_C; ++c) {
                for (int d = 0; d &lt; SIZE_D; ++d){       
                    int value = aray[ offSet(a,b,c,d) ] ;
                    assert(value == counter++);

                }}}}
}
</code></pre>
","922184","","<p>Your macro isn't quite correct. Change it to this:</p>

<pre><code>#define offSet(a,b,c,d) ( ((size_t) SIZE_B * SIZE_C * SIZE_D * a) + ((size_t) SIZE_C * SIZE_D * b) + ((size_t) SIZE_D * c) + d)
</code></pre>

<p>You basically had your <code>SIZE_X</code> shifted over by 1 letter.</p>

<p>I also suggest putting <code>()</code> around your macro parameters:</p>

<pre><code>#define offSet(a,b,c,d) ( ((size_t) SIZE_B * SIZE_C * SIZE_D * (a)) + ((size_t) SIZE_C * SIZE_D * (b)) + ((size_t) SIZE_D * (c)) + (d) )
</code></pre>
"
"<p>I'm trying to write an application which will populate an array with random numbers. Everything seems to work fine until I try to enter the for loop in my populateArray method.</p>

<pre><code>import java.util.Random;

public class PerformanceTester {

//takes an empty array, but the size must be allocated BEFORE passing 
//to this function. Function takes a pre-allocated array and input size.
public static int[] populateArray(int[] inputArray, int n) {

    //Create the number generator
    Random generator = new Random();

    int length = inputArray.length;
    System.out.println(""Inputted array is length: "" + length);

    for (int i = 0; i == length; i++) {
        // for debugging purposes: System.out.println(""For loop entered."");
        int random = generator.nextInt((2 * n) / 3);
        // for debugging purposes: System.out.println(""Adding "" + random + "" to the array at index "" + i);
        inputArray[i] = random;

    }
    return inputArray;
    }

public static void main(String[] args) {

    int[] input;
    input = new int[10];
    int[] outputArray = populateArray(input, 10);
    System.out.print(outputArray[0]);

}
}
</code></pre>

<p>As shown by my output, the compiler clearly enters the method (when called on line 29) but seems to stop all execution when the for loop is reached. I'm 100% sure that my loop has proper initialization and termination operators, because length is equal to ten.</p>

<p>I'm honestly stumped, but like most cases, I'm certain its a very simple answer. My output is below:</p>

<pre><code>Inputted array is length: 10
0 //The array is not populated with numbers, so all indexes of the array return zero.
</code></pre>

<p>Any and all help is greatly appreciated.</p>
","922184","","<p>Surely you meant your loop test to be this right?</p>

<pre><code>for (int i = 0; i &lt; length; i++) {
</code></pre>

<p>Otherwise, <code>i == length</code> will never be true (unless <code>length == 0</code>) and it will never enter the loop.</p>

<p>You also could have used:</p>

<pre><code>for (int i = 0; i != length; i++) {
</code></pre>
"
"<p>I'm confused with the byte order of a system/cpu/program.<br>
So I must ask some questions to make my mind clear.</p>

<h3>Question 1</h3>

<p>If I only use type <code>char</code> in my C++ program:</p>

<pre><code>void main()
{
    char c = 'A';
    char* s = ""XYZ"";    
}
</code></pre>

<p>Then compile this program to a executable binary file called <code>a.out</code>.<br>
Can <code>a.out</code> both run on little-endian and big-endian systems?</p>

<h3>Question 2</h3>

<p>If my Windows XP system is little-endian, can I install a big-endian Linux system in VMWare/VirtualBox? 
What makes a system little-endian or big-endian?</p>

<h3>Question 3</h3>

<p>If I want to write a byte-order-independent C++ program, what do I need to take into account?</p>
","922184","","<p><strong>Question 1:</strong></p>

<blockquote>
  <p>Can a.out both run on little-endian and big-endian system?</p>
</blockquote>

<p>No. Because <code>a.out</code> is already compiled for whatever architecture it is targeting. It will not run on another architecture that it is incompatible with.</p>

<p>However, the source code for that simple program has nothing that could possibly break on different endian machines.</p>

<p>So yes it (the source) will work properly. (well... aside from <code>void main()</code>, which you should be using <code>int main()</code> instead)</p>

<p><strong>Question 2:</strong></p>

<blockquote>
  <p>If my WindowsXP system is little-endian, can I install a big-endian
  Linux system in VMWare/VirtualBox?</p>
</blockquote>

<p>Endian-ness is determined by the hardware, not the OS. So whatever (native) VM you install on it, will be the same endian as the host. (since x86 is all little-endian)</p>

<blockquote>
  <p>What makes a system little-endian or big-endian?</p>
</blockquote>

<p>Here's an example of something that will behave differently on little vs. big-endian:</p>

<pre><code>uint64_t a = 0x0123456789abcdefull;
uint32_t b = *(uint32_t*)&amp;a;
printf(""b is %x"",b)
</code></pre>

<p>*Note that this violates strict-aliasing, and is only for demonstration purposes.</p>

<pre><code>Little Endian : b is 89abcdef
Big Endian    : b is 1234567
</code></pre>

<p>On little-endian, the lower bits of <code>a</code> are stored at the lowest address. So when you access <code>a</code> as a 32-bit integer, you will read the lower 32 bits of it. On big-endian, you will read the upper 32 bits.</p>

<p><strong>Question 3:</strong></p>

<blockquote>
  <p>If I want to write a byte-order independent C++ program, what do I
  need to take into account?</p>
</blockquote>

<p>Just follow the standard C++ rules and don't do anything ugly like the example I've shown above. Avoid undefined behavior, avoid type-punning...</p>
"
"<p>I'm trying to declare an array of pointers of a <code>struct</code> <code>some_struct</code> in C</p>

<p>Can I do:</p>

<pre><code>some_struct* arr[10];
</code></pre>

<p>instead of:</p>

<pre><code>some_struct** arr=(some_struct**)malloc(10*sizeof(some_struct*));
</code></pre>

<p>And what's the difference?</p>
","922184","","<ul>
<li>The first one puts the array on the stack.</li>
<li>The second one allocates it on the heap.</li>
</ul>

<p>In the first case, the lifetime of the array is only the scope at which it is defined in. 
When it falls out of scope, it will be freed automatically so you don't have to do any clean up.</p>

<p>In the second case, the array lives beyond the scope where the pointer is declared. So you will need to manually <code>free()</code> it later to avoid a memory leak.</p>
"
"<p>This is quite an interesting question so let me set the scene. I work at The National Museum of Computing, and we have just managed to get a Cray Y-MP EL super computer from 1992 running, and we really want to see how fast it can go!</p>

<p>We decided the best way to do this was to write a simple C program that would calculate prime numbers and show how long it took to do so, then run the program on a fast modern desktop PC and compare the results.</p>

<p>We quickly came up with this code to count prime numbers:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;time.h&gt;

void main() {
    clock_t start, end;
    double runTime;
    start = clock();
    int i, num = 1, primes = 0;

    while (num &lt;= 1000) { 
        i = 2; 
        while (i &lt;= num) { 
            if(num % i == 0)
                break;
            i++; 
        }
        if (i == num)
            primes++;

        system(""clear"");
        printf(""%d prime numbers calculated\n"",primes);
        num++;
    }

    end = clock();
    runTime = (end - start) / (double) CLOCKS_PER_SEC;
    printf(""This machine calculated all %d prime numbers under 1000 in %g seconds\n"", primes, runTime);
}
</code></pre>

<p>Which on our dual core laptop running Ubuntu (The Cray runs UNICOS), worked perfectly, getting 100% CPU usage and taking about 10 minutes or so. When I got home I decided to try it on my hex-core modern gaming PC, and this is where we get our first issues.</p>

<p>I first adapted the code to run on Windows since that is what the gaming PC was using, but was saddened to find that the process was only getting about 15% of the CPU's power. I figured that must be Windows being Windows, so I booted into a Live CD of Ubuntu thinking that Ubuntu would allow the process to run with its full potential as it had done earlier on my laptop.</p>

<p>However I only got 5% usage! So my question is, how can I adapt the program to run on my gaming machine in either Windows 7 or live Linux at 100% CPU utilisation? Another thing that would be great but not necessary is if the end product can be one .exe that could be easily distributed and ran on Windows machines.</p>

<p>Thanks a lot!</p>

<p>P.S. Of course this program didn't really work with the Crays 8 specialist processors, and that is a whole other issue... If you know anything about optimising code to work on 90's Cray super computers give us a shout too!</p>
","922184","","<p>If you want 100% CPU, you need to use more than 1 core. To do that, you need multiple threads.</p>

<p><strong>Here's a parallel version using OpenMP:</strong></p>

<p>I had to increase the limit to <code>1000000</code> to make it take more than 1 second on my machine.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;time.h&gt;
#include &lt;omp.h&gt;

int main() {
    double start, end;
    double runTime;
    start = omp_get_wtime();
    int num = 1,primes = 0;

    int limit = 1000000;

#pragma omp parallel for schedule(dynamic) reduction(+ : primes)
    for (num = 1; num &lt;= limit; num++) { 
        int i = 2; 
        while(i &lt;= num) { 
            if(num % i == 0)
                break;
            i++; 
        }
        if(i == num)
            primes++;
//      printf(""%d prime numbers calculated\n"",primes);
    }

    end = omp_get_wtime();
    runTime = end - start;
    printf(""This machine calculated all %d prime numbers under %d in %g seconds\n"",primes,limit,runTime);

    return 0;
}
</code></pre>

<p><strong>Output:</strong></p>

<blockquote>
  <p>This machine calculated all 78498 prime numbers under 1000000 in 29.753 seconds</p>
</blockquote>

<p><strong>Here's your 100% CPU:</strong></p>

<p><img src=""http://i.stack.imgur.com/d6jxk.png"" alt=""enter image description here""></p>
"
"<p>I made a simple program that allows the user to pick a number of dice then guess the outcome... I posted this code before but with the wrong question so it was deleted... now I cannot have any errors or even warnings on this code but for some reason this warning keeps popping and I have no clue how to fix it...
<strong>""warning C4244: 'argument' : conversion from 'time_t' to 'unsigned int', possible loss of data""</strong></p>

<pre><code>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;cstdlib&gt;
#include &lt;time.h&gt;

using namespace std;

int  choice, dice, random;

int main(){
    string decision;
    srand ( time(NULL) );
    while(decision != ""no"" || decision != ""No"")
    {
        std::cout &lt;&lt; ""how many dice would you like to use? "";
        std::cin &gt;&gt; dice;
        std::cout &lt;&lt; ""guess what number was thrown: "";
        std::cin &gt;&gt; choice;
         for(int i=0; i&lt;dice;i++){
            random = rand() % 6 + 1;
         }
        if( choice == random){
            std::cout &lt;&lt; ""Congratulations, you got it right! \n"";
            std::cout &lt;&lt; ""Want to try again?(Yes/No) "";
            std::cin &gt;&gt; decision;
        } else{
            std::cout &lt;&lt; ""Sorry, the number was "" &lt;&lt; random &lt;&lt; ""... better luck next  time \n"" ;
            std::cout &lt;&lt; ""Want to try again?(Yes/No) "";
            std::cin &gt;&gt; decision;
        }

    }
    std::cout &lt;&lt; ""Press ENTER to continue..."";
    std::cin.ignore( std::numeric_limits&lt;std::streamsize&gt;::max(), '\n' );
    return 0;
}
</code></pre>

<p>This is what I am trying to figure out, why am I getting this warning:
warning C4244: 'argument' : conversion from 'time_t' to 'unsigned int', possible loss of data</p>
","922184","","<p>That's because on your system, <code>time_t</code> is a larger integer type than <code>unsigned int</code>.</p>

<ul>
<li><code>time()</code> returns a <code>time_t</code> which is probably a 64-bit integer.</li>
<li><code>srand()</code> wants an <code>unsigned int</code> which is probably a 32-bit integer.</li>
</ul>

<p>Hence you get the warning. You can silence it with a cast:</p>

<pre><code>srand ( (unsigned int)time(NULL) );
</code></pre>

<p>In this case, the downcast (and potential data loss) doesn't matter since you're only using it to seed the RNG.</p>
"
"<p>I'm using <code>double long</code> in my 64 bit computer and <code>sizeof(double long)</code> is <code>16 bytes</code>.
So I do the following assignment:</p>

<pre><code>  long double f = 0xA0000000000000000000000000000000; // 32 characters in hex
</code></pre>

<p>and I get this warning: <code>warning: integer constant is too large for its type</code>. That warning doesn't seem correct, my constant can be easily saved in a 128bit value. So, why do I get the warning?</p>

<p>I also have this code:</p>

<pre><code>  long double tmp = 0x90000000CCCCCCCC0000000000000000;
  long double res = (f &amp; tmp);  // where f is the previously defined variable
</code></pre>

<p>and I get the following error <code>error: invalid operands to binary &amp;</code>. Why ?</p>
","922184","","<p>Expanding my comment:</p>

<p><code>long double</code> is a floating-point type. That's why you can't do bit-wise operators on them.</p>

<p>Unfortunately, the standard doesn't guarantee a 128-bit integer type. The only compiler I know of that actually supports it as an extension is <a href=""http://gcc.gnu.org/onlinedocs/gcc/_005f_005fint128.html"" rel=""nofollow"">GCC via __int128</a>. (EDIT: It doesn't look it always supports it.)</p>

<p>MSVC also has the <code>__int128</code> type, but it remains only reserved and unimplemented.</p>

<p>If you're only doing bit-wise operations, you can use a struct with two 64-bit integers. Or if you're on x86, you can use the 128-bit SSE datatypes.</p>
"
"<p>I am trying to concat two const char * strings. </p>

<p>When i have a statement like <code>strcat(a,b)</code> I get the warning <code>expected ‘char * restrict’ but argument is of type ‘const char *’</code> </p>

<p>is there a way to call strcat that will not produce the warning?
Thanks!</p>
","922184","","<p><code>strcat()</code> modifies the first operand. Therefore it cannot be <code>const</code>. But you passed it a <code>const char*</code>.</p>

<p>So you can't use <code>strcat()</code> on two <code>const *char</code> strings.</p>
"
"<p>I've got some code for which I'd like to use OpenMP in the following way:</p>

<pre><code>std::vector&lt;int&gt; v(1000);
# pragma omp parallel for
for (int i = 0; i &lt; 1000; ++i) {
    v[i] = i;
}
</code></pre>

<p>I have read that STL vector container is not thread-safe in the situation where multiple threads write to a single container, which would imply that I'd need to lock the vector before making any writes; however, I've also been told that the write operation above is somehow ""atomic"", and so there is no race condition above.  Could someone clarify this?</p>
","922184","","<p>In this particular example, it will be safe.</p>

<p>The reason is that you're not using operations that could cause a reallocation. (such as <code>push_back()</code>) You're only changing the contents of the individual elements.</p>

<p>Note that you can just at legally do this:</p>

<pre><code>std::vector&lt;int&gt; v(1000);
int *ptr = &amp;v[0];

# pragma omp parallel for
for (int i = 0; i &lt; 1000; ++i) {
    ptr[i] = i;
}
</code></pre>

<hr>

<p>It becomes not-thread-safe when you start calling methods like <code>push_back()</code>, <code>pop_back()</code>, <code>insert()</code>, etc... from multiple threads.</p>

<p>I'll also add that this particular example isn't well-suited for parallelism since there's hardly any work to be done. But I suppose it's just a dumbed-down example for the purposes of asking this question.</p>
"
"<p>I cant figure out how to properly pass this double pointer.... nothing i've tried works...</p>

<pre><code>class myClass{

    MyClass *attribClass;
}

void derp(MyClass **myA) {
    // recursively calls down classes....
    derp(&amp;(myA-&gt;attribClass)); // what am i doing wrong?
}

int main() {

    MyClass *myClass = new MyClass;

    myClass.attribClass = *whatever code to initialize a long linked list of MyClass's*;

    derp(&amp;myClass); 
}
</code></pre>
","922184","","<p>There's several issues:</p>

<pre><code>class MyClass {  //  Change to ""MyClass"".

public:   //  Need to make it public or it can't be accessed by ""derp()""
          //  Did you intend ""derp()"" to be a class member?

    MyClass *attribClass;
}; //  missing semicolon

void derp(MyClass **myA) {
    // recursively calls down classes....
    derp(&amp;((*myA)-&gt;attribClass)); // what am i doing wrong?
}
</code></pre>

<p>And in the last one, you need to deference <code>myA</code> once before you access <code>attribClass</code>.</p>

<pre><code>derp(&amp;((*myA)-&gt;attribClass)); // what am i doing wrong?
</code></pre>
"
"<p>I am presently using openMP for the first time, and have hit my head against the ""data members cannot be private""-rule.</p>

<p>I would like to know whether the below is valid, or if it will eventually break:</p>

<pre><code>class network
{
    double tau;
    void SomeFunction();
};

void network::SomeFunction()
{
    #pragma omp parallel for // &lt;-the openMP call
    for (uint iNeu=0;iNeu&lt;nNeurons;++iNeu)
    {
        neurons[iNeu].timeSinceSpike+=tau;  //tau is defined in some other place
        neurons[iNeu].E+=tau*tau;
    }   
}
</code></pre>

<p>So, I am using the minimal syntax, and letting openMP figure out everything on its own. This version compiles, and the output is correct (so far).
What I tried before that was</p>

<pre><code>void network::SomeFunction()
{
    #pragma omp parallel for default(none) shared(neurons) firstprivate(tau)  // &lt;-the openMP call
    for (uint iNeu=0;iNeu&lt;nNeurons;++iNeu)
    {
        neurons[iNeu].timeSinceSpike+=tau; //tau is defined in some other place
        neurons[iNeu].E+=tau*tau;
    }   
}
</code></pre>

<p>However, as hinted, that won't compile, presumably because tau and neurons are data members of network.</p>

<p>The question then is, if I have really just been lucky in my runs of the first version, and whether I have to do something like</p>

<pre><code>void network::SomeFunction()
{
    double tempTau=tau;
    vector &lt;neuron&gt; tempNeurons=neurons; //in realtity this copy-process would be quite involved
    #pragma omp parallel for shared(tempNeurons) firstprivate(tempTau)// &lt;-the openMP call
    for (uint iNeu=0;iNeu&lt;nNeurons;++iNeu)
    {
        tempNeurons[iNeu].timeSinceSpike+=tempTau;
        tempNeurons[iNeu].E+=tempTau*tempTau;
    }   
}
</code></pre>

<p>Naturally, I would much prefer to stick with the present version, as it is so short and easy to read, but I would also like to trust my output :)
I am using gcc 4.6.1</p>

<p>Hope someone can educate me on the proper way to do it.</p>
","922184","","<p>In this example, what you are initially doing should be fine:</p>

<ul>
<li>The reason is that you aren't modifying the <code>tau</code> member at all. So there's no reason to make it private in the first place. It's safe to asynchronously share the same value if it isn't modified.</li>
<li>As for <code>neurons</code>, you are modifying the elements independently. So there's no problem here either.</li>
</ul>

<p>When you declare a variable as <code>firstprivate</code>, it gets copy constructed into all the threads. So <code>shared(tempNeurons)</code> is definitely <em>not</em> what you want to do.</p>
"
"<p>I have the following code that I use to compute the distance between two vectors:</p>

<pre><code>double dist(vector&lt;double&gt; &amp; vecA, vector&lt;double&gt; &amp; vecB){
    double curDist = 0.0;
    for (size_t i = 0; i &lt; vecA.size(); i++){
        double dif = vecA[i] - vecB[i];
        curDist += dif * dif;
    }

    return curDist;
}
</code></pre>

<p>This function is a major bottleneck in my application since it relies on a lot of distance calculations, consuming more than 60% of CPU time on a typical input. Additionally, the following line:</p>

<pre><code>double dif = vecA[i] - vecB[i];
</code></pre>

<p>is responsible for more than 77% of CPU time in this function. My question is: is it possible to somehow optimize this function?</p>

<p>Notes:</p>

<ul>
<li>To profile my application I have used Intel Amplifier XE;</li>
<li>Reducing the number of distance computations is not a feasible solution for
me;</li>
</ul>
","922184","","<p>There are two possible issues I can think of right now:</p>

<ul>
<li>This computation is memory bound.</li>
<li>There is an iteration-to-iteration dependency on <code>curDist</code>.</li>
</ul>

<hr>

<p><strong>This computation is memory bound.</strong></p>

<p>Your dataset is larger than your CPU cache. So in this case, no amount of optimization is going to help unless you can restructure your algorithm.</p>

<hr>

<p><strong>There is an iteration-to-iteration dependency on <code>curDist</code>.</strong></p>

<p>You have a dependency on <code>curDist</code>. This will block vectorization by the compiler. (Also, don't always trust the profiler numbers to the line. They can be inaccurate especially after compiler optimizations.)</p>

<p>Normally, the compiler vectorizer can split up the <code>curDist</code> into multiple partial sums to and unroll/vectorize the loop. But it can't do that under strict-floating-point behavior. You can try relaxing your floating-point mode if you haven't already. Or you can split the sum and unroll it yourself.</p>

<p>For example, this kind of optimization is something the compiler can do with integers, <strong>but not necessarily with floating-point</strong>:</p>

<pre><code>double curDist0 = 0.0;
double curDist1 = 0.0;
double curDist2 = 0.0;
double curDist3 = 0.0;
for (size_t i = 0; i &lt; vecA.size() - 3; i += 4){
    double dif0 = vecA[i + 0] - vecB[i + 0];
    double dif1 = vecA[i + 1] - vecB[i + 1];
    double dif2 = vecA[i + 2] - vecB[i + 2];
    double dif3 = vecA[i + 3] - vecB[i + 3];
    curDist0 += dif0 * dif0;
    curDist1 += dif1 * dif1;
    curDist2 += dif2 * dif2;
    curDist3 += dif3 * dif3;
}

//  Do some sort of cleanup in case (vecA.size() % 4 != 0)

double curDist = curDist0 + curDist1 + curDist2 + curDist3;
</code></pre>
"
"<p>I've wrote program, and compiled it for x64 and x86 platform in Visual Studio 2010 on Intel Core i5-2500. x64 version take about 19 seconds for execution and x86 take about 17 seconds. What can be the reason of such behavior?</p>

<pre><code>#include ""timer.h""

#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;algorithm&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;

/********************DECLARATIONS************************************************/
class Vector
{
public:
    Vector():x(0),y(0),z(0){}

    Vector(double x, double y, double z)
        : x(x)
        , y(y)
        , z(z)
    {
    }

    double x;
    double y;
    double z;
};


double Dot(const Vector&amp; a, const Vector&amp; b)
{
    return a.x * b.x + a.y * b.y + a.z * b.z;
}


class Vector2
{
public:
    typedef double value_type;

    Vector2():x(0),y(0){}

    Vector2(double x, double y)
        : x(x)
        , y(y)
    {
    }

    double x;
    double y;
};

/******************************TESTS***************************************************/

void Test(const std::vector&lt;Vector&gt;&amp; m, std::vector&lt;Vector2&gt;&amp; m2)
{
    Vector axisX(0.3f, 0.001f, 0.25f);
    Vector axisY(0.043f, 0.021f, 0.45f);

    std::vector&lt;Vector2&gt;::iterator i2 = m2.begin();

    std::for_each(m.begin(), m.end(),
        [&amp;](const Vector&amp; v)
    {
        Vector2 r(0,0);
        r.x = Dot(axisX, v);
        r.y = Dot(axisY, v);

        (*i2) = r;
        ++i2;
    });
}


int main()
{
    cpptask::Timer timer;

    int len2 = 300;
    size_t len = 5000000;
    std::vector&lt;Vector&gt; m;
    m.reserve(len);
    for (size_t i = 0; i &lt; len; ++i)
    {
        m.push_back(Vector(i * 0.2345, i * 2.67, i * 0.98));
    }

    /***********************************************************************************/
    {
        std::vector&lt;Vector2&gt; m2(m.size());
        double time = 0;
        for (int i = 0; i &lt; len2; ++i)
        {
            timer.Start();
            Test(m, m2);
            time += timer.End();
        }
        std::cout &lt;&lt; ""Dot product double - "" &lt;&lt; time / len2 &lt;&lt; std::endl;
    }
    /***********************************************************************************/


    return 0;
}
</code></pre>
","922184","","<p><strong>Short Answer:</strong> It's a compiler hiccup. x64 optimizer fail.</p>

<hr>

<p><strong>Long Answer:</strong></p>

<p>This x86 version is very slow if SSE2 is disabled. But I'm able to reproduce the results with SSE2 enabled in x86.</p>

<p>If you dive into the assembly of that inner-most loop. The x64 version has two extra memory copies at the end.</p>

<p><strong>x86:</strong></p>

<pre><code>$LL71@main:
movsd   xmm2, QWORD PTR [eax-8]
movsd   xmm0, QWORD PTR [eax-16]
movsd   xmm3, QWORD PTR [eax]
movapd  xmm1, xmm0
mulsd   xmm0, QWORD PTR __real@3fa60418a0000000
movapd  xmm7, xmm2
mulsd   xmm2, QWORD PTR __real@3f95810620000000
mulsd   xmm7, xmm5
mulsd   xmm1, xmm4
addsd   xmm1, xmm7
movapd  xmm7, xmm3
mulsd   xmm3, QWORD PTR __real@3fdcccccc0000000
mulsd   xmm7, xmm6
add eax, 24                 ; 00000018H
addsd   xmm1, xmm7
addsd   xmm0, xmm2
movq    QWORD PTR [ecx], xmm1
addsd   xmm0, xmm3
movq    QWORD PTR [ecx+8], xmm0
lea edx, DWORD PTR [eax-16]
add ecx, 16                 ; 00000010H
cmp edx, esi
jne SHORT $LL71@main
</code></pre>

<p><strong>x64:</strong></p>

<pre><code>$LL175@main:
movsdx  xmm3, QWORD PTR [rdx-8]
movsdx  xmm5, QWORD PTR [rdx-16]
movsdx  xmm4, QWORD PTR [rdx]
movapd  xmm2, xmm3
mulsd   xmm2, xmm6
movapd  xmm0, xmm5
mulsd   xmm0, xmm7
addsd   xmm2, xmm0
movapd  xmm1, xmm4
mulsd   xmm1, xmm8
addsd   xmm2, xmm1
movsdx  QWORD PTR r$109492[rsp], xmm2
mulsd   xmm5, xmm9
mulsd   xmm3, xmm10
addsd   xmm5, xmm3
mulsd   xmm4, xmm11
addsd   xmm5, xmm4
movsdx  QWORD PTR r$109492[rsp+8], xmm5
mov rcx, QWORD PTR r$109492[rsp]
mov QWORD PTR [rax], rcx
mov rcx, QWORD PTR r$109492[rsp+8]
mov QWORD PTR [rax+8], rcx
add rax, 16
add rdx, 24
lea rcx, QWORD PTR [rdx-16]
cmp rcx, rbx
jne SHORT $LL175@main
</code></pre>

<p>The x64 version has a lot more (unexplained) moves at the end of the loop. It looks like some sort of memory-to-memory data-copy.</p>

<h1>EDIT:</h1>

<p>It turns out that the x64 optimizer isn't able to optimize out the following copy:</p>

<pre><code>(*i2) = r;
</code></pre>

<p>This is why the inner loop has two extra memory copies. If you change the loop to this:</p>

<pre><code>std::for_each(m.begin(), m.end(),
    [&amp;](const Vector&amp; v)
{
    i2-&gt;x = Dot(axisX, v);
    i2-&gt;y = Dot(axisY, v);
    ++i2;
});
</code></pre>

<p>This eliminates the copies. Now the x64 version is just as fast as the x86 version:</p>

<pre><code>x86: 0.0249423
x64: 0.0249348
</code></pre>

<p><strong>Lesson Learned:</strong> Compilers aren't perfect.</p>
"
"<p>I have just read this question: <a href=""http://stackoverflow.com/questions/2740268/could-this-code-damage-my-processor"">Could this code damage my processor?</a> and this made me think.</p>

<p>Is it possible to damage hardware just by software? I heard that ""in the good old days"" (TM), when hard disk actuators were controlled by software, they could be hit against the central spindle, which would damage the drive permanently.</p>

<p>There was also the infamous <a href=""http://en.wikipedia.org/wiki/CIH_(computer_virus)"" rel=""nofollow"">Chernobyl virus</a> which just killed the BIOS and rendered the machine useless, until someone reflashed it.</p>

<p>And there are microcode updates, which can be flashed to the CPU (and I don't know much about them).</p>

<p>But is this still possible today? Could you damage hardware by software? Execute the <code>hcf</code> (Halt &amp; Catch fire) instruction? Grill the cat by increasing WLAN output power?</p>
","922184","","<p>Being someone who likes to build and overclock computers, I can name a few (very extreme) cases where this <strong><em>could potentially</em></strong> happen. (I emphasize <strong><em>potentially</em></strong> because such conditions are somewhat unrealistic in most machines today.)</p>

<p>The first example is a <strong>BIOS flash</strong>. Some motherboards allow you to flash (modify) the BIOS via software from within the OS. This opens a backdoor for malware to flash the BIOS to something that will damage the processor. (for example, increase the voltage to 2V - and BOOM!!!)</p>

<p>In a second case, some motherboard provide <strong>overclocking tools</strong> that allow you to change CPU settings from within the OS. If a virus takes over that - then like in the first example, set your CPU to settings that are damaging and fry it.</p>

<p>In a third example (possibly the most realistic ones) are the <strong>stress-tests and intensive applications</strong>. For example, most laptops today aren't designed to run numerical code for very long durations and may overheat. Although hardware temperature sensors will usually shutdown a machine that has overheated to a certain point, the thresholds tend to be very high - and it is not safe to sustain a CPU at a temperature just below the safety shutdown threshold.</p>

<p>An example of some code that has the potential to overheat a CPU is my answer to this micro-optimization question: <a href=""http://stackoverflow.com/questions/8389648/how-to-achieve-4-flops-per-cycle/8391601#8391601"">how to achieve 4 flops per cycle</a></p>
"
"<p>My CPU is a Core i3 330M with 2 cores and 4 threads. When I execute the command cat <code>/proc/cpuinfo</code> in my terminal, it is like I have 4 CPUS. When I use the OpenMP function <code>get_omp_num_procs()</code> I also get 4. </p>

<p>Now I have a standard C++ vector class, I mean a fixed-size double array class that does not use expression templates. I have carefully parallelized all the methods of my class and I get the ""expected"" speedup. </p>

<p>The question is: can I guess the expected speedup in such a simple case? For instance, if I add two vectors without parallelized for-loops I get some time (using the shell time command). Now if I use OpenMP, should I get a time divided by 2 or 4, according to the number of cores/threads? I emphasize that I am only asking for this particular simple problem, where there is no interdependence in the data and everything is linear (vector addition). </p>

<p>Here is some code:</p>

<pre><code>Vector Vector::operator+(const Vector&amp; rhs) const
{
    assert(m_size == rhs.m_size);
    Vector result(m_size);
    #pragma omp parallel for schedule(static)
    for (unsigned int i = 0; i &lt; m_size; i++) 
            result.m_data[i] = m_data[i]+rhs.m_data[i];

    return result;
}
</code></pre>

<p>I have already read this post: <a href=""http://stackoverflow.com/questions/4717251/openmp-thread-mapping-to-physical-cores"">OpenMP thread mapping to physical cores</a>.</p>

<p>I hope that somebody will tell me more about how OpenMP get the work done in this simple case. I should say that I am a beginner in parallel computing.</p>

<p>Thanks!</p>
","922184","","<p><strong>EDIT :</strong> Now that some code has been added.</p>

<p>In that particular example, there is very little computation and lots of memory access. So the performance will depend heavily on:</p>

<ul>
<li>The size of the vector.</li>
<li>How you are timing it. (do you have an outer-loop for timing purposes)</li>
<li>Whether the data is already in cache.</li>
</ul>

<p>For larger vector sizes, you will likely find that the performance is limited by your memory bandwidth. In which case, parallelism is not going to help much. For smaller sizes, the overhead of threading will dominate. If you're getting the ""expected"" speedup, you're probably somewhere in between where the result is optimal.</p>

<p>I refuse to give hard numbers because in general, ""guessing"" performance, especially in multi-threaded applications is a lost cause unless you have prior testing knowledge or intimate knowledge of both the program and the system that it's running on.</p>

<p>Just as a simple example taken from my answer here: <a href=""http://stackoverflow.com/q/9244481/922184"">How to get 100% CPU usage from a C program</a></p>

<p>On a Core i7 920 @ 3.5 GHz (4 cores, 8 threads):</p>

<p>If I run with <strong>4 threads</strong>, the result is:</p>

<pre><code>This machine calculated all 78498 prime numbers under 1000000 in 39.3498 seconds
</code></pre>

<p>If I run with <strong>4 threads</strong> and explicitly (using Task Manager) <strong>pin the threads on 4 distinct physical cores</strong>, the result is:</p>

<pre><code>This machine calculated all 78498 prime numbers under 1000000 in 30.4429 seconds
</code></pre>

<hr>

<p>So this shows how unpredictable it is for even a very simple and embarrassingly parallel application. Applications involving heavy memory usage and synchronization get a lot uglier...</p>
"
"<pre><code>int i;
i=0;
for (i=0;i&gt;2;i++)
    {
     repeat((3),""|"",var);
     printf(""\n"");          
    }
</code></pre>

<p>For some reason it gets to the ""for"" and it skips it. I tried to put the <code>int i</code> outside of the for and even initialized it outside of the for and in debug it is zero.  all I need it to do is loop through this code twice.</p>
","922184","","<p>Change:</p>

<pre><code>for (i=0;i&gt;2;i++)
</code></pre>

<p>to:</p>

<pre><code>for (i=0;i&lt;2;i++)
</code></pre>

<p>You're testing if it's <code>&gt; 2</code> which will fail so it never enters the loop.</p>
"
"<p>I would like to know whether there might be any possibility of some performance gain on file read by using openMP.</p>

<p>Example code,</p>

<pre><code>fstream file;

file.open(""test.txt"",ios::in);

file.seekg(0,ios::end);

int len = file.tellg();

char *arr = new char[len];

char *temp = new char[1];

int i;

#pragma omp parallel for shared(arr, len) private(temp, i)
for(i = 0; i &lt; len; i++)
{
    file.seekg(i);
    file.read(temp,1);
    arr[i] = temp[0];
}
</code></pre>

<p>I guess using multiple threads for I/O operation is a bad option because finally file read operation will be serialized. But still, I would like to whether one can expect a performance gain. Moreover, I would also like to know how does openMP handles the parallel file read operations.</p>
","922184","","<p>As you mentioned, you're not likely to get any speedup parallelizing any sort of I/O bound task like this. However, there is a much bigger problem. The code isn't even correct.</p>

<p>The <code>seekg()</code> and <code>read()</code> methods modify the <code>file</code> variable. So your iterations aren't independent. So you will have race conditions on the stream. In other words, <strong>the loop isn't parallelizable.</strong></p>

<p>So don't expect that code to work at all - let alone with better performance.</p>
"
"<p>Why does this bit of code,</p>

<pre><code>const float x[16] = {  1.1,   1.2,   1.3,     1.4,   1.5,   1.6,   1.7,   1.8,
                       1.9,   2.0,   2.1,     2.2,   2.3,   2.4,   2.5,   2.6};
const float z[16] = {1.123, 1.234, 1.345, 156.467, 1.578, 1.689, 1.790, 1.812,
                     1.923, 2.034, 2.145,   2.256, 2.367, 2.478, 2.589, 2.690};
float y[16];
for (int i = 0; i &lt; 16; i++)
{
    y[i] = x[i];
}

for (int j = 0; j &lt; 9000000; j++)
{
    for (int i = 0; i &lt; 16; i++)
    {
        y[i] *= x[i];
        y[i] /= z[i];
        y[i] = y[i] + 0.1f; // &lt;--
        y[i] = y[i] - 0.1f; // &lt;--
    }
}
</code></pre>

<p>run more than 10 times faster than the following bit (identical except where noted)?</p>

<pre><code>const float x[16] = {  1.1,   1.2,   1.3,     1.4,   1.5,   1.6,   1.7,   1.8,
                       1.9,   2.0,   2.1,     2.2,   2.3,   2.4,   2.5,   2.6};
const float z[16] = {1.123, 1.234, 1.345, 156.467, 1.578, 1.689, 1.790, 1.812,
                     1.923, 2.034, 2.145,   2.256, 2.367, 2.478, 2.589, 2.690};
float y[16];
for (int i = 0; i &lt; 16; i++)
{
    y[i] = x[i];
}

for (int j = 0; j &lt; 9000000; j++)
{
    for (int i = 0; i &lt; 16; i++)
    {
        y[i] *= x[i];
        y[i] /= z[i];
        y[i] = y[i] + 0; // &lt;--
        y[i] = y[i] - 0; // &lt;--
    }
}
</code></pre>

<p>when compiling with Visual Studio 2010 SP1. (I haven't tested with other compilers.)</p>
","922184","","<p><strong>Welcome to the world of <a href=""http://en.wikipedia.org/wiki/Denormal_number"">denormalized floating-point</a>!</strong> They can wreak havoc on performance!!!</p>

<p>Denormal (or subnormal) numbers are kind of a hack to get some extra values very close to zero out of the floating point representation. Operations on denormalized floating-point can be <strong><em>tens to hundreds of times slower</em></strong> than on normalized floating-point. This is because many processors can't handle them directly and must trap and resolve them using microcode.</p>

<p>If you print out the numbers after 10,000 iterations, you will see that they have converged to different values depending on whether <code>0</code> or <code>0.1</code> is used.</p>

<p>Here's the test code compiled on x64:</p>

<pre><code>int main() {

    double start = omp_get_wtime();

    const float x[16]={1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6};
    const float z[16]={1.123,1.234,1.345,156.467,1.578,1.689,1.790,1.812,1.923,2.034,2.145,2.256,2.367,2.478,2.589,2.690};
    float y[16];
    for(int i=0;i&lt;16;i++)
    {
        y[i]=x[i];
    }
    for(int j=0;j&lt;9000000;j++)
    {
        for(int i=0;i&lt;16;i++)
        {
            y[i]*=x[i];
            y[i]/=z[i];
#ifdef FLOATING
            y[i]=y[i]+0.1f;
            y[i]=y[i]-0.1f;
#else
            y[i]=y[i]+0;
            y[i]=y[i]-0;
#endif

            if (j &gt; 10000)
                cout &lt;&lt; y[i] &lt;&lt; ""  "";
        }
        if (j &gt; 10000)
            cout &lt;&lt; endl;
    }

    double end = omp_get_wtime();
    cout &lt;&lt; end - start &lt;&lt; endl;

    system(""pause"");
    return 0;
}
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>#define FLOATING
1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007
1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007

//#define FLOATING
6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.46842e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044
6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.45208e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044
</code></pre>

<p>Note how in the second run the numbers are very close to zero.</p>

<p>Denormalized numbers are generally rare and thus most processors don't try to handle them efficiently.</p>

<hr>

<p>To demonstrate that this has everything to do with denormalized numbers, if we <strong>flush denormals to zero</strong> by adding this to the start of the code:</p>

<pre><code>_MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);
</code></pre>

<p>Then the version with <code>0</code> is no longer 10x slower and actually becomes faster. (This requires that the code be compiled with SSE enabled.)</p>

<p>This means that rather than using these weird lower precision almost-zero values, we just round to zero instead.</p>

<p><strong>Timings: Core i7 920 @ 3.5 GHz:</strong></p>

<pre><code>//  Don't flush denormals to zero.
0.1f: 0.564067
0   : 26.7669

//  Flush denormals to zero.
0.1f: 0.587117
0   : 0.341406
</code></pre>

<p>In the end, this really has nothing to do with whether it's an integer or floating-point. The <code>0</code> or <code>0.1f</code> is converted/stored into a register outside of both loops. So that has no effect on performance.</p>
"
"<p>I need a function of an __m128i variable that has period 2^128. It doesn't need to monotonically increase (like a counter), but visit each value once.</p>

<p>The simplest example I could think of is in fact a 128-bit counter, but I found that difficult to implement in SSE. Are there any simpler/faster solutions?</p>
","922184","","<p>Here's a monotonic counter. I'm not sure if you can call it simple though.</p>

<p>Assuming both <code>ONE</code> and <code>ZERO</code> are always in registers, then this should compile to 5 instructions. (7 or 8 if VEX-encoding is not used)</p>

<pre><code>inline __m128i nextc(__m128i x){
    const __m128i ONE = _mm_setr_epi32(1,0,0,0);
    const __m128i ZERO = _mm_setzero_si128();

    x = _mm_add_epi64(x,ONE);
    __m128i t = _mm_cmpeq_epi64(x,ZERO);
    t = _mm_and_si128(t,ONE);
    t = _mm_unpacklo_epi64(ZERO,t);
    x = _mm_add_epi64(x,t);

    return x;
}
</code></pre>

<p>Test Code (MSVC):</p>

<pre><code>int main() {

    __m128i x = _mm_setr_epi32(0xfffffffa,0xffffffff,1,0);

    int c = 0;
    while (c++ &lt; 10){
        cout &lt;&lt; x.m128i_u64[0] &lt;&lt; ""  "" &lt;&lt; x.m128i_u64[1] &lt;&lt; endl;
        x = nextc(x);
    }

    return 0;
}
</code></pre>

<p>Output:</p>

<pre><code>18446744073709551610  1
18446744073709551611  1
18446744073709551612  1
18446744073709551613  1
18446744073709551614  1
18446744073709551615  1
0  2
1  2
2  2
3  2
</code></pre>

<hr>

<p>Slightly better version suggested by @Norbert P. It saves 1 instruction over my original solution.</p>

<pre><code>inline __m128i nextc(__m128i x){
    const __m128i ONE = _mm_setr_epi32(1,0,0,0);
    const __m128i ZERO = _mm_setzero_si128();

    x = _mm_add_epi64(x,ONE);
    __m128i t = _mm_cmpeq_epi64(x,ZERO);
    t = _mm_unpacklo_epi64(ZERO,t);
    x = _mm_sub_epi64(x,t);

    return x;
}
</code></pre>
"
"<p>error:</p>

<pre><code>cxx.cpp:5:13: error: missing binary operator before token ""(""
cxx.cpp:7:15: error: missing binary operator before token ""(""
</code></pre>

<p>code:</p>

<pre><code>  #if definied(_WIN32) || definied(_WIN64) || definied(__WIN32__)
        const char * PORT = ""COM1"";
    #elif definied(__linux) || definied(__linux__) || definied(linux)
        const char * PORT = ""dev/ttyS1"";
    #else 
        const char * PORT = NULL;
    #endif
</code></pre>

<p>Questions:</p>

<ol>
<li>the compiler is waiting an new <code>defined()</code> call?</li>
<li>it can detected any linux(and variants) or windows version?</li>
</ol>

<p>thanks in advance.</p>
","922184","","<p>You misspelled <code>defined</code>:</p>

<pre><code>#if definied(_WIN32) || definied(_WIN64) || definied(__WIN32__)

#elif definied(__linux) || definied(__linux__) || definied(linux)
</code></pre>

<p>should be:</p>

<pre><code>#if defined(_WIN32) || defined(_WIN64) || defined(__WIN32__)

#elif defined(__linux) || defined(__linux__) || defined(linux)
</code></pre>
"
"<p>when compiling my program with GCC I get the following warning:</p>

<pre><code>format ‘%d’ expects type ‘int’, but argument 2 has type ‘long unsigned int
</code></pre>

<p>Now just by playing around I realize %lo fixes the warning. However I don't really understand what I am doing. </p>

<p>Is there a naming convention to get the short form of a type? For example, int is %d, why??</p>

<p>Thanks!</p>
","922184","","<pre><code>long unsigned int = unsigned long
</code></pre>

<p>You use <code>%lu</code> to print those.</p>

<p>And similarly, <code>%llu</code> is for <code>unsigned long long</code>.</p>

<hr>

<pre><code>%d    -   int
%u    -   unsigned
%ld   -   long
%lld  -   long long
%lu   -   unsigned long
%llu  -   unsigned long long
</code></pre>
"
"<p><strong>OUTPUT</strong>  </p>

<pre><code>Fun1 is not fun
9
</code></pre>

<p><strong>CODE</strong>  </p>

<pre><code>#include &lt;stdio.h&gt;

int fun1(void){
    printf(""Fun1 is not fun\n"");
    return 45%54/5;
}

main()
{
    int c;
    c=fun1();
    printf(""%d\n"", c);
}  
</code></pre>

<p><strong>QUESTION</strong>  </p>

<p>Why does it output 9 from the 45%54/5? Would this not output 2? The only way I could see this being 9 is by skipping the %, (modulus division operator, right?) then dividing by 5 omitting the 54 completely but that makes no sense to me.  </p>

<p>edit: random secondary question. If I name my file test.c, compile it with <code>cc test.c -o test</code>, then type ""test"", nothing happens. If I compile under any other name than test, it works fine. What gives?</p>
","922184","","<pre><code>45 % 54 / 5
</code></pre>

<p>is</p>

<pre><code>(45 % 54) / 5
</code></pre>

<p>Which evaluates as:</p>

<pre><code>45 % 54 = 45
45 / 5  = 9
</code></pre>

<hr>

<p>45 mod 54 is equal to 45. I don't see how you expect to get 2 regardless of how you order them.</p>
"
"<p>I've been running a single-threaded brute force version of the famous Traveling Salesman Problem, and YourKit is pinpointing me the fact that the CPU is being used at 25%, at most.</p>

<p>What's the reason behind that fact? We've been told that these kind of algorithms are highly CPU intensive, yet there seems to be a lot of wasted CPU in this case. </p>

<p>My theory is the bottleneck must be the RAM access. Locking issues seem to be out of question, as the algorithm I'm running is single-threaded. </p>

<p>Am I right?</p>
","922184","","<p>Promoting comment to answer.</p>

<p>You say your program is single-threaded, but you're only using 25% CPU.</p>

<p>That's an indication that you have a quad-core machine. (or perhaps dual-core with Hyper-Threading) With a single-thread, you cannot use more than 1 core.</p>

<p><strong>So what you're seeing is normal.</strong></p>

<hr>

<p>As a side point, bottlenecks such as locking and memory access do not directly decrease your CPU usage. A single-threaded program that spends the whole time cache missing will still show the same 25% usage (on quad-core) as one that is running real computation.</p>

<p>In multi-threaded applications, CPU usage could be affected if such bottlenecks block other threads from running or if they affect load-balance.</p>
"
"<p>So, in the aftermath of my previous attempt with openMP, I have realized that I don't have any example of a piece of code which actually runs faster on my system when parallelized compared to serial. Below is a short example of an attempt (which fails), first showing that there are indeed two cores, and that openMP is putting them use, and then timing two brain-dead tasks, one using openMP and the other not.
 It is very possible that there is something wrong about the task I'm testing on, so I'd appreciate it if someone could come up with another sanity-test, just so I can see with my own eyes that multi-threading CAN work :)</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;ctime&gt;
#include &lt;cmath&gt;

using namespace std;

#include &lt;omp.h&gt;

int main(int argc, char *argv[])
{


    //Below code will be run once for each processor (there are two)
    #pragma omp parallel 
    {
        cout &lt;&lt; omp_get_thread_num() &lt;&lt; endl; //this should output 1 and 0, in random order
    }


    //The parallel example:
    vector &lt;double&gt; a(50000,0);

    clock_t start = clock();
#pragma omp parallel for  shared(a) 
    for (int i=0; i &lt; 50000; i++)    
    {
        double StartVal=i;

        for (int j=0; j&lt;2000; ++j)
            a[i]=(StartVal + log(exp(exp((double) i)))); 
    } 

    cout&lt;&lt; ""Time: "" &lt;&lt; ( (double) ( clock() - start ) / (double)CLOCKS_PER_SEC ) &lt;&lt;endl;

    //The serial example:
    start = clock();

    for (int i=0; i &lt; 50000; i++)    
    {
        double StartVal=i;

        for (int j=0; j&lt;2000; ++j)
            a[i]=(StartVal + log(exp(exp((double) i)))); 
    } 

    cout&lt;&lt; ""Time: "" &lt;&lt; ( (double) ( clock() - start ) / (double)CLOCKS_PER_SEC ) &lt;&lt;endl;

    return 0;
}
</code></pre>

<p>the output is:</p>

<pre><code>    1
    0
    Time: 4.07
    Time: 3.84
</code></pre>

<p>Can it be something to do with forloop-optimization that openMP is missing out on? Or is there something wrong with how I measure time? In that case, do you have any ideas for a different test?</p>

<p>Thank you in advance :)</p>

<p>EDIT:
it did it indeed turn out that I was measuring time in a bad way. Using <code>omp_get_wtime()</code>, the output becomes:</p>

<pre><code>1
0
Time: 4.40776
Time: 7.77676
</code></pre>

<p>I guess I'd better go back and have another look at my old question then...</p>
","922184","","<p>There are two possibilities I can think of:</p>

<ol>
<li>If you are running on Linux. <code>clock()</code> doesn't measure wall time on Linux. It measures CPU time.<br>I suggest you use <code>omp_get_wtime()</code> instead.</li>
<li>Your test isn't large enough. Try increasing <code>2000</code> to something like <code>200000</code>.</li>
</ol>

<p>Here's what I get on Windows using <code>200000</code> iterations on the inner loop:</p>

<pre><code>4
5
2
3
1
6
7
0
Time: 1.834
Time: 6.792
</code></pre>

<hr>

<p>My answer for <a href=""http://stackoverflow.com/q/9244481/922184"">this question</a> has a very simple OpenMP example that achieves speedup.</p>
"
"<p>What are the gcc's intrinsic for loading 4 <code>ints</code> into <code>__m128</code> and 8 ints into <code>__m256</code> (aligned/unaligned)? What about <code>unsigned ints</code>?</p>
","922184","","<p>Using Intel's SSE intrnisics, the ones you're looking for are:</p>

<ul>
<li><code>_mm_load_si128()</code></li>
<li><code>_mm_loadu_si128()</code></li>
<li><code>_mm256_load_si256()</code></li>
<li><code>_mm256_loadu_si256()</code></li>
</ul>

<p>Documentation:</p>

<ul>
<li><a href=""http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-833DE069-7D58-43D8-8B63-7FEF4B84E2DF.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-833DE069-7D58-43D8-8B63-7FEF4B84E2DF.htm</a></li>
<li><a href=""http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-0A40CBDD-58FD-4F36-9C6D-F3D2355B5E44.htm"" rel=""nofollow"">http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-0A40CBDD-58FD-4F36-9C6D-F3D2355B5E44.htm</a></li>
</ul>

<p>There's no distinction between signed or unsigned. You'll need to cast the pointer to <code>__m128i*</code> or <code>__m256i*</code>.</p>

<hr>

<p>Note that these are Intel's SSE intrinsics and will work in GCC, Clang, MSVC, and ICC.<br>The GCC intrinsics work only in, well, GCC AFAIK of.</p>
"
"<p>When dealing with both ints and floats in SSE (AVX) is it a good practice to convert all ints to floats and work only with floats?
Because we need only a few SIMD instructions after that, and all we need to use is addition and compare instructions (<code>&lt;, &lt;=, ==</code>) which this conversion, I hope, should retain completely.</p>
","922184","","<p>Expand my comments into an answer.</p>

<p>Basically you weighing the following trade-off:</p>

<p><strong>Stick with integer:</strong></p>

<ul>
<li>Integer SSE is low-latency, high throughput. (dual issue on Sandy Bridge)</li>
<li>Limited to 128-bit SIMD width.</li>
</ul>

<p><strong>Convert to floating-point:</strong></p>

<ul>
<li>Benefit from 256-bit AVX.</li>
<li>Higher latencies, and only single-issue addition/subtraction (on Sandy Bridge)</li>
<li>Incurs initial conversion overhead.</li>
<li>Restricts input to those that fit into a <code>float</code> without precision loss.</li>
</ul>

<p>I'd say stick with integer for now. If you don't want to duplicate code with the <code>float</code> versions, then that's your call.</p>

<p>The only times I've seen where emulating integers with floating-point becomes faster are when you have to do divisions.</p>

<hr>

<p>Note that I've made no mention of readability as diving into manual vectorization probably implies that performance is more important.</p>
"
"<p>As one can see, I am just starting out with C++ and just began my hello world program. </p>

<pre><code>    #include &lt;iostream&gt;
using namespace std;

int main() {
    cout &lt;&lt; ""Hello, World!"" &lt;&lt; end1;
    cout &lt;&lt; ""Hooray!"" &lt;&lt; end1;

    system(""PAUSE"");
    return 0;
}
</code></pre>

<p>But for some reason, unknown to me, I am getting an error on both of the <code>cout</code> lines, saying <code>end1</code> was undeclared! How do I fix this?</p>
","922184","","<pre><code>end1
</code></pre>

<p>should be:</p>

<pre><code>endl
</code></pre>

<p>You used a <code>1</code> (the number) instead of <code>l</code> (the letter).</p>
"
"<p>I use the code below to calculate log base 2.</p>

<pre><code>Math.log(x)/Math.log(2);
</code></pre>

<p>With this function, i get nan if x=4/5.</p>

<p>With calc, excel this problem don't exist.</p>

<p>How to avoid to get nan and get the real value?</p>
","922184","","<p>I have a strong feeling that your <code>4/5</code> is integers. Which would mean that <code>4/5</code> will evaluate to <code>0</code> due to integer division.</p>

<p><code>log(0)</code> is negative infinity, that could be the source of your <code>NaN</code>.</p>

<p>To fix this, cast your numbers to floating-point before you do the division:</p>

<pre><code>double x = (double)4 / 5;
</code></pre>
"
"<p>The code below calculates the correlation matrix given a covariance matrix. How can I write this better? The issue is this section of code will run 1000s of times on matrices whose dimensions are about 100 x 100.</p>

<pre><code>// Copy upper triangle of covariance matrix to correlation matrix
for(i = 0; i &lt; rows; i++){
  for(j = i; j &lt; rows; j++){
    corrmatrix.array[i * rows + j] = covmatrix.array[i * rows + j];
  }
}

// Calculate upper triangle of corr matrix
for(i = 0; i &lt; rows; i++){

  root = sqrt(covmatrix.array[(i * rows) + i]);    

  for(j = 0; j &lt;= i; j++){ // Move down 
    corrmatrix.array[ j * rows + i ] /= root;
  }

  k = i * rows;

  for(j = i; j &lt; rows; j++){ // Move across
    corrmatrix.array[ k + j ] /= root;
  }

}

// Copy upper triangle to lower triangle
for(i = 0; i &lt; rows; i++){
  k = i * rows;
  for(j = i; j &lt; rows; j++){
    corrmatrix.array[ (j * rows) + i ] = corrmatrix.array[ k + j ];
  }
}
</code></pre>

<p>I have made checks that the rows and columns are equal etc, so I am just using rows everywhere. I want to optimize the speed (significantly). </p>

<p>PS:</p>

<ol>
<li>Matrices are stored in row-major, dense format</li>
<li>I am not using packed storage for now.</li>
</ol>

<p>Thank you</p>
","922184","","<p>The first thing that jumps out at me is that you're doing division by the same number in your inner loops.</p>

<p><strong>Don't do that.</strong> Division is slow.</p>

<p>What you should do instead is to multiply by the reciprocal of <code>root</code> instead of dividing by it repeatedly:</p>

<pre><code>inv_root = 1. / sqrt(covmatrix.array[(i * rows) + i]);

for(j = 0; j &lt;= i; j++){ // Move down 
    corrmatrix.array[ j * rows + i ] *= inv_root;
}

k = i * rows;

for(j = i; j &lt; rows; j++){ // Move across
    corrmatrix.array[ k + j ] *= inv_root;
}
</code></pre>

<p>Although this optimization may seem obvious to a compiler, it may not be allowed to do this optimization due to floating-point strictness. You can try relaxing your floating-point settings with <code>-ffast-math</code> (in GCC) or something similar.</p>
"
"<p>I'd like to know how C++ is dealing with memory of ""objects"" created by pointer inside class methods or functions.
For example method of class Example</p>

<pre><code>void Example::methodExample()
{

  ExampleObject *pointer = new ExampleObject(""image.jpg"");

}
</code></pre>

<p>Should i somehow delete this or it's automatically removed?
Sorry if my question is stupid but i am beginner : P</p>
","922184","","<blockquote>
  <p>Should i somehow delete this or it's automatically removed? Sorry if
  my question is stupid but i am beginner : P</p>
</blockquote>

<p>Yes, indeed you will need to manually delete is a follows:</p>

<pre><code>delete pointer;
</code></pre>

<p>Otherwise you will have a memory leak.</p>

<hr>

<p>On the other hand, if you declared is this, then it will be automatically freed when it falls out of scope:</p>

<pre><code>ExampleObject object = ExampleObject(""image.jpg"");
</code></pre>
"
"<p>Do I need to worry about performance in the case below and save the result of the expensive call, or does the compiler recognise it can do the expensive call once?</p>

<pre><code>String name;
if (object.expensiveCall() != null) {
  name = object.expensiveCall().getName();
}
</code></pre>
","922184","","<p>You're looking for something called <a href=""http://en.wikipedia.org/wiki/Memoization"" rel=""nofollow"">memoization</a>. <a href=""http://stackoverflow.com/questions/3934777/java-automatic-memoization"">This question</a> suggests that Java can't do it natively.</p>

<p>In general, memoization is only possible if the compiler/JIT can prove that the function has no side-effects. So I wouldn't count on it.</p>

<p>But is it really that hard to just save the result?</p>

<pre><code>String name;
ObjectType temp = object.expensiveCall();
if (temp != null) {
    name = temp.getName();
}
</code></pre>
"
"<pre><code>#include&lt;stdio.h&gt;

int main()
{
    char *name = ""Vikram"";
    printf(""%s"",name);
    name[1]='s';
    printf(""%s"",name);
    return 0;
}
</code></pre>

<p>There is no output printed on terminal and just get segmentation fault. But when I run it in GDB, I get following -</p>

<pre><code>Program received signal SIGSEGV, Segmentation fault.
0x0000000000400525 in main () at seg2.c:7
7       name[1]='s';
(gdb) 
</code></pre>

<p>This means program receive SEG fault on 7th line (obviously I can't write on constant char array) . Then why printf() of line number 6 is not executed ?</p>
","922184","","<p>This is due to stream buffering of <code>stdout</code>. Unless you do <code>fflush(stdout)</code> or you print a newline <code>""\n""</code> the output is may be buffered.</p>

<p>In this case, it's segfaulting before the buffer is flushed and printed.</p>

<p>You can try this instead:</p>

<pre><code>printf(""%s"",name);
fflush(stdout);        //  Flush the stream.
name[1]='s';           //  Segfault here (undefined behavior)
</code></pre>

<p>or:</p>

<pre><code>printf(""%s\n"",name);   //  Flush the stream with '\n'
name[1]='s';           //  Segfault here (undefined behavior)
</code></pre>
"
"<p>Hello stackoverflow crew. I'm in a programming class where we have just switched from python to C. I'm having a bit of trouble with it, as C doesn't seem to perform mathematical operations with the ease that python does, or I'm missing something when it comes to math in C.</p>

<p>For my homework, I'm writing a program that collects how many miles to a gallon user's car gets, how much their gas costs per gallon, and how many miles they drive each month. The program then tells them how much they can expect to pay for gas for the current month. My current code is as follows:</p>

<pre><code>#include &lt;stdio.h&gt;

int main () {

int mpg, miles;
double gas_price;

printf(""How many miles per gallon does your car get?\n"");
scanf(""%d"", &amp;mpg);

printf(""What is the price of gasoline per gallon?\n"");
scanf(""%lf"", &amp;gas_price);

printf(""How many miles do you drive in a month?\n"");
scanf(""%d"", &amp;miles);

printf(""The cost of gas this month is $%.2lf\n"", miles / mpg * gas_price);

printf(""%d %d %d"", mpg, gas_price, miles);

return 0;
}
</code></pre>

<p>When I run the program with the values 24 for ""mpg"", 3.00 for ""gas_price"", and 1000 for miles, the total comes to $123.00. This isn't correct, and is about two dollars less than the actual price. When you take ((1000 / 24) * 3.00), you should get 125 even. I added a string to print out all the values to see what C was using for the formula in line 23, and while mpg and gas_price are correct, ""miles"" shows up as having a value of 1,074,266,112. I know there must be some error here, as this would throw the result off way more than 2 dollars, but I can't help but think it's related.</p>

<p>I apologize for the length of the question, but I wanted to be as specific as possible, and I'm completely stumped as to why C is reading this in so strangely. Thanks in advance for all of your help.</p>
","922184","","<p>You're doing integer division here:</p>

<pre><code>miles / mpg * gas_price
</code></pre>

<p>Cast one of the two operands to a <code>double</code> first:</p>

<pre><code>(double)miles / mpg * gas_price
</code></pre>

<p>Integer division will truncate the fractional part. That's why your numbers are off.</p>

<hr>

<p>You have another error here:</p>

<pre><code>printf(""%d %d %d"", mpg, gas_price, miles);
</code></pre>

<p>Your <code>printf</code> format specifiers don't match the operands. It should be:</p>

<pre><code>printf(""%d %f %d"", mpg, gas_price, miles);
</code></pre>
"
"<p>It seems and looks really simple but a seemingly random spot of the char array is not filling correctly with 8's. There are no compiler errors either. I'm sorry that this is such a noob question but when I designed a sudoku solver a month ago I didn't have any problems running codes almost identical to this.</p>

<pre><code>#include &lt;iostream&gt;
using namespace std;

int main () {

//Initiates initial board.
char board[30][27];

//Fills entire board with b's to represent the edges of the board where the pac-man cannot go.
for (int control=0; control&lt;31; control++) {
    for (int control2=0; control2&lt;28; control2++) {
        board[control][control2]='8';
    }
}

//Code here filling the board with spaces representing where the pac-man can go.

//Temporary render of board.
for (int control=0; control&lt;31; control++) {
    for (int control2=0; control2&lt;28; control2++) {
        cout &lt;&lt; board[control][control2];
    }
    cout &lt;&lt; endl;
}

return 0;
}
</code></pre>

<p>It apparently has a random segmentation fault.</p>
","922184","","<p>You're exceeding the size of your matrix. You have:</p>

<pre><code>char board[30][27];
</code></pre>

<p>But your loops are:</p>

<pre><code>for (int control=0; control&lt;31; control++) {
    for (int control2=0; control2&lt;28; control2++) {
</code></pre>

<p>They will overshoot each dimension by 1.</p>

<p>So either change your matrix to: <code>char board[31][28];</code> or cut an iteration off of your loops.</p>
"
"<p>which of the two is faster: ?</p>

<p>1.</p>

<pre><code>char* _pos ..;
short value = ..;

*((short*)_pos = va;
</code></pre>

<p>2.</p>

<pre><code>char* _pos ..;
short value = ..;

memcpy(_pos, &amp;value, sizeof(short));
</code></pre>
","922184","","<p>As with all ""which is faster?"" questions, you should benchmark it to see for yourself. And if it matters, then ask why and pick which you want.</p>

<p>In any case, your first example is technically <strong><em>undefined behavior</em></strong> since you are violating strict-aliasing. So if you had to choose without benchmarking, go with the second one.</p>

<hr>

<p>To answer the actual question, which is faster will probably depend on the alignment of <code>pos</code>. If it's aligned properly, then 1 will probably be faster. If not, then 2 might be faster depending on how it's optimized by the compiler. (1 might even crash if the hardware doesn't support misaligned access.)</p>

<p>But this is all guess-work. You really need to benchmark it to know for sure.<br>
<strong>At the very least, you should look at the compiled assembly:</strong></p>

<pre><code>:     *(short *)_pos = value;

mov WORD PTR [rcx], dx
</code></pre>

<p>vs.</p>

<pre><code>:     memcpy(_pos, &amp;value, sizeof(short));

mov WORD PTR [rcx], dx
</code></pre>

<p>Which in this case (in MSVC) shows the exact same assembly with default optimizations. So you can expect the performance to be the same.</p>
"
"<p>I'm working on an old exam for a test and this code is printing the value of 10 for longVariable. Now, by hand, to me, the math would go 9 + 1 % 10 = remainder of 0, not 10... How am I wrong on this?</p>

<p>Thank you for helping!</p>

<pre><code> public class ExamSectionA
{
    public static void main(String[] args)
{
    int intVariable1 = 9;
    int intVariable2 = 10;
    double doubleVariable = 11.2;
    char charVariable = 'A';
    long longVariable;
    longVariable = intVariable1 + 1 % intVariable2;
    intVariable2 = (int) (doubleVariable / 10f);
    String[] theirSalary = {""10"",""20"",""30"",""40""};
    System.out.println(intVariable2);
    System.out.println(longVariable); 
}
}
</code></pre>

<p>EDIT: PEMDAS. Think I got it.</p>
","922184","","<p>Watch your order of operations:</p>

<pre><code>intVariable1 + 1 % intVariable2;
</code></pre>

<p>is:</p>

<pre><code>intVariable1 + (1 % intVariable2);
</code></pre>

<p>So <code>9 + 1 % 10</code> is being parsed as <code>9 + (1 % 10)</code>. Which gives <code>9 + 1 = 10</code>.</p>

<p><code>%</code> has higher precedence than <code>+</code>.</p>
"
"<p>In my case, product of two INT_MAX numbers is <code>296447233</code>, which is incorrect.</p>

<pre><code>long long int product = 0;
product = 2137483647 * 2137483647;
printf(""product: %lli\n"", product);
</code></pre>

<p>What I am doing wrong, and how to correct it ??
Thanks !</p>
","922184","","<p>Both of your <code>2137483647</code> are of type <code>int</code>. So they stay that type and overflow.</p>

<p>Make them <code>long long</code>s:</p>

<pre><code>product = 2137483647LL * 2137483647LL;
</code></pre>

<p>or cast:</p>

<pre><code>product = (long long)2137483647 * 2137483647;
</code></pre>
"
"<p>If I have a game which has a 3D world, and the world is quite big, so needs to be split into chunks, is there a major, if any, performance advantage of having 128 byte chunks over, say 150 byte chunks? Obviously, the objects in the chunks are still a whole number of bytes in size.</p>

<p>i.e. Is <code>chunks[128][128][128]</code> faster than <code>chunks[150][150][150]</code> or <code>chunks[112][112][112]</code>? Are there any other side effects such as excessive RAM wastage afterwards? Are there any other factors that should be taken into consideration?</p>

<p>I just see that it's a convention to store everything in variables and arrays of sizes that are powers of 2, but I'm not sure whether there's any merit to it, and if it could be better to use more human numbers like 100 or 150.</p>
","922184","","<p>The other answers are indeed correct that power-of-two sized data will benefit from using shifts over multiplies.</p>

<p><strong>However</strong>, there is a <strong><em>dark side</em></strong> to power-of-two size data. And it can hit you when you least expect it.</p>

<p><strong>See these two question/answers:</strong></p>

<ul>
<li><a href=""http://stackoverflow.com/q/7905760/922184"">Matrix multiplication: Small difference in matrix size, large difference in timings</a></li>
<li><a href=""http://stackoverflow.com/q/8547778/922184"">Why is one loop so much slower than two loops?</a></li>
</ul>

<p>When your datasets are powers-of-two, they are more likely to be super-aligned in memory. (meaning their addresses will likely have the same modulo over a large power-of-two.)</p>

<p>While this may seem desirable, they can lead to:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/CPU_cache#Cache_miss"">Conflict Cache Misses</a></li>
<li>False Aliasing Stalls (mentioned in the second link above)</li>
</ul>

<p>If you read the two questions linked to above, you can see that <strong><em>alignment can cause a slow-down of more than 3x</em></strong> - which will likely far out-weigh any benefit you get from using shifts as opposed to multiplies.</p>

<hr>

<p>So as with all performance questions, you need to measure, measure, measure... And be prepared to expect anything to happen.</p>

<p>You mention that you are representing a 3D-space - that is exactly the kind of situation that would exhibit power-of-two strided memory access that could lead to slow-downs.</p>
"
"<p>i seen to be having a problem with the line:</p>

<pre><code>int xPos = ((x / maxX) * X_AXIS_LENGTH) + X_AXIS_OFFSET; =
</code></pre>

<p>for testing purposes i have assigned:</p>

<pre><code>int x = 10;
int maxX = 52;
</code></pre>

<p>but when used in this calculation <code>x / maxX</code> gives me <code>0</code> instead of <code>0.19</code>!</p>

<p><a href=""http://s12.postimage.org/uawn8b6l9/image.png"" rel=""nofollow"">http://s12.postimage.org/uawn8b6l9/image.png</a></p>
","922184","","<p>You're doing integer division here:</p>

<pre><code>x / maxX
</code></pre>

<p>Integer division will truncate the fractional part.</p>

<p>Cast one of the parameters to floating-point to fix it:</p>

<pre><code>(double)x / maxX
</code></pre>

<p>You might also want to store the whole thing into a <code>double</code> instead of <code>int</code>:</p>

<pre><code>double xPos = (((double)x / maxX) * X_AXIS_LENGTH) + X_AXIS_OFFSET;
</code></pre>
"
"<p>Before starting let me say: It's not homework, just plain, old, fun.</p>

<p>Now, I'm trying to come up with an algorithm that can answer this question <a href=""http://stackoverflow.com/questions/9469898/1-x-1-y-1-nfactorial"">1/x + 1/y = 1/n!</a>.</p>

<p>And as you can see by the link above, the author asked only for hints and not the actual answer, so I would kindly ask for the same.</p>

<p>I simplified the expression until (x - n!)(y - n!) = (n!)^2 as suggested by <a href=""http://stackoverflow.com/a/9470399/366492"">one of the answers</a>, and by that time I understood that the number of combinations of (x,y) pairs is the same as the number of divisors of n!^2 (correct me if I'm wrong here).</p>

<p>So, as suggested by the <a href=""http://stackoverflow.com/a/9472563/366492"">accepted answer</a>, I'm trying to get the multiplication of all the factors of each prime composing N!^2.</p>

<p>I've come up with some code in C using <a href=""http://en.wikipedia.org/wiki/Trial_division"" rel=""nofollow"">trial division</a> to factorize N!^2 and the <a href=""http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"" rel=""nofollow"">Sieve of Eratosthenes</a> to get all the prime numbers up to sqrt(N!^2).</p>

<p>The problem now is memory, I have tried with N = 15 and my Mac (Quad Core 6GB of memory) almost died on me. The problem was memory. So I added some printf's and tried with N=11:</p>

<pre><code>Sieve of Eratosthenes took 13339.910000 ms and used 152 mb of memory
n= 11; n!^2 = 1593350922240000; d = 6885
[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,5,5,5,5,7,7,11,11]
</code></pre>

<p>The list is all the prime factors of N!^2 (besides 1 and N!^2 of course).</p>

<p>I would like some hints on how to minimize memory consumption and possible optimizations.</p>

<p>Code bellow, it was just a quick experiment so I'm sure it can be optimized.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
#include &lt;strings.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;assert.h&gt;

//Linked List
struct node {
    struct node * next;
    long val;
};

void addValue(struct node *list, long val) {
    struct node *n = list;

    if (n-&gt;val == -1) {
        n-&gt;val = val;
        return;
    }

    while (n-&gt;next) {
        n = n-&gt;next;
    }

    struct node *newNode = malloc(sizeof(struct node));
    newNode-&gt;val = val;
    newNode-&gt;next = NULL;
    n-&gt;next = newNode;
}

void freeLinkedList(struct node *list) {
    struct node *c = list;
    if (!c) return;
    struct node *n = c-&gt;next;
    free(c);
    freeLinkedList(n);
}

void printList(struct node *list) {
    struct node *n = list;
    printf(""["");
    while (n) {
        printf(""%ld"", n-&gt;val);
        n = n-&gt;next;
        if (n) {
            printf("","");
        }
    }
    printf(""]\n"");
}
//-----------


int fac(int n) {
    if (n == 1) return 1;
    return fac(n-1)*n;
}

//Sieve of Eratosthenes
int sieve_primes(long limit, long **list) {
    struct timeval t1;
    struct timeval t2;
    double elapsedTime = 0;
    gettimeofday(&amp;t1, NULL);

    assert(limit &gt; 0);

    //Create a list of consecutive integers from 2 to n: (2, 3, 4, ..., n).
    long arrSize = limit-1;
    long *arr = malloc(sizeof(long)*arrSize);

    long c = 2;
    for (long i = 0; i &lt; arrSize; i++) {
        arr[i] = c++;
    }   
    assert(arr[arrSize-1] == limit);


    for (long i = 0; i &lt; arrSize; i++) {
        //Let p be equal to the first number not crossed
        long p = arr[i];    
        if (p == 0) continue;

        //Starting from p, count up in increments of p and mark each of these numbers greater than p itself in the list. 
        for (long f = p+p; f &lt; arrSize; f+=p) {
            arr[f] = 0;
        }       
    }

    *list = arr;


    gettimeofday(&amp;t2, NULL);

    elapsedTime = (t2.tv_sec - t1.tv_sec) * 1000.0;      // sec to ms
    elapsedTime += (t2.tv_usec - t1.tv_usec) / 1000.0;   // us to ms
    printf(""Sieve of Eratosthenes took %f ms and used %lu mb of memory\n"",elapsedTime, (arrSize * sizeof(int))/1024/1024);
    return arrSize;
}

void trial_division(struct node* list, long n) {    if (n == 1) {
        addValue(list, 1);
        return;
    }
    long *primes;
    long primesSize = sieve_primes(sqrt(n), &amp;primes);   

    struct timeval t1;  
    struct timeval t2;
    double elapsedTime = 0;
    gettimeofday(&amp;t1, NULL);
    for (long i = 0; i &lt; primesSize; i++) {
        long p = primes[i];
        if (p == 0) continue;
        if (p*p &gt; n) break;
        while (n % p == 0) {
            addValue(list, p);
            n/=p;
        }       
    }
    if (n &gt; 1) {
        addValue(list, n);
    }
    free(primes);
}

int main(int argc, char *argv[]) {
    struct node *linkedList = malloc(sizeof(struct node));
    linkedList-&gt;val = -1;
    linkedList-&gt;next = NULL;


    long n = 11;
    long nF = fac(n);
    long nF2 = nF*nF;
    trial_division(linkedList, nF2);            

    long multOfAllPrimeFactors = 1;
    struct node *c = linkedList;
    while (c) {
        long sumOfVal = 2;
        long val = c-&gt;val;              
        c = c-&gt;next;
        while(c) {
            long val2 = c-&gt;val;
            if (val == val2) {
                sumOfVal++;
                c = c-&gt;next;
            } else break;           
        }
        multOfAllPrimeFactors*=sumOfVal;
    }       

    printf(""n= %ld; n!^2 = %ld; d = %ld\n"", n,nF2, multOfAllPrimeFactors);
    printList(linkedList);  

    freeLinkedList(linkedList);

}
</code></pre>

<p><strong>EDIT:</strong></p>

<p>As an example I will show you the calculation for getting all the possible positive integer solutions to the initial equation:</p>

<blockquote>
  <p>3!^2 = 36 = (3^2*2^2*1^0)</p>
</blockquote>

<p>So there are (1+2)(1+2)(1+0)=9 possible positive integer solutions to the diophantine equation. Double if you count negative integers. I'm using <a href=""http://www2.wolframalpha.com/input/?i=solve%20%28x-3!%29%28y-3!%29%29=3!%5E2%20for%20integers"" rel=""nofollow"">WolframAlpha</a> to be sure.</p>

<p><strong>EDIT 2:</strong></p>

<p>I think I just found out ""what a factorial is"", I'm getting this very interesting output:</p>

<pre><code>3! = [2,3]
3!^2 = [2,2,3,3]
3!^3 = [2,2,2,3,3,3]
3!^4 = [2,2,2,2,3,3,3,3]
</code></pre>

<p>Thanks :D</p>
","922184","","<p>The trick here is to recognize exactly what a factorial <code>N!</code> is. It's a product of all the numbers from <code>1</code> to <code>N</code>. Which is already a huge step forward.</p>

<p>So what you need to do, is just to prime factorize each of the numbers from <code>1</code> to <code>N</code>.</p>

<p>In this sense, you don't need to sieve up to <code>N!</code>. Instead, just sieve up to <code>sqrt(N)</code>. And the rest is just merging all your prime factors.</p>
"
"<p>I would like to have a vector z, and be able to access it as <code>z[i]</code> or <code>*pz[i]</code>, where <code>*pz[i]</code> points to <code>z[i]</code>. so there is one set of values but two ways to access it. </p>

<p>This is the code that I had:</p>

<pre><code>std::vector&lt;double&gt; z;
std::vector&lt;double*&gt; pz;

for (int i = 0; i &lt; 5; i++) {
  z.push_back(7+0.01*i);
  std::cout &lt;&lt; i &lt;&lt; ""  z = "" &lt;&lt; z &lt;&lt; std::endl;
  pz.push_back(&amp;z.back());
  std::cout &lt;&lt; i &lt;&lt; ""  pz = "" &lt;&lt; pz &lt;&lt; std::endl;
  std::cout &lt;&lt; i &lt;&lt; ""  *pz = "" ;
  for (int j = 0; j &lt; pz.size(); j++) {
    std::cout &lt;&lt; ""  "" &lt;&lt; *pz[j];
  }
  std::cout &lt;&lt; std::endl;
}

z[1]=17.3;
std::cout &lt;&lt; ""z[1] = "" &lt;&lt; z[1] &lt;&lt; std::endl;
std::cout &lt;&lt; ""*pz[1] = "" &lt;&lt; *pz[1] &lt;&lt; std::endl;

*pz[2]=34.1;
std::cout &lt;&lt; ""z[2] = "" &lt;&lt; z[2] &lt;&lt; std::endl;
std::cout &lt;&lt; ""*pz[2] = "" &lt;&lt; *pz[2] &lt;&lt; std::endl;
</code></pre>

<p>the output:</p>

<pre><code>0  z = vector(1) [ 7 ]
0  pz = vector(1) [ 0x1d00b80 ]
0  *pz =   7
1  z = vector(2) [ 7, 7.01 ]
1  pz = vector(2) [ 0x1d00b80, 0x1d00bc8 ]
1  *pz =   1.50254e-316  7.01
2  z = vector(3) [ 7, 7.01, 7.02 ]
2  pz = vector(3) [ 0x1d00b80, 0x1d00bc8, 0x1d00bf0 ]
2  *pz =   1.50254e-316  7.01  7.02
3  z = vector(4) [ 7, 7.01, 7.02, 7.03 ]
3  pz = vector(4) [ 0x1d00b80, 0x1d00bc8, 0x1d00bf0, 0x1d00bf8 ]
3  *pz =   1.50254e-316  7.01  7.02  7.03
4  z = vector(5) [ 7, 7.01, 7.02, 7.03, 7.04 ]
4  pz = vector(5) [ 0x1d00b80, 0x1d00bc8, 0x1d00bf0, 0x1d00bf8, 0x1d00c60 ]
4  *pz =   1.50254e-316  7.01  7.02  7.03  7.04
z[1] = 17.3
*pz[1] = 7.01
z[2] = 7.02
*pz[2] = 34.1
</code></pre>

<p>There are 3 problems:</p>

<ol>
<li>The first element of <code>*pz</code> gets undefined after second push.</li>
<li>When I assign <code>z[1]</code>, <code>*pz[1]</code> is not <code>z[1]</code> anymore.</li>
<li>When I assign <code>*pz[2]</code>, it's not assigning to <code>z[2]</code> anymore.</li>
</ol>

<p>(In my actual program I need to have a vector to access even elements and a vector to access odd elements but I don't want to make a clone and use more memory.)</p>
","922184","","<p>Two things:</p>

<ol>
<li>When you do a <code>push_back()</code> or any operation that might cause the vector to be reallocated, you <strong>invalidate all pointers to elements of that vector</strong>.</li>
<li>In 64-bit, a pointer will probably be the same size as a <code>double</code> so you won't save any memory that way.</li>
</ol>

<p>If you really want to create a second vector with pointers to elements of the first vector, you need to finish building the first vector first. Otherwise, the <code>push_back()</code> operations will invalidate the pointers.</p>
"
"<p>Recently, I work in C++ and I have to create a <code>array[60.000][60.000]</code>. However, i cannot create this array because it's too large. I tried <code>float **array</code> or even <code>static float array</code> but nothing is good. Does anyone have an ideas? 
Thanks for your helps!</p>
","922184","","<p>A matrix of size <code>60,000 x 60,000</code> has <code>3,600,000,000</code> elements.</p>

<p>You're using type <code>float</code> so it becomes:</p>

<pre><code>60,000 x 60,000 * 4 bytes = 14,400,000,000 bytes ~= 13.4 GB
</code></pre>

<p>Do you even have that much memory in your machine?</p>

<hr>

<p>Note that the issue of stack vs heap doesn't even matter unless you have enough memory to begin with.</p>

<hr>

<p><strong>Here's a list of possible problems:</strong></p>

<ul>
<li>You don't have enough memory.</li>
<li>If the matrix is declared globally, you'll exceed the maximum size of the binary.</li>
<li>If the matrix is declared as a local array, then you will blow your stack.</li>
<li>If you're compiling for 32-bit, you have far exceeded the 2GB/4GB addressing limit.</li>
</ul>
"
"<p>Here is the implementation of reverse in Long:</p>

<pre><code>public static long reverse(long i) {
        // HD, Figure 7-1
    i = (i &amp; 0x5555555555555555L) &lt;&lt; 1 | (i &gt;&gt;&gt; 1) &amp; 0x5555555555555555L;//1
    i = (i &amp; 0x3333333333333333L) &lt;&lt; 2 | (i &gt;&gt;&gt; 2) &amp; 0x3333333333333333L;//2
    i = (i &amp; 0x0f0f0f0f0f0f0f0fL) &lt;&lt; 4 | (i &gt;&gt;&gt; 4) &amp; 0x0f0f0f0f0f0f0f0fL;//3
    i = (i &amp; 0x00ff00ff00ff00ffL) &lt;&lt; 8 | (i &gt;&gt;&gt; 8) &amp; 0x00ff00ff00ff00ffL;//4
    i = (i &lt;&lt; 48) | ((i &amp; 0xffff0000L) &lt;&lt; 16) |
        ((i &gt;&gt;&gt; 16) &amp; 0xffff0000L) | (i &gt;&gt;&gt; 48);//5
    return i;
}
</code></pre>

<p>I can understand line 1,2,3,4, but not 5! How does it work?</p>

<p>I group the 64 bits to 8 groups,that is 1 is the first 8 bits, 2 is the second 8 bits, and so on.</p>

<p>Then after line 4,the sequence like <code>4,3,2,1,8,7,6,5</code></p>

<p>and I think line 5 working as below before the <code>|</code> operation:</p>

<pre><code>6,5,0,0,0,0,0,0--&gt;(i &lt;&lt; 48)
8,7,0,0,0,0,0,0--&gt;((i &amp; 0xffff0000L) &lt;&lt; 16)
0,0,0,0,4,3,2,1--&gt;((i &gt;&gt;&gt; 16) &amp; 0xffff0000L)
0,0,0,0,0,0,2,1--&gt;(i &gt;&gt;&gt; 48)
</code></pre>

<p>But, I don't know where dose it wrong or whether it is wrong! Thinking about it almost about a whole day!</p>

<p>Somebody can help me!! Thanks.</p>

<p>oh, i made a mistake like this:</p>

<pre><code>6,5,0,0,0,0,0,0--&gt;(i &lt;&lt; 48)
0,0,8,7,0,0,0,0--&gt;((i &amp; 0xffff0000L) &lt;&lt; 16)
0,0,0,0,2,1,0,0--&gt;((i &gt;&gt;&gt; 16) &amp; 0xffff0000L)
0,0,0,0,0,0,4,3--&gt;(i &gt;&gt;&gt; 48)
</code></pre>

<p>but i alse think it is wrong! i think the right sequence is <code>8,7,6,5,4,3,2,1</code></p>

<p>i am so sorry that i make some mistakes! it works right as below:</p>

<p>after line 4, the right pattern is:<code>2,1,4,3,6,5,8,7</code></p>

<pre><code>8,7,0,0,0,0,0,0--&gt;(i &lt;&lt; 48)
0,0,6,5,0,0,0,0--&gt;((i &amp; 0xffff0000L) &lt;&lt; 16)
0,0,0,0,4,3,0,0--&gt;((i &gt;&gt;&gt; 16) &amp; 0xffff0000L)
0,0,0,0,0,0,2,1--&gt;(i &gt;&gt;&gt; 48)
</code></pre>
","922184","","<p>Your attempt isn't quite correct. Here's the corrected version:</p>

<pre><code>2,1,4,3,6,5,8,7 --&gt; i       //  Assume this sequence after line 4
8,7,0,0,0,0,0,0 --&gt; (i &lt;&lt; 48)
0,0,6,5,0,0,0,0 --&gt; ((i &amp; 0xffff0000L) &lt;&lt; 16)
0,0,0,0,4,3,0,0 --&gt; ((i &gt;&gt;&gt; 16) &amp; 0xffff0000L)
0,0,0,0,0,0,2,1 --&gt; (i &gt;&gt;&gt; 48)
</code></pre>

<p>Here's the two middle steps broken up:</p>

<pre><code>2,1,4,3,6,5,8,7 --&gt; i       //  Assume this sequence after line 4
0,0,0,0,6,5,0,0 --&gt; (i &amp; 0xffff0000L)
0,0,6,5,0,0,0,0 --&gt; ((i &amp; 0xffff0000L) &lt;&lt; 16)

2,1,4,3,6,5,8,7 --&gt; i       //  Assume this sequence after line 4
0,0,2,1,4,3,6,5 --&gt; (i &gt;&gt;&gt; 16)
0,0,0,0,4,3,0,0 --&gt; ((i &gt;&gt;&gt; 16) &amp; 0xffff0000L)
</code></pre>

<hr>

<p>Though I'm slightly surprised at why it isn't implemented as follows:</p>

<pre><code>i = (i &amp; 0x5555555555555555L) &lt;&lt;  1 | (i &gt;&gt;&gt;  1) &amp; 0x5555555555555555L;  //  1
i = (i &amp; 0x3333333333333333L) &lt;&lt;  2 | (i &gt;&gt;&gt;  2) &amp; 0x3333333333333333L;  //  2
i = (i &amp; 0x0f0f0f0f0f0f0f0fL) &lt;&lt;  4 | (i &gt;&gt;&gt;  4) &amp; 0x0f0f0f0f0f0f0f0fL;  //  3
i = (i &amp; 0x00ff00ff00ff00ffL) &lt;&lt;  8 | (i &gt;&gt;&gt;  8) &amp; 0x00ff00ff00ff00ffL;  //  4
i = (i &amp; 0x0000ffff0000ffffL) &lt;&lt; 16 | (i &gt;&gt;&gt; 16) &amp; 0x0000ffff0000ffffL;  //  5
i = (i &amp; 0x00000000ffffffffL) &lt;&lt; 32 | (i &gt;&gt;&gt; 32) &amp; 0x00000000ffffffffL;  //  6
</code></pre>

<p>It keeps the pattern consistent. <strike>And I think it reduces the # of operations as well.</strike></p>

<p><strong>EDIT :</strong> I see why it's implemented the way it is. The version in the question uses only <strong>9 operations</strong> for the final two reversals. The version here (lines 5 and 6) needs <strong>10 operations</strong>.</p>

<p><strong>Geez... talking about micro-optimization to the extreme...</strong></p>

<hr>

<p><strong>EDIT 2:</strong> Why didn't I think of this? Why doesn't <code>java.lang.Long</code> use this?</p>

<pre><code>i = (i &amp; 0x5555555555555555L) &lt;&lt;  1 | (i &gt;&gt;&gt;  1) &amp; 0x5555555555555555L;  //  1
i = (i &amp; 0x3333333333333333L) &lt;&lt;  2 | (i &gt;&gt;&gt;  2) &amp; 0x3333333333333333L;  //  2
i = (i &amp; 0x0f0f0f0f0f0f0f0fL) &lt;&lt;  4 | (i &gt;&gt;&gt;  4) &amp; 0x0f0f0f0f0f0f0f0fL;  //  3
i = (i &amp; 0x00ff00ff00ff00ffL) &lt;&lt;  8 | (i &gt;&gt;&gt;  8) &amp; 0x00ff00ff00ff00ffL;  //  4
i = (i &amp; 0x0000ffff0000ffffL) &lt;&lt; 16 | (i &gt;&gt;&gt; 16) &amp; 0x0000ffff0000ffffL;  //  5
i = (i &lt;&lt; 32) | (i &gt;&gt;&gt; 32)                                               //  6
</code></pre>
"
"<p>So, I do:</p>

<pre><code>$ ulimit -s
8192
</code></pre>

<p>Great. As I understand this, the stack segment of any process cannot exceed 8192 kilobytes.</p>

<p>Now, to challenge that..</p>

<pre><code>#include &lt;stdio.h&gt;

void over_8k(void) {
    char buf[1024*1024*20];
}

int main(int argc, char** argv) {
    printf(""Starting .. "");
    over_8k();
    printf("" finishing.\nHow did this work?\n"");
    return 0;
}
</code></pre>

<p>Compiled. Ran. No problems. Well this isn't right? <code>over_8k</code> alone should have a stack frame of, well, over 20 megabytes. Well, let's try accessing those 20 million bytes:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void over_8k(void) {
    char buf[1024*1024*20];
    memset(buf, 'A', sizeof(buf));
}

int main(int argc, char** argv) {
    printf(""Starting .. "");
    over_8k();
    printf("" finishing.\nHow did this work?\n"");
    return 0;
}
</code></pre>

<p>.. drum roll ..</p>

<pre><code>Segmentation fault: 11
</code></pre>

<p>Great. But that's not the error I'd expect? Invalid memory access? </p>

<p>Why does it raise a segfault, and doesn't error out earlier? On call to <code>over_8k</code> perhaps? How does this work? I want to know everything.</p>
","922184","","<p>Expanding on my comment...</p>

<p>There's two possibilities I can think of:</p>

<p><strong>The compiler is optimizing out the entire <code>buf</code> array:</strong></p>

<p>In MSVC, with optimizations enabled, the entire array is being completely optimized out and is not allocated at all. So it's not using any stack.</p>

<p><strong>Stack allocation is just an increment/decrement to the stack pointer:</strong></p>

<pre><code>sub rsp, 20971520
</code></pre>

<p>won't segfault. It's just a pointer. It will only segfault when you try to access it into unmapped memory.</p>
"
"<p>I've been programming a simple WinSock application in Visual Studio 2010. I have named my application entry point ""main.c"", then I came across this error while declaring a SOCKET object:</p>

<pre><code>error C2275: 'SOCKET' : illegal use of this type as an expression
</code></pre>

<p>Oddly enough, I solved that problem by renaming the code file from  <strong>main.c</strong> to <strong>main.cpp</strong></p>

<p>Just out of curiosity, I want to know what is the meaning of this error, and what difference occurred by changing the extension.</p>

<p>Thanks in advance.</p>

<p><strong>EDIT</strong></p>

<p>Here is the relevant code:</p>

<pre><code>#pragma comment(lib,""ws2_32"")

#include &lt;WinSock2.h&gt;
#include &lt;stdio.h&gt;


int main()
{
// Startup the winsock
WORD wVersionRequested;
WSADATA wsaData;
int wsaerr;
wVersionRequested = MAKEWORD(2,2);
wsaerr = WSAStartup(wVersionRequested,&amp;wsaData);
if(wsaerr != 0)
{
    printf(""Winsock2 dll is not found!\n"");
    WSACleanup();
    return 0;
}
else
{
    printf(""Winsock2 dll is found!\n"");
    printf(""Current System Status: %s.\n"",wsaData.szSystemStatus);
}

//Create a SOCKET object called socketobj.
SOCKET socketobj;
socketobj = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
if (socketobj == INVALID_SOCKET)
{
    printf(""Socket Intialization Failed with error: %ld\n"", WSAGetLastError());
    WSACleanup();
    return 0;
}
else

{
    printf(""Socket Intialization Success\n"");
}

Sleep(10000);
return 0;
}
</code></pre>
","922184","","<p>Without seeing the code it's hard to tell.</p>

<p>But my guess is that you have some interleaved declarations and code. MSVC's C compiler is only C89 which does not support it. That would explain why the C++ compiler accepts it, but the C compiler doesn't.</p>

<p>Prior to C99, all declarations must be at the start of the function or a block.</p>

<p><strong>EDIT :</strong> Your code doesn't show the whole function, but you probably have some (non-declaration) code before the <code>SOCKET socketobj;</code> declaration.</p>

<hr>

<p>Now that the full function is shown, it confirms that you are interleaving declarations and code:</p>

<pre><code>WORD wVersionRequested;            //  Declaration: ok
WSADATA wsaData;                   //  Declaration: ok
int wsaerr;                        //  Declaration: ok
wVersionRequested = MAKEWORD(2,2); //  Code: ok

...

SOCKET socketobj;                  //  Declaration: NOT ok
socketobj = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
</code></pre>

<p>The solution here is to move <code>SOCKET socketobj;</code> to the start of the function with the other declarations.</p>
"
"<p>The problem is that I don't know how to exit from my loop.</p>

<pre><code>printf (""Do you order fish? (Y/N): "");
scanf  (""%c"", &amp;f);

while((f == 'y')||(f == 'Y'))
{
  do {
    fish = getfish_choice();
    printf (""Total of you fish is %.2lf\n"", sum);
    printf (""Do you want to order more fish?(Y/N)"");
    scanf  ("" %c"", &amp;morefish);
  }
  while ((morefish=='Y')||(morefish=='y'));
}

Printf (""Hello"");
</code></pre>

<p>How could I exit this loop so the output of my code will read Hello?</p>
","922184","","<p>What's happenning is that when <code>Y</code> or <code>y</code> is entered, you manage to break out of the inner loop, but you're still stuck in the outer loop. (<code>f</code> is never modified)</p>

<p>You don't even need two loops:</p>

<pre><code>printf (""Do you order fish? (Y/N): "");
scanf  (""%c"", &amp;morefish);

while ((morefish=='Y')||(morefish=='y')){
    fish = getfish_choice();
    printf (""Total of you fish is %.2lf\n"", sum);
    printf (""Do you want to order more fish?(Y/N)"");
    scanf  ("" %c"", &amp;morefish);
}

printf (""Hello"");
</code></pre>
"
"<p>I'm brand new to C++ and am trying to make a program that when the user inputs an int between 0-9 it displays the number, and between 9 and 36 displays the corresponding letter, A= 10 B= 11... I know how to use the switch function but with 26 cases that's a lot of typing. How would I use static_cast to convert the Int variables to Chars?</p>
","922184","","<p>If I'm understanding your question correctly, this will probably do what you want.</p>

<pre><code>int num = 12;  //  Input number

char ch;
if (num &lt; 10)
    ch = num + '0';
else
    ch = num + 'a' - 10;
</code></pre>

<p>or alternatively:</p>

<pre><code>const char DIGITS[] = ""0123456789abcdefghijklmnopqrstuvwxyz"";

int num = 12;          //  Input number

char ch = DIGITS[num]; //  Output number/letter
</code></pre>

<p>So there's no need to cast anything.</p>

<p>If you want capital letters instead, replace the <code>'a'</code> with <code>'A'</code> in the first example. The second example is trivial to switch to capitals.</p>
"
"<p>My code is like below:</p>

<pre><code>#include &lt;string.h&gt;
int main()
{
    int ii = 123;
    char str[7] = """";
    strcpy(str,""123456"");
    return 0;
}
</code></pre>

<p>I run this in VS2010, the memory is like below</p>

<p><img src=""http://i.stack.imgur.com/eNHa7.jpg"" alt=""enter image description here""></p>

<p>I am curious what the <code>cc</code> in the memory used for? And how the number of <code>cc</code> is calculated?</p>
","922184","","<p>When compile for ""Debug"" in Visual Studio, the <code>cc</code>'s are often used to fill up uninitialized memory. That way it's more obvious when you access uninitialized memory.</p>

<p>For example, if you try to dereference an uninitialized pointer, you'll likely get something like:</p>

<pre><code>Access Violation accessing 0xcccccccc
</code></pre>

<p>or something like that.</p>

<p><img src=""http://i.stack.imgur.com/t18dN.png"" alt=""enter image description here""></p>
"
"<p>In the following code:</p>

<pre><code>#include ""stdio.h""
signed char a= 0x80;
unsigned char b= 0x01;


void main (void)
{
    if(b*a&gt;1)
        printf(""promoted\n"");
    else if (b*a&lt;1)
        printf(""why doesnt promotion work?"");

    while(1);
}
</code></pre>

<p>I expected ""promoted' to be printed. But it doesnt. Why?
If I can the datatypes to signed and unsigned int, and have a as a negative number, eg, 0x80000000 and b as a positive number, 0x01, ""promoted"" gets printed as expected.</p>

<p>PLZ HELP me understand what the problem is!</p>
","922184","","<p>You've just been caught by the messy type-promotion rules of C.</p>

<p>In C, intermediates of integral type smaller than <code>int</code> are automatically promoted to <code>int</code>.</p>

<p>So you have:</p>

<pre><code>0x80 * 0x01 = -128 * 1
</code></pre>

<p><code>0x80</code> gets signed extended to type <code>int</code>:</p>

<pre><code>0xffffff80 * 0x00000001 = -128 * 1 = -128
</code></pre>

<p>So the result is <code>-128</code> and thus is less than <code>1</code>.</p>

<hr>

<p>When you use type <code>int</code> and <code>unsigned int</code>, both operands get promoted to <code>unsigned int</code>. <code>0x80000000 * 0x01 = 0x80000000</code> as an unsigned integer is bigger than <code>1</code>.</p>

<hr>

<p>So here's the side-by-side comparison of the type promotion that's taking place:</p>

<pre><code>(signed char) * (unsigned char) -&gt; int
(signed int ) * (unsigned int ) -&gt; unsigned int

(signed char)0x80       * (unsigned char)0x01 -&gt; (int)         0xffffff80
(signed int )0x80000000 * (unsigned int )0x01 -&gt; (unsigned int)0x80000000

(int)         0xffffff80 is negative   -&gt;   prints ""why doesnt promotion work?""
(unsigned int)0x80000000 is positive   -&gt;   prints ""promoted""
</code></pre>

<p><a href=""https://www.securecoding.cert.org/confluence/display/seccode/INT02-C.+Understand+integer+conversion+rules"" rel=""nofollow"">Here's a reference to the type-promotion rules of C.</a></p>
"
"<p>Following is the program that raised the mentioned doubt for me. </p>

<pre><code>#include &lt;stdio.h&gt;
int main() { 
    int g = 300000*300000/300000;
    printf(""%d"",g);
    return 0;
}
</code></pre>

<p>When the <code>*</code> is evaluated the result would be <code>90000000000</code>. Then is divided by <code>300000</code>.
I expected the first expression result to be stored somewhere then divided by <code>300000</code>. So output would be <code>300000</code>.</p>

<p>But it is giving me <code>-647</code>.
Does this mean it is evaluated as :</p>

<pre><code>g = 300000*300000;
g = g / 300000;
</code></pre>
","922184","","<p>Regardless of where it's stored, it's still of type <code>int</code>. Assuming <code>int</code> is 32-bits on your machine, you're getting integer overflow with <code>300000*300000</code>.</p>

<pre><code>300000*300000 -&gt; 90000000000 -&gt; -194313216  (integer overflow)
-194313216 / 300000 -&gt; -647
</code></pre>

<p>Basically, temporaries (or intermediates) don't magically allow you to get around overflow.</p>

<hr>

<p>*Note that signed integer overflow is technically undefined behavior. But in this case it happens to wrap-around the way you'd expect.</p>
"
"<p>For certain hash functions in Java it would be nice to see the value as an unsigned integer (e.g. for comparison to other implementations) but Java supports only signed types.  We can convert a signed <code>int</code> to an ""unsigned"" <code>long</code> as such:</p>

<pre class=""lang-java prettyprint-override""><code>public static final int BITS_PER_BYTE = 8;
public static long getUnsignedInt(int x) {
  ByteBuffer buf = ByteBuffer.allocate(Long.SIZE / BITS_PER_BYTE);
  buf.putInt(Integer.SIZE / BITS_PER_BYTE, x);
  return buf.getLong(0);
}
getUnsignedInt(-1); // =&gt; 4294967295
</code></pre>

<p>However, this solution seems like overkill for what we're really doing.  Is there a more efficient way to achieve the same thing?</p>
","922184","","<p>Something like this?</p>

<pre><code>int x = -1;
long y = x &amp; 0x00000000ffffffffL;
</code></pre>

<p>Or am I missing something?</p>

<pre><code>public static long getUnsignedInt(int x) {
    return x &amp; 0x00000000ffffffffL;
}
</code></pre>
"
"<p>I receive error reports with a Division by zero crash, and the crash occurs at a function called __alldiv. This function is not called anywhere in my code, I searched for it with Find in files.</p>
","922184","","<p><code>__alldiv</code> is MSVC's integer division function.</p>

<p>When you emit an integer division in your code, it doesn't always map one-to-one to the <code>div</code> or <code>idiv</code> assembly instruction. This is due to differences between the language specified behavior and the actual behavior of the <code>div</code> and <code>idiv</code> instructions.</p>

<p>Therefore MSVC invokes a function call to its own integer division function.</p>
"
"<pre><code>int main(int argc, char *argv[])
{
    uint64_t length = 0x4f56aa5d4b2d8a80;
    uint64_t new_length = 0;

    new_length = length + 119.000000;

    printf(""new length  0x%""PRIx64""\n"",new_length);

    new_length = length + 238.000000;

    printf(""new length  0x%""PRIx64""\n"",new_length);

    return 0;
}
</code></pre>

<p>With the above code. I am adding two different double values to a unsigned 64-bit integer.I am getting the exact same result in both the cases.The output of the program is show below</p>

<pre><code>$./a.out
new length  0x4f56aa5d4b2d8c00
new length  0x4f56aa5d4b2d8c00
</code></pre>

<p>I would expect two different results but that is not the case.I have also tried type-casting the <code>uint64_t</code> value to a <code>double</code> as in</p>

<pre><code>new_length = (double)length + 119.000000;
</code></pre>

<p>But this too doesn't seem to help.Any idea on what might be the problem?</p>
","922184","","<p>Since you adding a floating-point operand, both operands are implicitly cast to <code>double</code> and the addition is done using floating-point arithmetic.</p>

<p>However, <code>double</code> doesn't have enough precision to exactly hold either of the following values:</p>

<pre><code>0x4f56aa5d4b2d8a80 + 119.0  (requires 63 bits of precision)

0100111101010110101010100101110101001011001011011000101011110111
 &lt;-------------------63 bits of precision----------------------&gt;


0x4f56aa5d4b2d8a80 + 238.0  (requires 62 bits of precision)

0100111101010110101010100101110101001011001011011000101101101110
 &lt;-------------------62 bits of precision---------------------&gt;
</code></pre>

<p>Standard IEEE double precision only has <strong><em>53 bits of precision</em></strong>.</p>

<p>The result is that both of them get rounded to the same final value of:</p>

<pre><code>0x4f56aa5d4b2d8c00  (53 bits of precision)

0100111101010110101010100101110101001011001011011000110000000000
 &lt;-----------------53 bits of precision--------------&gt;
</code></pre>

<hr>

<p>If you want to avoid this rounding, you should avoid floating-point arithmetic altogether by casting the operands to integer. (or just using <code>119</code> and <code>238</code> instead)</p>
"
"<p>First I am not sure what is going on in this bitwise operation.
I get code written and supply to other parties as code snippets.</p>

<p>Now if VAR is unsigned 8bit integer (unsigned char) and r is either 0 or 1 or 2 or 4.
Can following be reversed if the value of r is known and resulting value is there.
<strong>VAR |= 1 &lt;&lt; r;</strong> //that is 200 where VAR was 192 and r was 3</p>

<p>For example initial value of <strong>VAR is 192</strong> and value of <strong>r is 3</strong> *<em>result is 200</em>*.</p>

<p>Now if <strong>I have this 200</strong>, and I <strong>know the value of r</strong> that was 3, <strong>can I reverse it back to 192 ?</strong></p>

<p>I hope it is most easy one, but I don't know these bitwise operations, so forgive me.</p>

<p>Thanks</p>
","922184","","<p>The answer is no. This is because the <code>|</code> (OR) operator is not a <a href=""http://en.wikipedia.org/wiki/Injective_function"">one-to-one function</a>.</p>

<p>In other words, there are multiple values of <code>VAR</code> that can produce the same result.</p>

<p>For example:</p>

<pre><code>r = 3;
var0 = 8;
var1 = 0;

var0 |= 1 &lt;&lt; r;  //  produces 8
var1 |= 1 &lt;&lt; r;  //  produces 8
</code></pre>

<p>If you tried to invert it, you wouldn't be able to tell whether the original value is <code>0</code> or <code>8</code>.</p>

<p>A similar situation applies to the <code>&amp;</code> AND operator.</p>

<hr>

<p><strong>From an information-theory perspective:</strong></p>

<p>The operators <code>|</code> and <code>&amp;</code> incur a <strong><em>loss of information</em></strong> and do not preserve the entropy of the data.</p>

<p>On the other hand, operators such as <code>^</code> (XOR), <code>+</code>, and <code>-</code> are one-to-one and thus preserve entropy and are invertible.</p>
"
"<p>I was wondering what kind of method was used to multiply numbers in C++. Is it the traditional schoolbook long multiplication? <a href=""http://en.wikipedia.org/wiki/F%C3%BCrer%27s_algorithm"" rel=""nofollow"">Fürer's algorithm</a>? <a href=""http://en.wikipedia.org/wiki/Toom%E2%80%93Cook_multiplication"" rel=""nofollow"">Toom-Cook</a>?</p>

<p>I was wondering because I am going to need to be multiplying extremely large numbers and need a high degree of efficiency. Therefore the traditional schoolbook long multiplication <code>O(n^2)</code> might be too inefficient, and I would need to resort to another method of multiplication.</p>

<p>So what kind of multiplication does C++ use?</p>
","922184","","<p>You seem to be missing several crucial things here:</p>

<ol>
<li>There's a difference between <strong><em>native</em></strong> arithmetic and <strong><em>bignum</em></strong> arithmetic.</li>
<li>You seem to be interested in <strong><em>bignum</em></strong> arithmetic.</li>
<li>C++ doesn't support <strong><em>bignum</em></strong> arithmetic. The primitive datatypes are generally <strong><em>native</em></strong> arithmetic to the processor.</li>
</ol>

<p>To get bignum (arbitrary precision) arithmetic, you need to implement it yourself or use a library. (such as <a href=""http://gmplib.org/"">GMP</a>) Unlike Java, and C# (among others), C++ does not have a library for arbitrary precision arithmetic.</p>

<p>All of those fancy algorithms:</p>

<ul>
<li>Karatsuba: <code>O(n^1.585)</code></li>
<li>Toom-Cook: <code>&lt; O(n^1.465)</code></li>
<li>FFT-based: <code>~ O(n log(n))</code></li>
</ul>

<p>are applicable only to bignum arithmetic which are implemented in bignum libraries. What the processor uses for its native arithmetic operations is somewhat irrelevant as it's 
usually constant time.</p>

<hr>

<p>In any case, I don't recommend that you try to implement a bignum library. I've done it before and it's quite demanding (especially the math). So you're better off using a library.</p>
"
"<pre><code>long long r = 0;
long long k = 0;
for (; k &lt; 9999999999999; k++) 
{
    for (long long i = 0; i &lt; 9999999999999; i++) 
    {
        for (long long j = 0; j &lt; 9999999999999; j++) 
        {
            r = (r + (i * j) % 100) % 47;
            if (r != 0) 
            {
                r++;
            }
        }
    }
 }
</code></pre>

<p>This code executes on i3Core in 0.000001 wall s. Checked with boost::timer::auto_cpu_timer. On i7Core But with visual studio 2010 it run in infinite time i guess =) What is wrong with gcc ot vs ?</p>
","922184","","<p>Yes, GCC is ""super-optimizing"" that code.</p>

<p>Specifically, it knows that you aren't using the result, so it's removing all of it.<br>
(You're never using the variable <code>r</code>.)</p>

<p>This is called <a href=""http://en.wikipedia.org/wiki/Dead_code_elimination"">Dead Code Elimination</a>.</p>

<p>To prevent the compiler from optimizing it out, you'll need to use the result somehow. Try printing <code>r</code> out at the end:</p>

<pre><code>cout &lt;&lt; r &lt;&lt; endl;
</code></pre>

<p>However, I warn that you'll need to reduce the iteration counts, or it probably won't finish in your lifetime.</p>

<hr>

<p>I just tested this in VS2010 x64. Looking at the assembly, it is clear that <strong><em>VS2010 is not able to optimize out the entire loop</em></strong>.</p>

<p>It goes to show that different compilers vary in their ability to optimize different things.</p>

<hr>

<p>Related, and more in-depth: <a href=""http://stackoverflow.com/questions/8841865/how-does-gcc-optimize-c-code"">How does GCC optimize C code?</a></p>
"
"<p>I tried to test <code>bad_alloc</code> exception by passing some negative arguments to <code>new[]</code>. When passing small negative numbers I get what I hoped for - a <code>bad_alloc</code>. However, when passing <code>-1</code>, I can see that my object is constructed thousands of times (I print static counter in constructor) and the application terminates with segfault. </p>

<p><code>new[]</code> converts signed integer to <code>size_t</code>, so <code>-1</code> is the max of <code>size_t</code> and <code>-2</code> is the <code>maximum - 1</code> and so on.</p>

<p>So why <code>new[]</code> throws exception when receiving some huge number, but tries to allocate when receiving the max of <code>size_t</code>? What is the difference between <code>1111...1</code> and <code>1111...0</code> for <code>new[]</code>? :)</p>

<p>Thanks in advance!</p>
","922184","","<p><strong>Here's my wild guess:</strong></p>

<p>In lot of implementations, the allocator will place some meta-data next to the allocated region.<br>
(For example, the size of the allocation.) So you are, in effect, allocating more than what you asked for.</p>

<p>Let's assume <code>size_t</code> is 32-bits. Compiled for 32-bits.</p>

<hr>

<p>When you do:</p>

<pre><code>int *array = new int[-1];
</code></pre>

<p>The <code>-1</code> becomes <code>-1 * 4 bytes = 4294967292</code> (after overflow). But if the allocator implementation puts 4-bytes of meta-data next to the allocated region. The actual size becomes:</p>

<pre><code>4294967292 + 4 bytes = 0 bytes (after overflow)
</code></pre>

<p>So <code>0</code> bytes is actually allocated.</p>

<p><strong>When you try to access the memory, you segfault since you go out-of-bounds immediately.</strong></p>

<hr>

<p>Now let's say you do:</p>

<pre><code>int *array = new int[-2];
</code></pre>

<p>The <code>-2</code> becomes <code>-2 * 4 bytes = 4294967288</code> (after overflow). Append 4-bytes of meta-data and you get <code>4294967288 + 4 = 4294967292</code>.</p>

<p><strong>When the allocator requests <code>4294967292</code> bytes from the OS, it is denied. So it throws <code>bad_alloc</code>.</strong></p>

<hr>

<p>So basically, it's possible that <code>-1</code> and <code>-2</code> makes the difference between whether or not it will overflow after the allocator appends its meta-data.</p>
"
"<p>While trying to figure out how to round a float like <code>1.255</code> to the nearest hundredth, I found something interesting. I'm using gcc 4.4.5 on Debian 6. </p>

<pre><code>int   x = (1.255 * 100) + 0.5;   //  gives me back 125 instead of 126. 
float y = (1.255 * 100) + 0.5;   //  gives me back 126.000000. 
</code></pre>

<p>Why is is that when I save to an <code>int</code> I get back <code>125</code> and not <code>126</code> ? In fedora when I save the above expression to an <code>int</code> I get back <code>126</code>. Is this a gcc bug in debian ? Any help would be greatly appreciated.
Thanks.</p>
","922184","","<p>Although this looks like a ""typical"" floating-point question, it's more complicated than that.</p>

<p>This one involves a combination of 3 things:</p>

<ul>
<li><a href=""http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html"">The ""usual"" floating-point representation stuff.</a></li>
<li>Implicit casting.</li>
<li>Implicit type-promotion.</li>
</ul>

<p><strong>Let's break this down:</strong></p>

<p>Floating-point literals are of type <code>double</code> by default. Hence <code>1.255</code> is of type <code>double</code>.</p>

<p>Thus the expression:</p>

<pre><code>(1.255 * 100) + 0.5
</code></pre>

<p>is done using type <code>double</code>.</p>

<p>But because binary floating-point can't represent <code>1.255</code> exactly, the expression evaluates to:</p>

<pre><code>(1.255 * 100) + 0.5 = 125.99999999999999000000
</code></pre>

<p>and is of type <code>double</code>.</p>

<p>Since this is less than <code>126</code>, storing it to an integer will result in <code>125</code>.
Storing it to <code>float</code> will round it to the nearest <code>float</code>, which results in <code>126</code>.</p>

<hr>

<pre><code>int    x = (1.255 * 100.) + 0.5;
float  y = (1.255 * 100.) + 0.5;
double z = (1.255 * 100.) + 0.5;

cout &lt;&lt; fixed;
cout &lt;&lt; x &lt;&lt; endl;
cout &lt;&lt; setprecision(20) &lt;&lt; y &lt;&lt; endl;
cout &lt;&lt; setprecision(20) &lt;&lt; z &lt;&lt; endl;
</code></pre>

<p>Output:</p>

<pre><code>125
126.00000000000000000000
125.99999999999999000000
</code></pre>
"
"<p>I was curious if there was a good way to do this. My current code is something like:</p>

<pre><code>def factorialMod(n, modulus):
    ans=1
    for i in range(1,n+1):
        ans = ans * i % modulus    
    return ans % modulus
</code></pre>

<p>But it seems quite slow!</p>

<p>I also can't calculate n! and then apply the prime modulus because sometimes n is so large that n! is just not feasible to calculate explicitly. </p>

<p>I also came across <a href=""http://en.wikipedia.org/wiki/Stirling%27s_approximation"">http://en.wikipedia.org/wiki/Stirling%27s_approximation</a> and wonder if this can be used at all here in some way?</p>

<p>Or, how might I create a recursive, memoized function in C++?</p>
","922184","","<p>Expanding my comment to an answer:</p>

<p>Yes, there are more efficient ways to do this. <strong><em>But they are extremely messy.</em></strong></p>

<p><strong>So unless you really need that extra performance, I don't suggest to try to implement these.</strong></p>

<hr>

<p>The key is to note that the modulus (which is essentially a division) is going to be the bottleneck operation. Fortunately, there are some very fast algorithms that allow you to perform modulus over the same number many times.</p>

<ul>
<li><a href=""http://gmplib.org/~tege/divcnst-pldi94.pdf"">Division by Invariant Integers using Multiplication</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Montgomery_reduction"">Montgomery Reduction</a></li>
</ul>

<p>These methods are fast because they essentially eliminate the modulus.</p>

<hr>

<p>Those methods alone should give you a moderate speedup. To be truly efficient, you may need to unroll the loop to allow for better IPC:</p>

<p>Something like this:</p>

<pre><code>ans0 = 1
ans1 = 1
for i in range(1,(n+1) / 2):
    ans0 = ans0 * (2*i + 0) % modulus    
    ans1 = ans1 * (2*i + 1) % modulus    

return ans0 * ans1 % modulus
</code></pre>

<p>but taking into account for an odd # of iterations and combining it with one of the methods I linked to above.</p>

<p>Some may argue that loop-unrolling should be left to the compiler. I will counter-argue that compilers are currently not smart enough to unroll this particular loop. Have a closer look and you will see why.</p>

<hr>

<p>Note that although my answer is language-agnostic, it is meant primarily for C or C++.</p>
"
"<p>I am trying to run the following code in assembly:</p>

<pre><code>  mov        %si, %ax
  mov        $15, %si
  div        %si
  mov        %eax, %esi
</code></pre>

<p>When I make my program, it compiles, but at runtime it gives me a floating point exception.
I tried to replace the last line's parameters by <code>%ah</code> and <code>%si</code>.</p>

<p>Briefly, I am trying to divide <code>%esi</code> by <code>15</code>. I only want an <code>int</code>, and have no need for a <code>double</code>.</p>

<p>Thank you</p>
","922184","","<p>The <code>div</code> instruction divides the two-word parameter <code>dx/ax</code> by the operand. If the quotient is too large to fit into a word, it will throw that exception.</p>

<p>Reference: <a href=""http://siyobik.info.gf/main/reference/instruction/DIV"">http://siyobik.info.gf/main/reference/instruction/DIV</a></p>

<p>What do you have in the <code>dx</code> register? Most likely <code>dx/ax</code> divided by <code>15</code> does not fit in a 16-bit word.</p>
"
"<p>I am using gmp's mpf_t to try and get very high precision.</p>

<p>My range of precision ranges from negative trillions to positive trillions, as well as 1 over these numbers.  However mpf doesn't support a power function that allows negative exponents, is there a way to get around this if I want to raise my value to 10^-30?</p>

<p><a href=""http://gmplib.org/manual/Float-Arithmetic.html#Float-Arithmetic"" rel=""nofollow"">http://gmplib.org/manual/Float-Arithmetic.html#Float-Arithmetic</a></p>

<p>my gdp output when I try to use mpf_pow_ui, when my exp is negative:</p>

<pre><code>(gdb) p exp_multiplier
$9 = {{_mp_prec = 2, _mp_size = 3, _mp_exp = 957480584338323631, _mp_d = 0x605070}}
</code></pre>

<p>This eventually will cause a segfault.</p>
","922184","","<p>When in doubt, apply math:</p>

<pre><code>10^-30 = 1 / 10^30
</code></pre>

<p>Just raise it to the positive power and take the reciprocal.</p>

<p>There's a division function <code>mpf_ui_div()</code> that takes an integer numerator for that.</p>
"
"<p>So, I know that in <code>C</code> you need to link the code to the math library, <code>libm</code>, to be able to use its functions. Today, while I was trying to demonstrate this to a friend, and explain why you need to do this, I came across the following situation that I do not understand.</p>

<p>Consider the following code:</p>

<pre><code>#include &lt;math.h&gt;
#include &lt;stdio.h&gt;

/* #define VARIABLE */

int main(void)
{
#ifdef VARIABLE
    double a = 2.0;
    double b = sqrt(a);
    printf(""b = %lf\n"",b);
#else
    double b = sqrt(2.0);
    printf(""b = %lf\n"",b);
#endif
    return 0;
}
</code></pre>

<p>If <code>VARIABLE</code> is defined, you need to link against <code>libm</code> as you would normally expect; otherwise you get the usual <code>main.c:(.text+0x29): undefined reference to sqrt</code> linking error indicating that the compiler cannot find the definition for the function <code>sqrt</code>. I was surprised to see that if I comment <code>#define VARIABLE</code>, the code runs fine and the result is correct!</p>

<p>Why is it that I need to link to <code>libm</code> when variables are used but I don't need to do so when literal constants are used? How does the compiler find the definition of <code>sqrt</code> when the library is not linked? I'm using <code>gcc 4.4.5</code> under linux.</p>
","922184","","<p>As everyone mentions, yes it has to do with <a href=""http://en.wikipedia.org/wiki/Constant_folding"" rel=""nofollow"">constant folding</a>.</p>

<p><strong>With optimizations off</strong>, GCC only seems to do it when <code>sqrt(2.0)</code> is used. Here's the evidence:</p>

<p><strong>Case 1:</strong> With the variable.</p>

<pre><code>    .file   ""main.c""
    .section    .rodata
.LC1:
    .string ""b = %lf\n""
    .text
.globl main
    .type   main, @function
main:
    pushl   %ebp
    movl    %esp, %ebp
    andl    $-16, %esp
    subl    $32, %esp
    fldl    .LC0
    fstpl   24(%esp)
    fldl    24(%esp)
    fsqrt
    fucom   %st(0)
    fnstsw  %ax
    sahf
    jp  .L5
    je  .L2
    fstp    %st(0)
    jmp .L4
.L5:
    fstp    %st(0)
.L4:
    fldl    24(%esp)
    fstpl   (%esp)
    call    sqrt
.L2:
    fstpl   16(%esp)
    movl    $.LC1, %eax
    fldl    16(%esp)
    fstpl   4(%esp)
    movl    %eax, (%esp)
    call    printf
    movl    $0, %eax
    leave
    ret
    .size   main, .-main
    .section    .rodata
    .align 8
.LC0:
    .long   0
    .long   1073741824
    .ident  ""GCC: (Ubuntu 4.4.3-4ubuntu5) 4.4.3""
    .section    .note.GNU-stack,"""",@progbits
</code></pre>

<p>You can see that it emits a call to the <code>sqrt</code> function. So you'll get a linker error if you don't link the math library.</p>

<p><strong>Case 2:</strong> With the Literal.</p>

<pre><code>    .file   ""main.c""
    .section    .rodata
.LC1:
    .string ""b = %lf\n""
    .text
.globl main
    .type   main, @function
main:
    pushl   %ebp
    movl    %esp, %ebp
    andl    $-16, %esp
    subl    $32, %esp
    fldl    .LC0
    fstpl   24(%esp)
    movl    $.LC1, %eax
    fldl    24(%esp)
    fstpl   4(%esp)
    movl    %eax, (%esp)
    call    printf
    movl    $0, %eax
    leave
    ret
    .size   main, .-main
    .section    .rodata
    .align 8
.LC0:
    .long   1719614413
    .long   1073127582
    .ident  ""GCC: (Ubuntu 4.4.3-4ubuntu5) 4.4.3""
    .section    .note.GNU-stack,"""",@progbits
</code></pre>

<p>There's no call to <code>sqrt</code>. Hence no linker error.</p>

<hr>

<p><strong>With optimizations on</strong>, GCC will do constant propagation in both cases. So no linker error in either case.</p>

<pre><code>$ gcc main.c -save-temps
main.o: In function `main':
main.c:(.text+0x30): undefined reference to `sqrt'
collect2: ld returned 1 exit status
$ gcc main.c -save-temps -O2
$ 
</code></pre>
"
"<p>As the question title reads, assigning 2^31 to a signed and unsigned 32-bit integer variable gives an unexpected result.</p>

<p>Here is the short program (in <code>C++</code>), which I made to see what's going on:</p>

<pre><code>#include &lt;cstdio&gt;
using namespace std;

int main()
{
    unsigned long long n = 1&lt;&lt;31;
    long long n2 = 1&lt;&lt;31;  // this works as expected
    printf(""%llu\n"",n);
    printf(""%lld\n"",n2);
    printf(""size of ULL: %d, size of LL: %d\n"", sizeof(unsigned long long), sizeof(long long) );
    return 0;
}
</code></pre>

<p>Here's the output:</p>

<pre><code>MyPC / # c++ test.cpp -o test
MyPC / # ./test
18446744071562067968      &lt;- Should be 2^31 right?
-2147483648               &lt;- This is correct ( -2^31 because of the sign bit)
size of ULL: 8, size of LL: 8
</code></pre>

<p>I then added another function <code>p()</code>, to it:</p>

<pre><code>void p()
{
  unsigned long long n = 1&lt;&lt;32;  // since n is 8 bytes, this should be legal for any integer from 32 to 63
  printf(""%llu\n"",n);
}
</code></pre>

<p>On compiling and running, this is what confused me even more:</p>

<pre><code>MyPC / # c++ test.cpp -o test
test.cpp: In function ‘void p()’:
test.cpp:6:28: warning: left shift count &gt;= width of type [enabled by default]
MyPC / # ./test 
0
MyPC /
</code></pre>

<p>Why should the compiler complain about left shift count being too large? <code>sizeof(unsigned long long</code>) returns 8, so doesn't that mean 2^63-1 is the max value for that data type?</p>

<p>It struck me that maybe n*2 and n&lt;&lt;1, don't always behave in the same manner, so I tried this:</p>

<pre><code>void s()
{
   unsigned long long n = 1;
   for(int a=0;a&lt;63;a++) n = n*2;
   printf(""%llu\n"",n);
}
</code></pre>

<p>This gives the correct value of 2^63 as the output which is <code>9223372036854775808</code> (I verified it using python). But what is wrong with doing a left shit?</p>

<blockquote>
  <p>A left arithmetic shift by n is equivalent to multiplying by 2<sup>n</sup>
  (provided the value does not overflow)</p>
</blockquote>

<p><strong>-- Wikipedia</strong></p>

<p>The value is not overflowing, only a minus sign will appear since the value is 2^63 (all bits are set).</p>

<p>I'm still unable to figure out what's going on with left shift, can anyone please explain this?</p>

<p>PS: This program was run on a 32-bit system running linux mint (if that helps)</p>
","922184","","<p>On this line:</p>

<pre><code>unsigned long long n = 1&lt;&lt;32;
</code></pre>

<p>The problem is that the literal <code>1</code> is of type <code>int</code> - which is probably only 32 bits. Therefore the shift will push it out of bounds.</p>

<p>Just because you're storing into a larger datatype doesn't mean that everything in the expression is done at that larger size.</p>

<p>So to correct it, you need to either cast it up or make it an <code>unsigned long long</code> literal:</p>

<pre><code>unsigned long long n = (unsigned long long)1 &lt;&lt; 32;
unsigned long long n = 1ULL &lt;&lt; 32;
</code></pre>
"
"<p>I have a multiply-add kernel inside my application and I want to increase its performance. </p>

<p>I use an Intel Core i7-960 (3.2 GHz clock) and have already manually implemented the kernel using SSE intrinsics as follows:</p>

<pre><code> for(int i=0; i&lt;iterations; i+=4) {
    y1 = _mm_set_ss(output[i]);
    y2 = _mm_set_ss(output[i+1]);
    y3 = _mm_set_ss(output[i+2]);
    y4 = _mm_set_ss(output[i+3]);

    for(k=0; k&lt;ksize; k++){
        for(l=0; l&lt;ksize; l++){
            w  = _mm_set_ss(weight[i+k+l]);

            x1 = _mm_set_ss(input[i+k+l]);
            y1 = _mm_add_ss(y1,_mm_mul_ss(w,x1));
            …
            x4 = _mm_set_ss(input[i+k+l+3]);
            y4 = _mm_add_ss(y4,_mm_mul_ss(w,x4));
        }
    }
    _mm_store_ss(&amp;output[i],y1);
    _mm_store_ss(&amp;output[i+1],y2);
    _mm_store_ss(&amp;output[i+2],y3);
    _mm_store_ss(&amp;output[i+3],y4);
 }
</code></pre>

<p>I know I can use packed fp vectors to increase the performance and I already did so succesfully, but I want to know why the single scalar code isn't able to meet the processor's peak performance. </p>

<p>The performance of this kernel on my machine is ~1.6 FP operations per cycle, while the maximum would be 2 FP operations per cycle (since FP add + FP mul can be executed in parallel). </p>

<p>If I'm correct from studying the generated assembly code, the ideal schedule would look like follows, where the <code>mov</code> instruction takes 3 cycles, the switch latency from the load domain to the FP domain for the dependent instructions takes 2 cycles, the FP multiply takes 4 cycles and the FP add takes 3 cycles. (Note that the dependence from the multiply -> add doesn't incur any switch latency because the operations belong to the same domain).</p>

<p><img src=""http://i.imgur.com/tUJ36.png"" alt=""schedule""></p>

<p>According to the measured performance (~80% of the maximum theoretical performance) there is an overhead of ~3 instructions per 8 cycles. </p>

<p>I am trying to either: </p>

<ul>
<li>get rid of this overhead, or</li>
<li>explain where it comes from</li>
</ul>

<p>Of course there is the problem with cache misses &amp; data misalignment which can increase the latency of the move instructions, but are there any other factors that could play a role here? Like register read stalls or something?</p>

<p>I hope my problem is clear, thanks in advance for your responses!</p>

<hr>

<p>Update: The assembly of the inner-loop looks as follows:</p>

<pre><code>...
Block 21: 
  movssl  (%rsi,%rdi,4), %xmm4 
  movssl  (%rcx,%rdi,4), %xmm0 
  movssl  0x4(%rcx,%rdi,4), %xmm1 
  movssl  0x8(%rcx,%rdi,4), %xmm2 
  movssl  0xc(%rcx,%rdi,4), %xmm3 
  inc %rdi 
  mulss %xmm4, %xmm0 
  cmp $0x32, %rdi 
  mulss %xmm4, %xmm1 
  mulss %xmm4, %xmm2 
  mulss %xmm3, %xmm4 
  addss %xmm0, %xmm5 
  addss %xmm1, %xmm6 
  addss %xmm2, %xmm7 
  addss %xmm4, %xmm8 
  jl 0x401b52 &lt;Block 21&gt; 
...
</code></pre>
","922184","","<p>I noticed in the comments that:</p>

<ul>
<li>The loop takes 5 cycles to execute.</li>
<li>It's ""supposed"" to take 4 cycles. (since there's 4 adds and 4 mulitplies)</li>
</ul>

<p>However, your assembly shows 5 SSE <code>movssl</code> instructions. According to <a href=""http://www.agner.org/optimize/instruction_tables.pdf"">Agner Fog's tables</a> all floating-point SSE move instructions are at least <strong><em>1 inst/cycle</em></strong> reciprocal throughput for Nehalem.</p>

<p>Since you have 5 of them, <strong>you can't do better than 5 cycles/iteration</strong>.</p>

<hr>

<p>So in order to get to peak performance, you need to reduce the # of loads that you have. How you can do that I can't see immediately this particular case - but it might be possible.</p>

<p>One common approach is to use <a href=""http://en.wikipedia.org/wiki/Loop_tiling"">tiling</a>. Where you add nesting levels to improve locality. Although it's used mostly for improving cache access, it can also be used in registers to reduce the # of load/stores that are needed.</p>

<p>Ultimately, your goal is to reduce the number of loads to be less than the numbers of add/muls. So this might be the way to go.</p>
"
"<p>Can any user run inline assembly for current linux kernel or does that require special permission?</p>
","922184","","<p>Inline assembly has nothing to do with the kernel. So the answer is no.</p>

<p>Anyone can write inline assembly and compile it into the program. It isn't any different from compiler generated code.</p>

<p>As for your comment, the answer is no it's not possible because of <a href=""http://en.wikipedia.org/wiki/Memory_protection"">memory protection</a>. As soon as you try to access memory that isn't mapped or you're not allowed to (whether it'd be in C or via inline assembly), you'll get a seg-fault.</p>

<hr>

<p>In other words, the layer of protection is not between the C code and the compiler. It's between the compiled code and the operating system.</p>

<p>So you can't damage the kernel using C or inline assembly - unless you have acquired the permissions to do so.</p>
"
"<p>I'm developing a parallel algorithm on a Intel i5-core machine, which has two cores, four threads.</p>

<p>n defines the size of the matrix, on which I perform my calculations on. As you can see from the table below there is almost 50% reduction from 1 thread to 2 threads utilization, but almost no difference between 2 threads and 4 threads. The numbers denote the seconds passed</p>

<p><img src=""http://i.stack.imgur.com/diuke.png"" alt=""#of threads - computation time""></p>

<p>My compiler is mingw-gcc on windows platform. My parallelization tool is openmp. I'm defining number of threads by <code>omp_set_num_threads(numThreads);</code>in the beginning of the parallel routine.</p>

<p>I have no means to test the algorithm on a ""real"" 8 core machine. On my i5 machine, At 1 thread, task manager shows 25% of the total cpu power is used. At 2 threads, it's 50%, and at 4 threads, it's 96-99% as expected.</p>

<p>So what might be the reason for that situation? Why doesn't the computation time get halved?</p>

<p>The parallel code segment is to be found below:</p>

<pre><code>    #pragma omp parallel for schedule(guided) shared(L,A) \
    private(i)
    for (i=k+1;i&lt;row;i++){
        double dummy = 0;
        for (int nn=0;nn&lt;k;nn++){
            dummy += L[i][nn]*L[k][nn];
            L[i][k] = (A[i][k] - dummy)/L[k][k];
        }
    }
</code></pre>
","922184","","<p>Well, your machine has <strong><em>2 cores</em></strong> and <strong><em>4 threads</em></strong>.</p>

<p>You only have 2 <strong><em>cores</em></strong>, so you won't get 4x speedup from 1 - 4 threads.</p>

<p>Secondly, as you scale to more threads, you will likely start hitting resource contention such as maxing out your memory bandwidth.</p>
"
"<p>What is the most efficient to share data between multiple cores. Sure you can use shared memory but that also comes at a cost. Say one core is continously writing to a variable and the other core has to continuously read from it. With the MESI cache coherence protocol, the writing core will cause the reading core to invalidate its cache every now and then. So in this scenario, what is the most efficient way of sharing data.</p>
","922184","","<p>On a typical shared memory machine, the scenario that you describe is probably already the most efficient method that is possible:</p>

<ul>
<li>Core A writes to memory location. Invalidates Core B's copy.</li>
<li>Core B grabs the data from memory or from Core A's cache.</li>
</ul>

<p>Either way, the data must be sent from Core A to Core B. Cache coherency in modern processors will sometimes support direct cache-to-cache transfer without going all the way to memory.</p>

<hr>

<p>What you want to avoid (whenever possible) is excessive locking of the shared resource. That will increase cache coherency traffic (and latency) in both directions.</p>
"
"<p>Given the following code : </p>

<pre><code>for (int i=0; i&lt;n; i++)
{
  counter += myArray[i];
}
</code></pre>

<p>And the Loop unrolling version :</p>

<pre><code>for (int i=0; i&lt;n; i+=4)
{
  counter1 += myArray[i+0];
  counter2 += myArray[i+1];
  counter3 += myArray[i+2];
  counter4 += myArray[i+3];
}

total = counter1+ counter2 + counter3+ counter4;
</code></pre>

<ol>
<li>Why do we have a cache miss in the first version ? </li>
<li>Is the second version has indeed a better performance than the 1st ? why ?</li>
</ol>

<p>Regards </p>
","922184","","<blockquote>
  <p>Why do we have a cache miss in the first version ?</p>
</blockquote>

<p>As Oli points out in the comments. This question is unfounded. If the data is already in the cache, then there will be no cache misses.</p>

<p>That aside, there is no difference in memory access between your two examples. So that will not likely be a factor in any performance difference between them.</p>

<blockquote>
  <p>Is the second version has indeed a better performance than the 1st ? why ?</p>
</blockquote>

<p>Usually, the thing to do is to actually measure. But in this particular example, I'd say that it will likely be faster. Not because of better cache access, but because of the loop-unrolling.</p>

<p>The optimization that you are doing is called ""Node-Splitting"", where you separate the <code>counter</code> variable for the purpose of breaking the dependency chain.</p>

<p>However, in this case, you are doing a trivial reduction operation. Many modern compilers are able to recognize this pattern and do this node-splitting for you.</p>

<p><strong>So is it faster? Most likely.</strong> But you should check to see if the compiler does it for you.</p>

<hr>

<p><strong>For the record:</strong> I just tested this on Visual Studio 2010.<br>And I am quite surprised that it is <strong><em>not able</em></strong> to do this optimization.</p>

<pre><code>; 129  : 
; 130  :     int counter = 0;
; 131  : 
; 132  :     for (int i=0; i&lt;n; i++)
    mov ecx, DWORD PTR n$[rsp]
    xor edx, edx
    test    ecx, ecx
    jle SHORT $LN1@main
$LL3@main:

; 133  :     {
; 134  :         counter += myArray[i];

    add edx, DWORD PTR [rax]
    add rax, 4
    dec rcx
    jne SHORT $LL3@main
$LN1@main:

; 135  :     }
</code></pre>

<p>Visual Studio 2010 does not seem to be capable of performing ""Node Splitting"" for this (trivial) example...</p>
"
"<p>Look at this code:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;omp.h&gt;

int main()
{
    long i, j;

    #pragma omp for
    for(i=0;i&lt;=100000;i++)
    {
        for(j=0;j&lt;=100000;j++)
        {
            if((i ^ j) == 5687)
            {
                //printf(""%ld ^ %ld\n"", i, j);
                break;
            }
        }
    }
}
</code></pre>

<p>So, result:</p>

<pre><code>robotex@robotex-work:~/Projects$ gcc test.c -fopenmp -o test_openmp
robotex@robotex-work:~/Projects$ gcc test.c -o test_noopenmp
robotex@robotex-work:~/Projects$ time ./test_openmp
real    0m11.785s
user    0m11.613s
sys 0m0.008s
robotex@robotex-work:~/Projects$ time ./test_noopenmp

real    0m13.364s
user    0m13.253s
sys 0m0.008s
robotex@robotex-work:~/Projects$ time ./test_noopenmp

real    0m11.955s
user    0m11.853s
sys 0m0.004s
robotex@robotex-work:~/Projects$ time ./test_openmp

real    0m15.048s
user    0m14.949s
sys 0m0.004s
</code></pre>

<p>What's wrong? Why are OpenMP program slower? How can I correct it?</p>

<p>I tested it in several computers (Intel Core i5 at work, Intel Core2Duo T7500 at home) with OS Ubuntu and always got the same result: OpenMP don't give significant performance gains.</p>

<p>I also tested example from Wikipedia and got the same result.</p>
","922184","","<p>There are two issues in your code:</p>

<ol>
<li>You're missing the <code>parallel</code> in your pragma. So it's only using 1 thread.</li>
<li>You have a race condition on <code>j</code> because it's declared outside the parallel region.</li>
</ol>

<hr>

<p>First, you need <code>parallel</code> to actually make OpenMP run in parallel:</p>

<pre><code>#pragma omp parallel for
</code></pre>

<p>Secondly, you are declaring <code>j</code> outside the parallel region. This will make it shared among all the threads. So all the threads read and modify it inside the parallel region. </p>

<p>So not only do you have a race-condition, but the cache coherence traffic caused by all the invalidations is killing your performance.</p>

<p>What you need to do is to make <code>j</code> local to each thread. This can be done by either:</p>

<ol>
<li>Declaring <code>j</code> inside the parallel region.</li>
<li>Or adding <code>private(j)</code> to the pragma: <code>#pragma omp parallel for private(j)</code><br>(as pointed out by @ArjunShankar in the comments)</li>
</ol>

<hr>

<p>Try this instead:</p>

<pre><code>int main()
{
    double start = omp_get_wtime();

    long i;

#pragma omp parallel for
    for(i=0;i&lt;=100000;i++)
    {
        long j;
        for(j=0;j&lt;=100000;j++)
        {
            if((i ^ j) == 5687)
            {
                //printf(""%ld ^ %ld\n"", i, j);
                break;
            }
        }
    }

    double end = omp_get_wtime();

    printf(""%f\n"",end - start);
    return 0;
}
</code></pre>

<hr>

<pre><code>No OpenMP:            6.433378
OpenMP with global j: 9.634591
OpenMP with local j:  2.266667
</code></pre>
"
"<p>I've read in a document that you can replace mod operation by logical and like this :</p>

<p>Instead:</p>

<pre><code>int Limit = Value % Range;
</code></pre>

<p>You do:</p>

<pre><code>int Limit = Value &amp; (Range-1);
</code></pre>

<p>But compilers still generate mod instructions and my question is basically : Why do compilers don't use the most efficient approach if they work the same ? </p>
","922184","","<p>Um no... that only works when <code>Range</code> is a power of two.</p>

<p>For all other values, you still need the modulus <code>%</code> operator.</p>

<p>There are also some subtle (possibly implementation-defined) differences when working with negative numbers.</p>

<hr>

<p>As a side note: Using the <code>%</code> operator is probably more readable too.</p>
"
"<p>This is the ""algorithm"", but when I want to measure the execution time it gives me zero. Why?</p>

<pre><code>#define ARRAY_SIZE 10000
...

clock_t start, end;

start = clock();

for( i = 0; i &lt; ARRAY_SIZE; i++) 
{
non_parallel[i] = vec[i] * vec[i];
}
end = clock();
printf( ""Number of seconds: %f\n"", (end-start)/(double)CLOCKS_PER_SEC );
</code></pre>

<p>So What should i do to measure the time?</p>
","922184","","<p>Two things:</p>

<ol>
<li><p><code>10000</code> is not a lot on a modern computer. Therefore that loop will run in probably less than a millisecond - less than the precision of <code>clock()</code>. Therefore it will return zero.</p></li>
<li><p>If you aren't using the result of <code>non_parallel</code> its possible that the entire loop will be optimized out by the compiler.</p></li>
</ol>

<p>Most likely, you just need a more expensive loop. Try increasing <code>ARRAY_SIZE</code> to something much larger.</p>

<hr>

<p><strong>Here's a test on my machine with a larger array size:</strong></p>

<pre><code>#define ARRAY_SIZE 100000000

int main(){

    clock_t start, end;

    double *non_parallel = (double*)malloc(ARRAY_SIZE * sizeof(double));
    double *vec          = (double*)malloc(ARRAY_SIZE * sizeof(double));

    start = clock();

    for(int i = 0; i &lt; ARRAY_SIZE; i++) 
    {
        non_parallel[i] = vec[i] * vec[i];
    }

    end = clock();
    printf( ""Number of seconds: %f\n"", (end-start)/(double)CLOCKS_PER_SEC );


    free(non_parallel);
    free(vec);
    return 0;
}
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>Number of seconds: 0.446000
</code></pre>
"
"<p>Can anyone explain what the trade off (even if it's negligible) would be between using <code>if</code>, <code>if else</code>, or <code>switch</code> in a sizable block of code similar to the following? Is the situation different if it were comparing a String or another Object instead of an int? The examples are in Java but it is meant as a general question.</p>

<p><strong>EDIT</strong></p>

<p>As several answers stated, a switch is going to be faster and should probably be used if there are more than a few cases. However, nobody has commented on <code>if</code> vs <code>if else</code> when in a long chain like this. What sparked this question is that I am frequently creating these blocks where a switch can't be used because most of the cases require multiple expressions. I guess excluding the <code>else</code> feels sloppy, but it isn't really necessary so why include it?</p>

<pre><code>public String getValueString(int x) {
    if (x == 1) return ""one"";
    if (x == 2) return ""two"";
    if (x == 3) return ""three"";
    if (x == 4) return ""four"";
    ...
    return null;
}
</code></pre>

<p>VS</p>

<pre><code>public String getValueString(int x) {
    if (x == 1) return ""one"";
    else if (x == 2) return ""two"";
    else if (x == 3) return ""three"";
    else if (x == 4) return ""four"";
    ...
    return null;
}
</code></pre>

<p>VS</p>

<pre><code>public String getValueString(int x) {
    switch(x) {
        case 1: return ""one"";
        case 2: return ""two"";
        case 3: return ""three"";
        case 4: return ""four"";
        ...
    }
    return null;        
}
</code></pre>
","922184","","<p>If you have a lot of cases, then the <code>switch</code> approach is the preferred method. The reason is because the first two requires essentially a linear search through all the if-statements. So it is <code>O(N)</code> to the number of cases you have.</p>

<p>On the other hand, <code>switch</code> statements are optimized differently and can be either <code>O(log(N))</code> or even <code>O(1)</code> for finding that correct case.</p>

<hr>

<p>How can the compiler achieve <code>O(log(N))</code> or even <code>O(1)</code>?</p>

<ul>
<li>Binary search of the case values will allow it to be done in <code>O(log(N))</code>.</li>
<li>If the case values are dense enough, the compiler may even use a jump table indexed by the case variable. In that case it is <code>O(1)</code>.</li>
</ul>
"
"<p>For a hobby project I'm working on, I need to emulate certain 64-bit integer operations on a x86 CPU, and it needs to be <em>fast</em>.</p>

<p>Currently, I'm doing this via MMX instructions, but that's really a pain to work with, because I have to flush the fp register state all the time (and because most MMX instructions deal with <em>signed</em> integers, and I need unsigned behavior).</p>

<p>So I'm wondering if the SSE/optimization gurus here on SO can come up with a better implementation using SSE.</p>

<p>The operations I need are the following (quite specific) ones:</p>

<pre><code>uint64_t X, Y;

X = 0;
X = 1;
X &lt;&lt; 1;
X != Y;
X + 1;
X &amp; 0x1 // get lsb
X | 0x1 // set lsb
X &gt; Y;
</code></pre>

<p>Specifically, I don't need general-purpose addition or shifting, for example, just add one and left-shift one. Really, just the <em>exact</em> operations shown here.</p>

<p>Except, of course, on x86, <code>uint64_t</code> is emulated by using two 32-bit scalars, which is slow (and, in my case, simply doesn't work, because I need loads/stores to be atomic, which they won't be when loading/storing two separate registers).</p>

<p>Hence, I need a SIMD solution.
Some of these operations are trivial, supported by SSE2 already. Others (<code>!=</code> and <code>&lt;</code>) require a bit more work.</p>

<p>Suggestions?
SSE and SSE2 are fine. It'd take some persuasion to permit SSE3, and SSE4 is probably out of the question (A CPU which supports SSE4 is likely to run 64-bit <em>anyway</em>, and so I don't need these workarounds)</p>
","922184","","<p>SSE2 has direct support for some 64-bit integer operations:</p>

<p><strong>Set both elements to 0:</strong></p>

<pre><code>__m128i z = _mm_setzero_si128();
</code></pre>

<p><strong>Set both elements to 1:</strong></p>

<pre><code>__m128i z = _mm_set_epi32(0,1,0,1);
</code></pre>

<p><strong>Vertically add/subtract each 64-bit integer:</strong></p>

<pre><code>__m128i z = _mm_add_epi64(x,y)
__m128i z = _mm_sub_epi64(x,y)
</code></pre>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_integer_arithmetic.htm#intref_sse2_integer_arithmetic"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_integer_arithmetic.htm#intref_sse2_integer_arithmetic</a></p>

<p><strong>Left Shift:</strong></p>

<pre><code>__m128i z = _mm_slli_epi64(x,i)   // i must be an immediate
</code></pre>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_shift.htm"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_shift.htm</a></p>

<p><strong>Bitwise operators:</strong></p>

<pre><code>__m128i z = _mm_and_si128(x,y)
__m128i z = _mm_or_si128(x,y)
</code></pre>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_integer_logical.htm"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_integer_logical.htm</a></p>

<p>SSE doesn't have increments, so you'll have to use a constant with <code>1</code>.</p>

<hr>

<p>Comparisons are harder since there's no 64-bit support.</p>

<p><strong>Here's the one for equality:</strong></p>

<pre><code>__m128i t = _mm_cmpeq_epi32(a,b);
__m128i z = _mm_and_si128(t,_mm_shuffle_epi32(t,177));
</code></pre>

<p>This will set the each 64-bit element to <code>0xffffffffffff</code> if they are equal. If you want it as a <code>0</code> or <code>1</code> in an <code>int</code>, you can pull it out using <code>_mm_cvtsi32_si128()</code> and add <code>1</code>.</p>

<p><strong>And Less-Than:</strong> (not fully tested)</p>

<pre><code>a = _mm_xor_si128(a,_mm_set1_epi32(0x80000000));
b = _mm_xor_si128(b,_mm_set1_epi32(0x80000000));
__m128i t = _mm_cmplt_epi32(a,b);
__m128i u = _mm_cmpgt_epi32(a,b);
__m128i z = _mm_or_si128(t,_mm_shuffle_epi32(t,177));
z = _mm_andnot_si128(_mm_shuffle_epi32(u,245),z);
</code></pre>

<p>This will set the each 64-bit element to <code>0xffffffffffff</code> if the corresponding element in <code>a</code> is less than <code>b</code>.</p>

<hr>

<p>Here's are versions of ""equals"" and ""less-than"" that return a bool. They return the result of the comparison for the bottom 64-bit integer.</p>

<pre><code>inline bool equals(__m128i a,__m128i b){
    __m128i t = _mm_cmpeq_epi32(a,b);
    __m128i z = _mm_and_si128(t,_mm_shuffle_epi32(t,177));
    return _mm_cvtsi128_si32(z) &amp; 1;
}
inline bool lessthan(__m128i a,__m128i b){
    a = _mm_xor_si128(a,_mm_set1_epi32(0x80000000));
    b = _mm_xor_si128(b,_mm_set1_epi32(0x80000000));
    __m128i t = _mm_cmplt_epi32(a,b);
    __m128i u = _mm_cmpgt_epi32(a,b);
    __m128i z = _mm_or_si128(t,_mm_shuffle_epi32(t,177));
    z = _mm_andnot_si128(_mm_shuffle_epi32(u,245),z);
    return _mm_cvtsi128_si32(z) &amp; 1;
}
</code></pre>
"
"<p>While writing an optimized <code>ftol</code> function I found some very odd behaviour in <code>GCC 4.6.1</code>. Let me show you the code first (for clarity I marked the differences):</p>

<p>fast_trunc_one, C:</p>

<pre><code>int fast_trunc_one(int i) {
    int mantissa, exponent, sign, r;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);
    sign = i &amp; 0x80000000;

    if (exponent &lt; 0) {
        r = mantissa &lt;&lt; -exponent;                       /* diff */
    } else {
        r = mantissa &gt;&gt; exponent;                        /* diff */
    }

    return (r ^ -sign) + sign;                           /* diff */
}
</code></pre>

<p>fast_trunc_two, C:</p>

<pre><code>int fast_trunc_two(int i) {
    int mantissa, exponent, sign, r;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);
    sign = i &amp; 0x80000000;

    if (exponent &lt; 0) {
        r = (mantissa &lt;&lt; -exponent) ^ -sign;             /* diff */
    } else {
        r = (mantissa &gt;&gt; exponent) ^ -sign;              /* diff */
    }

    return r + sign;                                     /* diff */
}
</code></pre>

<p>Seems the same right? Well GCC disagrees. After compiling with <code>gcc -O3 -S -Wall -o test.s test.c</code> this is the assembly output:</p>

<p>fast_trunc_one, generated:</p>

<pre><code>_fast_trunc_one:
LFB0:
    .cfi_startproc
    movl    4(%esp), %eax
    movl    $150, %ecx
    movl    %eax, %edx
    andl    $8388607, %edx
    sarl    $23, %eax
    orl $8388608, %edx
    andl    $255, %eax
    subl    %eax, %ecx
    movl    %edx, %eax
    sarl    %cl, %eax
    testl   %ecx, %ecx
    js  L5
    rep
    ret
    .p2align 4,,7
L5:
    negl    %ecx
    movl    %edx, %eax
    sall    %cl, %eax
    ret
    .cfi_endproc
</code></pre>

<p>fast_trunc_two, generated:</p>

<pre><code>_fast_trunc_two:
LFB1:
    .cfi_startproc
    pushl   %ebx
    .cfi_def_cfa_offset 8
    .cfi_offset 3, -8
    movl    8(%esp), %eax
    movl    $150, %ecx
    movl    %eax, %ebx
    movl    %eax, %edx
    sarl    $23, %ebx
    andl    $8388607, %edx
    andl    $255, %ebx
    orl $8388608, %edx
    andl    $-2147483648, %eax
    subl    %ebx, %ecx
    js  L9
    sarl    %cl, %edx
    movl    %eax, %ecx
    negl    %ecx
    xorl    %ecx, %edx
    addl    %edx, %eax
    popl    %ebx
    .cfi_remember_state
    .cfi_def_cfa_offset 4
    .cfi_restore 3
    ret
    .p2align 4,,7
L9:
    .cfi_restore_state
    negl    %ecx
    sall    %cl, %edx
    movl    %eax, %ecx
    negl    %ecx
    xorl    %ecx, %edx
    addl    %edx, %eax
    popl    %ebx
    .cfi_restore 3
    .cfi_def_cfa_offset 4
    ret
    .cfi_endproc
</code></pre>

<p>That's an <strong>extreme</strong> difference. This actually shows up on the profile too, <code>fast_trunc_one</code> is around 30% faster than <code>fast_trunc_two</code>. Now my question: what is causing this?</p>
","922184","","<p><strong>Updated to sync with the OP's edit</strong></p>

<p>By tinkering with the code, I've managed to see how GCC optimizes the first case.</p>

<p><strong>Before we can understand why they are so different, first we must understand how GCC optimizes <code>fast_trunc_one()</code>.</strong></p>

<p>Believe it or not, <code>fast_trunc_one()</code> is being optimized to this:</p>

<pre><code>int fast_trunc_one(int i) {
    int mantissa, exponent;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);

    if (exponent &lt; 0) {
        return (mantissa &lt;&lt; -exponent);             /* diff */
    } else {
        return (mantissa &gt;&gt; exponent);              /* diff */
    }
}
</code></pre>

<p>This produces the exact same assembly as the original <code>fast_trunc_one()</code> - register names and everything.</p>

<p>Notice that there are no <code>xor</code>s in the assembly for <code>fast_trunc_one()</code>. That's what gave it away for me.</p>

<hr>

<h1>How so?</h1>

<hr>

<p><strong>Step 1:</strong> <code>sign = -sign</code></p>

<p>First, let's take a look at the <code>sign</code> variable. Since <code>sign = i &amp; 0x80000000;</code>, there are only two possible values that <code>sign</code> can take:</p>

<ul>
<li><code>sign = 0</code></li>
<li><code>sign = 0x80000000</code></li>
</ul>

<p>Now recognize that in both cases, <code>sign == -sign</code>. Therefore, when I change the original code to this:</p>

<pre><code>int fast_trunc_one(int i) {
    int mantissa, exponent, sign, r;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);
    sign = i &amp; 0x80000000;

    if (exponent &lt; 0) {
        r = mantissa &lt;&lt; -exponent;
    } else {
        r = mantissa &gt;&gt; exponent;
    }

    return (r ^ sign) + sign;
}
</code></pre>

<p>It produces the exact same assembly as the original <code>fast_trunc_one()</code>. I'll spare you the assembly, but it is identical - register names and all.</p>

<hr>

<p><strong>Step 2:</strong> Mathematical reduction: <code>x + (y ^ x) = y</code></p>

<p><code>sign</code> can only take one of two values, <code>0</code> or <code>0x80000000</code>.</p>

<ul>
<li>When <code>x = 0</code>, then <code>x + (y ^ x) = y</code> then trivial holds.</li>
<li>Adding and xoring by <code>0x80000000</code> is the same. It flips the sign bit. Therefore <code>x + (y ^ x) = y</code> also holds when <code>x = 0x80000000</code>.</li>
</ul>

<p>Therefore, <code>x + (y ^ x)</code> reduces to <code>y</code>. And the code simplifies to this:</p>

<pre><code>int fast_trunc_one(int i) {
    int mantissa, exponent, sign, r;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);
    sign = i &amp; 0x80000000;

    if (exponent &lt; 0) {
        r = (mantissa &lt;&lt; -exponent);
    } else {
        r = (mantissa &gt;&gt; exponent);
    }

    return r;
}
</code></pre>

<p>Again, this compiles to the exact same assembly - register names and all.</p>

<hr>

<p>This above version finally reduces to this:</p>

<pre><code>int fast_trunc_one(int i) {
    int mantissa, exponent;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);

    if (exponent &lt; 0) {
        return (mantissa &lt;&lt; -exponent);             /* diff */
    } else {
        return (mantissa &gt;&gt; exponent);              /* diff */
    }
}
</code></pre>

<p>which is pretty much exactly what GCC generates in the assembly.</p>

<hr>

<p>So why doesn't the compiler optimize <code>fast_trunc_two()</code> to the same thing?</p>

<p>The key part in <code>fast_trunc_one()</code> is the <code>x + (y ^ x) = y</code> optimization. In <code>fast_trunc_two()</code> the <code>x + (y ^ x)</code> expression is being split across the branch. </p>

<p>I suspect that might be enough to confuse GCC to not make this optimization. (It would need to hoist the <code>^ -sign</code> out of the branch and merge it into the <code>r + sign</code> at the end.)</p>

<p>For example, this produces the same assembly as <code>fast_trunc_one()</code>:</p>

<pre><code>int fast_trunc_two(int i) {
    int mantissa, exponent, sign, r;

    mantissa = (i &amp; 0x07fffff) | 0x800000;
    exponent = 150 - ((i &gt;&gt; 23) &amp; 0xff);
    sign = i &amp; 0x80000000;

    if (exponent &lt; 0) {
        r = ((mantissa &lt;&lt; -exponent) ^ -sign) + sign;             /* diff */
    } else {
        r = ((mantissa &gt;&gt; exponent) ^ -sign) + sign;              /* diff */
    }

    return r;                                     /* diff */
}
</code></pre>
"
"<p>I browsed through the <a href=""http://www.tilera.com/scm/docs/UG401-ISA.pdf"" rel=""nofollow"">Tilera Instruction Set</a> and noticed it has only add, subtract, multiply, divide, and shifts. There is no mention of roots, powers, logs, etc.</p>

<p>I also noticed that SSE (in all flavors) does not have the latter mentioned instructions.</p>

<p>Both the Tilera and SSE are designed for math-based processing such as video encoding, so this has made me curious.</p>

<p>How would one perform one of these operations in such cases (Tilera &amp; SSE [excluding regular scalar ops])?</p>
","922184","","<p>To keep the hardware simple, they usually only implement the most basic and simple instructions that are most commonly used.</p>

<p>The most advanced functions are less commonly used and also take up a lot of silicon and die-space on the processor. Trig-functions, logs, powers, etc. are hard and expensive to implement.</p>

<p>In any case, nearly all special functions break down into basic operations (add/subtract/multiply/divide) so as long as you provide those, you can implement anything.</p>

<p>Vectorizing a special function is usually possible if there isn't too much data-dependent branching. As you can simply take the scalar implementation and replace everything with SIMD versions.</p>
"
"<p>I have a 64 bit register which holds a memory address.  If I perform an arithmetic operation on the lower half of the register and then try to dereference it, I get a segmentation fault.  Here is an example:</p>

<pre><code>movsx rax, BYTE PTR [rdi]  # ok
add edi, 1 # the address is correct but....
movsx rax, BYTE PTR [rdi] # segmentation fault here
</code></pre>

<p>If I change edi to rdi in line 2 it works, so I am just wondering why I can't use the lower half of rdi in this case.  I would also appreciate it if anyone has any links/references with information about the proper use of the lower parts of registers.</p>

<p>Thanks a lot for your help. </p>
","922184","","<p>When you do operations on a <code>edi</code> or any other 32-bit bottom-half register, it automatically zeros the top half of the whole register.</p>

<p>Therefore the upper 32-bits of <code>rdi</code> will be zero after the <code>add edi, 1</code>.</p>
"
"<p>From <a href=""http://en.wikipedia.org/wiki/Multiplication_algorithm#Fourier_transform_methods"" rel=""nofollow"">Wikipedia</a>:</p>

<p>""Anindya De, Chandan Saha, Piyush Kurur and Ramprasad Saptharishi[11] gave a similar algorithm using modular arithmetic in 2008 achieving the same running time. However, these latter algorithms are only faster than Schönhage–Strassen <em>for impractically large inputs</em>."" </p>

<p>I would be very interested in the size of such <em>impractically large</em> integers.</p>

<p>Maybe someone did implement both algorithms in a certain way and could do some benchmarks?</p>

<p>Thanks</p>
","922184","","<p><a href=""http://en.wikipedia.org/wiki/F%C3%BCrer%27s_algorithm"" rel=""nofollow"">Fürer's algorithm</a> and it's modular equivalent (DSKS) are very deep research topics and, for now, remain only as academic interest. Nobody actually knows how big the cross-over point is. And in all likeliness it doesn't matter because that cross-over point is likely to be <strong><em>well beyond 64-bit computing limits</em></strong>.</p>

<p>I've implemented Schönhage-Strassen before and I understand how Fürer's algorithm works. So I'm quite familiar with both of them. I can say it's very possible that the cross-over point between Schönhage-Strassen and Fürer's algorithm is so high that a computer capable of holding the parameters will be larger than the size of the observable universe.</p>

<p>That's the problem when you have complexities that differ by less than a logarithm. <strong><em>It takes exponentially large input sizes to compensate even for small differences in the Big-O constant.</em></strong></p>

<p>In this case, Fürer's algorithm is known to have a <em>very very very</em> large Big-O constant.</p>
"
"<p>So i was trying to do an array operation that looked something like</p>

<pre><code>for (int i=0;i++i&lt;32)
{
    output[offset+i] += input[i];
}
</code></pre>

<p>where <code>output</code> and <code>input</code> are <code>float</code> arrays (which are 16-byte aligned thanks to <code>malloc</code>).  However, I can't gurantee that <code>offset%4=0</code>.  I was wondering how you could fix these alignment problems.</p>

<p>I though something like</p>

<pre><code>while (offset+c %4 != 0)
{
    c++;
    output[offset+c] += input[c];
}
</code></pre>

<p>followed by an aligned loop - obviously this can't work as we now need an unaligned access to <code>input</code>.</p>

<p>Is there a way to vectorize my original loop?</p>
","922184","","<p>Moving comments to an answer:</p>

<p>There are SSE instructions for misaligned memory accesses. They are accessible via the following intrinsics:</p>

<ul>
<li><code>_mm_loadu_ps()</code> - <a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse_load.htm"">documentation</a></li>
<li><code>_mm_storeu_ps()</code> - <a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_fp_store.htm"">documentation</a></li>
</ul>

<p>and similarly for all the <code>double</code> and integer types.</p>

<p>So if you can't guarantee alignment, then this is the easy way to go. If possible, the ideal solution is to align your arrays from the start so that you avoid this problem altogether.</p>

<p>There will still be a performance penalty for misaligned accesses, but they're unavoidable unless you resort to extremely messy shift/shuffle hacks (such as <code>_mm_alignr_epi8()</code>).</p>

<p>The code using <code>_mm_loadu_ps</code> and <code>_mm_storeu_ps</code> - this is actually 50% slower than what gcc does by itself</p>

<pre><code>for (int j=0;j&lt;8;j++)
{
    float* out = &amp;output[offset+j*4];
    __m128 in = ((__m128*)input)[j]; //this is aligned so no need for _mm_loadu_ps
    __m128 res  = _mm_add_ps(in,_mm_loadu_ps(out)); //add values 
    _mm_storeu_ps(out,res); //store result
}
</code></pre>
"
"<p>Where does the x86-64's SSE instructions (vector instructions) outperform the normal instructions. Because what I'm seeing is that the frequent loads and stores that are required for executing SSE instructions is nullifying any gain we have due to vector calculation. So could someone give me an example SSE code where it performs better than the normal code.</p>

<p>Its maybe because I am passing each parameter separately, like this...</p>

<pre><code>__m128i a = _mm_set_epi32(pa[0], pa[1], pa[2], pa[3]);
__m128i b = _mm_set_epi32(pb[0], pb[1], pb[2], pb[3]);
__m128i res = _mm_add_epi32(a, b);

for( i = 0; i &lt; 4; i++ )
 po[i] = res.m128i_i32[i];
</code></pre>

<p>Isn't there a way I can pass all the 4 integers at one go, I mean pass the whole 128 bytes of <code>pa</code> at one go? And assign <code>res.m128i_i32</code> to <code>po</code> at one go?</p>
","922184","","<p>Summarizing comments into an answer:</p>

<p>You have basically fallen into the same trap that catches most first-timers. Basically there are two problems in your example:</p>

<ol>
<li>You are misusing <code>_mm_set_epi32()</code>.</li>
<li>You have a very low computation/load-store ratio. (1 to 3 in your example)</li>
</ol>

<hr>

<p><code>_mm_set_epi32()</code> is a very expensive intrinsic. Although it's convenient to use, it doesn't compile to a single instruction. Some compilers (such as VS2010) can generate very poor performing code when using <code>_mm_set_epi32()</code>.</p>

<p>Instead, since you are loading contiguous blocks of memory, you should use <code>_mm_load_si128()</code>. That requires that the pointer is aligned to 16 bytes. If you can't guarantee this alignment, you can use <code>_mm_loadu_si128()</code> - but with a performance penalty. Ideally, you should properly align your data so that don't need to resort to using <code>_mm_loadu_si128()</code>.</p>

<hr>

<p>The be truly efficient with SSE, you'll also want to maximize your computation/load-store ratio. A target that I shoot for is 3 - 4 arithmetic instructions per memory-access. This is a fairly high ratio. Typically you have to refactor the code or redesign the algorithm to increase it. Combining passes over the data is a common approach.</p>

<p>Loop unrolling is often necessary to maximize performance when you have large loop bodies with long dependency chains.</p>

<hr>

<p>Some examples of SO questions that successfully use SSE to achieve speedup.</p>

<ul>
<li><a href=""http://stackoverflow.com/questions/9992054/c-code-loop-performance"">C code loop performance</a> (non-vectorized)</li>
<li><a href=""http://stackoverflow.com/questions/10007243/c-code-loop-performance-continued"">C code loop performance [continued]</a> (vectorized)</li>
<li><a href=""http://stackoverflow.com/questions/8389648/how-to-achieve-4-flops-per-cycle"">how to achieve 4 flops per cycle</a> (contrived example for achieving peak processor performance)</li>
</ul>
"
"<p>I am currently writing a simple C compiler, that takes a .c file as input and generates assembly code (X86, AT&amp;T syntax).
Everyting is good, but when I try to execute a IDIVQ instruction, I get a floating-point exception. Here's my input:</p>

<pre><code>int mymain(int x){
  int d;
  int e;
  d = 3;
  e = 6 / d;
  return e;
}
</code></pre>

<p>And here is my generated code:</p>

<pre><code>mymain:
.LFB1:
    .cfi_startproc
    pushq   %rbp
    .cfi_def_cfa_offset 16
    movq    %rsp, %rbp
    .cfi_offset 6, -16
    .cfi_def_cfa_register 6
    movq    %rdi, -40(%rbp)
    movq    $3, -8(%rbp)
    movq    $6, %rax
    movq    -8(%rbp), %rdx
    movq    %rdx, %rbx
    idivq   %rbx
    movq    %rax, -16(%rbp)
    movq    -16(%rbp), %rax
    leave
    .cfi_def_cfa 7, 8
    ret
    .cfi_endproc
.LFE1:
    .size mymain, .-mymain
</code></pre>

<p>According to <a href=""http://www.cs.virginia.edu/~evans/cs216/guides/x86.html"">http://www.cs.virginia.edu/~evans/cs216/guides/x86.html</a>, <strong>idivq %rbx</strong> should produce 6/d (the quotient) in <strong>%rax</strong>. But I'm getting a floating-point exception, and I can't seem to find the problem.</p>

<p>Any help will be much appreciated!</p>
","922184","","<p>The <code>idiv</code> instruction divides a 128-bit integer (<code>rax:rdx</code>) by the operand.</p>

<ul>
<li><code>rax</code> holds the lower 64-bits of the dividend.</li>
<li><code>rdx</code> holds the upper 64-bits of the dividend.</li>
</ul>

<p>When the quotient doesn't fit into 64-bits, it will throw that floating-point exception.</p>

<p>So what you need to do is to zero <code>rdx</code>:</p>

<pre><code>movq    %rdx, %rbx
xorq    %rdx, %rdx    ;   &lt;-- zero ""rdx""
idivq   %rbx
</code></pre>
"
"<p>I'm trying to figure out what the assembly instruction actually does</p>

<pre><code>addsd   -8(%rbp), %xmm0
</code></pre>

<p>I know that it's a floating point addition on an x86-64 machine with SSE2. Also, I know that %xmm0 is a register. However, what I'm not sure of is what -8(%rbp) means. The manuals are a bit confusing on that.</p>

<p>Basically, the question is, does -8(%rbp) mean that it's taking a value from a register (maybe the last 8 bytes of rbp) or is it taking a value from memory (floating point value at an offset of -8 from the address contained in rbp). </p>
","922184","","<p>Your second guess is correct. It's accessing the value at <code>-8</code> bytes offset from address <code>rbp</code>.</p>

<p>Assuming AT&amp;T syntax, this instruction loads an 8-byte <code>double</code> from address <code>rbp - 8</code> and adds it to the value in the lower half of <code>xmm0</code>.</p>
"
"<p>I have the following two files :- </p>

<p>single.cpp :-</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;

using namespace std;

unsigned long a=0;

class A {
  public:
    virtual int f() __attribute__ ((noinline)) { return a; } 
};

class B : public A {                                                                              
  public:                                                                                                                                                                        
    virtual int f() __attribute__ ((noinline)) { return a; }                                      
    void g() __attribute__ ((noinline)) { return; }                                               
};                                                                                                

int main() {                                                                                      
  cin&gt;&gt;a;                                                                                         
  A* obj;                                                                                         
  if (a&gt;3)                                                                                        
    obj = new B();
  else
    obj = new A();                                                                                

  unsigned long result=0;                                                                         

  for (int i=0; i&lt;65535; i++) {                                                                   
    for (int j=0; j&lt;65535; j++) {                                                                 
      result+=obj-&gt;f();                                                                           
    }                                                                                             
  }                                                                                               

  cout&lt;&lt;result&lt;&lt;""\n"";                                                                             
}
</code></pre>

<p>And </p>

<p>multiple.cpp :- </p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;

using namespace std;

unsigned long a=0;

class A {
  public:
    virtual int f() __attribute__ ((noinline)) { return a; }
};

class dummy {
  public:
    virtual void g() __attribute__ ((noinline)) { return; }
};

class B : public A, public dummy {
  public:
    virtual int f() __attribute__ ((noinline)) { return a; }
    virtual void g() __attribute__ ((noinline)) { return; }
};


int main() {
  cin&gt;&gt;a;
  A* obj;
  if (a&gt;3)
    obj = new B();
  else
    obj = new A();

  unsigned long result=0;

  for (int i=0; i&lt;65535; i++) {
    for (int j=0; j&lt;65535; j++) {
      result+=obj-&gt;f();
    }
  }

  cout&lt;&lt;result&lt;&lt;""\n"";
}
</code></pre>

<p>I am using gcc version 3.4.6 with flags -O2</p>

<p>And this is the timings results I get :- </p>

<p>multiple :- </p>

<pre><code>real    0m8.635s
user    0m8.608s
sys 0m0.003s
</code></pre>

<p>single :- </p>

<pre><code>real    0m10.072s
user    0m10.045s
sys 0m0.001s
</code></pre>

<p>On the other hand, if in multiple.cpp I invert the order of class derivation thus :- </p>

<pre><code>class B : public dummy, public A {
</code></pre>

<p>Then I get the following timings (which is slightly slower than that for single inheritance as one might expect thanks to 'thunk' adjustments to the this pointer that the code would need to do) :- </p>

<pre><code>real    0m11.516s
user    0m11.479s
sys 0m0.002s
</code></pre>

<p>Any idea why this may be happening? There doesn't seem to be any difference in the assembly generated for all three cases as far as the loop is concerned. Is there some other place that I need to look at? </p>

<p>Also, I have bound the process to a specific cpu core and I am running it on a real-time priority with SCHED_RR. </p>

<p>EDIT:- This was noticed by Mysticial and reproduced by me.
Doing a </p>

<pre><code>cout &lt;&lt; ""vtable: "" &lt;&lt; *(void**)obj &lt;&lt; endl;
</code></pre>

<p>just before the loop in single.cpp leads to single also being as fast as multiple clocking in at 8.4 s just like public A, public dummy. </p>
","922184","","<p><strong>Note, this answer is highly speculative.</strong></p>

<p>Unlike some of my other answers to questions of the type ""Why is X slower than Y"", I've been unable to provide solid evidence to backup this answer.</p>

<hr>

<p>After tinkering with this for about an hour now, I think it's due to the address alignment of three things:</p>

<ul>
<li>The address of <code>obj</code></li>
<li>The address of the <a href=""http://en.wikipedia.org/wiki/Virtual_method_table"">Virtual Method Table</a> of <code>A</code></li>
<li>The address of function <code>f()</code></li>
</ul>

<p>(<a href=""http://stackoverflow.com/a/10484790/922184"">owagh's answer</a> also hints at the possibility of instruction alignment.)</p>

<p>The reason why multiple inheritance is slower than the single inheritance is not because it is ""magically"" fast, but because the single inheritance case is running into either a compiler or a hardware ""hiccup"".</p>

<hr>

<p>If you dump out the assembly for the single and multiple inheritance cases, they are identical (register names and everything) within the nested loop.</p>

<p>Here's the code I compiled:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
using namespace std;
unsigned long a=0;


#ifdef SINGLE
class A {
  public:
    virtual int f() { return a; } 
};

class B : public A {
  public:
    virtual int f() { return a; }                                      
    void g() { return; }                                               
};       
#endif

#ifdef MULTIPLE
class A {
  public:
    virtual int f() { return a; }
};

class dummy {
  public:
    virtual void g() { return; }
};

class B : public A, public dummy {
  public:
    virtual int f() { return a; }
    virtual void g() { return; }
};
#endif

int main() {
    cin &gt;&gt; a;
    A* obj;
    if (a &gt; 3)
        obj = new B();
    else
        obj = new A();

    unsigned long result = 0;


    clock_t time0 = clock();

    for (int i=0; i&lt;65535; i++) {
        for (int j=0; j&lt;65535; j++) {
            result += obj-&gt;f();
        }
    }      

    clock_t time1 = clock();   
    cout &lt;&lt; (double)(time1 - time0) / CLOCKS_PER_SEC &lt;&lt; endl;    

    cout &lt;&lt; result &lt;&lt; ""\n"";
    system(""pause"");  //  This is useless in Linux, but I left it here for a reason.
}
</code></pre>

<p>The assembly for the nested loop is <strong><em>identical in both single and multiple inheritance cases:</em></strong></p>

<pre><code>.L5:
    call    clock
    movl    $65535, %r13d
    movq    %rax, %r14
    xorl    %r12d, %r12d
    .p2align 4,,10
    .p2align 3
.L6:
    movl    $65535, %ebx
    .p2align 4,,10
    .p2align 3
.L7:
    movq    0(%rbp), %rax
    movq    %rbp, %rdi
    call    *(%rax)
    cltq
    addq    %rax, %r12
    subl    $1, %ebx
    jne .L7
    subl    $1, %r13d
    jne .L6
    call    clock
</code></pre>

<p>Yet the performance difference I see is:</p>

<ul>
<li>Single: <strong>9.4 seconds</strong></li>
<li>Multiple: <strong>8.06 seconds</strong></li>
</ul>

<p>Xeon X5482, Ubuntu, GCC 4.6.1 x64.</p>

<p>This leads me to the conclusion that the difference must be data dependent.</p>

<p>If you look at that assembly, you'll notice that the only instructions that could have variable latency are the loads:</p>

<pre><code>    ; %rbp = vtable

movq    0(%rbp), %rax   ; Dereference function pointer from vtable
movq    %rbp, %rdi
call    *(%rax)         ; Call function pointer - f()
</code></pre>

<p>followed by a few more memory accesses inside the call the <code>f()</code>.</p>

<hr>

<p>It just happens to be that in the single inheritance example, the offsets of the aforementioned values are not favorable to the processor. I have no idea why. <strike>But I had to suspect something, it'd be cache-bank conflicts in a similar manner to <a href=""http://stackoverflow.com/questions/8547778/why-is-one-loop-so-much-slower-than-two-loops"">region 2 in the diagram of this question</a>.</strike></p>

<p>By rearranging the code and adding dummy functions, I can change these offsets - which in a lot of cases will eliminate this slow down and make the single inheritance as fast as the multiple inheritance case.</p>

<hr>

<p>For example, removing the <code>system(""pause"")</code> inverts the times:</p>

<pre><code>#ifdef SINGLE
class A {
  public:
    virtual int f() { return a; } 
};

class B : public A {
  public:
    virtual int f() { return a; }                                      
    void g() { return; }                                               
};       
#endif

#ifdef MULTIPLE
class A {
  public:
    virtual int f() { return a; }
};

class dummy {
  public:
    virtual void g() { return; }
};

class B : public A, public dummy {
  public:
    virtual int f() { return a; }
    virtual void g() { return; }
};
#endif

int main() {
    cin &gt;&gt; a;
    A* obj;
    if (a &gt; 3)
        obj = new B();
    else
        obj = new A();

    unsigned long result = 0;


    clock_t time0 = clock();

    for (int i=0; i&lt;65535; i++) {
        for (int j=0; j&lt;65535; j++) {
            result += obj-&gt;f();
        }
    }      

    clock_t time1 = clock();   
    cout &lt;&lt; (double)(time1 - time0) / CLOCKS_PER_SEC &lt;&lt; endl;    

    cout &lt;&lt; result &lt;&lt; ""\n"";
//    system(""pause"");
}
</code></pre>

<ul>
<li>Single: <strong>8.06 seconds</strong></li>
<li>Multiple: <strong>9.4 seconds</strong></li>
</ul>
"
"<p>I'm implementing the producer/consumer problem for homework, and I have to compare the sequential algorithm with the parallel one, and my parallel one seems to only be able to run either at the same speed or slower than the sequential one. I've come to the conclusion that using a queue is a limiting factor and it won't speed up my algorithm.</p>

<p>Is this the case or am I just coding it wrong?</p>

<pre><code>int main() {
    long sum = 0;
    unsigned long serial = ::GetTickCount();
    for(int i = 0; i &lt; test; i++){
        enqueue(rand()%54354);
        sum+= dequeue(); 
    }
    printf(""%d \n"",sum);

    serial = (::GetTickCount() - serial);
    printf(""Serial Program took: %f seconds\n"", serial * .001);
    sum = 0;
    unsigned long omp = ::GetTickCount();

    #pragma omp parallel for num_threads(128) default(shared) 
    for(int i = 0; i &lt; test; i++){
        enqueue(rand()%54354);
        sum+= dequeue(); 

    }

    #pragma omp barrier //joins all threads
    omp = (::GetTickCount() - omp);
    printf(""%d \n"",sum);
    printf(""OpenMP Program took: %f seconds\n"", omp * .001);
    getchar();
}
</code></pre>
","922184","","<p><strong>Problem #1:</strong></p>

<p>You have <code>rand()</code> inside the parallel region.</p>

<p><strong><code>rand()</code> is not thread-safe.</strong> It uses global/static variables. So calling it concurrently from multiple threads will lead to unexpected (possibly undefined) behavior.</p>

<p>That aside, the data-races resulting from concurrent calls to <code>rand()</code> will lead to a lot of cache coherency stalls. This is likely the source of the slowdown.</p>

<hr>

<p><strong>Problem #2:</strong></p>

<p><strong>Is <code>enqueue()</code> and <code>dequeue()</code> thread-safe?</strong></p>

<p>If it isn't, then you need to fix that first. If it is, how are you synchronizing it?</p>

<p>If it's just a critical region that allows only one thread at a time to access the queue, then that kind of defeats the whole purpose of parallelism.</p>

<hr>

<p><strong>Problem #3:</strong></p>

<p>This line modifies the <code>sum</code> variable in each iteration:</p>

<pre><code>sum += dequeue(); 
</code></pre>

<p>Note that all the threads will be doing this concurrently. So you need to declare <code>sum</code> as a reduction variable.</p>
"
"<p>I am working on a very low level part of the application in which performance is critical.</p>

<p>While investigating the generated assembly, I noticed the following instruction:</p>

<pre><code>lea eax,[edx*8+8]
</code></pre>

<p>I am used to seeing additions when using memory references (e.g. [edx+4]), but this is the first time I see a multiplication.</p>

<ul>
<li>Does this mean that the x86 processor can perform simple multiplications in the lea instruction?</li>
<li>Does this multiplication have an impact on the number of cycles needed to execute the instruction?</li>
<li>Is the multiplication limited to powers of 2 (I would assume this is the case)?</li>
</ul>

<p>Thanks in advance.</p>
","922184","","<p>To expand on my comment and to answer the rest of the question...</p>

<p>Yes, it's limited to powers of two. (2, 4, and 8 specifically) So no multiplier is needed since it's just a shift. The point of it is to quickly generate an address from an index variable and a pointer - where the datatype is a simple 2, 4, or 8 byte word. (Though it's often abused for other uses as well.)</p>

<p>As for the number of cycles that are needed: According to <a href=""http://www.agner.org/optimize/instruction_tables.pdf"">Agner Fog's tables</a> it looks like the <code>lea</code> instruction is constant on some machines and variable on others.</p>

<p>On Sandy Bridge there's a 2-cycle penalty if it's ""complex or rip relative"". But it doesn't say what ""complex"" means... So we can only guess unless you do a benchmark.</p>
"
"<p>I'd like to find the ceiling of the square root of a very large number with GMP. In C, <code>ceil(sqrt(n))</code>. </p>

<p>The GMP square root for integers truncates the result, so the square root of 10 would be reported as 3. Floating point square root works as expected, but I need to take the next greatest integer. <code>mpf_get_d</code> rounds towards zero, but otherwise does what I want. How can I get the ceiling of the square root of a large number?</p>
","922184","","<p>Here's a quick-and-dirty trick:</p>

<pre><code>ceil( sqrt(n) ) = trunc_sqrt(n - 1) + 1
</code></pre>

<p>where <code>trunc_sqrt(n)</code> is GMP's integer square root function that you are currently using.</p>

<p>This should work for all integers <code>n &gt; 0</code>.</p>
"
"<p>I need to quickly compare two string on the machine with SSE4 support. How can I do it without writing assembler inserts?</p>

<p>Some wrappers like <code>long long bitmask = strcmp(char* a, char* b)</code> would be perfect.</p>
","922184","","<p>Instead of using inline assembly, you should use the Intel SSE intrinsics.</p>

<p>For string comparison, you'll need the SSE4.2 intrinsics:</p>

<p>Documentation is here:
<a href=""http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-6E9CFDF2-5DF6-42A4-B429-0E2CD441342E.htm"">http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-6E9CFDF2-5DF6-42A4-B429-0E2CD441342E.htm</a></p>
"
"<p>I have v1 and v2 versions of my software. v1 uses the registry to save settings, with lots of calls to GetProfileInt, etc.  v2 now uses an sqlite db to save settings.</p>

<p>We are currently developing both branches and are merging new features from v1 to the v2 branch.  We currently have to remember to update any registry calls to use the new config db and this has been missed a few times.</p>

<p>What I would like is to throw a compiler error if any of the GetProfile... or WriteProfile... functions are used in v2.</p>

<p>We're using C++ in Visual Studio 2010.  If there's nothing built in can I use the output from a script to throw a compiler error somehow?</p>
","922184","","<p>Promoting my comment to an answer:</p>

<p>You can use a macro to redefine them to something that won't compile:</p>

<pre><code>#define GetProfile  HAHA_Nice_try_This_will_not_compile!!!
</code></pre>

<p>The catch is that you need to make sure that it isn't (legitimately) called outside your code.<br>(So you should put the macro after all your includes.)</p>
"
"<pre><code>void test()
{

    unsigned char c;
    c = (~0)&gt;&gt;1 ;  
    printf(""c is %u\n"",c); 

}
</code></pre>

<p>It prints 255. I was expecting 127 as i was expecting the left most bit to be set to 0 after the right shift. Is this because my compiler is doing Right rotation?</p>
","922184","","<p>The literal <code>0</code> is of type <code>int</code>. Therefore the entire expression will be evaluated as type <code>int.</code></p>

<p>The expression:</p>

<pre><code>(~0) &gt;&gt; 1
</code></pre>

<p>evaluates as type <code>int</code>.</p>

<ul>
<li>Therefore <code>~0</code> is evaluating to <code>0xffffffff</code> (assuming 32-bit).</li>
<li>After the shift it becomes: <code>0x7fffffff</code>.</li>
</ul>

<p>When you store into <code>c</code> (which is <code>unsigned char</code>), it truncates to <code>0xff</code> which is <code>255</code>.</p>

<p>To get the <code>127</code> that you expected, you'll need to cast the <code>~0</code>:</p>

<pre><code>c = (unsigned char)(~0) &gt;&gt; 1;
</code></pre>

<hr>

<p><strong>Side Note:</strong> Even if we cast just the <code>0</code> to <code>unsigned char</code>, the result will still be <code>255</code>. This is because of implicit integer promotion. All intermediates that are smaller than <code>int</code> are promoted to <code>int</code>.</p>

<p>More Info: <a href=""https://www.securecoding.cert.org/confluence/display/seccode/INT02-C.+Understand+integer+conversion+rules"" rel=""nofollow"">https://www.securecoding.cert.org/confluence/display/seccode/INT02-C.+Understand+integer+conversion+rules</a></p>
"
"<p>Is there a function or any other way to calculate in C the logarithm of base <code>x</code>, where <code>x</code> is an integer variable of my program?</p>
","922184","","<p>C doesn't provide functions to compute logarithms of any bases other than <code>e</code> or <code>10</code>.</p>

<p>So just use math:</p>

<pre><code>logarithm of x base b = log(x)/log(b)
</code></pre>

<hr>

<p>If you'll be doing the logarithms over the same base repeatedly, you can precompute <code>1/log(b)</code>.<br>I wouldn't rely on the compiler being able to do this optimization for you.</p>
"
"<p>I have the following program. I wonder why it outputs -4 on the following 64 bit machine? Which of my assumptions went wrong ?</p>

<blockquote>
  <p>[Linux ubuntu 3.2.0-23-generic #36-Ubuntu SMP Tue Apr 10 20:39:51 UTC
  2012 x86_64 x86_64 x86_64 GNU/Linux]</p>
</blockquote>

<ol>
<li><p>In the above machine and gcc compiler, by default b should be pushed first and a second.
The stack grows downwards. So b should have higher address and a have lower address. So result should be positive. But I got -4. Can anybody explain this ?</p></li>
<li><p>The arguments are two chars occupying 2 bytes in the stack frame. But I saw the difference as 4 where as I am expecting 1. Even if somebody says it is because of alignment, then I am wondering a structure with 2 chars is not aligned at 4 bytes.</p></li>
</ol>

<blockquote>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;

void CompareAddress(char a, char b)
{
    printf(""Differs=%ld\n"", (intptr_t )&amp;b - (intptr_t )&amp;a);
}

int main()
{
    CompareAddress('a','b');
    return 0; 
}

/* Differs= -4 */
</code></pre>
</blockquote>
","922184","","<p>Here's my guess:</p>

<p>On Linux in x64, the <a href=""http://en.wikipedia.org/wiki/X86_calling_conventions"">calling convention</a> states that the first few parameters are passed by register.</p>

<p>So in your case, both <code>a</code> and <code>b</code> are passed by register rather than on the stack. However, since you take its address, the compiler will store it somewhere on the stack <strong><em>after</em></strong> the function is called.<br>(Not necessary in the downwards order.)</p>

<p>It's also possible that the function is just outright inlined.</p>

<p>In either case, the compiler makes temporary stack space to store the variables. Those can be in any order and subject to optimizations. So they may not be in any particular order that you might expect.</p>
"
"<p>Is there any implication for a Windows developer for NUMA supported CPU architecture if only one CPU is present?</p>
","922184","","<p>Comment -> Answer</p>

<p>As far as I know, there are no single-socket systems that are NUMA. The <a href=""http://en.wikipedia.org/wiki/POWER7"" rel=""nofollow"">IBM Power7</a> has a slightly NUMA L3 cache, but access to main memory is still uniform.</p>

<p>Many of the multi-socket motherboard systems are NUMA where each socket has its own bank of local and fast memory. You can choose to populate only one socket, but then it's no longer NUMA.</p>

<p>So no, if there's only CPU, then you don't need to worry about NUMA.</p>
"
"<p>I would like to make a little sample code in order to test the Open MP API.
I have made a three level For loop with a calcul in this.</p>

<p>The problem is that my result is wrong.</p>

<p>Here is my code :</p>

<pre><code>long value = 0;
#pragma omp parallel
{
#pragma omp for
for (int i=0;i&lt;=9999;i++)
{
    value += (M_PI * i * i -12,33 * M_PI)- M_PI;

    for (int j=0;j&lt;=888;j++)
    {
        value += (M_PI * j * i -12,33 * M_PI)- M_PI;

        for (int k=0;k&lt;=777;k++)
        {
            value += (M_PI * k * j -12,33 * M_PI)- M_PI;    
        }
    }
}
}    
</code></pre>

<p>My problem :</p>

<p>Without Open MP, the value of the <code>value</code> variable is : <code>191773766</code>
Whit Open MP, the value of the <code>value</code> variable is :    <code>1092397966</code></p>

<p>I think that is a synchronization problem, but how to solve this ?
I have read a lot about Open MP, but I don't find how solve it.</p>

<p>Thanks a lot,</p>

<p>Best regards,</p>
","922184","","<p>You're missing the <code>reduction(+:value)</code> clause.</p>

<pre><code>#pragma omp parallel reduction(+:value)  //  add reduction here
{
#pragma omp for
</code></pre>

<p>The reason why you need it is because you are sharing the <code>value</code> variable across all threads. So they asynchronously update it leading to a race condition. (You also get a performance hit from cache coherency.)</p>

<p>The <code>reduction(+:value)</code> clause tells the compile to create a separate instance of <code>value</code> for each thread and then sum them up at the end.</p>

<hr>

<p><strong>EDIT : Full code at OP's request.</strong></p>

<pre><code>int main() {

    double start = omp_get_wtime();

    long M_PI = 12;

    long value = 0;
#pragma omp parallel reduction(+:value)
{
#pragma omp for
for (int i=0;i&lt;=9999;i++)
{
    value += (M_PI * i * i -12,33 * M_PI)- M_PI;

    for (int j=0;j&lt;=888;j++)
    {
        value += (M_PI * j * i -12,33 * M_PI)- M_PI;

        for (int k=0;k&lt;=777;k++)
        {
            value += (M_PI * k * j -12,33 * M_PI)- M_PI;    
        }
    }
}
}    
    double end = omp_get_wtime();
    printf(""\n\nseconds = %f\n"",end - start);

    cout &lt;&lt; value &lt;&lt; endl;

    system(""pause"");
    return 0;
}
</code></pre>

<p><strong>Output: (without OpenMP)</strong></p>

<pre><code>seconds = 0.007816
738123776
</code></pre>

<p><strong>Output: (with OpenMP - 8 threads)</strong></p>

<pre><code>seconds = 0.012784
738123776
</code></pre>

<p>If you want any speedup, you need to make the task <em>much</em> larger.</p>
"
"<p>I am writing simple parallel program in C++ using OpenMP.
I am working on Windows 7 and on Microsoft Visual Studio 2010 Ultimate.
I changed the Language property of the project to ""Yes/OpenMP"" to support OpenMP</p>

<p>Here I provide the code:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;omp.h&gt; 

using namespace std;

double sum; 
int i;
int n = 800000000;

int main(int argc, char *argv[])
{               
    omp_set_dynamic(0);
    omp_set_num_threads(4); 

    sum = 0;    
    #pragma omp for reduction(+:sum)
    for (i = 0; i &lt; n; i++)
        sum+= i/(n/10);

    cout&lt;&lt;""sum=""&lt;&lt;sum&lt;&lt;endl;        

    return  EXIT_SUCCESS;
}
</code></pre>

<p>But, I couldn't get any acceleration by changing the <code>x</code> in <code>omp_set_num_threads(x);</code>
It doesn't matter if I use OpenMp or not, the calculating time is the same, about 7 seconds.</p>

<p>Does Someone know what is the problem?</p>
","922184","","<p>Your <code>pragma</code> statement is missing the <code>parallel</code> specifier:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;omp.h&gt; 

using namespace std;

double sum; 
int i;
int n = 800000000;

int main(int argc, char *argv[])
{               
    omp_set_dynamic(0);
    omp_set_num_threads(4); 

    sum = 0;    
    #pragma omp parallel for reduction(+:sum)  //  add ""parallel""
    for (i = 0; i &lt; n; i++)
        sum+= i/(n/10);

    cout&lt;&lt;""sum=""&lt;&lt;sum&lt;&lt;endl;        

    return  EXIT_SUCCESS;
}
</code></pre>

<p><strong>Sequential:</strong> </p>

<pre><code>sum=3.6e+009
2.30071
</code></pre>

<p><strong>Parallel:</strong></p>

<pre><code>sum=3.6e+009
0.618365
</code></pre>

<hr>

<p>Here's a version that some speedup with Hyperthreading. I had to increase the # of iterations by 10x and bump the datatypes to <code>long long</code>:</p>

<pre><code>double sum; 
long long i;
long long n = 8000000000;

int main(int argc, char *argv[])
{               
    omp_set_dynamic(0);
    omp_set_num_threads(8); 

    double start = omp_get_wtime();


    sum = 0;    
    #pragma omp parallel for reduction(+:sum)
    for (i = 0; i &lt; n; i++)
        sum+= i/(n/10);

    cout&lt;&lt;""sum=""&lt;&lt;sum&lt;&lt;endl;       

    double end = omp_get_wtime(); 
    cout &lt;&lt; end - start &lt;&lt; endl;
    system(""pause"");

    return  EXIT_SUCCESS;
}
</code></pre>

<p><strong>Threads: 1</strong></p>

<pre><code>sum=3.6e+014
13.0541
</code></pre>

<p><strong>Threads: 2</strong></p>

<pre><code>sum=3.6e+010
6.62345
</code></pre>

<p><strong>Threads: 4</strong></p>

<pre><code>sum=3.6e+010
3.85687
</code></pre>

<p><strong>Threads: 8</strong></p>

<pre><code>sum=3.6e+010
3.285
</code></pre>
"
"<p>Something like this:    </p>

<pre><code>__m128 a = _mm_set_ps(1,2,3,4);
__m128 b = _mm_set_ps(5,6,7,8);
</code></pre>

<p>to something like:</p>

<pre><code>__m256 c (1,2,3,4,5,6,7,8)
</code></pre>

<p>are there any intrinsics that I can use to do this?</p>
","922184","","<p>This should do what you want:</p>

<pre><code>__m128 a = _mm_set_ps(1,2,3,4);
__m128 b = _mm_set_ps(5,6,7,8);

__m256 c = _mm256_castps128_ps256(a);
c = _mm256_insertf128_ps(c,b,1);
</code></pre>

<p>If the order is reversed from what you want, then just switch <code>a</code> and <code>b</code>.</p>

<hr>

<p>The intrinsic of interest is <code>_mm256_insertf128_ps</code> which will let you insert a 128-bit register into either lower or upper half of a 256-bit AVX register:</p>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_avx_insertf128_ps.htm"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_avx_insertf128_ps.htm</a></p>

<p>The complete family of them is here:</p>

<ul>
<li><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_avx_insertf128_pd.htm""><code>_mm256_insertf128_pd()</code></a></li>
<li><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_avx_insertf128_ps.htm""><code>_mm256_insertf128_ps()</code></a></li>
<li><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_avx_insertf128_si256.htm""><code>_mm256_insertf128_si256()</code></a></li>
</ul>
"
"<p>The code without fission looks like this:</p>

<pre><code>int check(int * res, char * map, int n, int * keys){
    int ret = 0;
    for(int i = 0; i &lt; n; ++i){
        res[ret] = i;
        ret += map[hash(keys[i])]
    }
    return ret;
}
</code></pre>

<p>With fission:</p>

<pre><code>int check(int * res, char * map, int n, int * keys){
    int ret = 0;
    for(int i = 0; i &lt; n; ++i){
        tmp[i] = map[hash(keys[i])];
    }
    for(int i = 0; i &lt; n; ++i){
        res[ret] = i;
        ret += tmp[i];
    }
    return ret;
}
</code></pre>

<p>Notes:</p>

<ul>
<li><p>The bottleneck is <code>map[hash(keys[i])]</code> which accesses memory randomly.</p></li>
<li><p>normally, it would be <code>if(tmp[i]) res[ret++] = i;</code> to avoid the if, I'm using <code>ret += tmp[i]</code>.</p></li>
<li><p><code>map[..]</code> is always 0 or 1</p></li>
</ul>

<p>The fission version is usually significantly faster and I am trying to explain why. My best guess is that <code>ret += map[..]</code> still introduces some dependency and that prevents speculative execution.</p>

<p>I would like to hear if anyone has a better explanation.</p>
","922184","","<p>From my tests, I get roughly 2x speed difference between the fused and split loops. This speed difference is very consistent no matter how I tweak the loop.</p>

<pre><code>Fused: 1.096258 seconds
Split: 0.562272 seconds
</code></pre>

<p>(Refer to bottom for the full test code.)</p>

<hr>

<p>Although I'm not 100% sure, I suspect that this is due to a combination of two things:</p>

<ol>
<li>Saturation of the load-store buffer for <a href=""http://en.wikipedia.org/wiki/Memory_disambiguation"">memory disambigutation</a> due to the cache misses from <code>map[gethash(keys[i])]</code>.</li>
<li>An added dependency in the fused loop version.</li>
</ol>

<p>It's obvious that <code>map[gethash(keys[i])]</code> will result in a cache miss nearly every time. In fact, it is probably enough to saturate the entire load-store buffer.</p>

<p>Now let's look at the added dependency. The issue is the <code>ret</code> variable:</p>

<pre><code>int check_fused(int * res, char * map, int n, int * keys){
    int ret = 0;
    for(int i = 0; i &lt; n; ++i){
        res[ret] = i;
        ret += map[gethash(keys[i])];
    }
    return ret;
}
</code></pre>

<p>The <code>ret</code> variable is <strong><em>needed for address resolution</em></strong> of the the store <code>res[ret] = i;</code>.</p>

<ul>
<li>In the fused loop, <code>ret</code> is coming from a sure cache miss.</li>
<li>In the split loop, <code>ret</code> is coming <code>tmp[i]</code> - which is much faster.</li>
</ul>

<p>This delay in address resolution of the fused loop case likely causes <code>res[ret] = i</code> to store to clog up the load-store buffer along with <code>map[gethash(keys[i])]</code>.</p>

<p>Since the load-store buffer has a fixed size, but you have double the junk in it:<br><strong>You are only able to overlap the cache misses half as much as before.</strong> Thus 2x slow-down.</p>

<hr>

<p><strong>Suppose if we changed the fused loop to this:</strong></p>

<pre><code>int check_fused(int * res, char * map, int n, int * keys){
    int ret = 0;
    for(int i = 0; i &lt; n; ++i){
        res[i] = i;    //  Change ""res"" to ""i""
        ret += map[gethash(keys[i])];
    }
    return ret;
}
</code></pre>

<p>This will break the address resolution dependency.</p>

<p><sup>(Note that it's not the same anymore, but it's just to demonstrate the performance difference.)</sup></p>

<p>Then we get similar timings:</p>

<pre><code>Fused: 0.487477 seconds
Split: 0.574585 seconds
</code></pre>

<hr>

<p><strong>Here's the complete test code:</strong></p>

<pre><code>#define SIZE 67108864

unsigned gethash(int key){
    return key &amp; (SIZE - 1);
}

int check_fused(int * res, char * map, int n, int * keys){
    int ret = 0;
    for(int i = 0; i &lt; n; ++i){
        res[ret] = i;
        ret += map[gethash(keys[i])];
    }
    return ret;
}
int check_split(int * res, char * map, int n, int * keys, int *tmp){
    int ret = 0;
    for(int i = 0; i &lt; n; ++i){
        tmp[i] = map[gethash(keys[i])];
    }
    for(int i = 0; i &lt; n; ++i){
        res[ret] = i;
        ret += tmp[i];
    }
    return ret;
}


int main()
{
    char *map = (char*)calloc(SIZE,sizeof(char));
    int *keys =  (int*)calloc(SIZE,sizeof(int));
    int *res  =  (int*)calloc(SIZE,sizeof(int));
    int *tmp  =  (int*)calloc(SIZE,sizeof(int));
    if (map == NULL || keys == NULL || res == NULL || tmp == NULL){
        printf(""Memory allocation failed.\n"");
        system(""pause"");
        return 1;
    }

    //  Generate Random Data
    for (int i = 0; i &lt; SIZE; i++){
        keys[i] = (rand() &amp; 0xff) | ((rand() &amp; 0xff) &lt;&lt; 16);
    }

    printf(""Start...\n"");

    double start = omp_get_wtime();
    int ret;

    ret = check_fused(res,map,SIZE,keys);
//    ret = check_split(res,map,SIZE,keys,tmp);

    double end = omp_get_wtime();

    printf(""ret = %d"",ret);
    printf(""\n\nseconds = %f\n"",end - start);

    system(""pause"");
}
</code></pre>
"
"<p>The SSE shift instructions I have found can only shift by the same amount on all the elements:</p>

<ul>
<li><code>_mm_sll_epi32()</code></li>
<li><code>_mm_slli_epi32()</code></li>
</ul>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse2_int_shift.htm"" rel=""nofollow"">These shift all elements, but by the same shift amount.</a></p>

<p>Is there a way to apply different shifts to the different elements? Something like this:</p>

<pre><code>__m128i a,  __m128i b;  

r0:=    a0  &lt;&lt;  b0;
r1:=    a1  &lt;&lt;  b1;
r2:=    a2  &lt;&lt;  b2;
r3:=    a3  &lt;&lt;  b3;
</code></pre>
","922184","","<p>There exists the <code>_mm_shl_epi32()</code> intrinsic that does exactly that.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/gg445138.aspx"">http://msdn.microsoft.com/en-us/library/gg445138.aspx</a></p>

<p><strong>However, it requires the <a href=""http://en.wikipedia.org/wiki/XOP_instruction_set"">XOP instruction set</a></strong>. Only AMD Bulldozer and Interlagos processors or later have this instruction. It is not available on any Intel processor.</p>

<p>If you want to do it without XOP instructions, you will need to do it the hard way: Pull them out and do them one by one.</p>

<p>Without XOP instructions, you can do this with SSE4.1 using the following intrinsics:</p>

<ul>
<li><code>_mm_insert_epi32()</code></li>
<li><code>_mm_extract_epi32()</code></li>
</ul>

<p><a href=""http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse41_reg_ins_ext.htm"">http://software.intel.com/sites/products/documentation/studio/composer/en-us/2011/compiler_c/intref_cls/common/intref_sse41_reg_ins_ext.htm</a></p>

<p>Those will let you extract parts of a 128-bit register into regular registers to do the shift and put them back.</p>

<p>If you go with the latter method, it'll be horrifically inefficient. That's why <code>_mm_shl_epi32()</code> exists in the first place.</p>
"
"<p>Something like this:</p>

<pre><code>_declspec(align(16)) float dens[4];

//Here the code comes. F32vec4 S_START, Pos, _Vector

*((__m128*)dens) = (S_START - Pos) *_Vector;

float steps = max(max(dens[3], dens[2]), max(dens[1], dens[0]));
</code></pre>

<p>How do I do this directly using SSE?</p>
","922184","","<p>There's no easy way to do this. SSE isn't particularly meant for horizontal operations. So you have to shuffle...</p>

<p>Here's one approach:</p>

<pre><code>__m128 a = _mm_set_ps(10,9,7,8);

__m128 b = _mm_shuffle_ps(a,a,78);  //  {a,b,c,d} -&gt; {c,d,a,b}
a = _mm_max_ps(a,b);

b = _mm_shuffle_ps(a,a,177);        //  {a,b,c,d} -&gt; {b,a,d,c}
a = _mm_max_ss(a,b);

float out;
_mm_store_ss(&amp;out,a);
</code></pre>

<p>I note that the final store isn't really supposed to be a store. It's just a hack to get the value into the <code>float</code> datatype.</p>

<p>In reality no instruction is needed because <code>float</code> types will be stored in the same SSE registers. (It's just that the top 3 values are ignored.)</p>
"
"<p>Here is a piece of <strong>C++</strong> code that seems very peculiar. For some strange reason, sorting the data miraculously makes the code almost six times faster:</p>

<pre class=""lang-cpp prettyprint-override""><code>#include &lt;algorithm&gt;
#include &lt;ctime&gt;
#include &lt;iostream&gt;

int main()
{
    // Generate data
    const unsigned arraySize = 32768;
    int data[arraySize];

    for (unsigned c = 0; c &lt; arraySize; ++c)
        data[c] = std::rand() % 256;

    // !!! With this, the next loop runs faster
    std::sort(data, data + arraySize);

    // Test
    clock_t start = clock();
    long long sum = 0;

    for (unsigned i = 0; i &lt; 100000; ++i)
    {
        // Primary loop
        for (unsigned c = 0; c &lt; arraySize; ++c)
        {
            if (data[c] &gt;= 128)
                sum += data[c];
        }
    }

    double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC;

    std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl;
    std::cout &lt;&lt; ""sum = "" &lt;&lt; sum &lt;&lt; std::endl;
}
</code></pre>

<ul>
<li>Without <code>std::sort(data, data + arraySize);</code>, the code runs in <strong>11.54</strong> seconds.</li>
<li>With the sorted data, the code runs in <strong>1.93</strong> seconds.</li>
</ul>

<hr>

<p>Initially, I thought this might be just a language or compiler anomaly.  </p>

<p>So I tried it in <strong>Java</strong>:</p>

<pre class=""lang-java prettyprint-override""><code>import java.util.Arrays;
import java.util.Random;

public class Main
{
    public static void main(String[] args)
    {
        // Generate data
        int arraySize = 32768;
        int data[] = new int[arraySize];

        Random rnd = new Random(0);
        for (int c = 0; c &lt; arraySize; ++c)
            data[c] = rnd.nextInt() % 256;

        // !!! With this, the next loop runs faster
        Arrays.sort(data);

        // Test
        long start = System.nanoTime();
        long sum = 0;

        for (int i = 0; i &lt; 100000; ++i)
        {
            // Primary loop
            for (int c = 0; c &lt; arraySize; ++c)
            {
                if (data[c] &gt;= 128)
                    sum += data[c];
            }
        }

        System.out.println((System.nanoTime() - start) / 1000000000.0);
        System.out.println(""sum = "" + sum);
    }
}
</code></pre>

<p>With a somewhat similar, but less extreme result.</p>

<hr>

<p>My first thought was that sorting brings the data into the cache, but my next thought was how silly that is, because the array was just generated.</p>

<ul>
<li>What is going on? </li>
<li>Why is a sorted array faster than an unsorted array? </li>
<li>The code is summing up some independent terms, and the order should not matter. </li>
</ul>
","922184","","<p><strong>You are the victim of <a href=""//en.wikipedia.org/wiki/Branch_predictor"">branch prediction</a> fail.</strong></p>

<hr>

<h2>What is Branch Prediction?</h2>

<p>Consider a railroad junction:</p>

<p><a href=""//commons.wikimedia.org/wiki/File:Entroncamento_do_Transpraia.JPG""><img src=""//i.stack.imgur.com/muxnt.jpg"" alt=""""></a>
<sub><a href=""//commons.wikimedia.org/wiki/File:Entroncamento_do_Transpraia.JPG"">Image</a> by Mecanismo, via Wikimedia Commons. Used under the <a href=""//creativecommons.org/licenses/by-sa/3.0/deed.en"">CC-By-SA 3.0</a> license.</sub></p>

<p>Now for the sake of argument, suppose this is back in the 1800s - before long distance or radio communication.</p>

<p>You are the operator of a junction and you hear a train coming. You have no idea which way it will go. You stop the train to ask the captain which direction he wants. And then you set the switch appropriately.</p>

<p><em>Trains are heavy and have a lot of inertia. So they take forever to start up and slow down.</em></p>

<p>Is there a better way? You guess which direction the train will go!</p>

<ul>
<li>If you guessed right, it continues on.</li>
<li>If you guessed wrong, the captain will stop, back up, and yell at you to flip the switch. Then it can restart down the other path.</li>
</ul>

<p><strong>If you guess right every time</strong>, the train will never have to stop.<br>
<strong>If you guess wrong too often</strong>, the train will spend a lot of time stopping, backing up, and restarting.</p>

<hr>

<p><strong>Consider an if-statement:</strong> At the processor level, it is a branch instruction:</p>

<p><img src=""//i.stack.imgur.com/pyfwC.png"" alt=""enter image description here""></p>

<p>You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.</p>

<p><em>Modern processors are complicated and have long pipelines. So they take forever to ""warm up"" and ""slow down"".</em></p>

<p>Is there a better way? You guess which direction the branch will go!</p>

<ul>
<li>If you guessed right, you continue executing.</li>
<li>If you guessed wrong, you need to flush the pipeline and roll back to the branch. Then you can restart down the other path.</li>
</ul>

<p><strong>If you guess right every time</strong>, the execution will never have to stop.<br>
<strong>If you guess wrong too often</strong>, you spend a lot of time stalling, rolling back, and restarting.</p>

<hr>

<p>This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.</p>

<p>So how would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every 3 times, you guess the same...</p>

<p><strong><em>In other words, you try to identify a pattern and follow it.</em></strong> This is more or less how branch predictors work.</p>

<p>Most applications have well-behaved branches. So modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.</p>

<p>Further reading: <a href=""//en.wikipedia.org/wiki/Branch_predictor"">""Branch predictor"" article on Wikipedia</a>.</p>

<hr>

<h2>As hinted from above, the culprit is this if-statement:</h2>

<pre><code>if (data[c] &gt;= 128)
    sum += data[c];
</code></pre>

<p>Notice that the data is evenly distributed between 0 and 255. 
When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.</p>

<p>This is very friendly to the branch predictor since the branch consecutively goes the same direction many times.
Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.</p>

<p><strong>Quick visualization:</strong></p>

<pre><code>T = branch taken
N = branch not taken

data[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...
branch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...

       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)
</code></pre>

<p>However, when the data is completely random, the branch predictor is rendered useless because it can't predict random data.
Thus there will probably be around 50% misprediction. (no better than random guessing)</p>

<pre><code>data[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, 133, ...
branch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T,   N  ...

       = TTNTTTTNTNNTTTN ...   (completely random - hard to predict)
</code></pre>

<hr>

<p><strong>So what can be done?</strong></p>

<p>If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.</p>

<p>Replace:</p>

<pre><code>if (data[c] &gt;= 128)
    sum += data[c];
</code></pre>

<p>with:</p>

<pre><code>int t = (data[c] - 128) &gt;&gt; 31;
sum += ~t &amp; data[c];
</code></pre>

<p>This eliminates the branch and replaces it with some bitwise operations.</p>

<p><sub>(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of <code>data[]</code>.)</sub></p>

<p><strong>Benchmarks: Core i7 920 @ 3.5 GHz</strong></p>

<p>C++ - Visual Studio 2010 - x64 Release</p>

<pre><code>//  Branch - Random
seconds = 11.777

//  Branch - Sorted
seconds = 2.352

//  Branchless - Random
seconds = 2.564

//  Branchless - Sorted
seconds = 2.587
</code></pre>

<p>Java - Netbeans 7.1.1 JDK 7 - x64</p>

<pre><code>//  Branch - Random
seconds = 10.93293813

//  Branch - Sorted
seconds = 5.643797077

//  Branchless - Random
seconds = 3.113581453

//  Branchless - Sorted
seconds = 3.186068823
</code></pre>

<p>Observations:</p>

<ul>
<li><strong>With the Branch:</strong> There is a huge difference between the sorted and unsorted data.</li>
<li><strong>With the Hack:</strong> There is no difference between sorted and unsorted data.</li>
<li>In the C++ case, the hack is actually a tad slower than with the branch when the data is sorted.</li>
</ul>

<p>A general rule of thumb is to avoid data-dependent branching in critical loops. (such as in this example)</p>

<hr>

<p><strong>Update :</strong></p>

<ul>
<li><p>GCC 4.6.1 with <code>-O3</code> or <code>-ftree-vectorize</code> on x64 is able to generate a conditional move. So there is no difference between the sorted and unsorted data - both are fast.</p></li>
<li><p>VC++ 2010 is unable to generate conditional moves for this branch even under <code>/Ox</code>.</p></li>
<li><p>Intel Compiler 11 does something miraculous. It <a href=""//en.wikipedia.org/wiki/Loop_interchange"">interchanges the two loops</a>, thereby hoisting the unpredictable branch to the outer loop. So not only is it immune the mispredictions, it is also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...</p></li>
<li><p>If you give the Intel Compiler the branchless code, it just out-right vectorizes it... and is just as fast as with the branch (with the loop interchange).</p></li>
</ul>

<p>This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...</p>
"
"<p>I am trying to improve this code with the SSE4 dot product but I am having a hard time finding a solution. This function gets the parameters qi and tj which contain float arrays with  80 cell each and then calculate the dot product. The return value is a vector with four dot products. So I what I'm trying to do is calculating four dot products of twenty values in parallel. </p>

<p>Have you any idea how to improve this code?</p>

<pre><code>inline __m128 ScalarProd20Vec(__m128* qi, __m128* tj)
{
    __m128 res=_mm_add_ps(_mm_mul_ps(tj[0],qi[0]),_mm_mul_ps(tj[1],qi[1]));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[2],qi[2]),_mm_mul_ps(tj[3],qi[3])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[4],qi[4]),_mm_mul_ps(tj[5],qi[5])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[6],qi[6]),_mm_mul_ps(tj[7],qi[7])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[8],qi[8]),_mm_mul_ps(tj[9],qi[9])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[10],qi[10]),_mm_mul_ps(tj[11],qi[11])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[12],qi[12]),_mm_mul_ps(tj[13],qi[13])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[14],qi[14]),_mm_mul_ps(tj[15],qi[15])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[16],qi[16]),_mm_mul_ps(tj[17],qi[17])));
    res=_mm_add_ps(res,_mm_add_ps(_mm_mul_ps(tj[18],qi[18]),_mm_mul_ps(tj[19],qi[19])));
    return res;
}
</code></pre>
","922184","","<p>Of the hundreds of SSE examples I've seen on SO, your code is one of the few that's already in pretty good shape from the start. You don't need the SSE4 dot-product instruction. (You can do better!)</p>

<p><strong>However, there is one thing you can try:</strong> (I say try because I haven't timed it yet.)</p>

<p>Currently you have a data-dependency chain on <code>res</code>. Vector addition is 3-4 cycles on most machines today. So your code will take a minimum of 30 cycles to run since you have:</p>

<pre><code>(10 additions on critical path) * (3 cycles addps latency) = 30 cycles
</code></pre>

<p>What you can do is to node-split the <code>res</code> variable as follows:</p>

<pre><code>__m128 res0 = _mm_add_ps(_mm_mul_ps(tj[ 0],qi[ 0]),_mm_mul_ps(tj[ 1],qi[ 1]));
__m128 res1 = _mm_add_ps(_mm_mul_ps(tj[ 2],qi[ 2]),_mm_mul_ps(tj[ 3],qi[ 3]));

res0 = _mm_add_ps(res0,_mm_add_ps(_mm_mul_ps(tj[ 4],qi[ 4]),_mm_mul_ps(tj[ 5],qi[ 5]))); 
res1 = _mm_add_ps(res1,_mm_add_ps(_mm_mul_ps(tj[ 6],qi[ 6]),_mm_mul_ps(tj[ 7],qi[ 7])));

res0 = _mm_add_ps(res0,_mm_add_ps(_mm_mul_ps(tj[ 8],qi[ 8]),_mm_mul_ps(tj[ 9],qi[ 9])));
res1 = _mm_add_ps(res1,_mm_add_ps(_mm_mul_ps(tj[10],qi[10]),_mm_mul_ps(tj[11],qi[11])));

res0 = _mm_add_ps(res0,_mm_add_ps(_mm_mul_ps(tj[12],qi[12]),_mm_mul_ps(tj[13],qi[13])));
res1 = _mm_add_ps(res1,_mm_add_ps(_mm_mul_ps(tj[14],qi[14]),_mm_mul_ps(tj[15],qi[15])));

res0 = _mm_add_ps(res0,_mm_add_ps(_mm_mul_ps(tj[16],qi[16]),_mm_mul_ps(tj[17],qi[17])));
res1 = _mm_add_ps(res1,_mm_add_ps(_mm_mul_ps(tj[18],qi[18]),_mm_mul_ps(tj[19],qi[19])));

return _mm_add_ps(res0,res1);
</code></pre>

<p>This almost cuts your critical path in half. Note that because of floating-point non-associativity, this optimization is illegal for compilers to do.</p>

<hr>

<p>Here's an alternative version using 4-way node-splitting and AMD FMA4 instructions. If you can't use the fused-multiply adds, feel free to split them up. It might still be better than the first version above.</p>

<pre><code>__m128 res0 = _mm_mul_ps(tj[ 0],qi[ 0]);
__m128 res1 = _mm_mul_ps(tj[ 1],qi[ 1]);
__m128 res2 = _mm_mul_ps(tj[ 2],qi[ 2]);
__m128 res3 = _mm_mul_ps(tj[ 3],qi[ 3]);

res0 = _mm_macc_ps(tj[ 4],qi[ 4],res0);
res1 = _mm_macc_ps(tj[ 5],qi[ 5],res1);
res2 = _mm_macc_ps(tj[ 6],qi[ 6],res2);
res3 = _mm_macc_ps(tj[ 7],qi[ 7],res3);

res0 = _mm_macc_ps(tj[ 8],qi[ 8],res0);
res1 = _mm_macc_ps(tj[ 9],qi[ 9],res1);
res2 = _mm_macc_ps(tj[10],qi[10],res2);
res3 = _mm_macc_ps(tj[11],qi[11],res3);

res0 = _mm_macc_ps(tj[12],qi[12],res0);
res1 = _mm_macc_ps(tj[13],qi[13],res1);
res2 = _mm_macc_ps(tj[14],qi[14],res2);
res3 = _mm_macc_ps(tj[15],qi[15],res3);

res0 = _mm_macc_ps(tj[16],qi[16],res0);
res1 = _mm_macc_ps(tj[17],qi[17],res1);
res2 = _mm_macc_ps(tj[18],qi[18],res2);
res3 = _mm_macc_ps(tj[19],qi[19],res3);

res0 = _mm_add_ps(res0,res1);
res2 = _mm_add_ps(res2,res3);

return _mm_add_ps(res0,res2);
</code></pre>
"
"<p>So, a while back I read a joke that went something like this:</p>

<p>""Never compute pi in binary - because it goes on infinitely and is random, it theoretically contains every finite bit string. So, you will then possess all copyrighted material in existence and be liable for some serious fines.""</p>

<p>This is obviously meant to be humorous, but it got me thinking. If every finite bit string exists in a binary representation of pi, would it be possible to use this as a method of transmitting data?</p>

<p>For example, let's say I wanted to transmit a bit string that could be interpreted as an jpeg image. Instead of sending the information directly, I would find its location within the digits of pi, and simply send the location of the first bit within the digits of pi, as well as the lengths of the string.</p>

<p>This seems pretty straightforward to me, but the obvious hurtle here is that the probability of finding this string within even the first several trillion digits is remarkably small. So, it could end up taking an immense amount of time to find. </p>

<p>My thinking is that several machines could be dedicated to searching for large files within pi, and then creating an index of all of their start locations. So, each computation would only need to occur once and then that information could be transmitted extremely quickly from then on.</p>

<p>So, what do you think? Is this at all feasible, or would these computations take far too much time?</p>

<p>Thanks for reading! I apologize if I have overlooked any posting guidelines, this if my first question in this forum.</p>

<p>Cheers!</p>

<p>EDIT:</p>

<p>Thanks for your quick responses, folks! I figured there was error in my reasoning, nice to know why!</p>
","922184","","<p>Expanding on my comments. There's a very important concept here that's called <strong><a href=""http://en.wikipedia.org/wiki/Entropy_%28information_theory%29"">information entropy</a></strong>.</p>

<p>Out of full disclosure, I'm the current world record holder of the digits of Pi at 10 trillion digits (10^13).</p>

<p><strong>I have approximately 10,000 copies of everyone's <a href=""http://en.wikipedia.org/wiki/Social_Security_number"">social security number</a>.</strong></p>

<p>However that doesn't mean I can just hack into everyone's accounts and steal their identities. Because I don't know <strong><em>where</em></strong> each person's SSN starts. And for a typical 9-digit SSN, the first digit in Pi where that SSN will appear will be on the order of 9 digits long. In other words, the information about the SSN is kept in the <em>address</em> rather than in Pi itself.</p>

<hr>

<p>For example, if someone has the SSN: <strong>938-93-3556</strong></p>

<p>It starts at offset <strong>597,507,393</strong> in Pi. That number <code>597,507,393</code> is about as long as the SSN itself. In other words, we've gained nothing by using Pi.
<br>
<sub>(I'm not sure if there's an earlier offset where it appears, but the probability decreases exponentially with smaller offsets.)</sub></p>

<hr>

<p>To generalize this, even if you had infinite digits of Pi (which theoretically holds all possible information), the address that holds data XXX will (with extreme probability) be as large as XXX itself.</p>

<p>In other words, the information is not held in the digits of Pi itself, but rather the address where the information starts.</p>
"
"<p>I have tried to output following but got confused,</p>

<pre><code>    float f=3.4;
    char *cp;
    cp=(char *)&amp;f;
    printf(""%d\n"",*cp);
</code></pre>

<p>normalized number I have calculated IEEE 754 std is,</p>

<pre><code>0 10000000 10110011001100110011001
</code></pre>

<p>that's why I assumed at cp now value has,</p>

<pre><code>10011001
</code></pre>

<p>after convert to 2's complement,</p>

<pre><code>01100111
</code></pre>

<p>It should output -103 , but I got -102 in my bloodshed/DevC.
why such output???</p>
","922184","","<p>That's because <code>f</code> is being rounded up:</p>

<pre><code>3.4 = 10110011001100110011001 100110011001...  (repeating 1001)
</code></pre>

<p>rounds up to:</p>

<pre><code>3.4 = 10110011001100110011010
                            ^
</code></pre>

<p>when stored into single-precision floating-point.</p>

<p>Now when you extract out the last 8 bits, you're actually getting <code>10011010</code> instead of <code>10011001</code>.</p>

<p>Converting <code>10011010</code> -> <code>-102</code> instead of <code>-103</code>.</p>
"
"<h3>Can the compiler make automatic use of SSE2 while optimisations are disabled?</h3>

<h3>When optimisations are disabled, does the /arch:SSE2 flag mean anything?</h3>

<p>I've been given the task of squeezing more performance out of our software. Unfortunately, release builds are done using the debug settings, and attempts to argue for the case of optimisation have been unsuccessful so far.</p>

<p>Compiling for x86 with compiler flags <code>/ZI /Od /arch:SSE2 /FAs</code>. The generated assembly shows that the compiler is not making use of <code>SSE2</code>. Is this because optimisation is disabled?</p>

<p>In the code, there are a few situations similar to this:</p>

<pre><code>char* begin = &amp;bufferObject;
char* end   = begin + sizeof(bufferObject);
char  result;
while ( begin != end ) {
    result ^= *begin++;
}
</code></pre>

<p>I'd like to have the compiler vectorise this operation for me, but it doesn't; I suspect optimisation needs to be enabled.</p>

<p>I hand-coded two solutions: one using an inline <code>__asm</code> block, and the other using the SSE2 intrinsicts defined in <code>&lt;emmintrin.h&gt;</code>. I'd prefer not to rely on this.</p>

<h3>Update</h3>

<p>Further to the questions above, I would like calls to library functions, like <code>memcpy</code>, to use the provided vectorised versions when appropriate. Looking at the assembly code for <code>memcpy</code>, I can see that there is a function called <code>_VEC_memcpy</code> which makes use of <code>SSE2</code>  for faster copying. The block which decides whether to branch to this routine or not is this:</p>

<pre><code>    ; First, see if we can use a ""fast"" copy SSE2 routine
    ; block size greater than min threshold?
    cmp     ecx,080h
    jb      Dword_align
    ; SSE2 supported?
    cmp     DWORD PTR __sse2_available,0
    je      Dword_align
    ; alignments equal?
    push    edi
    push    esi
    and     edi,15
    and     esi,15
    cmp     edi,esi
    pop     esi
    pop     edi
    jne     Dword_align

    ; do fast SSE2 copy, params already set
    jmp     _VEC_memcpy
</code></pre>

<p>I don't think that <code>_VEC_memcpy</code> is being called... <em>ever</em>.</p>

<h3>Should the <code>/arch:SSE2</code> flag be defining this <code>__sse2_available</code> symbol?</h3>
","922184","","<p>Visual Studio 2010 and earlier has no support for automatic vectorization at all.</p>

<p>The purpose of <code>/arch:SSE2</code> is to allow the compiler to use scalar SSE for floating-point operations instead of the x87 FPU.</p>

<p>So you <em>may</em> get some speedup with <code>/arch:SSE2</code> since it allows you to access more registers on x64. But keep it mind that it is not from vectorization.</p>

<p>If you want vectorization on VS2010, you pretty much have to do it manually with intrinsics.</p>

<hr>

<p>Visual Studio 2012 has support for auto-vectorization:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/hh872235%28v=vs.110%29.aspx"">http://msdn.microsoft.com/en-us/library/hh872235%28v=vs.110%29.aspx</a></p>
"
"<pre><code>#include &lt;stdio.h&gt;

int main() {
    int *a[2]; // an array of 2 int pointers
    int (*b)[2];
    // pointer to an array of 2 int (invalid until assigned) //
    int c[2] = {1, 2}; // like b, but statically allocated

    printf(""size of int %ld\n"", sizeof(int));
    printf(""size of array of 2 (int *) a=%ld\n"", sizeof(a));
    printf(""size of ptr to an array of 2 (int) b=%ld\n"", sizeof(b));
    printf(""size of array of 2 (int) c=%ld\n"", sizeof(c));
    return 0;
}
</code></pre>

<p><code>a</code> is an array of 2 integer pointers, so shouldn't the size be <code>2 * 4 = 8</code>?</p>

<p>Tested on GCC.</p>
","922184","","<p>You're probably compiling on a 64-bit machine where pointers are 8 bytes.</p>

<p><code>int *a[2]</code> is an array of 2 pointers. Therefore <code>sizeof(a)</code> is returning 16.<br>
(So it has nothing to do with the size of an <code>int</code>.)</p>

<hr>

<p>If you compiled this for 32-bit, you'll mostly get <code>sizeof(a) == 8</code> instead.</p>
"
"<p>I've already gone through a bunch of threads on hear and a bunch of others I found on Google.  I still can't seem to get this right.</p>

<pre><code>//Room.h
#ifndef ROOM_H
#define ROOM_H

#include ""Door.h""

typedef struct {
   Door* doors[3];

} Room;

#endif

//Door.h
#ifndef DOOR_H
#define DOOR_H

#include ""Room.h""

typedef struct {
   Room* room1;
   Room* room2;
} Door;

//main.c
#include &lt;stdio.h&gt;
#include ""Room.h""
int main() { ... }
</code></pre>

<p>I already tried adding this to the top of Door.h</p>

<pre><code>typedef struct Room room1;
//typedef struct Room* room1;
//typedef stuct Room;
//typedef struct Room*;
</code></pre>

<p>All gave me this error:</p>

<p>""unknown type name ‘Room’""</p>

<p>I want to keep these structs separate header files.</p>
","922184","","<p>Try it like this:</p>

<pre><code>typedef struct Room Room;
typedef struct Door Door;

struct Room{
   Door* doors[3];
};

struct Door{
   Room* room1;
   Room* room2;
};
</code></pre>

<hr>

<p>The first two lines are the type declarations that will allow them to reference each other.</p>

<p>It won't matter how you separate these in the header files as long as the first two lines come first.</p>

<hr>

<p>In your case, they can be split as follows:</p>

<p><strong>room.h</strong></p>

<pre><code>typedef struct Door Door;

struct Room{
   Door* doors[3];
};
</code></pre>

<p><strong>door.h</strong></p>

<pre><code>typedef struct Room Room;

struct Door{
   Room* room1;
   Room* room2;
};
</code></pre>
"
"<pre><code>#include &lt;stdio.h&gt;

int main(){
    int a[4];
    int b[4],i;
    a[0] = 4;
    a[1] = 3;
    a[2] = 2;
    a[3] = 1;
    memcpy(&amp;b, &amp;a, sizeof(a));
    for (i = 0; i &lt; 4; i++){
        printf(""b[%d]:%d"",i,b[i]);
    }
    printf(""%d"",sizeof(b));
}
</code></pre>

<h2>ANS:</h2>

<pre><code>b[0]:4b[1]:3b[2]:2b[3]:116
Exited: ExitFailure 2
</code></pre>

<p>I'm getting the correct answers. But getting a exception as Exited: ExitFailure 2.</p>

<p>Is this way of copying the array datas using memcpy is wrong?</p>
","922184","","<p>Try adding a <code>return 0;</code> at the end of <code>main()</code>.</p>

<p>Omitting the return value is probably causing the function to return stack garbage. (that's not 0)</p>

<p>The test app/script is therefore complaining of failure when it sees a non-zero return value.</p>

<hr>

<p>Prior to C99, omitting the <code>return</code> statement is technically undefined behavior. Starting from C99, it will default to <code>0</code> if it is omitted.</p>

<p>More details here: <a href=""http://stackoverflow.com/questions/8677672/why-main-does-not-return-0-here"">Why main does not return 0 here?</a></p>
"
"<p>While using OpenMP threads, </p>

<ol>
<li><p>Each thread can declare its own set of private variables. Is it correct to assume, 
that fetching data, which are private to each thread, has lower latency than fetching data visible
to all threads. In other words, are the thread local variables <strong>cached</strong> ? </p></li>
<li><p>Say each thread, wants to use a thread private STL data container like <code>std::vector</code>. In    single threaded C++
code, data in the <code>std::vector</code> is stored on the heap. What about the multi-threaded case ?
Are the data of the thread-private std::vectors still stored on the heap ? </p></li>
</ol>
","922184","","<p>Unless you're using a NUMA machine, memory is uniform.</p>

<blockquote>
  <p>Is it correct to assume, that fetching data, which are private to each
  thread, has lower latency than fetching data visible to all threads.</p>
</blockquote>

<p>Thread-local storage isn't inherently ""faster"" than memory that is visible to all threads. However, memory that is only used by one thread is less likely to suffer from cache coherency effects - since it is only accessed by a single thread.</p>

<blockquote>
  <p>In other words, are the thread local variables cached?</p>
</blockquote>

<p>Not necessarily. And it definitely won't be the case if it doesn't fit in the CPU cache. It is also possible for shared data to be in the caches of multiple cores at the same time.</p>

<blockquote>
  <p>What about the multi-threaded case ? Are the data of the
  thread-private std::vectors still stored on the heap ?</p>
</blockquote>

<p>Yes, they will be in the heap regardless of the number of threads.</p>
"
"<p>I have tried to use restrict qualified pointers, and I have encountered a problem.
The program below is just a simple one only to present the problem.</p>

<p>The calc_function uses three pointers, which is restricted so they ""SHALL"" not alias with each other. When compiling this code in visual studio, the function will be inlined, so for no reason Visual Studio 2010 ignores the qualifiers. If I disable inlining, the code executes more then six times faster (from 2200ms to 360ms). But I do not want to disable inlining in the whole project nor the whole file (because then will it be call overheads in e.g. all getters and setters, which would be horrible).</p>

<p>(Might the only solution be to disable inlining of only this function?)</p>

<p>I have tried to create temporary restrict qualified pointers in the function, both at the top and in the inner loop to try to tell the compiler that I promise that there is no aliasing, but the compiler won't believe me, and it will not work.
I have also tried to tweaking compiler settings, but the only one that i have found that works, is to disable inlining.</p>

<p>I would appreciate some help to solve this optimization problem.</p>

<p>To run the program (in realeasemode) don't forget to use the arguments 0 1000 2000.
Why the use of userinput/program arguments is to be sure that the compiler can't know if there is or isn't aliasing between the pointers a, b and c.</p>

<pre><code>#include &lt;cstdlib&gt;
#include &lt;cstdio&gt;
#include &lt;ctime&gt;

// Data-table where a,b,c will point into, so the compiler cant know if they alias.
const size_t listSize = 10000;
int data[listSize];

//void calc_function(int * a, int * b, int * c){
void calc_function(int *__restrict a, int *__restrict b, int *__restrict c){
    for(size_t y=0; y&lt;1000*1000; ++y){  // &lt;- Extra loop to be able to messure the time.
        for(size_t i=0; i&lt;1000; ++i){
            *a += *b;
            *c += *a;
        }
    }
}
int main(int argc, char *argv[]){ // argv SHALL be ""0 1000 2000"" (with no quotes)
    // init
    for(size_t i=0; i&lt;listSize; ++i)
        data[i] = i;

    // get a, b and c from argv(0,1000,2000)
    int *a,*b,*c;
    sscanf(argv[1],""%d"",&amp;a);
    sscanf(argv[2],""%d"",&amp;b);
    sscanf(argv[3],""%d"",&amp;c);
    a = data + int(a);  // a, b and c will (after the specified argv) be,
    b = data + int(b);  // a = &amp;data[0], b = &amp;data[1000], c = &amp;data[2000],
    c = data + int(c);  // So they will not alias, and the compiler cant know.

    // calculate and take time
    time_t start = clock();
        funcResticted(a,b,c);
    time_t end = clock();
    time_t t = (end-start);
    printf(""funcResticted       %u (microSec)\n"", t);

    system(""PAUSE"");
    return EXIT_SUCCESS;
}
</code></pre>
","922184","","<p>If you declare a function with <code>__declspec(noinline)</code>, it will force it not to be inlined:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/kxybs02x%28v=vs.80%29.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/kxybs02x%28v=vs.80%29.aspx</a></p>

<p>You can use this to manually disable inlining on a per-function basis.</p>

<hr>

<p>As for <code>restrict</code>, the compiler is free to use it only when it wants to. So fiddling around with different versions of the same code is somewhat unavoidable when attempting to ""trick"" compilers to do such optimizations.</p>
"
"<p>Does VC++ 2010 Express not have std::thread? I am using the multi-threaded DLL. The compiler does not find the header file , nor does it recognize std::thread::hardware_concurrency. Is there some setting I need to fix, or is it just missing? (July 2012, latest and greatest.)</p>
","922184","","<p><code>std::thread</code> was added in C++11 which is still relatively recent.</p>

<p>VC++ 2010 doesn't support it. But VC++ 2012 should have it.</p>
"
"<p>I am learning about C pointers by creating various simple functions. I have just created a function to reverse a char array. It works, but after the output it also displays a bunch of garbage chars (see screenshot below).</p>

<p><img src=""http://i.stack.imgur.com/0qDoQ.png"" alt=""Screenshot""></p>

<p>Here's my code:</p>

<pre><code>void reverseString();

int main()
{
    reverseString();

    system(""PAUSE"");
    return 0;
}

void reverseString()
{
    char string1[20], string2[20];
    char *ptr1, *ptr2;
    ptr1 = &amp;string1[0];
    ptr2 = &amp;string2[0];

    printf(""Enter string: \n"");
    scanf(""%s"", string1);

    int len1 = strlen(string1);

    int i;
    for (i = 0; i &lt; len1; i++)
    {
        ptr2[i] = ptr1[len1 - i - 1];
    }

    printf(""%s\n"", string2);
}
</code></pre>

<p>How can I get rid of the garbage chars? Is there something wrong with my code or did I just nto account for something or what?</p>
","922184","","<p>You forgot to nul-terminate the new string:</p>

<pre><code>int i;
for (i = 0; i &lt; len1; i++)
{
    ptr2[i] = ptr1[len1 - i - 1];
}

//  Add this
ptr2[i] = '\0';
</code></pre>

<hr>

<p>When you print a <code>char*</code>, it will keep reading until it finds that nul character. But since you left it out, it kept going and going...</p>
"
"<p>So a question I often ask myself is:</p>

<p>Is there a way to safety and simply deal with angle wrap with the minimum number of case statements. </p>

<p>Angle wrap occurs when using a particular representation for angle (either 0-360 deg or -180 - 180 deg (or equivalent in radians)) and you wrap over the angle. For example say you have an angle of -170, and you subtract 50 deg. You mathematically add up to -220 but should actually be +140 deg.</p>

<p>Obviously you can check for this using:</p>

<pre><code>if (deg &lt; -180) { 180 - abs(deg + 180); }
</code></pre>

<p>or similar. But firstly you need multitudes of checks and secondly it doesn't work if you wrap twice. </p>

<p>I have heard of a good way to get around this using complex number multiplication/subtraction but I have not been able to find any evidence of it. </p>

<p>I would appreciate any methods that are suggested, what sort of things have people come up with to handle this very common problem?</p>

<p>Cheers</p>

<p>Ben</p>

<p>EDIT:</p>

<p>Thankyou @Mystical for your answer but I fear I have not made my purpose clear enough. </p>

<p>What i am trying to do on a larger scale is interpolate between two angles. </p>

<p>For Example, say i have an angle of -170 deg and 160 deg and i want halfway in between them. A common way to do this is ang1 + 0.5(ang2-ang1) but in the example i have provided it will cause the angle to be -5 deg when it should be 175.</p>

<p>If this is not angle wrap let me know but this is the issue i am trying to solve. Now i am led to believe there is a method where you use polar complex numbers to add and subtract (using multiply and divide in complex space) the angles. Does anyone know about this method?</p>
","922184","","<p>For completeness I'll include both <code>[0, 360)</code> and <code>[-180, 180)</code> normalizations.</p>

<p>You will need <code>#include &lt;math.h&gt;</code>.</p>

<hr>

<p><strong>Normalize to <code>[0,360)</code>:</strong></p>

<pre><code>double constrainAngle(double x){
    x = fmod(x,360);
    if (x &lt; 0)
        x += 360;
    return x;
}
</code></pre>

<p><strong>Normalize to <code>[-180,180)</code>:</strong></p>

<pre><code>double constrainAngle(double x){
    x = fmod(x + 180,360);
    if (x &lt; 0)
        x += 360;
    return x - 180;
}
</code></pre>

<p>The pattern should be easy enough to recognize to generalize to radians.</p>

<hr>

<p><strong>Angle Bisection:</strong></p>

<pre><code>double angleDiff(double a,double b){
    double dif = fmod(b - a + 180,360);
    if (dif &lt; 0)
        dif += 360;
    return dif - 180;
}
double bisectAngle(double a,double b){
    return constrainAngle(a + angleDiff(a,b) * 0.5);
}
</code></pre>

<p>This should bisect an angle on the ""smaller"" side. (warning: not fully tested)</p>
"
"<p>I'm trying to get the bytes from an int into a series of chars in a portable way across all little endian systems.</p>

<p>I have the following code:</p>

<pre><code>#include &lt;stdio.h&gt;

int
main()
{
  int i = 0xabcdef12;
  printf(""i: %x\n"", i);
  char a, b, c, d;
  a = (i &gt;&gt; 000) &amp; 0xFF;
  b = (i &gt;&gt; 010) &amp; 0xFF;
  c = (i &gt;&gt; 020) &amp; 0xFF;
  d = (i &gt;&gt; 030) &amp; 0xFF;
  printf(""a b c d: %x %x %x %x\n"", a , b, c, d);
  if(a == 0x12)
    printf(""a is 0x12\n"");
  if(b == 0xef)
    printf(""b is 0xef\n"");
  if(c == 0xcd)
    printf(""c is 0xcd\n"");
  if(d == 0xab)
    printf(""d is 0xab\n"");
  if(a == 0xffffff12)
    printf(""a is 0x12\n"");
  if(b == 0xffffffef)
    printf(""b is 0xffffffef\n"");
  if(c == 0xffffffcd)
    printf(""c is 0xffffffcd\n"");
  if(d == 0xffffffab)
    printf(""d is 0xffffffab\n"");
  return 0;
}
</code></pre>

<p>This piece of code compiles without any warning when using -Wall.</p>

<p>When run this gives:</p>

<pre><code>i: abcdef12
a b c d: 12 ffffffef ffffffcd ffffffab
a is 0x12
b is 0xffffffef
c is 0xffffffcd
d is 0xffffffab
</code></pre>

<p>Here are some gcc prints:</p>

<pre><code>Breakpoint 1, main () at test.c:14
14    if(a == 0x12)
(gdb) p/x a
$1 = 0x12
(gdb) p/x b
$2 = 0xef
(gdb) p/x c
$3 = 0xcd
(gdb) p/x d
$4 = 0xab
</code></pre>

<p>I'm pretty sure I'm doing something wrong. It would really help me understand what is going on if you could answer a few  of the following questions:</p>

<ul>
<li>How can a char have value greater than 0xff?</li>
<li>What aren't the <code>&amp; 0xff</code> bitmasks working?</li>
<li>Why does gdb report the correct values?</li>
</ul>

<p>And if anybody has a reliable (system independent, but endianess is not important) way of going from int to char[], that would be great.</p>
","922184","","<p>Here's a quick fix.</p>

<p>Change:</p>

<pre><code>char a, b, c, d;
</code></pre>

<p>to</p>

<pre><code>unsigned char a, b, c, d;
</code></pre>

<p>The reason is that <code>char</code> is signed on your system. When you pass, <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code> into <code>printf()</code>, they get promoted to <code>int</code>. They are sign-extended. That's why you get all those leading <code>ff</code>s.</p>

<p>GDB is reporting the correct values because it is reading the <code>chars</code> directly. (and thus no integer promotion)</p>
"
"<p>The following code is working fine in C but when I try to write it in c++ then the program does not work.Please explain.</p>

<p><strong>C code :</strong></p>

<pre><code>#include&lt;stdio.h&gt;
#include&lt;stdlib.h&gt;

int main()
{
    int a = 33,b = 7;
    printf(""%d\n"",a&amp;b);
    return 0;
}
</code></pre>

<p><strong>C++ code:</strong></p>

<pre><code>#include&lt;iostream&gt;

using namespace std;

int main()
{
    int a = 33,b = 7;
    cout &lt;&lt; 33&amp;7 &lt;&lt; endl;
    return 0;
}
</code></pre>
","922184","","<p>Watch your operator precedence:</p>

<pre><code>cout &lt;&lt; (33 &amp; 7) &lt;&lt; endl;
</code></pre>

<p><code>&amp;</code> has lower precedence than <code>&lt;&lt;</code>. So you need to use <code>()</code>.</p>

<hr>

<p>For the full list of operator precedence in C and C++:</p>

<p><a href=""http://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B#Operator_precedence"" rel=""nofollow"">http://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B#Operator_precedence</a></p>
"
"<p>I'm trying to cast unsigned short array to <code>__m128i</code>:</p>

<pre><code>const unsigned short x[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15};
const unsigned short y[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15};

__m128i n = *(__m128i*) &amp;y[0];
__m128i m = *(__m128i*) &amp;x[0];
</code></pre>

<p>First casting work fine, but the second one - not. I've got:</p>

<pre><code>Unhandled exception at 0x013839ee in sse2_test.exe: 0xC0000005: Access violation reading location 0xffffffff.
</code></pre>

<p>What's wrong? Can somebody help me?</p>
","922184","","<p>Watch your data alignment.</p>

<p>When you dereference a <code>__m128i*</code> or any other SSE type, the pointer is required to be aligned to 16 bytes. However, <code>x</code> and <code>y</code> are not guaranteed to be aligned to 16 bytes.</p>

<p>Enforcing alignment is dependent on the compiler.</p>

<p><strong>Visual C++</strong></p>

<pre><code>__declspec(align(16)) const unsigned short x[] = ...
</code></pre>

<p><strong>GCC</strong></p>

<pre><code>const unsigned short x[] __attribute__((aligned(16))) = ...
</code></pre>

<hr>

<p>Alternatively, you can use unaligned loads (abeit at a possible performance penalty):</p>

<pre><code>__m128i n = __mm_loadu_si128((__m128i*) &amp;y[0]);
__m128i m = __mm_loadu_si128((__m128i*) &amp;x[0]);
</code></pre>
"
"<p>I have a class with an <code>enum</code> member variable. One of the member functions bases its behavior on this <code>enum</code> so as a ""possible"" optimization, I have the two different behaviors as two different functions and I give the class a member function pointer which is set at construction. I simulated this situation like this:</p>

<pre><code>enum catMode {MODE_A, MODE_B};

struct cat
{
    cat(catMode mode) : stamp_(0), mode_(mode) {}

    void
    update()
    {
        stamp_ = (mode_ == MODE_A) ? funcA() : funcB();
    }

    uint64_t stamp_;
    catMode  mode_;
};

struct cat2
{
    cat2(catMode mode) : stamp_(0), mode_(mode)
    {
        if (mode_ = MODE_A)
            func_ = funcA;
        else
            func_ = funcB;
    }

    void
    update()
    {
        stamp_ = func_();
    }

    uint64_t stamp_;
    catMode  mode_;
    uint64_t (*func_)(void);
};
</code></pre>

<p>And then I create a cat object and an array of length <code>32</code>. I traverse the array to bring it into cache, then I call cats update method <code>32</code> times and store the latency using <code>rdtsc</code> in the array...</p>

<p>Then I call a function which loops several hundred times using <code>rand()</code>, <code>ulseep()</code>, and some arbitrary <code>strcmp()</code>..come back and I do the <code>32</code> thing again.</p>

<p>The result is that the method with the branch seems to always be around <code>44</code> +/- <code>10</code> cycles whereas the one with the function pointer tends to be around <code>130</code>. I'm curious as to why this would be the case?</p>

<p>If anything, I would have expected similar performance. Also, templating is hardly an option because full specialization of the real cat class for that one function would be overkill.</p>
","922184","","<p>Without a complete SSCCE I can't approach this the same way that I usually do with such questions.<br>So the best I can do is speculate:</p>

<p>The core difference between your two cases is that you have a branch vs. a function pointer. The fact that you are seeing a difference at all strongly hints that <code>funcA()</code> and <code>funcB()</code> are very small functions.</p>

<p><strong>Possibility #1:</strong></p>

<p>In the branch version of the code, <code>funcA()</code> and <code>funcB()</code> are being inlined by the compiler. Not only does that skip the function call overhead, but if the functions are trivial enough, the branch could also be completely optimized out as well.</p>

<p>Function pointers, on the other hand, cannot be inlined unless the compiler can resolve them at compile-time.</p>

<p><strong>Possibility #2:</strong></p>

<p>By comparing a branch against a function-pointer, you are putting the <a href=""http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array"">branch-predictor</a> against the <a href=""http://en.wikipedia.org/wiki/Branch_target_predictor"" rel=""nofollow"">branch target predictor</a>.</p>

<p>Branch target prediction is not the same as branch prediction. In the branch case, the processor needs to predict which way to branch. In the function pointer case, it needs to predict where to branch to.</p>

<p>It's very likely that your processor's branch predictor is much more accurate than its branch target predictor. But then again, this is all guesswork...</p>
"
"<p>Consider a simple loop in :</p>

<pre><code>for(int i=0;i&lt;32;i++) 
    a[i] = i;
</code></pre>

<p>The LLVM disassembler shows the following assembly:</p>

<pre><code>.LBB0_1:                                # =&gt;This Inner Loop Header: Depth=1
movl    %eax, (%esp,%eax,4)
addl    $1, %eax
adcl    $0, %ecx
cmpl    $32, %eax
jne .LBB0_1
# BB#2:
xorl    %eax, %eax
addl    $140, %esp
ret
</code></pre>

<p><strong>Question 1:</strong> Can anyone explain <code>movl    %eax, (%esp,%eax,4)</code> instruction?</p>

<p>Moreover, Visual Studio disassembler outputs the following assembly:</p>

<pre><code>    ;for(int i=0;i&lt;32;i++)
00F290B5  mov         dword ptr [ebp-94h],0  
00F290BF  jmp         main+60h (0F290D0h)  
00F290C1  mov         eax,dword ptr [ebp-94h]  
00F290C7  add         eax,1  
00F290CA  mov         dword ptr [ebp-94h],eax  
00F290D0  cmp         dword ptr [ebp-94h],20h  
00F290D7  jge         main+7Eh (0F290EEh)  
        ;a[i] = i;
00F290D9  mov         eax,dword ptr [ebp-94h]  
00F290DF  mov         ecx,dword ptr [ebp-94h]  
00F290E5  mov         dword ptr a[eax*4],ecx  
00F290EC  jmp         main+51h (0F290C1h)  
    ;return 0;
00F290EE  xor         eax,eax   
</code></pre>

<p>Obvoiusly the LLVM's output is more optimized.</p>

<p><strong>Question 2:</strong> Is there an option in Visual Studio to optimize the code like LLVM does?</p>

<p><br /><br />
<strong>Update:</strong></p>

<p>Results after setting Solution Configurations to Release &amp; Optimization to Full Optimization(/Ox):</p>

<pre><code>;   int a[32] = {0};
;   for(int i=0;i&lt;32;i++)
 0039128B  xor         eax,eax  
 0039128D  lea         ecx,[a]  
 00391293  movd        xmm0,eax  
 00391297  pshufd      xmm0,xmm0,0  
 0039129C  paddd       xmm0,xmm1  
 003912A0  add         eax,4  
;   {
;       a[i] = i;
 003912A3  movdqu      xmmword ptr [ecx],xmm0  
 003912A7  lea         ecx,[ecx+10h]  
 003912AA  cmp         eax,20h  
 003912AD  jl          main+23h (0391293h)  
;   }
;   return 0;
; };
 003912AF  mov         ecx,dword ptr [ebp-4]  
 003912B2  xor         ecx,ebp  
 003912B4  xor         eax,eax  
 003912B6  call        __security_check_cookie (03916FDh)  
 003912BB  mov         esp,ebp  
 003912BD  pop         ebp  
 003912BE  ret  
</code></pre>
","922184","","<p><code>movl %eax, (%esp,%eax,4)</code> is just an indirect memory store.</p>

<p>It stores <code>%eax</code> into the memory location: <code>%esp + %eax * 4</code>. In this case:</p>

<ul>
<li><code>%esp</code> is the array <code>a</code>.</li>
<li><code>%eax</code> is the index <code>i</code>.</li>
<li><code>4</code> is the size of <code>int</code>.</li>
</ul>

<hr>

<p>For your second question, the code output by Visual Studio looks like it was done without optimizations. There's a lot of excessive memory loads and stores.</p>

<p>For example: <code>dword ptr [ebp-94h]</code> appears to be the index <code>i</code> variable. But without optimizations, it never got promoted to a register.</p>

<p>Enable optimizations, and you will see that it will produce much more sane code.</p>
"
"<p>An operation I need to perform requires me to get one int32_t value and 2 int64_t values from a char array</p>

<p>the first 4 bytes of the char array contain the int32 value, the next 8 bytes contain the first int64_t value, the the next 8 bytes contain the second. I can't figure out how to get to these values. I have tried;</p>

<pre><code>int32_t firstValue = (int32_t)charArray[0];
int64_t firstValue = (int64_t)charArray[1];
int64_t firstValue = (int64_t)charArray[3];

int32_t *firstArray = reinterpet_cast&lt;int32_t*&gt;(charArray);
int32_t num = firstArray[0]; 
int64_t *secondArray = reinterpet_cast&lt;int64_t*&gt;(charArray);
int64_t secondNum = secondArray[0];
</code></pre>

<p>I'm just grabbing at straws. Any help appreciated</p>
","922184","","<p>Quick and dirty solution:</p>

<pre><code>int32_t value1 = *(int32_t*)(charArray +  0);
int64_t value2 = *(int64_t*)(charArray +  4);
int64_t value3 = *(int64_t*)(charArray + 12);
</code></pre>

<p>Note that this could potentially cause misaligned memory accesses. So it may not always work.</p>

<hr>

<p>A more robust solution that doesn't violate strict-aliasing and won't have alignment issues:</p>

<pre><code>int32_t value1;
int64_t value2;
int64_t value3;

memcpy(&amp;value1,charArray +  0,sizeof(int32_t));
memcpy(&amp;value2,charArray +  4,sizeof(int64_t));
memcpy(&amp;value3,charArray + 12,sizeof(int64_t));
</code></pre>
"
"<p>By default OpenMP directive:</p>

<p><code>opm_get_num_threads</code> gives number of threads equivalent to processors/cores.</p>

<p>I have an 8 core machine, so it gives me 8 threads. Is that the maximum? Can I get more threads than 8, if I deliberately specify more than 8?</p>

<p>Thanks</p>
","922184","","<p>You can set as many threads as you want with:</p>

<pre><code>int threads = 16;
omp_set_num_threads(threads);
</code></pre>

<p><a href=""http://msdn.microsoft.com/en-US/library/e16bady3%28v=vs.80%29"" rel=""nofollow"">http://msdn.microsoft.com/en-US/library/e16bady3%28v=vs.80%29</a></p>

<p>But be sure you are aware of the drawbacks of using more threads than there are logical cores in the system.</p>
"
"<p>As per my knowledge, By default 4-byte alignment will be done. say</p>

<pre><code>typedef struct
{
     int data7;  
     unsigned char data8;
     //3 -bytes will be added here.
}Sample1;
</code></pre>

<p>so <code>sizeof(Sample1)</code> will be 8.</p>

<p>But for the following structure,  why padding is not happened?.</p>

<pre><code>typedef struct
{
     unsigned char data1;
     unsigned char data2;
     unsigned char data3;
     unsigned char data4;
     unsigned char data5;
     unsigned char data6;

}Sample2;
</code></pre>

<p>But the sizeof(Sample2) is 6 only. This Sample2 is not a 4 byte aligned structure?</p>

<p><strong>EDIT::</strong></p>

<p>As per Wiki</p>

<p>Data alignment means putting the data at a memory offset equal to some multiple of the word size, which increases the system's performance due to the way the CPU handles memory.</p>

<p>But members of Sample2 will not be aligned in multiples of two right??</p>

<p>Thanks.</p>
","922184","","<p>None of the fields in your second struct require 4-byte alignment. <code>unsigned char</code> only needs 1-byte alignment. Therefore, there is no need to actually align it to 4 bytes.</p>

<p>Structs are generally only aligned to the maximum alignment of all the fields.</p>
"
"<p>Suppose in speed-critical code we have a pair of arrays that are frequently used together, where the exact size doesn't matter, it just needs to be set to something reasonable, e.g.</p>

<pre><code>int a[256], b[256];
</code></pre>

<p>Is this potentially a pessimization because the low address bits being the same can make it harder for the cache to handle both arrays simultaneously? Would it be better to specify e.g. 300 instead of 256?</p>
","922184","","<p>Moving my comment to an answer:</p>

<p>You are correct to suspect that powers-of-two could be problematic. But it usually only applies when you have more than 2 strides. It doesn't get really bad until you exceed your L1 <a href=""http://en.wikipedia.org/wiki/CPU_cache#Associativity"">cache associativity</a>. But even before that you might run into false aliasing issues.</p>

<p>Here are two examples where powers-of-two actually become problematic:</p>

<ul>
<li><a href=""http://stackoverflow.com/questions/8547778/why-is-one-loop-so-much-slower-than-two-loops"">Why is one loop so much slower than two loops?</a></li>
<li><a href=""http://stackoverflow.com/questions/7905760/matrix-multiplication-small-difference-in-matrix-size-large-difference-in-timi"">Matrix multiplication: Small difference in matrix size, large difference in timings</a></li>
</ul>

<p>In the first example, there are 4 arrays - all of which are aligned to the same offset from the start of a 4k page.</p>

<p>In the second example, the column-wise hopping of a matrix completely destroys performance when the size is a power-of-two.</p>

<hr>

<p>In any case, note that the key concept is actually the alignment of the arrays, not the size of them. If you find that you are running into slow-downs, just add some padding between your arrays to break the alignment.</p>
"
"<p>I'm optimizing a matrix numerical hotspot.</p>

<p>Currently, I'm doing blocking and <a href=""http://en.wikipedia.org/wiki/Loop_unwinding"" rel=""nofollow"">loop unrolling</a> to improve performance. However, I deliberately avoid peeling the borders. Instead I let the blocking steps overflow, and of course, the algorithm then touches uninitialized values.</p>

<p>However, the matrix is generously pre-allocated to cope with the overflow so I am not actually illegally accessing a memory location.</p>

<p>I don't do peeling for several reasons:</p>

<ul>
<li>Laziness</li>
<li>Performance hit due to the very bad locality of the peeling border case.</li>
<li>To avoid complex border peeling code.</li>
</ul>

<p>However, I am wondering whether these overflowed accesses that touch uninitialized value(s) would actually cause a performance hit?</p>

<p>I predictably know where the uninitialized accesses happen and they are also reported via valgrind. I have also profiled the code using Intel's VTune and could not see any signs that would point to a degraded performance due to this.</p>
","922184","","<p>Just to get pedantic stuff out of the way:</p>

<p>According to the standard, bad things can happen if you use uninitialized data. (The standard allows for ""trap"" values that could trigger exceptions.) But for all practical purposes, this probably doesn't apply here.</p>

<hr>

<p><strong>If you're dealing with integers</strong>, accessing and operating on uninitialized data will have no effect on performance. (aside from division, all operations are usually fixed latency)</p>

<p><strong>For floating-point</strong>, there are two problems:</p>

<ol>
<li><a href=""http://en.wikipedia.org/wiki/NaN#Signaling_NaN"" rel=""nofollow"">Signalling NaNs</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Denormal_number"" rel=""nofollow"">Denormalized Values</a></li>
</ol>

<p>Depending on the environment, signalling NaNs may trigger a hardware exception. So this would actually be a correctness issue, not just a performance issue.</p>

<p>It may counter-intuitive that denormal floats have anything to do with this. However, 
<em>uninitialized data has a high probability of being denormalized</em>.</p>

<p><a href=""http://stackoverflow.com/questions/9314534/why-does-changing-0-1f-to-0-slow-down-performance-by-10x"">And you really don't want to be messing with denormalized floating-point.</a></p>

<p>So if you're unlucky enough for the uninitialized values to have even one denormalized value, you can expect a nasty 100+ cycle penalty at the end of each loop iteration. Now depending on how large the loops are, this may or may not matter.</p>

<p>That said, <strong>why is uninitialized data prone to be denormalized?</strong> If the first few bits of a floating-point value are zero, then it is denormalized. It's that easy. If the data used to be a integer, or a 64-bit pointer... It'll be denormalized when reinterpreted as a floating-point value.</p>

<hr>

<p>Suggestions:</p>

<ul>
<li>Zero initialize the data. If it's too expensive, at least zero-initialize the end-points.</li>
<li>Avoid accessing the uninitialized data by putting in that clean up code. Something like <a href=""http://en.wikipedia.org/wiki/Duff%27s_device"" rel=""nofollow"">Duff's Device</a> might be appropriate. Though I generally prefer a set of binary reducing if-statements.</li>
</ul>
"
"<p>I have a problem about the openmp compiling.</p>

<p>Like the following code:</p>

<pre><code>#include &lt;iostream&gt; 
#include &lt;pthread.h&gt;
#include &lt;omp.h&gt;
#include &lt;semaphore.h&gt;
#include &lt;stack&gt;
using namespace std;
sem_t empty,full;
stack&lt;int&gt; stk;
void produce(int i)
{
    {
    sem_wait(&amp;empty);
            cout&lt;&lt;""produce ""&lt;&lt;i*i&lt;&lt;endl;
            stk.push(i*i);
    sem_post(&amp;full);
    }
}
void consume1(int &amp;x)
{
    sem_wait(&amp;full);
            int data=stk.top();
            stk.pop();
            x=data;
    sem_post(&amp;empty);
}
void consume2()
{
    sem_wait(&amp;full);
            int data=stk.top();
            stk.pop();
            cout&lt;&lt;""consume2 ""&lt;&lt;data&lt;&lt;endl;
    sem_post(&amp;empty);
}
int main()
{
    sem_init(&amp;empty,0,1);
    sem_init(&amp;full,0,0);
    pthread_t t1,t2,t3;
    omp_set_num_threads(3);
    int TID=0;
    #pragma omp parallel private(TID)
    {
            TID=omp_get_thread_num();
            if(TID==0)
            {
            cout&lt;&lt;""There are ""&lt;&lt;omp_get_num_threads()&lt;&lt;"" threads""&lt;&lt;endl;
            for(int i=0;i&lt;5;i++)
                    produce(i);
            }
            else if(TID==1)
            {
                    int x;
                    while(true)
                    {
                            consume1(x);
                            cout&lt;&lt;""consume1 ""&lt;&lt;x&lt;&lt;endl;
                    }
            }
            else if(TID==2)
            {
                    int x;
                    while(true)
                    {
                            consume1(x);
                            cout&lt;&lt;""consume2 ""&lt;&lt;x&lt;&lt;endl;
                    }
            }
    }
    return 0;
}
</code></pre>

<p>Firstly, I compile it using:</p>

<pre><code>g++ test.cpp -fopenmp -lpthread
</code></pre>

<p>And, I got the right answer, there are 3 threads totally.</p>

<p>But, when I do the compile like this:</p>

<pre><code>g++ -c test.cpp -o test.o
g++ test.o -o test -fopenmp -lpthread
</code></pre>

<p>there is just only ONE thread.</p>

<p>Anyone can tell me how to compile this code correctly. Thankyou in advance.</p>
","922184","","<p>The OpenMP pragmas are only enabled when compiled with <code>-fopenmp</code>. Otherwise they are completely ignored by the compiler. (Hence, only 1 thread...)</p>

<p>Therefore, you will need to add <code>-fopenmp</code> to the compilation of every single module that uses OpenMP. (As opposed to just the final linking step.)</p>

<pre><code>g++ -c test.cpp -o test.o -fopenmp
g++ test.o -o test -fopenmp -lpthread
</code></pre>
"
"<p>I am confused about using expm1 function in java
The Oracle java doc for Math.expm1 says:</p>

<blockquote>
  <p>Returns exp(x) -1. Note that for values of x near 0, the exact sum of
  expm1(x) + 1 is much closer to the true result of ex than exp(x).</p>
</blockquote>

<p>but <a href=""http://www.ibm.com/developerworks/java/library/j-math2/index.html"">this page</a> says:</p>

<blockquote>
  <p>However, for negative values of x, roughly -4 and lower, the algorithm
  used to calculate Math.exp() is relatively ill-behaved and subject to
  round-off error. It's more accurate to calculate ex - 1 with a
  different algorithm and then add 1 to the final result.</p>
</blockquote>

<p>should we use expm1(x) for negative x values or near 0 values?</p>
","922184","","<p>You use <code>expm1(x)</code> for anything close to 0. Positive or negative.</p>

<p>The reason is because <code>exp(x)</code> of anything close to 0 will be very close to 1. Therefore <code>exp(x) - 1</code> will suffer from destructive cancellation when <code>x</code> is close to 0.</p>

<p><code>expm1(x)</code> is properly optimized to avoid this destructive cancellation.</p>

<hr>

<p>From the mathematical side: If <code>exp</code> is implemented using its Taylor Series, then <code>expm1(x)</code> can be done by simply omitting the first <code>+1</code>.</p>
"
"<p>Quick Question guys... Are these code spinets have the same alignment ?</p>

<pre><code>struct sse_t {
     float sse_data[4];
};

// the array ""cacheline"" will be aligned to 64-byte boundary
struct sse_t alignas(64) cacheline[1000000];
</code></pre>

<p>Or </p>

<pre><code>// every object of type sse_t will be aligned to 64-byte boundary
struct sse_t {
     float sse_data[4];
} __attribute((aligned(64)));

struct sse_t cacheline[1000000];
</code></pre>
","922184","","<blockquote>
  <p>Are these code spinets have the same alignment ?</p>
</blockquote>

<p>Not quite. Your two examples are actually very different.</p>

<p>In your first example, you will get an array of <code>sse_t</code> objects. A <code>sse_t</code> object is only guaranteed 4-byte alignment. But since the entire array is aligned to 64-bytes, each <code>sse_t</code> object will be properly aligned for SSE access.</p>

<p>In your second example, you are forcing each <code>sse_t</code> object to be aligned to 64-bytes. But each <code>sse_t</code> object is only 16 bytes. So the array will be 4x larger. (You will have 48 bytes of padding at the end of each <code>sse_t</code> object).</p>

<hr>

<pre><code>struct objA {
     float sse_data[4];
};
struct objB {
     float sse_data[4];
} __attribute((aligned(64)));

int main(){
    cout &lt;&lt; sizeof(objA) &lt;&lt; endl;
    cout &lt;&lt; sizeof(objB) &lt;&lt; endl;
}
</code></pre>

<p>Output:</p>

<pre><code>16
64
</code></pre>

<p>I'm pretty sure that the second case is <strong>not</strong> what you want.</p>
"
"<p>When compiling with <code>gcc -O3</code>, why does the following loop not vectorize (automatically):</p>

<pre><code>#define SIZE (65536)

int a[SIZE], b[SIZE], c[SIZE];

int foo () {
  int i, j;

  for (i=0; i&lt;SIZE; i++){
    for (j=i; j&lt;SIZE; j++) {
      a[i] = b[i] &gt; c[j] ? b[i] : c[j];
    }
  }
  return a[0];
}
</code></pre>

<p>when the following one does?</p>

<pre><code>#define SIZE (65536)

int a[SIZE], b[SIZE], c[SIZE];

int foov () {
  int i, j;

  for (i=0; i&lt;SIZE; i++){
    for (j=i; j&lt;SIZE; j++) {
      a[i] += b[i] &gt; c[j] ? b[i] : c[j];
    }
  }
  return a[0];
}
</code></pre>

<p>The only difference is whether the result of the expression in the inner loop is <strong>assigned to a[i], or added to a[i]</strong>.</p>

<p>For reference <code>-ftree-vectorizer-verbose=6</code> gives the following output for the first (non-vectorizing) loop.</p>

<pre><code>v.c:8: note: not vectorized: inner-loop count not invariant.
v.c:9: note: Unknown alignment for access: c
v.c:9: note: Alignment of access forced using peeling.
v.c:9: note: not vectorized: live stmt not supported: D.2700_5 = c[j_20];

v.c:5: note: vectorized 0 loops in function.
</code></pre>

<p>And the same output for the loop that vectorizes is:</p>

<pre><code>v.c:8: note: not vectorized: inner-loop count not invariant.
v.c:9: note: Unknown alignment for access: c
v.c:9: note: Alignment of access forced using peeling.
v.c:9: note: vect_model_load_cost: aligned.
v.c:9: note: vect_model_load_cost: inside_cost = 1, outside_cost = 0 .
v.c:9: note: vect_model_simple_cost: inside_cost = 1, outside_cost = 1 .
v.c:9: note: vect_model_reduction_cost: inside_cost = 1, outside_cost = 6 .
v.c:9: note: cost model: prologue peel iters set to vf/2.
v.c:9: note: cost model: epilogue peel iters set to vf/2 because peeling for alignment is unknown .
v.c:9: note: Cost model analysis:
  Vector inside of loop cost: 3
  Vector outside of loop cost: 27
  Scalar iteration cost: 3
  Scalar outside cost: 7
  prologue iterations: 2
  epilogue iterations: 2
  Calculated minimum iters for profitability: 8

v.c:9: note:   Profitability threshold = 7

v.c:9: note: Profitability threshold is 7 loop iterations.
v.c:9: note: LOOP VECTORIZED.
v.c:5: note: vectorized 1 loops in function.
</code></pre>
","922184","","<p><strong>In the first case</strong>: the code overwrites the same memory location <code>a[i]</code> in each iteration. This inherently sequentializes the loop as the loop iterations are not independent.<br>
(In reality, only the final iteration is actually needed. So the entire inner loop could be taken out.)</p>

<p><strong>In the second case</strong>: GCC recognizes the loop as a reduction operation - for which it has special case handling to vectorize.</p>

<p>Compiler vectorization is often implemented as some sort of ""pattern matching"". Meaning the compiler analyzes code to see if it fits a certain pattern that it's able to vectorize. If it does, it gets vectorized. If it doesn't, then it doesn't.</p>

<p>This seems to be a corner case where the first loop doesn't fit any of the pre-coded patterns that GCC can handle. But the second case fits the ""vectorizable reduction"" pattern.</p>

<hr>

<p>Here's the relevant part of GCC's source code that spits out that <code>""not vectorized: live stmt not supported: ""</code> message:</p>

<p><a href=""http://svn.open64.net/svnroot/open64/trunk/osprey-gcc-4.2.0/gcc/tree-vect-analyze.c"">http://svn.open64.net/svnroot/open64/trunk/osprey-gcc-4.2.0/gcc/tree-vect-analyze.c</a></p>

<pre><code>if (STMT_VINFO_LIVE_P (stmt_info))
{
    ok = vectorizable_reduction (stmt, NULL, NULL);

    if (ok)
        need_to_vectorize = true;
    else
        ok = vectorizable_live_operation (stmt, NULL, NULL);

    if (!ok)
    {
        if (vect_print_dump_info (REPORT_UNVECTORIZED_LOOPS))
        {
            fprintf (vect_dump, 
                ""not vectorized: live stmt not supported: "");
            print_generic_expr (vect_dump, stmt, TDF_SLIM);
        }
        return false;
    }
}
</code></pre>

<p>From just the line:</p>

<pre><code>vectorizable_reduction (stmt, NULL, NULL);
</code></pre>

<p>It's clear that GCC is checking to see if it matches a ""vectorizable reduction"" pattern.</p>
"
"<p>I've read a lot about floats, but it's all unnecessarily involved. I <em>think</em> I've got it pretty much understood, but there's just one thing I'd like to know for sure:</p>

<p>I know that, fractions of the form <code>1/pow(2,n)</code>, with <code>n</code> an integer, can be represented exactly in floating point numbers. This means that if I add <code>1/32</code> to itself 32 million times, I would get exactly <code>1,000,000</code>.</p>

<p>What about something like <code>1/(32+16)</code>? It's one over the sum of two powers of two, does this work? Or is it <code>1/32+1/16</code> that works? This is where I'm confused, so if anyone could clarify that for me I would appreciate it.</p>
","922184","","<p>The rule can be summed up as this:</p>

<ul>
<li>A number can be represented exactly in binary if the prime factorization of the denominator contains only 2. (i.e. the denominator is a power-of-two)</li>
</ul>

<p>So <code>1/(32 + 16)</code> is not representable in binary because it has a factor of 3 in the denominator. But <code>1/32 + 1/16 = 3/32</code> is.</p>

<p>That said, there are more restrictions to be representable in a floating-point type. For example, you only have 53 bits of mantissa in an IEEE <code>double</code> so <code>1/2 + 1/2^500</code> is not representable.</p>

<p>So you can do sum of powers-of-two as long as the range of the exponents doesn't span more than 53 powers.</p>

<hr>

<p>To generalize this to other bases:</p>

<ul>
<li><p>A number can be exactly represented in base 10 if the prime factorization of the denominator consists of only 2's and 5's.</p></li>
<li><p>A rational number <code>X</code> can be exactly represented in base <code>N</code> if the prime factorization of the denominator of <code>X</code> contains only primes found in the factorization of <code>N</code>.</p></li>
</ul>
"
"<p>Consider these two functions using SSE:</p>

<pre><code>#include &lt;xmmintrin.h&gt;

int ftrunc1(float f) {
    return _mm_cvttss_si32(_mm_set1_ps(f));
}

int ftrunc2(float f) {
    return _mm_cvttss_si32(_mm_set_ss(f));
}
</code></pre>

<p>Both are exactly the same in behaviour for any input. But the assembler output is different:</p>

<pre><code>ftrunc1:
    pushl   %ebp
    movl    %esp, %ebp
    cvttss2si   8(%ebp), %eax
    leave
    ret

ftrunc2:
    pushl   %ebp
    movl    %esp, %ebp
    movss   8(%ebp), %xmm0
    cvttss2si   %xmm0, %eax
    leave
    ret
</code></pre>

<p>That is, <code>ftrunc2</code> uses one <code>movss</code> instruction extra!</p>

<p>Is this normal? Does it matter? Should <code>_mm_set1_ps</code> always be preferred over <code>_mm_set_ss</code> when you only need to set the bottom element?</p>

<hr>

<p>Compiler used was GCC 4.5.2 with <code>-O3 -msse</code>.</p>
","922184","","<p><code>_mm_set_ss</code> maps directly to an assembly instruction (<code>movss</code>). But <code>_mm_set1_ps</code> does not.</p>

<p>From what I've seen on GCC, MSVC, and ICC:</p>

<p>SSE intrinsics that map one-to-one to an assembly instruction are generally treated ""as-is"" - a black box. So the compiler will only optimizations that apply to the entire instruction itself. But it will not attempt to do any optimizations that require dataflow/dependency analysis on the individual vector elements.</p>

<p>The <code>_mm_set1_ps</code> and <code>_mm_set_ps</code> intrinsics do not map to a single instruction and have special case handling by most compilers. From what I've seen, all three of the compilers I've listed above <em>do</em> attempt to perform dataflow analysis optimizations on the individual elements.</p>

<hr>

<p>When you put it all together, the second example leaves the <code>movss</code> because the compiler doesn't realize that the top 3 elements don't matter. (It makes no attempt to ""open up"" the <code>_mm_set_ss</code> intrinsic.)</p>
"
"<p>I'm trying to write a bit of code that will predict the time taken to perform a discrete Fourier transform on a given n-dimensional array, but I'm struggling to get my head around the computational complexity of n-dimensional FFTs.</p>

<p>As I understand it:</p>

<ul>
<li><p>The 1D FFT of a vector of length <code>N</code> should take <code>k*(N*log(N))</code> where <code>k</code> is some timing constant</p></li>
<li><p>For an <code>M*N</code> matrix, the 2D FFT should take:</p>

<p><code>N*(k*M*log(M)) + M*(k*N*log(N)) = k*M*N*(log(M)+log(N))</code></p>

<p>since it requires taking 1D FFTs in each row and column</p></li>
</ul>

<p>How does this generalize to the ND case? Does it follow that it should be <code>k*prod(dimensions)*sum(log(dimensions))</code>?</p>
","922184","","<p>If we take your derivation of 2D a bit further, it becomes clear:</p>

<pre><code>N*(k*M*log(M)) + M*(k*N*log(N)) = k*M*N*(log(M)+log(N))
</code></pre>

<p>becomes:</p>

<pre><code>                                = k*M*N*(log(M*N))
</code></pre>

<p>For N dimensions (A,B,C, etc...), the complexity is:</p>

<pre><code>O( A*B*C*... * log(A*B*C*...) )
</code></pre>

<p>Mathematically speaking, an N-Dimensional FFT is the same as a 1-D FFT with the size of the product of the dimensions, except that the <a href=""http://en.wikipedia.org/wiki/Twiddle_factor"">twiddle factors</a> are different. So it naturally follows that the computational complexity is the same.</p>
"
"<p>Here is the extract from the program in question. The matrix <code>img[][]</code> has the size SIZE×SIZE, and is initialized at:</p>

<p><code>img[j][i] = 2 * j + i</code></p>

<p>Then, you make a matrix <code>res[][]</code>, and each field in here is made to be the average of the 9 fields around it in the img matrix. The border is left at 0 for simplicity.</p>

<pre><code>for(i=1;i&lt;SIZE-1;i++) 
    for(j=1;j&lt;SIZE-1;j++) {
        res[j][i]=0;
        for(k=-1;k&lt;2;k++) 
            for(l=-1;l&lt;2;l++) 
                res[j][i] += img[j+l][i+k];
        res[j][i] /= 9;
}
</code></pre>

<p>That's all there's to the program. For completeness' sake, here is what comes before. No code comes after. As you can see, it's just initialization.</p>

<pre><code>#define SIZE 8192
float img[SIZE][SIZE]; // input image
float res[SIZE][SIZE]; //result of mean filter
int i,j,k,l;
for(i=0;i&lt;SIZE;i++) 
    for(j=0;j&lt;SIZE;j++) 
        img[j][i] = (2*j+i)%8196;
</code></pre>

<p>Basically, this program is slow when SIZE is a multiple of 2048, e.g. the execution times:</p>

<pre><code>SIZE = 8191: 3.44 secs
SIZE = 8192: 7.20 secs
SIZE = 8193: 3.18 secs
</code></pre>

<p>The compiler is GCC.
From what I know, this is because of memory management, but I don't really know too much about that subject, which is why I'm asking here.</p>

<p>Also how to fix this would be nice, but if someone could explain these execution times I'd already be happy enough.</p>

<p>I already know of malloc/free, but the problem is not amount of memory used, it's merely execution time, so I don't know how that would help.</p>
","922184","","<p>The difference is caused by the same super-alignment issue from the following related questions:</p>

<ul>
<li><a href=""http://stackoverflow.com/q/11413855/922184"">Why is transposing a matrix of 512x512 much slower than transposing a matrix of 513x513?</a></li>
<li><a href=""http://stackoverflow.com/q/7905760/922184"">Matrix multiplication: Small difference in matrix size, large difference in timings</a></li>
</ul>

<p>But that's only because there's one other problem with the code.</p>

<p>Starting from the original loop:</p>

<pre><code>for(i=1;i&lt;SIZE-1;i++) 
    for(j=1;j&lt;SIZE-1;j++) {
        res[j][i]=0;
        for(k=-1;k&lt;2;k++) 
            for(l=-1;l&lt;2;l++) 
                res[j][i] += img[j+l][i+k];
        res[j][i] /= 9;
}
</code></pre>

<p>First notice that the two inner loops are trivial. They can be unrolled as follows:</p>

<pre><code>for(i=1;i&lt;SIZE-1;i++) {
    for(j=1;j&lt;SIZE-1;j++) {
        res[j][i]=0;
        res[j][i] += img[j-1][i-1];
        res[j][i] += img[j  ][i-1];
        res[j][i] += img[j+1][i-1];
        res[j][i] += img[j-1][i  ];
        res[j][i] += img[j  ][i  ];
        res[j][i] += img[j+1][i  ];
        res[j][i] += img[j-1][i+1];
        res[j][i] += img[j  ][i+1];
        res[j][i] += img[j+1][i+1];
        res[j][i] /= 9;
    }
}
</code></pre>

<p>So that leaves the two outer-loops that we're interested in.</p>

<p>Now we can see the problem is the same in this question: <a href=""http://stackoverflow.com/q/9936132/922184"">Why does the order of the loops affect performance when iterating over a 2D array?</a></p>

<p>You are iterating the matrix column-wise instead of row-wise.</p>

<hr>

<p>To solve this problem, you should interchange the two loops.</p>

<pre><code>for(j=1;j&lt;SIZE-1;j++) {
    for(i=1;i&lt;SIZE-1;i++) {
        res[j][i]=0;
        res[j][i] += img[j-1][i-1];
        res[j][i] += img[j  ][i-1];
        res[j][i] += img[j+1][i-1];
        res[j][i] += img[j-1][i  ];
        res[j][i] += img[j  ][i  ];
        res[j][i] += img[j+1][i  ];
        res[j][i] += img[j-1][i+1];
        res[j][i] += img[j  ][i+1];
        res[j][i] += img[j+1][i+1];
        res[j][i] /= 9;
    }
}
</code></pre>

<p>This eliminates all the non-sequential access completely so you no longer get random slow-downs on large powers-of-two.</p>

<hr>

<p><strong>Core i7 920 @ 3.5 GHz</strong></p>

<p>Original code:</p>

<pre><code>8191: 1.499 seconds
8192: 2.122 seconds
8193: 1.582 seconds
</code></pre>

<p>Interchanged Outer-Loops:</p>

<pre><code>8191: 0.376 seconds
8192: 0.357 seconds
8193: 0.351 seconds
</code></pre>
"
"<p>I often find myself wanting to copy the contents of arrays that have a constant size, I usually just write something along the lines of:</p>

<pre><code>float a[4] = {0,1,2,3};
float b[4];

for(int i=0; i&lt;4; i++){
    b[i]=a[i];
}
</code></pre>

<p>As of lately, I am writing a linear calculus library for educational purposes, and I was wondering if there was a better way to do it.</p>

<p>The first thing that came to my mind, was using memcpy:</p>

<pre><code>memcpy(b, a, sizeof(float) * 4);
</code></pre>

<p>But this seems very c-like and error prone to me. I like having my errors at compile time, and this can get ugly for data types with non-trivial copy constructors, or if I forget to multiply with sizeof(datatype).</p>

<p>Since I am writing a math library that I am going to use intensively, performance is very important to me. Are the compilers today smart enough to understand that the first example is just copying a chunk of memory and optimize it to be as efficient as the second solution?</p>

<p>Perhaps there is a function in the standard library that can help me? Something new in c++11? Or should I just create a macro or a template function?</p>
","922184","","<p>The C++03 way would be to use <a href=""http://www.cplusplus.com/reference/algorithm/copy/""><code>std::copy()</code></a>:</p>

<pre><code>float a[4] = {0,1,2,3};
float b[4];

std::copy(a,a + 4, b);
</code></pre>

<p>That's about as clean as it gets. On C++11 prefer</p>

<pre><code>std::copy(std::begin(a), std::end(a), std::begin(b));
</code></pre>

<p>Or better yet, use std::array and get assignment for free:</p>

<pre><code>std::array&lt;float,4&gt; a = {0,1,2,3};
auto b = a;
</code></pre>
"
"<p>By definition taken from: <a href=""http://www.cplusplus.com/reference/iostream/ostream/flush/"" rel=""nofollow"">http://www.cplusplus.com/reference/iostream/ostream/flush/</a> , it is not clear why the function exists, and for what purpose you would use it for. Why not call flush(), every time your write to the stream?  </p>
","922184","","<p>In all likelihood, the word <code>flush</code> comes from exactly what you'd flush in real-life. A toilet...</p>

<p>So let's try a toilet analogy:</p>

<p>Flushing every time a new one drops into the bowl is very time-consuming and a complete waste of water. That's a big problem today where everyone's trying to be environmentally friendly.</p>

<p>So what do you do instead? You buffer it by saving it all up and flushing once at the end. If for whatever reason, you can always ""prematurely"" flush somewhere in the middle when you're not done.</p>

<hr>

<p>C++ streams (among other things) work much the same way. To reduce overhead and improve performance, a stream buffers its contents and only periodically ""flushes"" it. The draw-back of this is that you may get ""delayed"" behavior like in this question: <a href=""http://stackoverflow.com/questions/1716296/why-does-printf-not-flush-after-the-call-unless-a-newline-is-in-the-format-strin"">Why does printf not flush after the call unless a newline is in the format string?</a></p>

<p>So that's what <code>flush()</code> is for. To allow you to override the buffering.</p>
"
"<p>I am trying to use pread and pwrite so that I can lseek to the beginning of the file and start reading or writing in one atomic operation.  Both of these functions will do that for me however, the issue I am having is that the compiler is giving me <code>warning: implicit declaration of function ‘pread’</code> even after I added <code>#define _XOPEN_SOURCE 500</code> and <code>#include&lt;unistd.h&gt;</code> like the man pages said.  Am I missing something? The two statements with the function calls are below.
Thanks!</p>

<pre><code> #include&lt;unistd.h&gt;



 #define _XOPEN_SOURCE 500
    int main (int argc, char *argv[])
    {



while ( (read_in += pread(source_fd, in_buf, in_buf_size,read_in) )  )
    {

if (write_out += pwrite(dest_fd, in_buf, read_in, write_out) == -1)
        {
</code></pre>
","922184","","<p>You need to define <code>_XOPEN_SOURCE 500</code> <strong><em>before</em></strong> your includes:</p>

<pre><code>#define _XOPEN_SOURCE 500

#include&lt;unistd.h&gt;
</code></pre>

<p>Otherwise, the <code>unistd.h</code> header won't see the macro definition.</p>
"
"<p>I would like to use instruction _mm_prefetch. MSDN <a href=""http://msdn.microsoft.com/en-us/library/84szxsww%28v=vs.100%29.aspx#feedback"" rel=""nofollow"">specifies</a> that it is in header mmintrin.h, but there is not. I use Visual Studio 2012.</p>
","922184","","<p>Looks like a bug in their documentation. I couldn't find it in <code>&lt;mmintrin.h&gt;</code> either, but it appears to be in <code>&lt;xmmintrin.h&gt;</code>.</p>

<hr>

<p>This compiles in VS2010:</p>

<pre><code>#include &lt;xmmintrin.h&gt;

int main()
{

    _mm_prefetch(0,0);

    return 0;
}
</code></pre>
"
"<p>Sorry if the question sounds stupid. I'm only vaguely cognizant of the issue of data alignment and have never done any 64-bit programming. I'm working on some 32-bit x86 code right now. It frequently accesses an array of int. Sometimes one 32-bit integer is read. Sometimes two or more are read. At some point I'd like to make the code 64-bit. What I'm not sure is whether I should declare this int array as <code>int</code> or <code>long int</code>. I would rather keep the width of the integer the same, so I don't have to worry about differences. I'm sort of worried though that reading/writing off an address that isn't aligned to the natural word might be slow.</p>
","922184","","<p>Misalignment penalties only occur when the load or store crosses an alignment boundary. The boundary is <em>usually</em> the smaller of:</p>

<ul>
<li>The natural word-size of the hardware. (32-bits or 64-bit*)</li>
<li>The size of the data-type.</li>
</ul>

<p>If you're loading a 4-byte word on a 64-bit (8-byte) architecture. It does not need to be 8-byte aligned. It only needs to be 4-byte aligned.</p>

<p>Likewise, if you're loading a 1-byte char on any machine, it doesn't need to be aligned at all.</p>

<p><sub>*Note that SIMD vectors can imply a larger natural word-size. For example, 16-byte SSE still requires 16-byte alignment on both x86 and x64. (barring explicit misaligned loads/stores)</sub></p>

<hr>

<p>So in short, no you don't have to worry about data-alignment. The language and the compiler tries pretty hard to prevent you from having to worry about it.</p>

<p>So just stick with whatever datatype makes the most sense for you.</p>
"
"<p>Having the following unions:</p>

<pre><code>union {double first_d; uint64 first;};
union {double second_d; uint64 second;};
...
first_d = &lt;a double value&gt;
second_d = &lt;a double value&gt;
</code></pre>

<p>Does the output of following comparisons:</p>

<pre><code>if(first_d &gt; second_d)
    // CASE 1 OUTPUT
else if(first_d &lt; second_d)
    // CASE 2 OUTPUT
else
    // CASE 3 OUTPUT
</code></pre>

<p>always the same for the following?</p>

<pre><code>if(first&gt; second)
    // CASE 1' OUTPUT
else if(first &lt; second)
    // CASE 2' OUTPUT
else
    // CASE 3' OUTPUT
</code></pre>
","922184","","<p>Nope. Here's a counter-example using <code>NaNs</code>:</p>

<pre><code>int main()
{

    union {double first_d; uint64 first;};
    union {double second_d; uint64 second;};

    first  = 0x7ff8000000000001;
    second = 0x7ff8000000000002;

    if(first_d &gt; second_d)
        printf(""greater\n"");
    else if(first_d &lt; second_d)
        printf(""less\n"");
    else
        printf(""other\n"");

    if(first &gt; second)
        printf(""greater\n"");
    else if(first &lt; second)
        printf(""less\n"");
    else
        printf(""other\n"");

    return 0;
}
</code></pre>

<p>Output:</p>

<pre><code>other
less
</code></pre>

<hr>

<p>I'll also mention that type-punning via unions isn't 100% standard conformant. So you could also say it's undefined behavior.</p>
"
"<p>I am writing a program to parse a file. It consists of a main loop that parses character by character and treats them. Here is the main loop:</p>

<pre><code>char c;
char * ptr;

for( size_t i = 0; i &lt; size ; ++i )
{
    ptr = ( static_cast&lt;char*&gt;(sentenceMap) + i );
    c = *ptr;

    __builtin_prefetch( ptr + i + 1 );

   // some treatment on ptr and c   
}
</code></pre>

<p>As you can see, I added a <code>builtin_prefetch</code> instruction, hoping to put in cache the next iteration of my loop. I tried with different values : <code>ptr+i+1</code>, <code>ptr+i+2</code>, <code>ptr+i+10</code> but nothing seems to change.</p>

<p>To measure performance, I use valgrind’s tool cachegrind, which gives me an indication of the number of cache misses. On the line <code>c = *ptr</code>, cachegrind records 632,378 DLmr (L3 cache miss) when <code>__builtin_prefetch</code> is not set. What’s weird though, is that this value does not change, regardless of the parameter I set to <code>__builtin_prefetch</code>.</p>

<p>Any explanation to that?</p>
","922184","","<p>That's because the hardware is years ahead of you. :)</p>

<p>There are hardware prefetchers that are designed to recognize simple patterns and do the prefetching for you. In this case, you have a simple sequential access pattern, that's more than trivial for the hardware prefetcher.</p>

<p>Manual prefetching only comes handy when you have access patterns that the hardware cannot predict.</p>

<p>Here's one such example: <a href=""http://stackoverflow.com/q/7327994/922184"">Prefetching Examples?</a></p>
"
"<p>The standard doesn't specify the order of evaluation of arguments with this line:</p>

<blockquote>
  <p>The order of evaluation of arguments is unspecified.</p>
</blockquote>

<p>What does</p>

<blockquote>
  <p>Better code can be generated in the absence of restrictions on
  expression evaluation order</p>
</blockquote>

<p>imply? </p>

<p>What is the drawback in asking all the compilers to evaluate the function arguments Left to Right for example? What kinds of optimizations do compilers perform because of this unspecified spec?</p>
","922184","","<p>Allowing the compiler to re-order the evaluation of the operands adds more room for optimization.</p>

<p>Here's a completely made up example for illustration purposes.</p>

<p>Suppose the processor can:</p>

<ul>
<li>Issue 1 instruction each cycle.</li>
<li>Execute an addition in 1 cycle.</li>
<li>Execute a multiplication in 3 cycles.</li>
<li>Can execute additions and multiplications at the same time.</li>
</ul>

<p>Now suppose you have a function call as follows:</p>

<pre><code>foo(a += 1, b += 2, c += 3, d *= 10);
</code></pre>

<p>If you were to execute this left-to-right on a processor without <a href=""http://en.wikipedia.org/wiki/Out-of-order_execution"">OOE</a>:</p>

<pre><code>Cycle - Operation
0     -    a += 1
1     -    b += 2
2     -    c += 3
3     -    d *= 10
4     -    d *= 10
5     -    d *= 10
</code></pre>

<p>Now if you allow the compiler to re-order them: (and start the multiplication first)</p>

<pre><code>Cycle - Operation
0     -    d *= 10
1     -    a += 1, d *= 10
2     -    b += 2, d *= 10
3     -    c += 3
</code></pre>

<p>So 6 cycles vs. 4 cycles.</p>

<p>Again this is completely contrived. Modern processors are much more complicated than that. But you get the idea.</p>
"
"<p>This is kind of obscure, but I need a function that can be computed very quickly and resembles  a^b where a is between 0 and 1 and b is very large. It will be calculated for one a at a time for many b's. Ideally, the result would be within 0.4%. Thanks in advance.</p>
","922184","","<p>Pulling my comments into an answer:</p>

<p>Since you mention that <code>b</code> is large enough to be rounded to an integer, then one approach is to use the <a href=""http://en.wikipedia.org/wiki/Exponentiation_by_squaring"" rel=""nofollow"">Binary Exponentiation algorithm</a> by squaring.</p>

<p><code>Math.pow()</code> is slow because it needs to handle non-integral powers. So might be possible to do better in your case because you can utilize the integer powering algorithms.</p>

<hr>

<p>As always, benchmark your implementation to see if it actually is faster than <code>Math.pow()</code>.</p>

<hr>

<p>Here's an implementation that the OP found:</p>

<pre><code>public static double pow(double a, int b) {
    double result = 1;
    while(b &gt; 0) {
        if (b % 2 != 0) {
            result *= a;
            b--;
        } 
        a *= a;
        b /= 2;
    }

    return result;

}
</code></pre>

<hr>

<p>Here's my quick-and-dirty (unoptimized) implementation:</p>

<pre><code>public static double intPow(double base,int pow){
    int c = Integer.numberOfLeadingZeros(pow);

    pow &lt;&lt;= c;

    double value = 1;
    for (; c &lt; 32; c++){
        value *= value;
        if (pow &lt; 0)
            value *= base;
        pow &lt;&lt;= 1;
    }

    return value;
}
</code></pre>

<p>This should work on all positive <code>pow</code>. But I haven't benchmarked it against <code>Math.pow()</code>.</p>
"
"<p>I am looking at some assembly that was generated by disassembling some C programs and I am confused by a single optimization that I see repeated frequently.</p>

<p>When I have no optimizations on the GCC compiler uses the <code>subl</code> instruction for subtraction, but when I do have optimizations turned on (<code>-O3</code> to be precise) the compiler uses a <code>leal</code> instruction instead of subtraction, example below: </p>

<p>without optimizations: </p>

<pre><code>83 e8 01     subl $0x1, %eax 
</code></pre>

<p>with optimizations </p>

<pre><code>8d 6f ff     leal -0x1(%edi), %ebp 
</code></pre>

<p>Both of these instructions are 3 bytes long, so I am not seeing an optimization here. Could someone help me out and try to explain the compiler's choice ?</p>

<p>Any help would be appreciated.</p>
","922184","","<p>It's hard to tell without seeing the original C code that produces this.</p>

<p>But if I had to guess, it's because the <code>leal</code> allows the subtraction to be done out-of-place without destroying the source register.</p>

<p>This can save an extra register move.</p>

<hr>

<p>The first example:</p>

<pre><code>83 e8 01     subl $0x1, %eax 
</code></pre>

<p>overwrites <code>%eax</code> thereby destroying the original value.</p>

<p>The second example :</p>

<pre><code>8d 6f ff     leal -0x1(%edi), %ebp 
</code></pre>

<p>stores <code>%edi - 1</code> into <code>%ebp</code>. <code>%edi</code> is preserved for future use.</p>
"
"<p>I am in the process of optimizing my code for matrix multiplication. </p>

<pre><code>for (int i = 0; i &lt; SIZE; i++) {
    for (int j = 0; j &lt; SIZE; j++) {
        float tmp = 0;
        for (int k = 0; k &lt; SIZE; k+=4) {
            v1 = _mm_load_ps(&amp;m1[i][k]);
            v2 = _mm_load_ps(&amp;m2[j][k]);
            vMul = _mm_mul_ps(v1, v2);

            vRes = _mm_add_ps(vRes, vMul);
        }
        vRes = _mm_hadd_ps(vRes, vRes);
        vRes = _mm_hadd_ps(vRes, vRes);
        _mm_store_ss(&amp;result[i][j], vRes);
    }
}
</code></pre>

<p>But <code>g++</code> complains that ""*'_mm_hadd_ps' was not declared in this scope*"". Why is that, I am able to use other SSE functions like <code>_mm_add_ps</code> ...</p>
","922184","","<p>Horizontal add instructions (such as <code>_mm_hadd_ps</code>) are part of SSE3. All the other ones that you are currently using are SSE.</p>

<p>It seems that you've only included the SSE or SSE2 headers.</p>

<p>So you'll need the SSE3 header:</p>

<pre><code>#include &lt;pmmintrin.h&gt;
</code></pre>

<p>It will enable:</p>

<ul>
<li><code>_mm_addsub_ps</code></li>
<li><code>_mm_addsub_pd</code></li>
<li><code>_mm_hadd_ps</code></li>
<li><code>_mm_hadd_pd</code></li>
<li><code>_mm_hsub_ps</code></li>
<li><code>_mm_hsub_pd</code></li>
<li><code>_mm_movehdup_ps</code></li>
<li><code>_mm_movehdup_pd</code></li>
<li><code>_mm_moveldup_ps</code></li>
<li><code>_mm_moveldup_pd</code></li>
<li><code>_mm_lddqu_si128</code></li>
</ul>
"
"<p>I was wondering how can matlab multiply two matrices so fast. When multiplying two NxN matrices, N^3 multiplications are performed.  Even with the <a href=""http://en.wikipedia.org/wiki/Strassen_algorithm"" rel=""nofollow"">Strassen Algorithm</a> it takes N^2.8 multiplications, which is still a large number. I was running the following test program:</p>

<pre><code>a = rand(2160);
b = rand(2160);
tic;a*b;toc
</code></pre>

<p>2160 was used because 2160^3=~10^10 ( a*b should be about  10^10 multiplications)</p>

<p>I got:</p>

<pre><code>Elapsed time is 1.164289 seconds.
</code></pre>

<p>(I'm running on 2.4Ghz notebook and no threading occurs)
which mean my computer made ~10^10 operation in a little more than 1 second. </p>

<p>How this could be??</p>
","922184","","<p>It's a combination of several things:</p>

<ul>
<li>Matlab does indeed multi-thread.</li>
<li>The core is heavily optimized with vector instructions.</li>
</ul>

<p>Here's the numbers on my machine: Core i7 920 @ 3.5 GHz (4 cores)</p>

<pre><code>&gt;&gt; a = rand(10000);
&gt;&gt; b = rand(10000);
&gt;&gt; tic;a*b;toc
Elapsed time is 52.624931 seconds.
</code></pre>

<p>Task Manager shows 4 cores of CPU usage.</p>

<p>Now for some math:</p>

<pre><code>Number of multiplies = 10000^3 = 1,000,000,000,000 = 10^12

Max multiplies in 53 secs =
    (3.5 GHz) * (4 cores) * (2 mul/cycle via SSE) * (52.6 secs) = 1.47 * 10^12
</code></pre>

<p>So Matlab is achieving about <code>1 / 1.47 = 68%</code> efficiency of the maximum possible CPU throughput.</p>

<p>I see nothing out of the ordinary.</p>
"
"<p>In trying to determine the cache size for a given CPU, I tried to time the memory access to memory/cache like: </p>

<pre><code>lengthMod = sizes[i]/sizeof(int)  - 1; // where sizes[i] is something like 1024, 2048 ... 
for (unsigned int k = 0; k &lt; REPS; k++) {
    data[(k * 16) &amp; lengthMod]++;
}

1, 0.52 
4, 0.52 
8, 0.52 
16, 0.52 
32, 0.52 
64, 1.11 // &lt;&lt; note the jump in timing. L1 cache size is 32K
128, 1.12 
256, 1.19 
</code></pre>

<p>So I think if the lengthMod is not a power of 2, I cant do this. So I tried doing </p>

<pre><code>lengthMod = sizes[i]/sizeof(int);
for (unsigned int k = 0; k &lt; REPS; k++) {
    data[(k * 16) % lengthMod]++;
}

1, 2.67 
4, 2.57 
8, 2.55 
16, 2.51 
32, 2.42 
64, 2.42 // &lt;&lt; no jump anymore ...
128, 2.42 
256, 2.42
</code></pre>

<p>Then I find that the timing increase that I expected is non-existant anymore ... I expected the time to increase but it should apply to all values? So if its <code>x</code> seconds when using <code>&amp;</code>, I'd expect <code>~x+c</code> seconds (where <code>c</code> is approximatly constant), but thats not the case, in fact, it reduces the timing difference to non-existant why is that? </p>
","922184","","<p>What you're seeing is a trade-off of bottlenecks.</p>

<ul>
<li>In the first example, you are bottlenecked by your cache bandwidth.</li>
<li>In the second example, you are bottlenecked by integer division.</li>
</ul>

<p>Before we continue, let's look at the difference between the two examples:</p>

<ul>
<li>In the first case, you use <code>&amp;</code> which is a fast bitwise operation.</li>
<li>In the second case, you use <code>%</code> which is very slow division.</li>
</ul>

<p>Divisions are <em>very</em> slow. Modern compilers will try to optimize them when the divisor/modulus is a compile-time constant.</p>

<p>But that's not the case here. <strong><em>So you pay the full cost of a hardware division.</em></strong> This is why the times in your second example are much slower than the first.</p>

<hr>

<p>With the <code>&amp;</code>, the code is fast enough to max out the cache bandwidth. However, with <code>%</code>, the code is much slower - not fast enough to keep up with the cache. So you see the same times all the way up.</p>
"
"<p>In my Intel x86 Pentium handbook it says that ADD and shifts like SAL/SHR take 1/3 clock compared to things like JMP and MOV that take 1 clock. Is this really true that a bunch of adds and shifts will 3 times faster than a bunch of movs?</p>

<p>I guess I am doubly confused because there is table of ""latencies"" on the web showing ""Pentium M"" and none of timings are 1/3, although a few are 1/2. Is this because my book is old and on newer Pentiums shift is the same speed as JMP?</p>
","922184","","<p>Don't confuse ""latency"" with ""reciprocal throughput"".</p>

<ul>
<li><strong>Latency</strong> is how many cycles it takes to execute one instance of the instruction.</li>
<li><strong>Reciprocal Throughput</strong> is how many instructions per cycle that the processor can sustain.</li>
</ul>

<p>That <code>1/3</code> that you are seeing isn't the latency. It's the reciprocal throughput. The processor can sustain 3 ADDs per cycle. (if they are all independent) But each one still takes at least 1 cycle to execute.</p>

<p>If you have latency <code>1</code> and reciprocal throughput of <code>1/3</code>, that means that the processor can execute up to 3 ADDs simultaneously. But each one still takes 1 cycle.</p>

<hr>

<p>Historically, most Intel processors (since Pentium?) have 3 main execution units that can all do basic operations such as additions and shifts. That's why most of these are <code>1/3</code> reciprocal throughput.</p>

<p>Register-to-register MOVs should also be <code>1/3</code>. But MOVs that touch memory (ie. loads and stores) are historically only 1/cycle. (Recently with Sandy Bridge and later, this has been increased.)</p>
"
"<p>Consider the following</p>

<pre><code>while(true)
{
    if(x&gt;5)
     // Run function A
    else
     // Run function B
}
</code></pre>

<p>if x is always less than 5, does visual studio compiler do any optimization? i.e. like never checks if x is larger than 5 and always run function B</p>
","922184","","<p>It depends on whether or not the compiler ""knows"" that <code>x</code> will always be less than <code>5</code>.</p>

<p>Yes, nearly all modern compilers are capable of removing the branch. But the compiler needs to be able to <em>prove</em> that the branch will always go one direction.</p>

<hr>

<p>Here's an example that <strong>can</strong> be optimized:</p>

<pre><code>int x = 1;

if (x &gt; 5)
    printf(""Hello\n"");
else
    printf(""World\n"");
</code></pre>

<p>The disassembly is:</p>

<pre><code>    sub rsp, 40                 ; 00000028H
    lea rcx, OFFSET FLAT:??_C@_06DKJADKFF@World?6?$AA@
    call    QWORD PTR __imp_printf
</code></pre>

<p><code>x = 1</code> is provably less than <code>5</code>. So the compiler is able to remove the branch.</p>

<hr>

<p>But in this example, even if you always input less than 5, the compiler doesn't know that. It must assume any input.</p>

<pre><code>int x;
cin &gt;&gt; x;

if (x &gt; 5)
    printf(""Hello\n"");
else
    printf(""World\n"");
</code></pre>

<p>The disassembly is:</p>

<pre><code>    cmp DWORD PTR x$[rsp], 5
    lea rcx, OFFSET FLAT:??_C@_06NJBIDDBG@Hello?6?$AA@
    jg  SHORT $LN5@main
    lea rcx, OFFSET FLAT:??_C@_06DKJADKFF@World?6?$AA@
$LN5@main:
    call    QWORD PTR __imp_printf
</code></pre>

<p>The branch stays. But note that it actually hoisted the function call out of the branch. So it really optimized the code down to something like this:</p>

<pre><code>const char *str = ""Hello\n"";

if (!(x &gt; 5))
    str = ""World\n"";

printf(str);
</code></pre>
"
"<p>I'm attempting to implement circular bit-shifting in C++. It kind of works, except after a certain point I get a bunch of zeroes.</p>

<pre><code>for (int n=0;n&lt;12;n++) {
    unsigned char x=0x0f;
    x=((x&lt;&lt;n)|(x&gt;&gt;(8-n))); //chars are 8 bits
    cout&lt;&lt;hex&lt;&lt;""0x""&lt;&lt;(int)x&lt;&lt;endl;
}
</code></pre>

<p>My output is:</p>

<pre><code>0xf
0x1e
0x3c
0x78
0xf0
0xe1
0xc3
0x87
0xf
0x0
0x0
0x0
</code></pre>

<p>As you can see, I start getting 0x0's instead of the expected 0x1e, 0x3c, etc.</p>

<p>If I expand the for loop to iterate 60 times or so, the numbers come back correctly (after a bunch of zeroes.) </p>

<p>I'm assuming that a char houses a big space, and the ""gaps"" of unused data are zeroes. My understanding is a bit limited, so any suggestions would be appreciated. Is there a way to toss out those zeroes?</p>
","922184","","<p>Shifting by a negative amount is undefined behavior.</p>

<p>You loop from <code>0</code> to <code>12</code>, but you have an <code>8 - n</code> in your shifts. So that will go negative.</p>

<p>If you want to handle <code>n &gt; 8</code>, you'll need to take a modulus by 8. (assuming you want 8-bit circular shift.)</p>

<hr>

<pre><code>for (int n=0; n &lt; 12; n++) {
    unsigned char x = 0x0f;
    int shift = n % 8;   //  Wrap modulus
    x = ((x &lt;&lt; shift) | (x &gt;&gt; (8 - shift))); //chars are 8 bits
    cout &lt;&lt; hex &lt;&lt; ""0x"" &lt;&lt; (int)x &lt;&lt; endl;
}
</code></pre>
"
"<p>I've often noticed gcc converting multiplications into shifts in the executable. Something similar might happen when multiplying an <code>int</code> and a <code>float</code>. For example, <code>2 * f</code>, might simply increment the exponent of <code>f</code> by 1, saving some cycles. Do the compilers, perhaps if one requests them to do so (e.g. via <code>-ffast-math</code>), in general, do it?</p>

<p>Are compilers generally smart enough to do this, or do I need to do this myself using the <code>scalb*()</code> or <code>ldexp()/frexp()</code> function family?</p>
","922184","","<blockquote>
  <p>For example, 2 * f, might simply increment the exponent of f by 1,
  saving some cycles.</p>
</blockquote>

<p>This simply isn't true.</p>

<p>First you have too many corner cases such as zero, infinity, Nan, and denormals. Then you have the performance issue.</p>

<p><em>The misunderstanding is that incrementing the exponent is not faster than doing a multiplication.</em></p>

<p>If you look at the hardware instructions, there is no direct way to increment the exponent.
So what you need to do instead is:</p>

<ol>
<li>Bitwise convert into integer.</li>
<li>Increment the exponent.</li>
<li>Bitwise convert back to floating-point.</li>
</ol>

<p>There is generally a medium to large latency for moving data between the integer and floating-point execution units. So in the end, this ""optimization"" becomes much worse than a simple floating-point multiply.</p>

<p>So the reason why the compiler doesn't do this ""optimization"" is because it isn't any faster.</p>
"
"<p>What does bandwidth demand mean?
I've seen it being used in this paragraph: </p>

<blockquote>
  <p>""Memory must be distributed among the processors rather than
  centralized; otherwise the memory system would not be able to support
  the <strong>bandwidth demands</strong> of a large number of processors without
  incurring long access latency""</p>
</blockquote>
","922184","","<p>In this case, ""bandwidth demand"" refers the amount of memory bandwidth a large distributed application needs. It mainly refers to the combined amount of traffic between the nodes in the system.</p>

<hr>

<p>Consider a city with streets and roads. Every day, people need to get to and from work. The total number of people who need to get from point A to point B is the <strong>bandwidth demand</strong>.</p>

<p>Depending on the size of the city, this can be a very large number.</p>

<p><em>What would happen if you made everyone work in the same place?</em></p>

<p>Each morning, everybody gets up and converges on the same ""work district"". What's the result?</p>

<h1>Traffic!</h1>

<p><img src=""http://i.stack.imgur.com/dLp7v.jpg"" alt=""""></p>

<p><sub>Image by NOMAD, from Wikipedia Commons: <a href=""http://en.wikipedia.org/wiki/File:Trafficjamdelhi.jpg"" rel=""nofollow"">http://en.wikipedia.org/wiki/File:Trafficjamdelhi.jpg</a></sub></p>

<p>Everybody gets stuck in traffic and they take forever to get to work (high access latency).</p>

<hr>

<p>A distributed computing system isn't too different from a city. If you don't distribute your memory correctly, you will have bandwidth congestion on certain channels in the network.</p>

<p>For example, if all your data is concentrated on node X and all the other nodes need to access that data, you will overwhelm all the data channels going to and from node X.</p>

<p>On the contrary, a better designed system will distribute the data evenly across the network and close to the processors that will use them. This cuts down on traffic congestion by shortening commute times and splitting up the traffic over all the channels rather than just one or a few.</p>

<hr>

<p>The point that the quote is saying is that you need to properly distribute memory in order to satisfy the high bandwidth demands of the application.</p>
"
"<p>I have the following for loop. When I switch on the type array the code doesn't vectorize. When I fix type to '1' gcc performs a primitize vectorization vectorizes. Does anybody have any reccomendtions to trigger some kind of vectorization? </p>

<pre><code>#define type(M,N) type[(M)*sizeX + (N)]
for (int i = 0; i &lt; sizeY - 1; i++)
{
    for (int j = 0; j &lt; sizeX - 1; j++)
    {
       const int id = type(i, j);
       //const int id = 1; //vectorizes
       const float A = this-&gt;A[id];
       const float B = this-&gt;B[id];
       a(i, j) = A * a(i, j) + B * (b(i, j) - b(i + 1, j))*(p[i]);
    }
 }
</code></pre>

<p>The approximate error from gcc 4.7.1</p>

<pre><code>45: not vectorized: not suitable for gather A_26 = *D.14145_25;
</code></pre>

<p>Edit 1</p>

<p>All of the arrays are stored as pointers and are defined with the <strong>restrict</strong> keyword as members of some class.</p>

<p>Edit 2</p>

<p>Is there something I can do if '<code>type</code>' is small?</p>

<p>Edit 3</p>

<p>Small means 8. </p>
","922184","","<p>The difference is the memory access.</p>

<p>When <code>id = 1</code>, the following array loads become a single element vector broadcast.</p>

<pre><code> const float A = this-&gt;A[id];
 const float B = this-&gt;B[id];
</code></pre>

<p>But when <code>id = type[(i)*sizeX + (k)]</code>, the memory access is strided (not contiguous).</p>

<p>Vector loads and stores in SSE and AVX can only be done on:</p>

<ol>
<li>Contiguous memory blocks.</li>
<li>Or from a single element that is broadcast to the entire vector.</li>
</ol>

<p>They cannot handle strided memory access where you load each of the vector elements from different parts of memory.</p>

<p>AVX2 will have support for such ""gather/scatter"" instructions.</p>

<hr>

<p>To address the edits:</p>

<p>If the <code>i</code> in <code>type(i, j)</code> is anything other than zero, the memory access is still strided. So it will be difficult to vectorize. (I say ""difficult"" instead of ""impossible"", because it is possible for very small compile-time-deterimined strides - albeit at reduced efficiency.)</p>

<p>The core problem you have here is that you're iterating down rows of a matrix. Not only is this not vectorizable without gather/scatter support, but it's also bad for cache.</p>

<p>I'm not sure what task you're trying to accomplish, but you may need to consider a different data-layout to get maximum performance.</p>
"
"<p>The <code>_mm_shuffle_ps()</code> intrinsic allows one to interleave float inputs into low 2 floats and high 2 floats of the output.</p>

<p>For example: </p>

<pre><code>R = _mm_shuffle_ps(L1, H1, _MM_SHUFFLE(3,2,3,2))
</code></pre>

<p>will result in: </p>

<pre><code>R[0] = L1[2];
R[1] = L1[3];
R[2] = H1[2];
R[3] = H1[3]
</code></pre>

<p>I wanted to know if there was a similar intrinsic available for the integer data type? Something that took two <code>__m128i</code> variables and a mask for interleaving?</p>

<p>The <code>_mm_shuffle_epi32()</code> intrinsic, takes just one 128-bit vector instead of two. </p>
","922184","","<p>Nope, there is no integer equivalent to this. So you have to either emulate it, or cheat.</p>

<p>One method is to use <code>_mm_shuffle_epi32()</code> on <code>A</code> and <code>B</code>. Then mask out the desired terms and OR them back together.</p>

<p>That tends to be messy and has around 5 instructions. (Or 3 if you use the SSE4.1 blend instructions.)</p>

<p>Here's the SSE4.1 solution with 3 instructions:</p>

<pre><code>__m128i A = _mm_set_epi32(13,12,11,10);
__m128i B = _mm_set_epi32(23,22,21,20);

A = _mm_shuffle_epi32(A,2*1 + 3*4 + 2*16 + 3*64);
B = _mm_shuffle_epi32(B,2*1 + 3*4 + 2*16 + 3*64);

__m128i C = _mm_blend_epi16(A,B,0xf0);
</code></pre>

<hr>

<p>The method that I prefer is to actually cheat - and floating-point shuffle like this:</p>

<pre><code>__m128i Ai,Bi,Ci;
__m128  Af,Bf,Cf;

Af = _mm_castsi128_ps(Ai);
Bf = _mm_castsi128_ps(Bi);
Cf = _mm_shuffle_ps(Af,Bf,_MM_SHUFFLE(3,2,3,2));
Ci = _mm_castps_si128(Cf);
</code></pre>

<p>What this does is to convert the datatype to floating-point so that it can use the float-shuffle. Then convert it back.</p>

<p>Note that these ""conversions"" are bitwise conversions (aka reinterpretations). No conversion is actually done and they don't map to any instructions. In the assembly, there is no distinction between an integer or a floating-point SSE register. These cast intrinsics are just to get around the type-safety imposed by C/C++.</p>

<p>However, be aware that this approach incurs extra latency for moving data back-and-forth between the integer and floating-point SIMD execution units. So it will be more expensive than just the shuffle instruction.</p>
"
"<p>Can I have a union like this</p>

<pre><code>  union eight_floats_t
  {
    __m256 a;
    __m128 b[2];
  };
  eight_floats_t eight_floats;
</code></pre>

<p>to have an instant access to the two 128 bit parts of a 256 bit register?</p>

<p>Edit: I was asking to understand the performance impact of this approach.</p>
","922184","","<p>You certainly can do that. The C and C++ languages allow you do it. And it will most likely do what you want it to do.</p>

<p>However, the fact that you're using AVX means you care about performance. So it might be useful to know that this is one of the most common (performance) traps that SSE programmers fall into. (and many don't notice)</p>

<p><strong>Problem 1:</strong></p>

<p>Current compilers implement such a union using a memory location. So that's the first problem, every time you access the union from a different field, it forces the data to memory and reads it back. That's one slow-down.</p>

<p>Here's what MSVC2010 generates for (with optimizations):</p>

<pre><code>eight_floats a;
a.a = vecA[0];

__m128 fvecA = a.b[0];
__m128 fvecB = a.b[1];
fvecA = _mm_add_ps(fvecA,fvecB);
</code></pre>

<p></p>

<pre><code>vmovaps YMMWORD PTR a$[rbp], ymm0
movaps  xmm1, XMMWORD PTR a$[rbp+16]
addps   xmm1, XMMWORD PTR a$[rbp]
movaps  XMMWORD PTR fvecA$[rbp], xmm1
movss   xmm1, DWORD PTR fvecA$[rbp]
</code></pre>

<p>You can see that it's being flushed to memory.</p>

<p><strong>Problem 2:</strong></p>

<p>The second slow-down is even worse. When you write something to memory, and immediately access it with a different word-size, you will likely trigger a store-to-load stall. (typically on the order of > 10 cycles)</p>

<p>This is because the load-store queues on current processors aren't usually designed to handle this (unusual) situation. So they deal with it by simply flushing the queues to memory.</p>

<hr>

<p>The ""correct"" way to access the lower and upper half of AVX datatypes is to use:</p>

<ul>
<li><code>_mm256_extractf128_ps()</code></li>
<li><code>_mm256_insertf128_ps()</code></li>
<li><code>_mm256_castps256_ps128()</code></li>
</ul>

<p>and family. Likewise for the other datatypes as well.</p>

<p>That said, it is possible that the compiler may be smart enough to recognize what you are doing and use those instructions anyway. (At least MSVC2010 doesn't.)</p>
"
"<p>I am trying to write the equivalent of an if statement with SSE intrinsics.</p>

<p>I am using <code>__m128 _mm_cmplt_ps(__m128 a, __m128 b)</code> to do the comparison a &lt; b, and this returns <code>0xffffffff</code> or <code>0x0</code> if the comparison was respectively true or false. I would like to convert these values into 1 and 0. In order to do this, is it correct to implement the logical ""and"" <code>__m128 _mm_and_ps(__m128 c , __m128 d)</code>, where <code>c</code> is the result of the conversion and <code>d</code> is, e.g., <code>0xffffffff</code>?</p>

<p>Thank you for your attention.</p>
","922184","","<p>You're comparing to get a <code>1</code> or a <code>0</code>, then multiplying by another number. That is essentially this:</p>

<pre><code>c = (a &lt; b) * d;
</code></pre>

<p>which is the same as this:</p>

<pre><code>c = 0;
if (a &lt; b)
    c = d;
</code></pre>

<p>This is also known as a conditional move.</p>

<p>If that's what you want, then you don't need the <code>0</code> or the <code>1</code>. Just AND the result of the compare directly with the number you will multiply with.</p>

<pre><code>__m128 c = _mm_cmplt_ps(a,b);
c = _mm_and_ps(c,d);
</code></pre>

<p>This works because the comparison returns either all <code>0</code>'s or all <code>1</code>'s. So ANDing them with the result will either zero it, or keep it entirely.</p>

<p>It was intentionally designed that way. There's no need for a multiplication.</p>
"
"<p>I've recently tried to experiment with OpenMP in Visual Studio to learn how to multi-thread my program. </p>

<p>If I try to execute this code serially:</p>

<pre><code>int totalSum = 0;

for(int x=0; x &lt; 100; x++)
{
    for(int y=0; y &lt; 100; y++)
    {
        totalSum = totalSum + x + y;
    }
}  
</code></pre>

<p>What I end up with is that <strong>totalSum  = 990000</strong></p>

<p>When I try to merely add OpenMP functionality by saying:</p>

<pre><code>#pragma omp parallel for
    for(int x=0; x &lt; 100; x++)
    {

        for(int y=0; y &lt; 100; y++)
        {
            totalSum = totalSum + x + y;
        }
    }
</code></pre>

<p>I end up with <strong>totalSum  = 491293</strong> or 596865 or 638260 etc...</p>

<p>Clearly what is happening is that race conditions seem to be occurring and depending on which thread accesses totalSum first, the final answer differs.</p>

<p>What am I doing incorrectly? x and y are correctly defined as private variables (since they are created within the parallel region).</p>

<p>What can I do to ensure that I get the same answer when I am multi-threading the program compared to when I am executing it serially?</p>
","922184","","<p>The fix is to use the <code>reduction</code> clause:</p>

<pre><code>int totalSum = 0;

#pragma omp parallel for reduction(+:totalSum)  //  reduction
for(int x=0; x &lt; 100; x++)
{

    for(int y=0; y &lt; 100; y++)
    {
        totalSum = totalSum + x + y;
    }
}
</code></pre>

<p>Read up on the OpenMP reduction clause and then you'll understand how it works.</p>
"
"<p>I want to calculate <i>e</i> to 2 trillion (2,000,000,000,000) digits. This is about 1,8 TiB of pure <i>e</i>. I just implemented a taylor series expansion algorithm using <a href=""http://gmplib.org/"">GMP</a> (<a href=""https://gist.github.com/4047379"">code can be found here</a>).</p>

<p>Unfortuanetly it crashes when summing more than 4000 terms on my computer, probably because it runs out of memory.</p>

<p>What is the current state of the art in computing <i>e</i>? Which algorithm is the fastest? Any open source implementations that are worth looking at? Please don't mention <i>y-cruncher</i>, it's closed source.</p>
","922184","","<p>Since I'm the author of the <a href=""http://www.numberworld.org/y-cruncher/"">y-cruncher</a> program that you mention, I'll add my 2 cents.</p>

<p>For such a large task, the two biggest barriers that must be tackled are as follows:</p>

<ol>
<li>Memory</li>
<li>Run-time Complexity</li>
</ol>

<p><strong>Memory</strong></p>

<p>2 trillion digits is <em>extreme</em> - to say the least. That's double the <a href=""http://www.numberworld.org/digits/E/"">current record set by Shigeru Kondo and myself back in 2010</a>. (It took us more than 9 days to compute 1 trillion digits using y-cruncher.)</p>

<p>In plain text, that's about 1.8 TiB in decimal. In packed binary representation, that's 773 GiB.</p>

<p>If you're going to be doing arithmetic on numbers of this size, you're gonna need <strong>773 GiB for each operand</strong> not counting scratch memory.</p>

<p>Feasibly speaking, y-cruncher actually needs <strong>8.76 TiB of memory</strong> to do this computation all in ram. So you can expect other implementations to need the same give or take a factor of 2 at most.</p>

<p>That said, I doubt you're gonna have enough ram. And even if you did, it'd be heavily NUMA. So the alternative is to use disk. But this is not trivial, as to be efficient, you need to treat memory as a cache and micromanage all data that is transferred between memory and disk.</p>

<hr>

<p><strong>Run-time Complexity</strong></p>

<p>Here we have the other problem. For 2 trillion digits, you're gonna need a very fast algorithm. Not just any fast algorithm, but a quasi-linear run-time algorithm.</p>

<p>Your current attempt runs in about <code>O(N^2)</code>. So even if you had enough memory, it won't finish in your lifetime.</p>

<p>The standard approach to computing <code>e</code> to high precision runs in <code>O(N log(N)^2)</code> and combines the following algorithms:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Binary_splitting"">Binary Splitting</a> on the Taylor series expansion of <code>e</code>.</li>
<li><a href=""http://numbers.computation.free.fr/Constants/Algorithms/fft.html"">FFT-based large multiplication</a></li>
</ul>

<p>Fortunately, GMP already uses FFT-based large multiplication. But it lacks two crucial features:</p>

<ol>
<li>Out-of-core (swap) computation to use disk when there isn't enough memory.</li>
<li>It isn't parallelized.</li>
</ol>

<p>The second point isn't as important since you can just wait longer. But for all practical purposes, you're probably gonna need to roll out your own. And that's what I did when I wrote y-cruncher.</p>

<hr>

<p>That said, there are many other loose-ends that also need to be taken care of:</p>

<ol>
<li>The final division will require a fast algorithm like Newton's Method.</li>
<li>If you're gonna compute in binary, you're gonna need to do a radix conversion.</li>
<li>If the computation is gonna take a lot of time and a lot of resources, you may need to implement fault-tolerance to handle hardware failures.</li>
</ol>
"
"<p><img src=""http://i.stack.imgur.com/s9nGb.png"" alt=""enter image description here""></p>

<p>I've problem with the size of <code>long int</code> on a 16-bit CPU. Looking at its architecture:</p>

<p><img src=""http://i.stack.imgur.com/iV38C.jpg"" alt=""enter image description here""></p>

<p>No register is more than 16-bit long. So, how come <code>long int</code> can have more than 16bits. In fact, according to me for any Processor, the maximum size of the data type must be the size of the general purpose register. Am I right?</p>
","922184","","<p>Yes. In fact the C and C++ standards require that <code>sizeof(long int) &gt;= 4</code>.*</p>

<p>(I'm assuming <code>CHAR_BIT == 8</code> in this case.)</p>

<p>This is the same deal with 64-bit integers on 32-bit machines. The way it is implemented is to use two registers to represent the lower and upper halves.</p>

<p>Addition and subtraction are done as two instructions:</p>

<p>On x86:</p>

<ul>
<li>Addition: <code>add</code> and <code>adc</code> where <code>adc</code> is ""add with carry""</li>
<li>Subtraction: <code>sub</code> and <code>sbb</code> where <code>sbb</code> is ""subtract with borrow""</li>
</ul>

<p>For example:</p>

<pre><code>long long a = ...;
long long b = ...;

a += b;
</code></pre>

<p>will compile to something like:</p>

<pre><code>add eax,ebx
adc edx,ecx
</code></pre>

<p>Where <code>eax</code> and <code>edx</code> are the lower and upper parts of <code>a</code>. And <code>ebx</code> and <code>ecx</code> are the lower and upper parts of <code>b</code>.</p>

<p>Multiplication and division for double-word integers is more complicated, but it follows the same sort of grade-school math - but where each ""digit"" is a processor word.</p>
"
"<p>If I have an AVX register with 4 doubles in them and I want to store the reverse of this in another register, is it possible to do this with a single intrinsic command?</p>

<p>For example: If I had 4 floats in a SSE register, I could use:</p>

<pre><code>_mm_shuffle_ps(A,A,_MM_SHUFFLE(0,1,2,3));
</code></pre>

<p>Can I do this using, maybe <code>_mm256_permute2f128_pd()</code>? I don't think you can address each individual double using the above intrinsic.</p>
","922184","","<p>You actually need 2 permutes to do this:</p>

<ul>
<li><code>_mm256_permute2f128_pd()</code> only permutes in 128-bit chunks.</li>
<li><code>_mm256_permute_pd()</code> does not permute across 128-bit boundaries.</li>
</ul>

<p>So you need to use both:</p>

<pre><code>inline __m256d reverse(__m256d x){
    x = _mm256_permute2f128_pd(x,x,1);
    x = _mm256_permute_pd(x,5);
    return x;
}
</code></pre>

<p>Test:</p>

<pre><code>int main(){
    __m256d x = _mm256_set_pd(13,12,11,10);

    cout &lt;&lt; x.m256d_f64[0] &lt;&lt; ""  "" &lt;&lt; x.m256d_f64[1] &lt;&lt; ""  "" &lt;&lt; x.m256d_f64[2] &lt;&lt; ""  "" &lt;&lt; x.m256d_f64[3] &lt;&lt; endl;
    x = reverse(x);
    cout &lt;&lt; x.m256d_f64[0] &lt;&lt; ""  "" &lt;&lt; x.m256d_f64[1] &lt;&lt; ""  "" &lt;&lt; x.m256d_f64[2] &lt;&lt; ""  "" &lt;&lt; x.m256d_f64[3] &lt;&lt; endl;
}
</code></pre>

<p>Output:</p>

<pre><code>10  11  12  13
13  12  11  10
</code></pre>
"
"<p>I was looking at a program in IDA as i was trying to figure out how a certain function worked, when I came across something like this:</p>

<pre><code>; C_TestClass::Foo(void)
__text:00000000 __ZN14C_TestClass7FooEv proc near
__text:00000000                 jmp     __ZN14C_TestClass20Barr ; C_TestClass::Barr(void)
__text:00000000 __ZN14C_TestClass7FooEv endp
__text:00000000
</code></pre>

<p>Can anyone explain to me what exactly jumping to a function would do in a case like this?
I am guessing that it acts as a wrapper for the other function?</p>
","922184","","<p>You are correct that jumping is often a way to efficiently handle wrapper functions that aren't inlined.</p>

<p>Normally, you'd have to read all the function parameters and push them back onto the stack before you can call the sub-function.</p>

<p>But when the wrapper function has the exact same prototype:</p>

<ol>
<li>Same calling convention</li>
<li>Same parameters (and in the same order)</li>
<li>Same return type</li>
</ol>

<p>there's no need for all the usual function calling overhead. You can just jump directly to the target. (These categories may not be entirely necessary, as it may still be possible in some other cases.)</p>

<p>All the parameters (either on the stack or register) that were setup when calling the wrapper function will already be in place (and compatible) for the sub-function.</p>
"
"<p>I wrote two Matrix Multiplications programs in C++: Regular MM <a href=""http://pastebin.com/HqHtFpq9"" rel=""nofollow"">(source)</a>, and Strassen's MM <a href=""http://pastebin.com/USRQ5tuy"" rel=""nofollow"">(source)</a>, both of which operate on square matrices of sizes 2^k x 2^k(in other words, square matrices of even size). </p>

<p>Results are just terrible. For 1024 x 1024 matrix, Regular MM takes <code>46.381 sec</code>, while Strassen's MM takes <code>1484.303 sec</code> (<code>25 minutes</code> !!!!).</p>

<p>I attempted to keep the code as simple as possible. Other Strassen's MM examples found on the web are not that much different from my code. One issue with Strassen's code is obvious - I don't have cutoff point, that switches to regular MM. </p>

<p>What other issues my Strassen's MM code has ???  </p>

<p>Thanks !</p>

<p>Direct links to sources<br>
<a href=""http://pastebin.com/HqHtFpq9"" rel=""nofollow"">http://pastebin.com/HqHtFpq9</a><br>
<a href=""http://pastebin.com/USRQ5tuy"" rel=""nofollow"">http://pastebin.com/USRQ5tuy</a></p>

<p>Edit1.
Fist, a lot of great advices. Thank you for taking your time and sharing knowledge. </p>

<p>I implemented changes(kept all of my code), added cut-off point.
MM of 2048x2048 matrix, with cutoff 512 already gives good results.
Regular MM: 191.49s
Strassen's MM: 112.179s 
Significant improvement.
Results were obtained on prehistoric Lenovo X61 TabletPC with Intel Centrino processor, using Visual Studio 2012.
I will do more checks(to make sure I got the correct results), and will publish the results.</p>
","922184","","<blockquote>
  <p>One issue with Strassen's code is obvious - I don't have cutoff point,
  that switches to regular MM.</p>
</blockquote>

<p>It's fair to say that recursing down to 1 point is the bulk of (if not the entire) problem. Trying to guess at other performance bottlenecks without addressing this is almost moot due to the massive performance hit that it brings. (In other words, you're comparing Apples to Oranges.)</p>

<p>As discussed in the comments, cache alignment could have an effect, but not to this scale. Furthemore, cache alignment would likely hurt the regular algorithm more than the Strassen algorithm since the latter is cache-oblivious.</p>

<pre><code>void strassen(int **a, int **b, int **c, int tam) {

    // trivial case: when the matrix is 1 X 1:
    if (tam == 1) {
            c[0][0] = a[0][0] * b[0][0];
            return;
    }
</code></pre>

<p>That's far too small. While the Strassen algorithm has a smaller complexity, it has a much bigger Big-O constant. For one, you have function call overhead all the way down to 1 element.</p>

<p>This is analogous to using merge or quick sort and recursing all the way down to one element. To be efficient you need to stop the recursion when the size gets small and fall back to the classic algorithm.</p>

<p>In quick/merge sort, you'd fall back to a low-overhead <code>O(n^2)</code> insertion or selection sort. Here you would fall back to the normal <code>O(n^3)</code> matrix multiply.</p>

<hr>

<p>The threshold which you fall back the classic algorithm should be a tunable threshold that will likely vary depending on the hardware and the ability of the compiler to optimize the code.</p>

<p>For something like Strassen multiplication where the advantage is only <code>O(2.8074)</code> over the classic <code>O(n^3)</code>, don't be surprised if this threshold turns out to be very high. (thousands of elements?)</p>

<hr>

<p>In some applications there can be many algorithms each with decreasing complexity but increasing Big-O. The result is that multiple algorithms become optimal at different sizes.</p>

<p>Large integer multiplication is a notorious example of this:</p>

<ul>
<li>Grade-school Multiplication: <strong>O(N^2)</strong> optimal for &lt; ~100 digits*</li>
<li><a href=""http://en.wikipedia.org/wiki/Karatsuba_algorithm"">Karatsuba Multiplication</a>: <strong>O(N^1.585)</strong> faster than above at ~100 digits*</li>
<li><a href=""http://en.wikipedia.org/wiki/Toom%E2%80%93Cook_multiplication"">Toom-Cook 3-way</a>: <strong>O(N^1.465)</strong> faster than Karatsuba at ~3000 digits*</li>
<li><a href=""http://numbers.computation.free.fr/Constants/Algorithms/fft.html"">Floating-point FFT</a>: <strong>O(> N log(N))</strong> faster than Karatsuba/Toom-3 at ~700 digits*</li>
<li><a href=""http://en.wikipedia.org/wiki/Sch%C3%B6nhage%E2%80%93Strassen_algorithm"">Schönhage–Strassen algorithm (SSA)</a>: <strong>O(N log(n) loglog(n))</strong> faster than FFT at ~ a billion digits*</li>
<li><a href=""http://en.wikipedia.org/wiki/Discrete_Fourier_transform_%28general%29#Number-theoretic_transform"">Fixed-width Number-Theoretic Transform</a>: <strong>O(N log(n)</strong> faster than SSA at ~ a few billion digits?*</li>
</ul>

<p><sub>*Note these example thresholds are approximate and can vary drastically - often by more than a factor of 10.</sub></p>
"
"<p>When I compile a given file with the -opt-report or -vec-report options in ICC I get, among others, this message:</p>

<pre><code>foo.c(226:7-226:7):VEC:function_foo:  loop was not vectorized: subscript too complex
foo.c(226): (col. 7) warning #13379: loop was not vectorized with ""simd""
vectorization support: call to function absorbing_apply cannot be vectorized
loop was not vectorized: not inner loop
loop was not vectorized: unsupported loop structure
loop was not vectorized: subscript too complex
</code></pre>

<p>I know the meaning of these messages. What concerns me is that in  <code>foo.c:226</code> there isn't any loop at all. In fact, what is there is the invocation of another function. That function does contain some loops that operate through a volume and which indeed vectorizes properly as icc reports it.  However, all the calls to that function give the same messages as the ones I pasted. </p>

<p>Does icc get into a mess since it's showing vectorization messages in places with no loops at all? Or it's me that I misunderstood something?</p>

<p>EDIT: I have semi-replicated the issue. This time, the compiler tells that it vectorized a line of a code where there is a call to another function (in the original case is just the other way, it says that it cannot). Here is the code:</p>

<pre><code> 1 
 2 
 3 void foo(float *a, float *b, float *c, int n1, int n2, int n3, int ini3, int end3 ) {
 4    int i, j, k;
 5 
 6    for( i = ini3; i &lt; end3; i++ ) {
 7       for( j = 0; j &lt; n2; j++ ) {
 8        #pragma simd
 9        #pragma ivdep
10        for( k = 0; k &lt; 4; k ++ ) {
11          int index = k + j*n1 + i*n1*n2;
12          a[index] = b[index] + 2* c[index];
13        }
14      }
15    }
16 
17    for( i = ini3; i &lt; end3; i++ ) {
18       for( j = 0; j &lt; n2; j++ ) {
19        #pragma simd
20        #pragma ivdep
21        for( k = n1-4; k &lt; n1; k ++ ) {
22          int index = k + j*n1 + i*n1*n2;
23          a[index] = b[index] + 2* c[index];
24        }
25      }
26    }
27 
28   return;
29 }
30 int main(void){
31    int n1, n2, n3;
32    int ini3 = 20;
33    int end3 = 30;
34    n1 = n2 = n3 = 200;
35 
36    float *a = malloc( n1 * n2 * n3 * sizeof(float ));
37    float *b = malloc( n1 * n2 * n3 * sizeof(float ));
38    float *c = malloc( n1 * n2 * n3 * sizeof(float ));
39 
40    foo( a,b,c, n1, n2, n3, ini3, end3 );
41 
42    ini3 += 50;
43    end3 += 50;
44 
45    foo( a,b,c, n1, n2, n3, ini3, end3 );
46 
47    free(a); free(b); free(c);
48 
49   return 0;
50 }
51 
</code></pre>

<p>And the piece of the optimization report where ICC says it vectorized lines 40 and 45:</p>

<pre><code>foo.c(40:4-40:4):VEC:main:  LOOP WAS VECTORIZED
loop was not vectorized: not inner loop
loop was not vectorized: not inner loop
LOOP WAS VECTORIZED
loop was not vectorized: not inner loop
loop was not vectorized: not inner loop
foo.c(45:4-45:4):VEC:main:  LOOP WAS VECTORIZED
loop was not vectorized: not inner loop
loop was not vectorized: not inner loop
</code></pre>

<p>Is this normal?</p>
","922184","","<p>In the example you have posted, the function call to <code>foo()</code> is being inlined. The loops within <code>foo()</code> are vectorized <em>after</em> it is inlined.</p>

<p>The result is that all that code is ""collapsed"" into line 40 and 45. By the time the vectorizor touches the code, it has no idea that it was originally from a different function.</p>

<p>In the original example where you say that it is not vectorized, the same situation applies. The function call is inlined, but it contains non-vectorizable loops.</p>

<hr>

<p>Perhaps, ICC could have preserved the line information through the function call. But then you would get a duplicate vectorization report each time the function is inlined. Furthermore, they would all point to the same line. That would arguably be even more confusing.</p>
"
"<p>If I have an <code>int</code>, convert it to a <code>double</code>, then convert the <code>double</code> back to an <code>int</code>, am I guaranteed to get the same value back that I started with?  In other words, given this function:</p>

<pre><code>int passThroughDouble(int input)
{
  double d = input;
  return d;
}
</code></pre>

<p>Am I guaranteed that <code>passThroughDouble(x) == x</code> for all <code>int</code>s <code>x</code>?</p>
","922184","","<p>No it isn't. The standard says nothing about the relative sizes of <code>int</code> and <code>double</code>.</p>

<p>If <code>int</code> is a 64-bit integer and <code>double</code> is the standard IEEE double-precision, then it will already fail for numbers bigger than <code>2^53</code>.</p>

<hr>

<p>That said, <code>int</code> is still 32-bit on the majority of environments today. So it will still hold in many cases.</p>
"
"<p>I'm trying to write a Java program that can take values and put them into a formula involving log base 10.</p>

<p>How can I calculate log_10 in Java?</p>
","922184","","<p>It looks like Java actually has a <a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/Math.html#log10%28double%29""><code>log10</code></a> function:</p>

<pre><code>Math.log10(x)
</code></pre>

<p>Otherwise, just use math:</p>

<pre><code>Math.log(x) / Math.log(10)
</code></pre>

<p><a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/Math.html"">http://docs.oracle.com/javase/7/docs/api/java/lang/Math.html</a></p>
"
"<p>I have the below snippet which is a hotspot in an application.
The <code>for</code> loop is not vectorized due to vector dependance.
Is there a way to rewrite this loop to make it run faster.</p>

<pre><code>#define  NUM_KEYS  (1L &lt;&lt; 20)
#define  NUM_BUCKETS (1L &lt;&lt; 10)    
int i,k;
int shift = (1L &lt;&lt; 11);
int key_array[NUM_KEYS],key_buff[NUM_KEYS];
int bucket_ptrs[NUM_BUCKETS];

for( i=0; i&lt;NUM_KEYS; i++ )  
{
    k = key_array[i];
    key_buff[bucket_ptrs[k &gt;&gt; shift]++] = k;
}
</code></pre>

<p>One approach I tried was to create a temporary array to hold the shifted values of <code>key_array</code>.</p>

<pre><code>for( i=0; i&lt;NUM_KEYS; i++ )  
{
        key_arrays[i] = key_array[i] &gt;&gt; shift;
}
for( i=0; i&lt;NUM_KEYS; i++ )  
{
    k = key_array[i];
    j = key_arrays[i];
    key_buff[bucket_ptrs[j]++] = k;
}
</code></pre>

<p>Here the first loop gets vectorized. But overall there is no improvement in performance.</p>
","922184","","<blockquote>
  <p>Why is the loop not vectorizable?</p>
</blockquote>

<p>This is because you have non-sequential memory access here:</p>

<pre><code>key_buff[bucket_ptrs[k &gt;&gt; shift]++] = k;
</code></pre>

<p><code>bucket_ptrs</code> determines the index for accessing <code>key_buff</code>. Since these indices are all over the place, the memory access is non-sequential.</p>

<p>Currently, x86 processors only support SIMD loads/stores to contiguous chunks of memory. (ideally aligned as well)</p>

<p>If you want it to vectorize, you will need AVX2's gather/scatter instructions. Those don't exist it, but should be coming out in the next generation of Intel processors.</p>

<blockquote>
  <p>Here the first loop gets vectorized. But overall there is no
  improvement in performance.</p>
</blockquote>

<p>This is because you're adding additional loop-overhead. So you're now making two passes over <code>key_array</code>. If anything, I'm surprised that it isn't <em>slower</em>.</p>

<blockquote>
  <p>Is there a way to rewrite this loop to make it run faster.</p>
</blockquote>

<p>I doubt it - at least not without altering the algorithm. At the very least, you will want <code>key_buff</code> to fit comfortably into your L1 cache.</p>

<p>AVX2 will let it vectorize, but the problem is that <code>key_buff</code> is 4MB. That won't fit into the lower level caches. So even AVX2 might not help much. You will be bound completely by memory access.</p>
"
"<p>I saw this post on SO which contains C code to get the latest CPU Cycle count:</p>

<p><a href=""http://stackoverflow.com/questions/3830883/cpu-cycle-count-based-profiling-in-c-c-linux-x86-64"">CPU Cycle count based profiling in C/C++ Linux x86_64</a></p>

<p>Is there a way I can use this code in C++ (windows and linux solutions welcome)? Although written in C (and C being a subset of C++) I am not too certain if this code would work in a C++ project and if not, how to translate it?</p>

<p>I am using x86-64</p>

<p>EDIT2:</p>

<p>Found this function but cannot get VS2010 to recognise the assembler. Do I need to include anything? (I believe I have to swap <code>uint64_t</code> to <code>long long</code> for windows....?)</p>

<pre><code>static inline uint64_t get_cycles()
{
  uint64_t t;
  __asm volatile (""rdtsc"" : ""=A""(t));
  return t;
}
</code></pre>

<p>EDIT3:</p>

<p>From above code I get the error: </p>

<blockquote>
  <p>""error C2400: inline assembler syntax error in 'opcode'; found 'data
  type'""</p>
</blockquote>

<p>Could someone please help?</p>
","922184","","<p>Pulled directly out of one of my projects:</p>

<pre><code>#include &lt;stdint.h&gt;

//  Windows
#ifdef _WIN32

#include &lt;intrin.h&gt;
uint64_t rdtsc(){
    return __rdtsc();
}

//  Linux/GCC
#else

uint64_t rdtsc(){
    unsigned int lo,hi;
    __asm__ __volatile__ (""rdtsc"" : ""=a"" (lo), ""=d"" (hi));
    return ((uint64_t)hi &lt;&lt; 32) | lo;
}

#endif
</code></pre>
"
"<p>I understand the <code>&gt;&gt;&gt;</code> fixes the overflow: when adding two big positive longs you may endup with a negative number. Can someone explain how this bitwise shift magically fixes the overflow problem? And how it is different than <code>&gt;&gt;</code> ?</p>

<hr>

<p>My suspicious: I think it has to do with the fact that Java uses two-compliments so the overflow is the right number if we had the extra space but because we don't it becomes negative. So when you shift and paddle with zero it magically gets fixed due to the two-compliments. But I can be wrong and someone with a bitwise brain has to confirm. :)</p>
","922184","","<p>In short, <code>(high + low) &gt;&gt;&gt; 1</code> is a trick that uses the unused sign-bit to perform a correct average of non-negative numbers.</p>

<hr>

<p>Under the assumption that <code>high</code> and <code>low</code> are both non-negative, we know for sure that the upper-most bit (the sign-bit) is zero.</p>

<p>So both <code>high</code> and <code>low</code> are in fact 31-bit integers.</p>

<pre><code>high = 0100 0000 0000 0000 0000 0000 0000 0000 = 1073741824
low  = 0100 0000 0000 0000 0000 0000 0000 0000 = 1073741824
</code></pre>

<p>When you add them together they may ""spill"" over into the top-bit.</p>

<pre><code>high + low =       1000 0000 0000 0000 0000 0000 0000 0000
           =  2147483648 as unsigned 32-bit integer
           = -2147483648 as signed   32-bit integer

(high + low) / 2   = 1100 0000 0000 0000 0000 0000 0000 0000 = -1073741824
(high + low) &gt;&gt;&gt; 1 = 0100 0000 0000 0000 0000 0000 0000 0000 = 1073741824
</code></pre>

<ul>
<li><p>As a signed 32-bit integer, it is overflow and flips negative. Therefore <code>(high + low) / 2</code> is wrong because <code>high + low</code> could be negative.</p></li>
<li><p>As unsigned 32-bit integers, the sum is correct. All that's needed is to divide it by 2.</p></li>
</ul>

<p>Of course Java doesn't support unsigned integers, so the best thing we have to divide by 2 (as an unsigned integer) is the logical right-shift <code>&gt;&gt;&gt;</code>.</p>

<p>In languages with unsigned integers (such as C and C++), it gets trickier since your input can be full 32-bit integers. One solution is: <code>low + ((high - low) / 2)</code></p>

<hr>

<p>Finally to enumerate the differences between <code>&gt;&gt;&gt;</code>, <code>&gt;&gt;</code>, and <code>/</code>:</p>

<ul>
<li><code>&gt;&gt;&gt;</code> is logical right-shift. It fills the upper bits with zero.</li>
<li><code>&gt;&gt;</code> is arithmetic right-shift. It fills the upper its with copies of the original top bit.</li>
<li><code>/</code> is division.</li>
</ul>

<p>Mathematically:</p>

<ul>
<li><code>x &gt;&gt;&gt; 1</code> treats <code>x</code> as an unsigned integer and divides it by two. It rounds down.</li>
<li><code>x &gt;&gt; 1</code> treats <code>x</code> as a signed integer and divides it by two. It rounds towards negative infinity.</li>
<li><code>x / 2</code> treats <code>x</code> as a signed integer and divides it by two. It rounds towards zero.</li>
</ul>
"
"<p>What is the overhead in splitting a <code>for</code>-loop like this,</p>

<pre><code>int i;

for (i = 0; i &lt; exchanges; i++)
{
    // some code
    // some more code
    // even more code
}
</code></pre>

<p>into multiple <code>for</code>-loops like this?</p>

<pre><code>int i;

for (i = 0; i &lt; exchanges; i++)
{
    // some code
}

for (i = 0; i &lt; exchanges; i++)
{
    // some more code
}

for (i = 0; i &lt; exchanges; i++)
{
    // even more code
}
</code></pre>

<p>The code <em>is</em> performance-sensitive, but doing the latter would improve readability <em>significantly</em>. (In case it matters, there are no other loops, variable declarations, or function calls, save for a few accessors, within each loop.)</p>

<p>I'm not exactly a low-level programming guru, so it'd be even better if someone could measure up the performance hit in comparison to basic operations, <em>e.g.</em> ""Each additional <code>for</code>-loop would cost the equivalent of two <code>int</code> allocations."" But, I understand (and wouldn't be surprised) if it's not that simple.</p>

<p>Many thanks, in advance.</p>
","922184","","<p>There are often way too many factors at play... And it's easy to demonstrate both ways:</p>

<p>For example, splitting the following loop results in almost a 2x slow-down (full test code at the bottom):</p>

<pre><code>for (int c = 0; c &lt; size; c++){
    data[c] *= 10;
    data[c] += 7;
    data[c] &amp;= 15;
}
</code></pre>

<p>And this is almost stating the obvious since you need to loop through 3 times instead of once and you make 3 passes over the entire array instead of 1.</p>

<p>On the other hand, if you take a look at this question: <a href=""http://stackoverflow.com/q/8547778/922184"">Why is one loop so much slower than two loops?</a></p>

<pre><code>for(int j=0;j&lt;n;j++){
    a1[j] += b1[j];
    c1[j] += d1[j];
}
</code></pre>

<p>The opposite is sometimes true due to memory alignment.</p>

<hr>

<p><strong>What to take from this?</strong></p>

<p>Pretty much anything can happen. Neither way is always faster and it depends heavily on what's inside the loops.</p>

<p>And as such, determining whether such an optimization will increase performance is usually trial-and-error. With enough experience you can make fairly confident (educated) guesses. But in general, expect anything.</p>

<blockquote>
  <p>""Each additional for-loop would cost the equivalent of two int allocations.""</p>
</blockquote>

<p>You are correct that it's not that simple. In fact it's so complicated that the numbers don't mean much. A loop iteration may take X cycles in one context, but Y cycles in another due to a multitude of factors such as <a href=""http://en.wikipedia.org/wiki/Out-of-order_execution"">Out-of-order Execution</a> and data dependencies.</p>

<p>Not only is the performance context-dependent, but it also vary with different processors.</p>

<hr>

<p>Here's the test code:</p>

<pre><code>#include &lt;time.h&gt;
#include &lt;iostream&gt;
using namespace std;

int main(){

    int size = 10000;
    int *data = new int[size];


    clock_t start = clock();

    for (int i = 0; i &lt; 1000000; i++){
#ifdef TOGETHER
        for (int c = 0; c &lt; size; c++){
            data[c] *= 10;
            data[c] += 7;
            data[c] &amp;= 15;
        }
#else
        for (int c = 0; c &lt; size; c++){
            data[c] *= 10;
        }
        for (int c = 0; c &lt; size; c++){
            data[c] += 7;
        }
        for (int c = 0; c &lt; size; c++){
            data[c] &amp;= 15;
        }
#endif
    }

    clock_t end = clock();
    cout &lt;&lt; (double)(end - start) / CLOCKS_PER_SEC &lt;&lt; endl;

    system(""pause"");
}
</code></pre>

<p><strong>Output (one loop):</strong> 4.08 seconds<br>
<strong>Output (3 loops):</strong> 7.17 seconds</p>
"
"<p>Is this a fair test for comparing a vector with an array? The difference in speed seems too large. My test suggests the array is 10 to 100 times faster!</p>

<pre><code>#include ""stdafx.h""
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;windows.h&gt;
#include &lt;stdint.h&gt;

using namespace std;

double PCFreq = 0.0;
__int64 CounterStart = 0;

using namespace std;

void StartCounter()
{
    LARGE_INTEGER li;
    if(!QueryPerformanceFrequency(&amp;li))
    std:cout &lt;&lt; ""QueryPerformanceFrequency failed!\n"";

    PCFreq = double(li.QuadPart)/1000000000;

    QueryPerformanceCounter(&amp;li);
    CounterStart = li.QuadPart;
}
double GetCounter()
{
    LARGE_INTEGER li;
    QueryPerformanceCounter(&amp;li);
    return double(li.QuadPart-CounterStart)/PCFreq;
}

int _tmain(int argc, _TCHAR* argv[])
{
    //Can do 100,000 but not 1,000,000
    const int vectorsize = 100000;
    cout.precision(10);

    StartCounter();
    vector&lt;int&gt; test1(vectorsize);
    for(int i=0; i&lt;vectorsize; i++){
        test1[i] = 5;
    }
    cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;


    StartCounter();
    int test2[vectorsize];
    for(int i=0; i&lt;vectorsize; i++){
        test2[i] = 5;
    }
    cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;

    cout &lt;&lt; test2[0];

    int t = 0;
    cin &gt;&gt; t;
    return 0;
}
</code></pre>
","922184","","<p>It depends on what you are comparing.</p>

<p>Your benchmark measures both <em>setup</em> time and <em>access</em> times together. It's doubtless that <code>std::vector</code> has a more expensive setup time. This is because it needs to allocate memory, and then (by necessity of the standard) call default constructors on all the elements. Which for a POD type, means zeroing.</p>

<p>So if you're trying to measure access times, then no your benchmark isn't accurate.</p>

<p>Here's some numbers to digest:</p>

<p><strong>Original Code:</strong></p>

<pre><code>StartCounter();
vector&lt;int&gt; test1(vectorsize);

for(int i=0; i&lt;vectorsize; i++){
    test1[i] = 5;
}
cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;
</code></pre>

<p><strong>Time: 444353.5206</strong></p>

<hr>

<p>Start timing <em>after</em> declaring and initializing the <code>vector</code>:</p>

<pre><code>vector&lt;int&gt; test1(vectorsize);

StartCounter();
for(int i=0; i&lt;vectorsize; i++){
    test1[i] = 5;
}
cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;
</code></pre>

<p><strong>Time: 15031.76101</strong></p>

<hr>

<p>And for the array:</p>

<pre><code>StartCounter();
int test2[vectorsize];
for(int i=0; i&lt;vectorsize; i++){
    test2[i] = 5;
}
cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;
</code></pre>

<p><strong>Time: 38129.345</strong></p>

<p>The times are about the same regardless of whether the declaration is timed. This is likely because stack allocation is done all at once upon entry to the function.</p>

<hr>

<p>Basically, the vector memory allocation and initialization is taking a disproportionate amount of time. But the actual loop is fast.</p>

<p>I'll also note that your current benchmark framework is still sightly flawed. You only make one pass over each array. So cache-effects and lazy-allocation will be significant.</p>

<p>The reason why the array is now slower is likely due to lazy-allocation. The array is allocated, but it hasn't been committed yet. Lazy allocation means that it is committed upon first access - which involves a page-fault and a context-switch to the kernel.</p>

<hr>

<p>Here's a fairer test with an outer loop to increase the benchmark time:</p>

<pre><code>vector&lt;int&gt; test1(vectorsize);

StartCounter();
for (int c = 0; c &lt; 10000; c++){
    for(int i=0; i&lt;vectorsize; i++){
        test1[i] = 5;
    }
}
cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;
</code></pre>

<p><strong>Time: 227330454.6</strong></p>

<pre><code>int test2[vectorsize];
memset(test2,0,sizeof(test2));

StartCounter();
for (int c = 0; c &lt; 10000; c++){
    for(int i=0; i&lt;vectorsize; i++){
        test2[i] = 5;
    }
}
cout &lt;&lt; GetCounter() &lt;&lt; endl &lt;&lt; endl;
cout &lt;&lt; test2[0];
</code></pre>

<p><strong>Time: 212286228.2</strong></p>

<p>So no an array is <strong><em>NOT</em></strong> faster than a vector for steady-state access. It's just tricky to benchmark properly.</p>
"
"<p>Does anyone see anything obvious about the loop code below that I'm not seeing as to why this cannot be auto-vectorized by VS2012's C++ compiler?</p>

<p>All the compiler gives me is <code>info C5002: loop not vectorized due to reason '1200'</code> when I use the <code>/Qvec-report:2</code> command-line switch.</p>

<p>Reason 1200 is documented in MSDN as:</p>

<blockquote>
  <p>Loop contains loop-carried data dependences that prevent
  vectorization. Different iterations of the loop interfere with each
  other such that vectorizing the loop would produce wrong answers, and
  the auto-vectorizer cannot prove to itself that there are no such data
  dependences.</p>
</blockquote>

<p>I know (or I'm pretty sure that) there aren't any loop-carried data dependencies but I'm not sure what's preventing the compiler from realizing this.</p>

<p>These <code>source</code> and <code>dest</code> pointers do not ever overlap nor alias the same memory and I'm trying to provide the compiler with that hint via <code>__restrict</code>.</p>

<p><code>pitch</code> is always a positive integer value, something like <code>4096</code>, depending on the screen resolution, since this is a 8bpp->32bpp rendering/conversion function, operating column-by-column.</p>

<pre><code>byte  * __restrict source;
DWORD * __restrict dest;
int pitch;

for (int i = 0; i &lt; count; ++i) {
    dest[(i*2*pitch)+0] = (source[(i*8)+0]);
    dest[(i*2*pitch)+1] = (source[(i*8)+1]);
    dest[(i*2*pitch)+2] = (source[(i*8)+2]);
    dest[(i*2*pitch)+3] = (source[(i*8)+3]);

    dest[((i*2+1)*pitch)+0] = (source[(i*8)+4]);
    dest[((i*2+1)*pitch)+1] = (source[(i*8)+5]);
    dest[((i*2+1)*pitch)+2] = (source[(i*8)+6]);
    dest[((i*2+1)*pitch)+3] = (source[(i*8)+7]);
}
</code></pre>

<p>The parens around each <code>source[]</code> are remnants of a function call which I have elided here because the loop still won't be auto-vectorized without the function call, in its most simplest form.</p>

<p><strong>EDIT:</strong></p>

<p>I've simplified the loop to its most trivial form that I can:</p>

<pre><code>for (int i = 0; i &lt; 200; ++i) {
    dest[(i*2*4096)+0] = (source[(i*8)+0]);
}
</code></pre>

<p>This still produces the same 1200 reason code.</p>

<p><strong>EDIT (2):</strong></p>

<p>This minimal test case with local allocations and identical pointer types still fails to auto-vectorize. I'm simply baffled at this point.</p>

<pre><code>const byte * __restrict source;
byte * __restrict dest;
source = (const byte * __restrict ) new byte[1600];
dest = (byte * __restrict ) new byte[1600];
for (int i = 0; i &lt; 200; ++i) {
    dest[(i*2*4096)+0] = (source[(i*8)+0]);
}
</code></pre>
","922184","","<p>Let's just say there's more than just a couple of things preventing this loop from vectorizing...</p>

<p>Consider this:</p>

<pre><code>int main(){
    byte  *source = new byte[1000];
    DWORD *dest   = new DWORD[1000];

    for (int i = 0; i &lt; 200; ++i) {
        dest[(i*2*4096)+0] = (source[(i*8)+0]);
    }
    for (int i = 0; i &lt; 200; ++i) {
        dest[i*2*4096] = source[i*8];
    }
    for (int i = 0; i &lt; 200; ++i) {
        dest[i*8192] = source[i*8];
    }
    for (int i = 0; i &lt; 200; ++i) {
        dest[i] = source[i];
    }
}
</code></pre>

<p>Compiler Output:</p>

<pre><code>main.cpp(10) : info C5002: loop not vectorized due to reason '1200'
main.cpp(13) : info C5002: loop not vectorized due to reason '1200'
main.cpp(16) : info C5002: loop not vectorized due to reason '1203'
main.cpp(19) : info C5002: loop not vectorized due to reason '1101'
</code></pre>

<hr>

<p>Let's break this down:</p>

<ol>
<li><p>The first two loops are the same. So they give the original reason <code>1200</code> which is the loop-carried dependency.</p></li>
<li><p>The 3rd loop is the same as the 2nd loop. Yet the compiler gives a different reason <code>1203</code>:</p>

<blockquote>
  <blockquote>
    <p>Loop body includes non-contiguous accesses into an array</p>
  </blockquote>
</blockquote>

<p>Okay... Why a different reason? I dunno. But this time, the reason is correct.</p></li>
<li><p>The 4th loop gives <code>1101</code>:</p>

<blockquote>
  <blockquote>
    <p>Loop contains a non-vectorizable conversion operation (may be implicit)</p>
  </blockquote>
</blockquote>

<p>So VC++ doesn't isn't smart enough to issue the SSE4.1 <code>pmovzxbd</code> instruction.</p>

<p>That's a pretty niche case, I wouldn't have expected any modern compiler to be able to do this. And if it could, you'd need to specify SSE4.1.</p></li>
</ol>

<hr>

<p>So the only thing that's out-of-the ordinary is why the initial loop reports a loop-carried dependency.<br>Well, that's a tough call... I would go so far to say that the compiler just isn't issuing the correct reason. (When it really should be non-contiguous access.)</p>

<p>Getting back to the point, I wouldn't expect MSVC or any compiler to be able to vectorize your original loop. Your original loop has accesses grouped in chunks of 4 - which makes it contiguous enough to vectorize. But it's a long-shot to expect the compiler to be able to recognize that.</p>

<p>So if it matters, I suggest manually vectorizing this loop. The intrinsic that you will need is <a href=""http://msdn.microsoft.com/en-us/library/bb531467%28v=vs.90%29.aspx""><code>_mm_cvtepu8_epi32()</code></a>.</p>

<hr>

<p><strong>Your original loop:</strong></p>

<pre><code>for (int i = 0; i &lt; count; ++i) {
    dest[(i*2*pitch)+0] = (source[(i*8)+0]);
    dest[(i*2*pitch)+1] = (source[(i*8)+1]);
    dest[(i*2*pitch)+2] = (source[(i*8)+2]);
    dest[(i*2*pitch)+3] = (source[(i*8)+3]);

    dest[((i*2+1)*pitch)+0] = (source[(i*8)+4]);
    dest[((i*2+1)*pitch)+1] = (source[(i*8)+5]);
    dest[((i*2+1)*pitch)+2] = (source[(i*8)+6]);
    dest[((i*2+1)*pitch)+3] = (source[(i*8)+7]);
}
</code></pre>

<p><strong>vectorizes as follows:</strong></p>

<pre><code>for (int i = 0; i &lt; count; ++i) {
    __m128i s0 = _mm_loadl_epi64((__m128i*)(source + i*8));
    __m128i s1 = _mm_unpackhi_epi64(s0,s0);

    *(__m128i*)(dest + (i*2 + 0)*pitch) = _mm_cvtepu8_epi32(s0);
    *(__m128i*)(dest + (i*2 + 1)*pitch) = _mm_cvtepu8_epi32(s1);
}
</code></pre>

<p>Disclaimer: This is untested and ignores alignment.</p>
"
"<p>I'm trying to use OpenMP for parallelization of an already vectorized code with intrinsics, but the problem is that I'm using one XMM register as an outside 'variable' that I increment each loop. For now I'm using the <code>shared</code> clause</p>

<pre><code>__m128d xmm0 = _mm_setzero_pd();
__declspec(align(16)) double res[2];

#pragma omp parallel for shared(xmm0)
for (int i = 0; i &lt; len; i++)
{
    __m128d xmm7 = ... result of some operations

    xmm0 = _mm_add_pd(xmm0, xmm7);
}

_mm_store_pd(res, xmm0);
double final_result = res[0] + res[1];
</code></pre>

<p>because the <code>atomic</code> operation is not supported (in VS2010)</p>

<pre><code>__m128d xmm0 = _mm_setzero_pd();
__declspec(align(16)) double res[2];

#pragma omp parallel for
for (int i = 0; i &lt; len; i++)
{
    __m128d xmm7 = ... result of some operations

    #pragma omp atomic
    xmm0 = _mm_add_pd(xmm0, xmm7);
}

_mm_store_pd(res, xmm0);
double final_result = res[0] + res[1];
</code></pre>

<p>Does anyone know a clever work-around?</p>

<hr>

<p>EDIT: I've also tried it using the Parallel Patterns Library just now:</p>

<pre><code>__declspec(align(16)) double res[2];
combinable&lt;__m128d&gt; xmm0_comb([](){return _mm_setzero_pd();});

parallel_for(0, len, 1, [&amp;xmm0_comb, ...](int i)
{
    __m128d xmm7 = ... result of some operations

    __m128d&amp; xmm0 = xmm0_comb.local();
    xmm0 = _mm_add_pd(xmm0, xmm7);
});

__m128d xmm0 = xmm0_comb.combine([](__m128d a, __m128d b){return _mm_add_pd(a, b);});
_mm_store_pd(res, xmm0);
double final_result = res[0] + res[1];
</code></pre>

<p>but the result was disappointing.</p>
","922184","","<p>You're solving the problem the wrong way. You should be using a reduction instead of atomic operations:</p>

<p>This is a better approach:</p>

<pre><code>double sum = 0;

#pragma omp parallel for reduction(+:sum)
for (int i = 0; i &lt; len; i++)
{
    __m128d xmm7;// = ... result of some operations

    //  Collapse to a ""double"".
    _declspec(align(16)) double res[2];
    _mm_store_pd(res, xmm7);

    //  Add to reduction variable.
    sum += res[0] + res[1];
}

double final_result = sum;
</code></pre>

<p>A reduction is essentially an operation that collapses ""reduces"" everything to a single variable using an associative operation such as <code>+</code>.</p>

<p>If you're doing a reduction, always try to use an actual reduction approach. Don't try to cheat it with atomic operations or critical sections.</p>

<p>The reason for this is that atomic/critical section approaches are inherently not scalable as they maintain a long critical path data-dependency. A proper reduction approach reduces this critical path to <code>log(# of threads)</code>.</p>

<p>The only downside of course is that it breaks floating-point associativity. If that matters, then you're basically stuck with sequentially summing up each iteration.</p>
"
"<p>I've used the GMP library and C++ to code an implementation of the Gauss-Legendre algorithm to calculate the digits of pi.</p>

<p>It has correct output, but the problem is I don't know at which point the output ""turns bad"", since I have to specify the precision in the code.</p>

<p>Here is the output using 64-bit precision: 3.141592653589793238*<em>35</em>*, the last two digits being incorrect.</p>

<p>My question is, if I want <em>n</em> digits of pi, how many bits of precision <em>b</em>, and how many iterations of the algorithm <em>i</em> will be needed?</p>

<p>Thank You</p>
","922184","","<p>The Gauss-Legendre algorithm (aka the AGM algorithm) requires full precision all the way through.</p>

<p>Unlike Newton's Method iterations, AGM iterations aren't self-correcting. So you need full precision from the start. Furthermore, you need extra guard digits.</p>

<blockquote>
  <p>My question is, if I want <code>n</code> digits of pi, how many bits of precision <code>b</code> will be needed?</p>
</blockquote>

<p>First you need to convert the <code>n</code> (decimal) digits into <code>b</code> binary bits. So that would be:</p>

<pre><code>        log(10)
b = n ---------- + epsilon
        log(2)
</code></pre>

<p>Where <code>epsilon</code> is the number of guard digits. How much you need depends on the implementation and rounding behavior, but typically 100 bits is more than enough for any # of iterations.</p>

<p>As for how many iterations you need. This can be found by empirical evidence.</p>

<p>Here's the output of a small app I wrote that compute Pi to 100 million digits using the  Gauss-Legendre algorithm:</p>

<pre><code>================================================================
Computing pi to 100000000 digits:
Threads: 8

Starting AGM...         1.394965 seconds
Starting Iteration 0...    -3 (error in decimal digits)
Starting Iteration 1...    -9
Starting Iteration 2...    -20
Starting Iteration 3...    -42
Starting Iteration 4...    -85
Starting Iteration 5...    -173
Starting Iteration 6...    -347
Starting Iteration 7...    -696
Starting Iteration 8...    -1395
Starting Iteration 9...    -2792
Starting Iteration 10...    -5586
Starting Iteration 11...    -11175
Starting Iteration 12...    -22352
Starting Iteration 13...    -44706
Starting Iteration 14...    -89414
Starting Iteration 15...    -178829
Starting Iteration 16...    -357661
Starting Iteration 17...    -715324
Starting Iteration 18...    -1430650
Starting Iteration 19...    -2861302
Starting Iteration 20...    -5722607
Starting Iteration 21...    -11445216
Starting Iteration 22...    -22890435
Starting Iteration 23...    -45780871
Starting Iteration 24...    -91561745
Starting Iteration 25...    -183123492
AGM:                    118.796792 seconds
Finishing...            3.033239   seconds
Radix Conversion...     2.924844   seconds

Total Wall Time:        126.151086 seconds

CPU Utilization:        495.871%
CPU Efficiency:         61.984%

Writing to ""pi.txt""...  Done
</code></pre>

<p>So 25 iterations is sufficient for 183 million digits. Likewise, it doubles with each iteration, so you can run some basic logarithm math to figure out how many iterations you need.</p>
"
"<p>I was trying various methods to implement a program that gives the digits of pi sequentially. I tried the <a href=""http://en.wikipedia.org/wiki/Taylor_series"">Taylor series</a> method, but it proved to converge extremely slowly (when I compared my result with the online values after some time). Anyway, I am trying better algorithms.</p>

<p>So, while writing the program I got stuck on a problem, as with all algorithms: How do I know that the <code>n</code> digits that I've calculated are accurate?</p>
","922184","","<p>Since I'm the current world record holder for the most digits of pi, I'll add my <a href=""http://en.wiktionary.org/wiki/two_cents#Noun"">two cents</a>:</p>

<p>Unless you're actually setting a new world record, the common practice is just to verify the computed digits against the known values. So that's simple enough.</p>

<p>In fact, I have a webpage that lists snippets of digits for the purpose of verifying computations against them: <a href=""http://www.numberworld.org/digits/Pi/"">http://www.numberworld.org/digits/Pi/</a></p>

<hr>

<p>But when you get into world-record territory, there's nothing to compare against.</p>

<p>Historically, the standard approach for verifying that computed digits are correct is to recompute the digits using a second algorithm. So if either computation goes bad, the digits at the end won't match.</p>

<p>This does typically more than double the amount of time needed (since the second algorithm is usually slower). But it's the only way to verify the computed digits once you've wandered into the uncharted territory of never-before-computed digits and a new world record.</p>

<hr>

<p>Back in the days where supercomputers were setting the records, two different <a href=""http://en.wikipedia.org/wiki/AGM_method"">AGM algorithms</a> were commonly used:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/Gauss%E2%80%93Legendre_algorithm"">Gauss–Legendre algorithm</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Borwein%27s_algorithm"">Borwein's algorithm</a></li>
</ul>

<p>These are both <code>O(N log(N)^2)</code> algorithms that were fairly easy to implement.</p>

<p>However, nowadays, things are a bit different. In the last three world records, instead of performing two computations, we performed only one computation using the fastest known formula (<a href=""http://en.wikipedia.org/wiki/Chudnovsky_algorithm"">Chudnovsky Formula</a>):</p>

<p><img src=""http://mathurl.com/bjkw6tu.png"" alt=""Enter image description here""></p>

<p>This algorithm is much harder to implement, but it is a lot faster than the AGM algorithms.</p>

<p>Then we verify the binary digits using the <a href=""http://en.wikipedia.org/wiki/Bailey%E2%80%93Borwein%E2%80%93Plouffe_formula"">BBP formulas for digit extraction</a>.</p>

<p><img src=""http://mathurl.com/b56zl9d.png"" alt=""Enter image description here""></p>

<p>This formula allows you to compute arbitrary binary digits <em>without</em> computing all the digits before it. So it is used to verify the last few computed binary digits. Therefore it is <strong><em>much</em></strong> faster than a full computation.</p>

<p>The advantage of this is:</p>

<ol>
<li>Only one expensive computation is needed.</li>
</ol>

<p>The disadvantage is:</p>

<ol>
<li>An implementation of the <a href=""http://en.wikipedia.org/wiki/Bailey%E2%80%93Borwein%E2%80%93Plouffe_formula"">Bailey–Borwein–Plouffe</a> (BBP) formula is needed.</li>
<li>An additional step is needed to verify the radix conversion from binary to decimal.</li>
</ol>

<p><sub>I've glossed over some details of why verifying the last few digits implies that all the digits are correct. But it is easy to see this since any computation error will propagate to the last digits.</sub></p>

<hr>

<p>Now this last step (verifying the conversion) is actually fairly important. One of the previous world record holders <strong><em>actually called us out</em></strong> on this because, initially, I didn't give a sufficient description of how it worked.</p>

<p>So I've pulled this snippet from my blog:</p>

<pre><code>N = # of decimal digits desired
p = 64-bit prime number
</code></pre>

<p><img src=""http://mathurl.com/csv4fyo.png"" alt=""Enter image description here""><br></p>

<p>Compute A using base 10 arithmetic and B using binary arithmetic.</p>

<p><img src=""http://mathurl.com/cu4slf5.png"" alt=""enter image description here""></p>

<p>If <code>A = B</code>, then with ""extremely high probability"", the conversion is correct.</p>

<hr>

<p>For further reading, see my blog post <strong><a href=""http://www.numberworld.org/misc_runs/pi-5t/details.html"">Pi - 5 Trillion Digits</a></strong>.</p>
"
"<p>I am using the PAPI high level API to check TLB misses in a simple program looping through an array, but seeing larger numbers than expected.</p>

<p>In other simple test cases, the results seem quite reasonable, which leads me to think the results are real and the extra misses are due to a hardware prefetch or similar.</p>

<p>Can anyone explain the numbers or point me to some error in my use of PAPI?</p>

<pre><code>int events[] = {PAPI_TLB_TL};
long long values[1];
char * databuf = (char *) malloc(4096 * 32);

if (PAPI_start_counters(events, 1) != PAPI_OK) exit(-1);
if (PAPI_read_counters(values, 1) != PAPI_OK) exit(-1); //Zeros the counters

for(int i=0; i &lt; 32; ++i){
    databuf[4096 * i] = 'a';
}

if (PAPI_read_counters(values, 1) != PAPI_OK) exit(-1); //Extracts the counters

printf(""%llu\n"", values[0]);
</code></pre>

<p>I expected the printed number to be in the region of 32, or at least some multiple, but consistently get a result of 93 or above (not consistently above 96 i.e. not simply 3 misses for every iteration). I am running pinned to a core with nothing else on it (apart from timer interrupts).</p>

<p>I am on Nehalem and not using huge pages, so there are 64 entries in DTLB (512 in L2).</p>
","922184","","<p>Based on the comments:</p>

<ul>
<li>~90 misses if <code>malloc()</code> is used.</li>
<li>32 misses if <code>calloc()</code> is used or if the array is iterated through before hand.</li>
</ul>

<p>The reason is due to lazy allocation. The OS isn't actually giving you the memory until you touch it.</p>

<p>When you first touch the page, it will result in a page-fault. The OS will trap this page-fault and properly allocate it on the fly (<a href=""http://stackoverflow.com/questions/8029584/why-does-malloc-initialize-the-values-to-0-in-gcc"">which involves zeroing</a> among other things). This is the overhead that is resulting in all those extra TLB misses.</p>

<p>But if you use <code>calloc()</code> or you touch all the memory ahead of time, you move this overhead to <em>before</em> you start the counters. Hence the smaller result.</p>

<p>As for the 32 remaining misses... I have no idea.<br>
(Or as mentioned in the comments, it's probably the PAPI interference.)</p>
"
"<p>I intend to use buffers <code>std::vector&lt;size_t&gt; buffer(100)</code>, one in each thread in a parallelization of a loop, as suggested by this code:</p>

<pre><code>std::vector&lt;size_t&gt; buffer(100);
#pragma omp parallel for private(buffer)
for(size_t j = 0; j &lt; 10000; ++j) {
    // ... code using the buffer ...
}
</code></pre>

<p>This code does not work. Although there is a buffer for every thread, those can have size 0. </p>

<p>How can I allocate the buffer in the beginning of each thread? Can I still use <code>#pragma omp parallel for</code>? And can I do it more elegantly than this:</p>

<pre><code>std::vector&lt;size_t&gt; buffer;
#pragma omp parallel for private(buffer)
for(size_t j = 0; j &lt; 10000; ++j) {
    if(buffer.size() != 100) {
        #pragma omp critical
        buffer.resize(100);
    }
    // ... code using the buffer ...
}
</code></pre>
","922184","","<p>Split the OpenMP region as shown in <a href=""http://stackoverflow.com/questions/1448318/openmp-omp-parallel-vs-omp-parallel-for"">this question</a>.</p>

<p>Then declare the vector inside the outer-region, but outside the for-loop itself. This will make one local vector for each thread.</p>

<pre><code>#pragma omp parallel
{
    std::vector&lt;size_t&gt; buffer(100);

#pragma omp for
    for(size_t j = 0; j &lt; 10000; ++j) {
    {

        // ... code using the buffer ...

    }
}
</code></pre>
"
"<p>I'd like to profile some code in C using Linux. I usually just do the usual <code>gettimeofday()</code> functions, they're easy to put in, understandable, and portable. I've had someone ask me why not using CPU counters or RDTSC for profiling the code, but although I understand that RDTSC may be more precise, I cannot argue in favor or against one or the other. So, my question is: all else being equal, would people profile code with the usual time functions or the RDTSC?</p>
","922184","","<p>CPU counters and wall clocks are different tools for different purposes.</p>

<p><strong>When to use a wall clock:</strong></p>

<p>When you want to measure time in a standard time unit (such as seconds). If you want to measure how long X task takes, use a wall clock.</p>

<p>Examples:</p>

<ul>
<li><code>clock()</code></li>
<li><code>gettimeofday()</code></li>
<li><code>clock_gettime(2)</code></li>
<li>etc...</li>
</ul>

<p><strong>When to use RDTSC:</strong></p>

<p>If you're looking to measure the <em>relative</em> times of two different tasks to as high precision as possible, then RDTSC may be suitable.</p>

<p>RDTSC measures the number of pseudo-cycles that have elapsed since the CPU has started up. Often (but not always), this is equal to the CPU clock speed of your processor. But there's no easy to determine the exact number of ""ticks per second"" without actually measuring it against a wall clock.</p>

<p>However, RDTSC is about as low overhead as it can get for a time function. So it is well suited for micro-optimizations when you're comparing one implementation against another to determine which is <em>faster</em>. (as opposed to how much absolute time it takes)</p>

<hr>

<p>Other things to note:</p>

<ul>
<li>In most cases, most benchmarking purposes can be done sufficiently well with wall clocks. So the use of RDTSC is pretty limited. Stick with standardized functions when possible.</li>
<li>High precision wall clocks are typically implemented on top of RDTSC. So if you're trying to use RDTSC to get a high-precision measurement of wall time, you'll just be reinventing the wheel.</li>
</ul>

<p><sub>As a side note, I use RDTSC both for seeing RNGs and as an anti-cheating measure for my overclocker benchmarks.</sub></p>
"
"<p>I have been trying to get an idea of the impact of having an array in L1 cache versus memory by timing a routine that scales and sums the elements of an array using the following code (I am aware that I should just scale the result by 'a' at the end; the point is to do both a multiply and an add within the loop - so far, the compiler hasn't figured out to factor out 'a'): </p>

<pre><code>double sum(double a,double* X,int size)
{
    double total = 0.0;
    for(int i = 0;  i &lt; size; ++i)
    {
        total += a*X[i];
    }
    return total;
}

#define KB 1024
int main()
{
    //Approximately half the L1 cache size of my machine
    int operand_size = (32*KB)/(sizeof(double)*2);
    printf(""Operand size: %d\n"", operand_size);
    double* X = new double[operand_size];
    fill(X,operand_size);

    double seconds = timer();
    double result;
    int n_iterations = 100000;
    for(int i = 0; i &lt; n_iterations; ++i)
    {
        result = sum(3.5,X,operand_size);
        //result += rand();  
    }
    seconds = timer() - seconds; 

    double mflops = 2e-6*double(n_iterations*operand_size)/seconds;
    printf(""Vector size %d: mflops=%.1f, result=%.1f\n"",operand_size,mflops,result);
    return 0;
}
</code></pre>

<p>Note that the timer() and fill() routines are not included for brevity; their full source can be found here if you want to run the code:</p>

<p><a href=""http://codepad.org/agPWItZS"">http://codepad.org/agPWItZS</a></p>

<p>Now, here is where it gets interesting. This is the output:</p>

<pre><code>Operand size: 2048
Vector size 2048: mflops=588.8, result=-67.8
</code></pre>

<p>This is totally un-cached performance, despite the fact that all elements of X should be held in cache between loop iterations. Looking at the assembly code generated by:</p>

<pre><code>g++ -O3 -S -fno-asynchronous-unwind-tables register_opt_example.cpp
</code></pre>

<p>I notice one oddity in the sum function loop: </p>

<pre><code>L55:
    movsd   (%r12,%rax,8), %xmm0
    mulsd   %xmm1, %xmm0
    addsd   -72(%rbp), %xmm0
    movsd   %xmm0, -72(%rbp)
    incq    %rax
    cmpq    $2048, %rax
    jne L55
</code></pre>

<p>The instructions: </p>

<pre><code>    addsd   -72(%rbp), %xmm0
    movsd   %xmm0, -72(%rbp)
</code></pre>

<p>indicate that it is storing the value of ""total"" in sum() on the stack, and reading and writing it at every loop iteration. I modified the assembly so that this operand is kept in a a register:</p>

<pre><code>...
addsd   %xmm0, %xmm3
...
</code></pre>

<p>This small change creates a <strong>huge</strong> performance boost: </p>

<pre><code>Operand size: 2048
Vector size 2048: mflops=1958.9, result=-67.8
</code></pre>

<p><strong>tl;dr</strong>
My question is: why does replacing a single memory location access with a register, speed up the code so much, given that the single location should be stored in L1 cache? What architectural factors make this possible? It seems very strange that writing one stack location repeatedly would completely destroy the effectiveness of a cache. </p>

<p><strong>Appendix</strong></p>

<p>My gcc version is: </p>

<pre><code>Target: i686-apple-darwin10
Configured with: /var/tmp/gcc/gcc-5646.1~2/src/configure --disable-checking --enable-werror --prefix=/usr --mandir=/share/man --enable-languages=c,objc,c++,obj-c++ --program-transform-name=/^[cg][^.-]*$/s/$/-4.2/ --with-slibdir=/usr/lib --build=i686-apple-darwin10 --with-gxx-include-dir=/include/c++/4.2.1 --program-prefix=i686-apple-darwin10- --host=x86_64-apple-darwin10 --target=i686-apple-darwin10
Thread model: posix
gcc version 4.2.1 (Apple Inc. build 5646) (dot 1)
</code></pre>

<p>My CPU is: </p>

<p>Intel Xeon X5650</p>
","922184","","<p>It's likely a combination of a longer dependency chain, along with Load Misprediction*.</p>

<hr>

<p><strong>Longer Dependency Chain:</strong></p>

<p>First, we identify the critical dependency paths. Then we look at the instruction latencies provided by: <a href=""http://www.agner.org/optimize/instruction_tables.pdf"">http://www.agner.org/optimize/instruction_tables.pdf</a> (page 117)</p>

<p>In the unoptimized version, the critical dependency path is:</p>

<ul>
<li><code>addsd   -72(%rbp), %xmm0</code></li>
<li><code>movsd   %xmm0, -72(%rbp)</code></li>
</ul>

<p>Internally, it probably breaks up into:</p>

<ul>
<li>load (2 cycles)</li>
<li>addsd (3 cycles)</li>
<li>store (3 cycles)</li>
</ul>

<p>If we look at the optimized version, it's just:</p>

<ul>
<li>addsd (3 cycles)</li>
</ul>

<p>So you have 8 cycles vs. 3 cycles. Almost a factor of 3.</p>

<p>I'm not sure how sensitive the Nehalem processor line is to store-load dependencies and how well it does <a href=""http://en.wikipedia.org/wiki/Memory_disambiguation#Store_to_load_forwarding"">forwarding</a>. But it's reasonable to believe that it's not zero.</p>

<hr>

<p><strong>Load-store Misprediction:</strong></p>

<p>Modern processors use prediction in more ways you can imagine. The most famous of these is probably <a href=""http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array"">Branch Prediction</a>. One of the lesser known ones is Load Prediction.</p>

<p>When a processor sees a load, it will immediately load it before all pending writes finish. It will assume that those writes will not conflict with the loaded values.</p>

<p>If an earlier write turns out to conflict with a load, then the load must be re-executed and the computation rolled back to the point of the load. (in much the same way that branch mispredictions roll back)</p>

<p>How it is relevant here:</p>

<p>Needless to say, modern processors will be able to execute multiple iterations of this loop simultaneously. So the processor will be attempting to perform the load (<code>addsd   -72(%rbp), %xmm0)</code> before it finishes the store (<code>movsd   %xmm0, -72(%rbp)</code>) from the previous iteration.</p>

<p>The result? The previous store conflicts with the load - thus a misprediction and a roll back.</p>

<p><sub>*Note that I'm unsure of the name ""Load Prediction"". I only read about it in the Intel docs and they didn't seem to give it a name.</sub></p>
"
"<p>I have learned that some Intel/AMD CPUs can do simultanous multiply and add with SSE/AVX:<br>  <a href=""http://stackoverflow.com/questions/15655835/flops-per-cycle-for-sandy-bridge-and-haswell-sse2-avx-avx2"">FLOPS per cycle for sandy-bridge and haswell SSE2/AVX/AVX2</a>.</p>

<p>I like to know how to do this best in code and I also want to know how it's done internally in the CPU.  I mean with the super-scalar architecture.  Let's say I want to do a long sum such as the following in SSE:</p>

<pre><code>//sum = a1*b1 + a2*b2 + a3*b3 +... where a is a scalar and b is a SIMD vector (e.g. from matrix multiplication)
sum = _mm_set1_ps(0.0f);
a1  = _mm_set1_ps(a[0]); 
b1  = _mm_load_ps(&amp;b[0]);
sum = _mm_add_ps(sum, _mm_mul_ps(a1, b1));

a2  = _mm_set1_ps(a[1]); 
b2  = _mm_load_ps(&amp;b[4]);
sum = _mm_add_ps(sum, _mm_mul_ps(a2, b2));

a3  = _mm_set1_ps(a[2]); 
b3  = _mm_load_ps(&amp;b[8]);
sum = _mm_add_ps(sum, _mm_mul_ps(a3, b3));
...
</code></pre>

<p>My question is how does this get converted to simultaneous multiply and add?  Can the data be dependent?  I mean can the CPU do <code>_mm_add_ps(sum, _mm_mul_ps(a1, b1))</code> simultaneously or do the registers used in the multiplication and add have to be independent?</p>

<p>Lastly how does this apply to FMA (with Haswell)?  Is <code>_mm_add_ps(sum, _mm_mul_ps(a1, b1))</code> automatically converted to a single FMA instruction or micro-operation?</p>
","922184","","<p>The compiler is not allowed to fuse a separated add and multiply unless you allow for a relaxed floating-point model.</p>

<p>This is because an FMA has only one rounding, while an ADD + MUL has two. So the compiler will violate strict IEEE floating-point behavior by fusing.</p>

<p>Even if you enable relaxed floating-point, the compiler might still choose not to fuse since it might expect you to know what you're doing if you're already using intrinsics.</p>

<hr>

<p>So the best way to make sure you actually get the FMA instructions you want is you actually use the provided intrinsics for them:</p>

<p><a href=""http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-F2F72E9F-C27C-44C4-BAD8-26B6209B6D2F.htm"">FMA3 Intrinsics:</a> (AVX2 - Intel Haswell)</p>

<ul>
<li><code>_mm_fmadd_pd()</code>, _<code>mm256_fmadd_pd()</code></li>
<li><code>_mm_fmadd_ps()</code>, <code>_mm256_fmadd_ps()</code></li>
<li>and about a gazillion other variations...</li>
</ul>

<p><a href=""http://msdn.microsoft.com/en-us/library/vstudio/gg445134%28v=vs.100%29.aspx"">FMA4 Intrinsics:</a> (XOP - AMD Bulldozer)</p>

<ul>
<li><code>_mm_macc_pd()</code>, <code>_mm256_macc_pd()</code></li>
<li><code>_mm_macc_ps()</code>, <code>_mm256_macc_ps()</code></li>
<li>and about a gazillion other variations...</li>
</ul>
"
"<p>I have a short to float cast in C++ that is bottlenecking my code.</p>

<p>The code translates from a hardware device buffer which is natively shorts, this represents the input from a fancy photon counter.</p>

<pre><code>float factor=  1.0f/value;
for (int i = 0; i &lt; W*H; i++)//25% of time is spent doing this
{
    int value = source[i];//ushort -&gt; int
    destination[i] = value*factor;//int*float-&gt;float
}
</code></pre>

<p><strong>A few details</strong></p>

<ol>
<li><p>Value should go from 0 to 2^16-1, it represents the pixel values of a highly sensitive camera</p></li>
<li><p>I'm on a multicore x86 machine with an i7 processor (i7 960 which is SSE 4.2 and 4.1).</p></li>
<li><p>Source is aligned to an 8 bit boundary (a requirement of the hardware device)</p></li>
<li><p>W*H is always divisible by 8, most of the time W and H are divisible by 8</p></li>
</ol>

<p>This makes me sad, is there anything I can do about it?</p>

<p>I am using Visual Studios 2012...</p>
","922184","","<p>Here's a basic SSE4.1 implementation:</p>

<pre><code>__m128 factor = _mm_set1_ps(1.0f / value);
for (int i = 0; i &lt; W*H; i += 8)
{
    //  Load 8 16-bit ushorts.
    //  vi = {a,b,c,d,e,f,g,h}
    __m128i vi = _mm_load_si128((const __m128i*)(source + i));

    //  Convert to 32-bit integers
    //  vi0 = {a,0,b,0,c,0,d,0}
    //  vi1 = {e,0,f,0,g,0,h,0}
    __m128i vi0 = _mm_cvtepu16_epi32(vi);
    __m128i vi1 = _mm_cvtepu16_epi32(_mm_unpackhi_epi64(vi,vi));

    //  Convert to float
    __m128 vf0 = _mm_cvtepi32_ps(vi0);
    __m128 vf1 = _mm_cvtepi32_ps(vi1);

    //  Multiply
    vf0 = _mm_mul_ps(vf0,factor);
    vf1 = _mm_mul_ps(vf1,factor);

    //  Store
    _mm_store_ps(destination + i + 0,vf0);
    _mm_store_ps(destination + i + 4,vf1);
}
</code></pre>

<p>This assumes:</p>

<ol>
<li><code>source</code> and <code>destination</code> are both aligned to 16 bytes.</li>
<li><code>W*H</code> is a multiple of 8.</li>
</ol>

<p>It's possible to do better by further unrolling this loop. (see below)</p>

<hr>

<p>The idea here is as follows:</p>

<ol>
<li>Load 8 shorts into a single SSE register.</li>
<li>Split the register into two: One with the bottom 4 shorts and the other with the top 4 shorts.</li>
<li>Zero-extend both registers into 32-bit integers.</li>
<li>Convert them both to <code>float</code>s.</li>
<li>Multiply by the factor.</li>
<li>Store them into <code>destination</code>.</li>
</ol>

<hr>

<p><strong>EDIT :</strong></p>

<p>It's been a while since I've done this type of optimization, so I went ahead and unrolled the loops.</p>

<p><strong>Core i7 920 @ 3.5 GHz<br>
Visual Studio 2012 - Release x64:</strong></p>

<pre><code>Original Loop      : 4.374 seconds
Vectorize no unroll: 1.665
Vectorize unroll 2 : 1.416
</code></pre>

<p>Further unrolling resulted in diminishing returns.</p>

<p>Here's the test code:</p>

<pre><code>#include &lt;smmintrin.h&gt;
#include &lt;time.h&gt;
#include &lt;iostream&gt;
#include &lt;malloc.h&gt;
using namespace std;


void default_loop(float *destination,const short* source,float value,int size){
    float factor = 1.0f / value; 
    for (int i = 0; i &lt; size; i++)
    {
        int value = source[i];
        destination[i] = value*factor;
    }
}
void vectorize8_unroll1(float *destination,const short* source,float value,int size){
    __m128 factor = _mm_set1_ps(1.0f / value);
    for (int i = 0; i &lt; size; i += 8)
    {
        //  Load 8 16-bit ushorts.
        __m128i vi = _mm_load_si128((const __m128i*)(source + i));

        //  Convert to 32-bit integers
        __m128i vi0 = _mm_cvtepu16_epi32(vi);
        __m128i vi1 = _mm_cvtepu16_epi32(_mm_unpackhi_epi64(vi,vi));

        //  Convert to float
        __m128 vf0 = _mm_cvtepi32_ps(vi0);
        __m128 vf1 = _mm_cvtepi32_ps(vi1);

        //  Multiply
        vf0 = _mm_mul_ps(vf0,factor);
        vf1 = _mm_mul_ps(vf1,factor);

        //  Store
        _mm_store_ps(destination + i + 0,vf0);
        _mm_store_ps(destination + i + 4,vf1);
    }
}
void vectorize8_unroll2(float *destination,const short* source,float value,int size){
    __m128 factor = _mm_set1_ps(1.0f / value);
    for (int i = 0; i &lt; size; i += 16)
    {
        __m128i a0 = _mm_load_si128((const __m128i*)(source + i + 0));
        __m128i a1 = _mm_load_si128((const __m128i*)(source + i + 8));

        //  Split into two registers
        __m128i b0 = _mm_unpackhi_epi64(a0,a0);
        __m128i b1 = _mm_unpackhi_epi64(a1,a1);

        //  Convert to 32-bit integers
        a0 = _mm_cvtepu16_epi32(a0);
        b0 = _mm_cvtepu16_epi32(b0);
        a1 = _mm_cvtepu16_epi32(a1);
        b1 = _mm_cvtepu16_epi32(b1);

        //  Convert to float
        __m128 c0 = _mm_cvtepi32_ps(a0);
        __m128 d0 = _mm_cvtepi32_ps(b0);
        __m128 c1 = _mm_cvtepi32_ps(a1);
        __m128 d1 = _mm_cvtepi32_ps(b1);

        //  Multiply
        c0 = _mm_mul_ps(c0,factor);
        d0 = _mm_mul_ps(d0,factor);
        c1 = _mm_mul_ps(c1,factor);
        d1 = _mm_mul_ps(d1,factor);

        //  Store
        _mm_store_ps(destination + i +  0,c0);
        _mm_store_ps(destination + i +  4,d0);
        _mm_store_ps(destination + i +  8,c1);
        _mm_store_ps(destination + i + 12,d1);
    }
}
void print_sum(const float *destination,int size){
    float sum = 0;
    for (int i = 0; i &lt; size; i++){
        sum += destination[i];
    }
    cout &lt;&lt; sum &lt;&lt; endl;
}

int main(){

    int size = 8000;

    short *source       = (short*)_mm_malloc(size * sizeof(short), 16);
    float *destination  = (float*)_mm_malloc(size * sizeof(float), 16);

    for (int i = 0; i &lt; size; i++){
        source[i] = i;
    }

    float value = 1.1;

    int iterations = 1000000;
    clock_t start;

    //  Default Loop
    start = clock();
    for (int it = 0; it &lt; iterations; it++){
        default_loop(destination,source,value,size);
    }
    cout &lt;&lt; (double)(clock() - start) / CLOCKS_PER_SEC &lt;&lt; endl;
    print_sum(destination,size);

    //  Vectorize 8, no unroll
    start = clock();
    for (int it = 0; it &lt; iterations; it++){
        vectorize8_unroll1(destination,source,value,size);
    }
    cout &lt;&lt; (double)(clock() - start) / CLOCKS_PER_SEC &lt;&lt; endl;
    print_sum(destination,size);

    //  Vectorize 8, unroll 2
    start = clock();
    for (int it = 0; it &lt; iterations; it++){
        vectorize8_unroll2(destination,source,value,size);
    }
    cout &lt;&lt; (double)(clock() - start) / CLOCKS_PER_SEC &lt;&lt; endl;
    print_sum(destination,size);

    _mm_free(source);
    _mm_free(destination);

    system(""pause"");
}
</code></pre>
"
"<p>I'm just getting started with SSE intrinsics using Visual C++ 2012 and I need some pointers (no pun intended).</p>

<p>I have two arrays containing 4 signed shorts each (each array is thus 64-bit, totalling 128). I want to load one into the upper bits of an XMM register, and the other in the lower bits. Can I accomplish this efficiently using intrinsics? If so, how? </p>
","922184","","<p><strong>SSE2:</strong></p>

<pre><code>short A[] = {0,1,2,3};
short B[] = {4,5,6,7};

__m128i a,b,v;
a = _mm_loadl_epi64((const __m128i*)A);
b = _mm_loadl_epi64((const __m128i*)B);
v = _mm_unpacklo_epi64(a,b);

// v = {0,1,2,3,4,5,6,7}
</code></pre>

<p><strong>SSE4.1 + x64:</strong></p>

<pre><code>short A[] = {0,1,2,3};
short B[] = {4,5,6,7};

__m128i v;
v = _mm_loadl_epi64((const __m128i*)A);
v = _mm_insert_epi64(v,*(const long long*)B,1);

// v = {0,1,2,3,4,5,6,7}
</code></pre>

<hr>

<p>Note that there are no alignment requirements for <code>A</code> or <code>B</code>. But I'd recommend that they both be aligned to 8 bytes anyway.</p>
"
"<p>I saw the following code from some legacy codes:</p>

<pre><code> size_t a = 1 ???- 2 :0;
</code></pre>

<p>What does the symbol <code>???-</code> mean in C++?  How should I understand it?</p>

<p>Thank you!</p>
","922184","","<p>It's actually:</p>

<pre><code>size_t a = 1 ? ~2 :0;
</code></pre>

<p><code>??-</code> is a <a href=""http://en.wikipedia.org/wiki/Digraphs_and_trigraphs"">trigraph</a> for <code>~</code></p>

<hr>

<p>Trigraphs are from an old era... before some of us were even born.</p>

<p>Back in the days, there were some characters that weren't always supported. An unknowing programmer would try to type in such a character only to find that it doesn't exist on the keyboard!</p>

<p><img src=""http://i.stack.imgur.com/kiiBU.jpg"" alt=""enter image description here""><br><sub>Image Source: <a href=""http://www.myoldmac.net/cgi-data/forum/phpBB2/viewtopic.php?t=305"">http://www.myoldmac.net/cgi-data/forum/phpBB2/viewtopic.php?t=305</a></sub></p>

<p>So trigraphs were added to allow the programmer to access the functionality of these characters when they didn't exist (either in the encoding or from the keyboard).</p>

<p>Nowadays, they are obsolete and are more effective in confusing the reader than in getting around old standards.</p>

<p>So either that code is really old, or the author was being a jerk.</p>
"
"<h1>Original Problem:</h1>

<p>So I have written some code to experiment with threads and do some testing.</p>

<p>The code should create some numbers and then find the mean of those numbers.</p>

<p>I think it is just easier to show you what I have so far. I was expecting with two threads that the code would run about 2 times as fast. Measuring it with a stopwatch I think it runs about 6 times slower! EDIT: Now using the computer and clock() function to tell the time.</p>

<pre><code>void findmean(std::vector&lt;double&gt;*, std::size_t, std::size_t, double*);


int main(int argn, char** argv)
{

    // Program entry point
    std::cout &lt;&lt; ""Generating data..."" &lt;&lt; std::endl;

    // Create a vector containing many variables
    std::vector&lt;double&gt; data;
    for(uint32_t i = 1; i &lt;= 1024 * 1024 * 128; i ++) data.push_back(i);

    // Calculate mean using 1 core
    double mean = 0;
    std::cout &lt;&lt; ""Calculating mean, 1 Thread..."" &lt;&lt; std::endl;
    findmean(&amp;data, 0, data.size(), &amp;mean);
    mean /= (double)data.size();

    // Print result
    std::cout &lt;&lt; ""  Mean="" &lt;&lt; mean &lt;&lt; std::endl;

    // Repeat, using two threads
    std::vector&lt;std::thread&gt; thread;
    std::vector&lt;double&gt; result;
    result.push_back(0.0);
    result.push_back(0.0);
    std::cout &lt;&lt; ""Calculating mean, 2 Threads..."" &lt;&lt; std::endl;

    // Run threads
    uint32_t halfsize = data.size() / 2;
    uint32_t A = 0;
    uint32_t B, C, D;
    // Split the data into two blocks
    if(data.size() % 2 == 0)
    {
        B = C = D = halfsize;
    }
    else if(data.size() % 2 == 1)
    {
        B = C = halfsize;
        D = hsz + 1;
    }

    // Run with two threads
    thread.push_back(std::thread(findmean, &amp;data, A, B, &amp;(result[0])));
    thread.push_back(std::thread(findmean, &amp;data, C, D , &amp;(result[1])));

    // Join threads
    thread[0].join();
    thread[1].join();

    // Calculate result
    mean = result[0] + result[1];
    mean /= (double)data.size();

    // Print result
    std::cout &lt;&lt; ""  Mean="" &lt;&lt; mean &lt;&lt; std::endl;

    // Return
    return EXIT_SUCCESS;
}


void findmean(std::vector&lt;double&gt;* datavec, std::size_t start, std::size_t length, double* result)
{
    for(uint32_t i = 0; i &lt; length; i ++) {
        *result += (*datavec).at(start + i);
    }
}
</code></pre>

<p>I don't think this code is exactly wonderful, if you could suggest ways of improving it then I would be grateful for that also.</p>

<h1>Register Variable:</h1>

<p>Several people have suggested making a local variable for the function 'findmean'. This is what I have done:</p>

<pre><code>void findmean(std::vector&lt;double&gt;* datavec, std::size_t start, std::size_t length, double* result)
{
register double holding = *result;
for(uint32_t i = 0; i &lt; length; i ++) {
    holding += (*datavec).at(start + i);
}
*result = holding;
}
</code></pre>

<p>I can now report: The code runs with almost the same execution time as with a single thread. That is a big improvement of 6x, but surely there must be a way to make it nearly twice as fast?</p>

<h1>Register Variable and O2 Optimization:</h1>

<p>I have set the optimization to 'O2' - I will create a table with the results.</p>

<h1>Results so far:</h1>

<p>Original Code with no optimization or register variable:
1 thread: 4.98 seconds, 2 threads: 29.59 seconds</p>

<p>Code with added register variable:
1 Thread: 4.76 seconds, 2 Threads: 4.76 seconds</p>

<p>With reg variable and -O2 optimization:
1 Thread: 0.43 seconds, 2 Threads: 0.6 seconds <strong>2 Threads is now slower?</strong></p>

<p>With Dameon's suggestion, which was to put a large block of memory in between the two result variables:
1 Thread: 0.42 seconds, 2 Threads: 0.64 seconds</p>

<p>With TAS 's suggestion of using iterators to access contents of the vector:
1 Thread: 0.38 seconds, 2 Threads: 0.56 seconds</p>

<p>Same as above on Core i7 920 (single channel memory 4GB):
1 Thread: 0.31 seconds, 2 Threads: 0.56 seconds</p>

<p>Same as above on Core i7 920 (dual channel memory 2x2GB):
1 Thread: 0.31 seconds, 2 Threads: 0.35 seconds</p>
","922184","","<blockquote>
  <p>Why are 2 threads 6x slower than 1 thread?</p>
</blockquote>

<p>You are getting hit by a bad case of <a href=""http://en.wikipedia.org/wiki/False_sharing"">false sharing</a>.</p>

<blockquote>
  <p>After getting rid of the false-sharing, why is 2 threads not faster than 1 thread?</p>
</blockquote>

<p>You are bottlenecked by your memory bandwidth.</p>

<hr>

<p><strong>False Sharing:</strong></p>

<p>The problem here is that each thread is accessing the <code>result</code> variable at adjacent memory locations. It's likely that they fall on the same cacheline so each time a thread accesses it, it will bounce the cacheline between the cores.</p>

<p>Each thread is running this loop:</p>

<pre><code>for(uint32_t i = 0; i &lt; length; i ++) {
    *result += (*datavec).at(start + i);
}
</code></pre>

<p>And you can see that the <code>result</code> variable is being accessed very often (each iteration). So each iteration, the threads are fighting for the same cacheline that's holding both values of <code>result</code>.</p>

<p>Normally, the compiler should put <code>*result</code> into a register thereby removing the constant access to that memory location. But since you never turned on optimizations, it's very likely the compiler is indeed still accessing the memory location and thus incurring false-sharing penalties at every iteration of the loop.</p>

<p><strong>Memory Bandwidth:</strong></p>

<p>Once you have eliminated the false sharing and got rid of the 6x slowdown, the reason why you're not getting improvement is because you've maxed out your memory bandwidth.</p>

<p>Sure your processor may be 4 cores, but they all share the same memory bandwidth. Your particular task of summing up an array does very little (computational) work for each memory access. A single thread is already enough to max out your memory bandwidth. Therefore going to more threads is not likely to get you much improvement.</p>

<p>In short, no you won't be able to make summing an array significantly faster by throwing more threads at it.</p>
"
"<p>I mean: how can I measure time my CPU spent on function execution and wall clock time it takes to run my function? (Im interested in Linux/Windows and both x86 and x86_64). See what I want to do (Im using C++ here but I would prefer C solution):</p>

<pre><code>int startcputime, endcputime, wcts, wcte;

startcputime = cputime();
function(args);
endcputime = cputime();

std::cout &lt;&lt; ""it took "" &lt;&lt; endcputime - startcputime &lt;&lt; "" s of CPU to execute this\n"";

wcts = wallclocktime();
function(args);
wcte = wallclocktime();

std::cout &lt;&lt; ""it took "" &lt;&lt; wcte - wcts &lt;&lt; "" s of real time to execute this\n"";
</code></pre>

<p><strong>Another important question: is this type of time measuring architecture independent or not?</strong></p>
","922184","","<p>Here's a copy-paste solution that works on both Windows and Linux as well as C and C++.</p>

<p>As mentioned in the comments, there's a boost library that does this. But if you can't use boost, this should work:</p>

<pre><code>//  Windows
#ifdef _WIN32
#include &lt;Windows.h&gt;
double get_wall_time(){
    LARGE_INTEGER time,freq;
    if (!QueryPerformanceFrequency(&amp;freq)){
        //  Handle error
        return 0;
    }
    if (!QueryPerformanceCounter(&amp;time)){
        //  Handle error
        return 0;
    }
    return (double)time.QuadPart / freq.QuadPart;
}
double get_cpu_time(){
    FILETIME a,b,c,d;
    if (GetProcessTimes(GetCurrentProcess(),&amp;a,&amp;b,&amp;c,&amp;d) != 0){
        //  Returns total user time.
        //  Can be tweaked to include kernel times as well.
        return
            (double)(d.dwLowDateTime |
            ((unsigned long long)d.dwHighDateTime &lt;&lt; 32)) * 0.0000001;
    }else{
        //  Handle error
        return 0;
    }
}

//  Posix/Linux
#else
#include &lt;sys/time.h&gt;
double get_wall_time(){
    struct timeval time;
    if (gettimeofday(&amp;time,NULL)){
        //  Handle error
        return 0;
    }
    return (double)time.tv_sec + (double)time.tv_usec * .000001;
}
double get_cpu_time(){
    return (double)clock() / CLOCKS_PER_SEC;
}
#endif
</code></pre>

<p>There's a bunch of ways to implement these clocks. But here's what the above snippet uses:</p>

<p>For Windows:</p>

<ul>
<li>Wall Time: <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/aa373083%28v=vs.85%29.aspx"">Performance Counters</a></li>
<li>CPU Time: <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/ms683223%28v=vs.85%29.aspx""><code>GetProcessTimes()</code></a></li>
</ul>

<p>For Linux:</p>

<ul>
<li>Wall Time: <a href=""http://linux.die.net/man/2/gettimeofday""><code>gettimeofday()</code></a></li>
<li>CPU Time: <a href=""http://www.cplusplus.com/reference/ctime/clock/""><code>clock()</code></a></li>
</ul>

<hr>

<p>And here's a small demonstration:</p>

<pre><code>#include &lt;math.h&gt;
#include &lt;iostream&gt;
using namespace std;

int main(){

    //  Start Timers
    double wall0 = get_wall_time();
    double cpu0  = get_cpu_time();

    //  Perform some computation.
    double sum = 0;
#pragma omp parallel for reduction(+ : sum)
    for (long long i = 1; i &lt; 10000000000; i++){
        sum += log((double)i);
    }

    //  Stop timers
    double wall1 = get_wall_time();
    double cpu1  = get_cpu_time();

    cout &lt;&lt; ""Wall Time = "" &lt;&lt; wall1 - wall0 &lt;&lt; endl;
    cout &lt;&lt; ""CPU Time  = "" &lt;&lt; cpu1  - cpu0  &lt;&lt; endl;

    //  Prevent Code Elimination
    cout &lt;&lt; endl;
    cout &lt;&lt; ""Sum = "" &lt;&lt; sum &lt;&lt; endl;

}
</code></pre>

<p>Output (12 threads):</p>

<pre><code>Wall Time = 15.7586
CPU Time  = 178.719

Sum = 2.20259e+011
</code></pre>
"
"<p>Regarding OOO, lets assume I have one process only (with one thread) that runs this code:</p>

<pre><code>void foo() {

    if (x == 0) {
        return;
    }

    y-&gt;data = 5;

}
</code></pre>

<p>Now, lets assume <em>I know</em> that <code>y</code> is valid only if <code>x</code> is not zero.
from hardware perspective, can the CPU execute <code>y-&gt;data = 5</code> before reading <code>x</code>?
It may cause the CPU to access a NULL/garbage pointer and crashs.</p>

<p>And if not, what is the reason for this?
because if/while/for/goto are control statements and the CPU will not fetch ahead instructions when it sees a control statement?</p>

<p>A I remember, OOO should be 100% transparent to one thread executing its instructions.</p>
","922184","","<p>Depends on how you look at it.</p>

<ul>
<li>From the user's perspective, no.</li>
<li>From the CPU's perspective, yes.</li>
</ul>

<p>From the user's perspective, the behavior of the program must be ""as if"" it was run sequentially.<br>
In other words, there is no visible difference between being run sequentially and being run with OOE. (aside from maybe performance)</p>

<p>From the CPU's perspective, yes it actually can bypass the if-statement and execute <code>y-&gt;data = 5;</code>. But this is because of <a href=""http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array"">branch prediction</a> rather than OOE.</p>

<hr>

<p>On a modern processor, it is possible for the thread to mispredict the branch:</p>

<pre><code>if (x == 0) {
    return;
}
</code></pre>

<p>and actually try to execute <code>y-&gt;data = 5;</code>...</p>

<p>If this happens and <code>y</code> is a bad pointer, it will get hardware exception, but that exception is withheld since the execution is still in speculation mode.</p>

<p>Once the thread realizes that it has mispredicted the branch, it will throw away everything past the branch (including the exception).</p>

<p>So in the end, there is nothing to worry. Even if the processor tries to do something it can't, it won't affect the sequential behavior.</p>

<p><em>In other words, a modern processor will clean up after itself if it makes a mess that isn't your fault.</em></p>

<hr>

<p>Things get uglier when you have multiple threads, but that's outside the scope of this question.</p>
"
"<p>I am investigating the effect of vectorization on the performance of the program. In this regard, I have written following code:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;stdlib.h&gt;

#define LEN 10000000

int main(){

    struct timeval stTime, endTime;

    double* a = (double*)malloc(LEN*sizeof(*a));
    double* b = (double*)malloc(LEN*sizeof(*b));
    double* c = (double*)malloc(LEN*sizeof(*c));

    int k;
    for(k = 0; k &lt; LEN; k++){
        a[k] = rand();
        b[k] = rand();
    }

    gettimeofday(&amp;stTime, NULL);

    for(k = 0; k &lt; LEN; k++)
        c[k] = a[k] * b[k];

    gettimeofday(&amp;endTime, NULL);

    FILE* fh = fopen(""dump"", ""w"");
    for(k = 0; k &lt; LEN; k++)
        fprintf(fh, ""c[%d] = %f\t"", k, c[k]);
    fclose(fh);

    double timeE = (double)(endTime.tv_usec + endTime.tv_sec*1000000 - stTime.tv_usec - stTime.tv_sec*1000000);

    printf(""Time elapsed: %f\n"", timeE);

    return 0;
}
</code></pre>

<p>In this code, I am simply initializing and multiplying two vectors. The results are saved in vector <code>c</code>. What I am mainly interested in is the effect of vectorizing following loop:</p>

<pre><code>for(k = 0; k &lt; LEN; k++)
    c[k] = a[k] * b[k];
</code></pre>

<p>I compile the code using following two commands:</p>

<pre><code>1) icc -O2 TestSMID.c -o TestSMID -no-vec -no-simd
2) icc -O2 TestSMID.c -o TestSMID -vec-report2
</code></pre>

<p>I expect to see performance improvement since the second command successfully vectorizes the loop. However, my studies show that there is no performance improvement when the loop is vectorized.</p>

<p>I may have missed something here since I am not super familiar with the topic. So, please let me know if there is something wrong with my code.</p>

<p>Thanks in advance for your help.</p>

<p>PS: I am using Mac OSX, so there is no need to align the data as all the allocated memories are 16-byte aligned.</p>

<p>Edit:
I would like to first thank you all for your comments and answers.
I thought about the answer proposed by @Mysticial and there are some further points that should be mentioned here.
Firstly, as @Vinska mentioned, <code>c[k]=a[k]*b[k]</code> does not take only one cycle. In addition to loop index increment and the comparison made to ensure that <code>k</code> is smaller than <code>LEN</code>, there are other things to be done to perform the operation. Having a look at the assembly code generated by the compiler, it can be seen that a simple multiplication needs much more than one cycle. The vectorized version looks like:</p>

<pre><code>L_B1.9:                         # Preds L_B1.8
        movq      %r13, %rax                                    #25.5
        andq      $15, %rax                                     #25.5
        testl     %eax, %eax                                    #25.5
        je        L_B1.12       # Prob 50%                      #25.5
                                # LOE rbx r12 r13 r14 r15 eax
L_B1.10:                        # Preds L_B1.9
        testb     $7, %al                                       #25.5
        jne       L_B1.32       # Prob 10%                      #25.5
                                # LOE rbx r12 r13 r14 r15
L_B1.11:                        # Preds L_B1.10
        movsd     (%r14), %xmm0                                 #26.16
        movl      $1, %eax                                      #25.5
        mulsd     (%r15), %xmm0                                 #26.23
        movsd     %xmm0, (%r13)                                 #26.9
                                # LOE rbx r12 r13 r14 r15 eax
L_B1.12:                        # Preds L_B1.11 L_B1.9
        movl      %eax, %edx                                    #25.5
        movl      %eax, %eax                                    #26.23
        negl      %edx                                          #25.5
        andl      $1, %edx                                      #25.5
        negl      %edx                                          #25.5
        addl      $10000000, %edx                               #25.5
        lea       (%r15,%rax,8), %rcx                           #26.23
        testq     $15, %rcx                                     #25.5
        je        L_B1.16       # Prob 60%                      #25.5
                                # LOE rdx rbx r12 r13 r14 r15 eax
L_B1.13:                        # Preds L_B1.12
        movl      %eax, %eax                                    #25.5
                                # LOE rax rdx rbx r12 r13 r14 r15
L_B1.14:                        # Preds L_B1.14 L_B1.13
        movups    (%r15,%rax,8), %xmm0                          #26.23
        movsd     (%r14,%rax,8), %xmm1                          #26.16
        movhpd    8(%r14,%rax,8), %xmm1                         #26.16
        mulpd     %xmm0, %xmm1                                  #26.23
        movntpd   %xmm1, (%r13,%rax,8)                          #26.9
        addq      $2, %rax                                      #25.5
        cmpq      %rdx, %rax                                    #25.5
        jb        L_B1.14       # Prob 99%                      #25.5
        jmp       L_B1.20       # Prob 100%                     #25.5
                                # LOE rax rdx rbx r12 r13 r14 r15
L_B1.16:                        # Preds L_B1.12
        movl      %eax, %eax                                    #25.5
                                # LOE rax rdx rbx r12 r13 r14 r15
L_B1.17:                        # Preds L_B1.17 L_B1.16
        movsd     (%r14,%rax,8), %xmm0                          #26.16
        movhpd    8(%r14,%rax,8), %xmm0                         #26.16
        mulpd     (%r15,%rax,8), %xmm0                          #26.23
        movntpd   %xmm0, (%r13,%rax,8)                          #26.9
        addq      $2, %rax                                      #25.5
        cmpq      %rdx, %rax                                    #25.5
        jb        L_B1.17       # Prob 99%                      #25.5
                                # LOE rax rdx rbx r12 r13 r14 r15
L_B1.18:                        # Preds L_B1.17
        mfence                                                  #25.5
                                # LOE rdx rbx r12 r13 r14 r15
L_B1.19:                        # Preds L_B1.18
        mfence                                                  #25.5
                                # LOE rdx rbx r12 r13 r14 r15
L_B1.20:                        # Preds L_B1.14 L_B1.19 L_B1.32
        cmpq      $10000000, %rdx                               #25.5
        jae       L_B1.24       # Prob 0%                       #25.5
                                # LOE rdx rbx r12 r13 r14 r15
L_B1.22:                        # Preds L_B1.20 L_B1.22
        movsd     (%r14,%rdx,8), %xmm0                          #26.16
        mulsd     (%r15,%rdx,8), %xmm0                          #26.23
        movsd     %xmm0, (%r13,%rdx,8)                          #26.9
        incq      %rdx                                          #25.5
        cmpq      $10000000, %rdx                               #25.5
        jb        L_B1.22       # Prob 99%                      #25.5
                                # LOE rdx rbx r12 r13 r14 r15
L_B1.24:                        # Preds L_B1.22 L_B1.20
</code></pre>

<p>And non-vectoized version is:</p>

<pre><code>L_B1.9:                         # Preds L_B1.8
        xorl      %eax, %eax                                    #25.5
                                # LOE rbx r12 r13 r14 r15 eax
L_B1.10:                        # Preds L_B1.10 L_B1.9
        lea       (%rax,%rax), %edx                             #26.9
        incl      %eax                                          #25.5
        cmpl      $5000000, %eax                                #25.5
        movsd     (%r15,%rdx,8), %xmm0                          #26.16
        movsd     8(%r15,%rdx,8), %xmm1                         #26.16
        mulsd     (%r13,%rdx,8), %xmm0                          #26.23
        mulsd     8(%r13,%rdx,8), %xmm1                         #26.23
        movsd     %xmm0, (%rbx,%rdx,8)                          #26.9
        movsd     %xmm1, 8(%rbx,%rdx,8)                         #26.9
        jb        L_B1.10       # Prob 99%                      #25.5
                                # LOE rbx r12 r13 r14 r15 eax
</code></pre>

<p>Beside this, the processor does not load only 24 bytes. In each access to memory, a full line (64 bytes) is loaded. More importantly, since the memory required for <code>a</code>, <code>b</code>, and <code>c</code> is contiguous, prefetcher would definitely help a lot and loads next blocks in advance.
Having said that, I think the memory bandwidth calculated by @Mysticial is too pessimistic.</p>

<p>Moreover, using SIMD to improve the performance of program for a very simple addition is mentioned in <a href=""http://download-software.intel.com/sites/default/files/m/d/4/1/d/8/CompilerAutovectorizationGuide.pdf"">Intel Vectorization Guide</a>. Therefore, it seems we should be able to gain some performance improvement for this very simple loop.</p>

<p>Edit2: 
Thanks again for your comments. Also, thank to @Mysticial sample code, I finally saw the effect of SIMD on performance improvement. The problem, as Mysticial mentioned, was the memory bandwidth. With choosing small size for <code>a</code>, <code>b</code>, and <code>c</code> which fit into the L1 cache, it can be seen that SIMD can help to improve the performance significantly. Here are the results that I got:</p>

<pre><code>icc -O2 -o TestSMIDNoVec -no-vec TestSMID2.c: 17.34 sec

icc -O2 -o TestSMIDVecNoUnroll -vec-report2 TestSMID2.c: 9.33 sec
</code></pre>

<p>And unrolling the loop improves the performance even further:</p>

<pre><code>icc -O2 -o TestSMIDVecUnroll -vec-report2 TestSMID2.c -unroll=8: 8.6sec
</code></pre>

<p>Also, I should mention that it takes only one cycle for my processor to complete an iteration when compiled with <code>-O2</code>.</p>

<p>PS: My computer is a Macbook Pro core i5 @2.5GHz (dual core)</p>
","922184","","<p>Because you're bottlenecked by memory bandwidth.</p>

<p>While vectorization and other micro-optimizations can improve the speed of computation, they can't increase the speed of your memory.</p>

<p>In your example:</p>

<pre><code>for(k = 0; k &lt; LEN; k++)
    c[k] = a[k] * b[k];
</code></pre>

<p>You are making a single pass over all the memory doing very little work. This is maxing out your memory bandwidth.</p>

<p>So regardless of how it's optimized, (vectorized, unrolled, etc...) it isn't gonna get much faster.</p>

<hr>

<p>A typical desktop machine of 2013 has on the order of <strong>10 GB/s</strong> of memory bandwidth*.<br>Your loop touches <strong>24 bytes/iteration</strong>.</p>

<p>Without vectorization, a modern x64 processor can probably do about 1 iteration a cycle*.</p>

<p>Suppose you're running at 4 GHz:</p>

<ul>
<li><code>(4 * 10^9) * 24 bytes/iteration = 96 GB/s</code></li>
</ul>

<p>That's almost 10x of your memory bandwidth - without vectorization.</p>

<hr>

<p>*Not surprisingly, a few people doubted the numbers I gave above since I gave no citation. Well those were off the top of my head from experience. So here's some benchmarks to prove it.</p>

<p><strong>The loop iteration can run as fast as 1 cycle/iteration:</strong></p>

<p>We can get rid of the memory bottleneck if we reduce <code>LEN</code> so that it fits in cache.<br>
(I tested this in C++ since it was easier. But it makes no difference.)</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;time.h&gt;
using std::cout;
using std::endl;

int main(){
    const int LEN = 256;

    double *a = (double*)malloc(LEN*sizeof(*a));
    double *b = (double*)malloc(LEN*sizeof(*a));
    double *c = (double*)malloc(LEN*sizeof(*a));

    int k;
    for(k = 0; k &lt; LEN; k++){
        a[k] = rand();
        b[k] = rand();
    }

    clock_t time0 = clock();

    for (int i = 0; i &lt; 100000000; i++){
        for(k = 0; k &lt; LEN; k++)
            c[k] = a[k] * b[k];
    }

    clock_t time1 = clock();
    cout &lt;&lt; (double)(time1 - time0) / CLOCKS_PER_SEC &lt;&lt; endl;
}
</code></pre>

<ul>
<li>Processor: Intel Core i7 2600K @ 4.2 GHz</li>
<li>Compiler: Visual Studio 2012</li>
<li>Time: 6.55 seconds</li>
</ul>

<p>In this test, I ran 25,600,000,000 iterations in only <strong>6.55</strong> seconds.</p>

<ul>
<li><code>6.55 * 4.2 GHz</code> = <strong>27,510,000,000 cycles</strong></li>
<li><code>27,510,000,000 / 25,600,000,000</code> = <strong>1.074 cycles/iteration</strong></li>
</ul>

<hr>

<p>Now if you're wondering how it's possible to do:</p>

<ul>
<li>2 loads</li>
<li>1 store</li>
<li>1 multiply</li>
<li>increment counter</li>
<li>compare + branch</li>
</ul>

<p>all in one cycle...</p>

<p>It's because modern processors and compilers are awesome.</p>

<p>While each of these operations have latency (especially the multiply), the processor is able to execute multiple iterations at the same time. My test machine is a Sandy Bridge processor, which is capable of sustaining 2 loads, 1 store, and 1 multiply every single cycle.</p>

<p>Looking at the assembly (which I'll omit for brevity), it seems that the compiler unrolled the loop, thereby reducing the looping overhead. But it didn't quite manage to vectorize it.</p>

<hr>

<p><strong>Memory bandwidth is on the order of 10 GB/s:</strong></p>

<p>The easiest way to test this is via a <code>memset()</code>:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;time.h&gt;
using std::cout;
using std::endl;

int main(){
    const int LEN = 1 &lt;&lt; 30;    //  1GB

    char *a = (char*)calloc(LEN,1);

    clock_t time0 = clock();

    for (int i = 0; i &lt; 100; i++){
        memset(a,0xff,LEN);
    }

    clock_t time1 = clock();
    cout &lt;&lt; (double)(time1 - time0) / CLOCKS_PER_SEC &lt;&lt; endl;
}
</code></pre>

<ul>
<li>Processor: Intel Core i7 2600K @ 4.2 GHz</li>
<li>Compiler: Visual Studio 2012</li>
<li>Time: 5.811 seconds</li>
</ul>

<p>So it takes my machine <strong>5.811</strong> seconds to write to 100 GB of memory. That's about <strong>17.2 GB/s</strong>.</p>

<p>And my processor is on the higher end. The Nehalem and Core 2 generation processors have less memory bandwidth.</p>
"
"<p>In addition to <a href=""http://stackoverflow.com/questions/18314523/sse-copy-avx-copy-and-stdcopy-performance"">SSE-copy, AVX-copy and std::copy performance</a>. Suppose that we need to vectorize some loop in following manner: 1) vectorize first loop-batch (which is multiple by 8) via AVX. 2) split loop's remainder into two batches. Vectorize the batch that is a multiple of 4 via SSE. 3) Process residual batch of entire loop via serial routine. Let's consider example of copying arrays:</p>

<pre><code>#include &lt;immintrin.h&gt;

template&lt;int length,
         int unroll_bound_avx = length &amp; (~7),
         int unroll_tail_avx  = length - unroll_bound_avx,
         int unroll_bound_sse = unroll_tail_avx &amp; (~3),
         int unroll_tail_last = unroll_tail_avx - unroll_bound_sse&gt;
void simd_copy(float *src, float *dest)
{
    auto src_  = src;
    auto dest_ = dest;

    //Vectorize first part of loop via AVX
    for(; src_!=src+unroll_bound_avx; src_+=8, dest_+=8)
    {
         __m256 buffer = _mm256_load_ps(src_);
         _mm256_store_ps(dest_, buffer);
    }

    //Vectorize remainder part of loop via SSE
    for(; src_!=src+unroll_bound_sse+unroll_bound_avx; src_+=4, dest_+=4)
    {
        __m128 buffer = _mm_load_ps(src_);
        _mm_store_ps(dest_, buffer);
    }

    //Process residual elements
    for(; src_!=src+length; ++src_, ++dest_)
        *dest_ = *src_;
}

int main()
{  
    const int sz = 15;
    float *src = (float *)_mm_malloc(sz*sizeof(float), 16);
    float *dest = (float *)_mm_malloc(sz*sizeof(float), 16);
    float a=0;
    std::generate(src, src+sz, [&amp;](){return ++a;});

    simd_copy&lt;sz&gt;(src, dest);

    _mm_free(src);
    _mm_free(dest);
}
</code></pre>

<p>Is it correct to use both SSE and AVX? Do I need to avoid AVX-SSE transitions? </p>
","922184","","<p>You can mix SSE and AVX intrinsics all you want.</p>

<p>The only thing you want to make sure is to specify the correct compiler flag to enable AVX.</p>

<ul>
<li>GCC: <code>-mavx</code></li>
<li>Visual Studio: <code>/arch:AVX</code></li>
</ul>

<p>Failing to do so will either result in the code not compiling (GCC), or in the case of Visual Studio,<br>
this kind of crap:</p>

<ul>
<li><a href=""http://stackoverflow.com/questions/7839925/using-avx-cpu-instructions-poor-performance-without-archavx"">Using AVX CPU instructions: Poor performance without &quot;/arch:AVX&quot;</a></li>
</ul>

<p>What the flag does is that it forces all SIMD instructions to use VEX encoding to avoid the state-switching penalties described in the question above.</p>
"
"<p>I have the following working implementation of <code>modf</code> using SSE intrinsics, but it seems quite wasteful to be converting to <code>__m128i</code> and back in the process, when I need the result as a <code>__m128</code>. </p>

<pre><code>__m128 integer = _mm_cvtepi32_ps(_mm_cvttps_epi32(value));
__m128 fraction = _mm_sub_ps(value, integer);
</code></pre>

<p>Does there exist an instruction for truncation without type conversion, or some magic number hack?</p>
","922184","","<p>With SSE4.1, you can use the <a href=""http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/composerxe/compiler/cpp-mac/GUID-DAFA16CE-DB78-4FFD-9C1E-4AE0EA96CEA7.htm"" rel=""nofollow""><code>roundps</code> and <code>roundpd</code></a> instructions:</p>

<pre><code>//  Single Precision
__m128 integer = _mm_round_ps(value,_MM_FROUND_TRUNC);
__m128 fraction = _mm_sub_ps(value,integer);

//  Double Precision
__m128d integer = _mm_round_pd(value,_MM_FROUND_TRUNC);
__m128d fraction = _mm_sub_pd(value,integer);
</code></pre>

<p>This will separate the integer and fractional parts while preserving the sign for both of them.</p>

<p>Likewise, for AVX:</p>

<pre><code>//  Single Precision
__m256 integer = _mm256_round_ps(value,_MM_FROUND_TRUNC);
__m256 fraction = _mm256_sub_ps(value,integer);

//  Double Precision
__m256d integer = _mm256_round_pd(value,_MM_FROUND_TRUNC);
__m256d fraction = _mm256_sub_pd(value,integer);
</code></pre>

<hr>

<p>If you also have the XOP instruction set, you can get the fractional part alone with only one instruction (via <code>_mm256_frcz_pd</code> and family).</p>

<p>But without SSE4.1, then there isn't really a better way to do it aside from converting, or doing the +/- magic number trick. (both of which will run into problems in the case of overflow)</p>
"
"<p>Very simple question, probably difficult answer:</p>

<p>Does using SSE instructions for example for parallel sum/min/max/average operations consume more power than doing any other instructions (e.g. a single sum)?</p>

<p>For example, on <a href=""http://en.wikipedia.org/wiki/Streaming_SIMD_Extensions"" rel=""nofollow"">Wikipedia</a> I couldn't find any information in this respect.</p>

<p>The only hint of an answer I could find is <a href=""http://serverfault.com/a/196590"">here</a>, but it's a little bit generic and there is no reference to any published material in this respect.</p>
","922184","","<p>I actually did a study on this a few years ago. The answer depends on what exactly your question is:</p>

<p>In today's processors, power consumption is not much determined by the type of instruction (scalar vs. SIMD), but rather everything else such as:</p>

<ol>
<li>Memory/cache</li>
<li>Instruction decoding</li>
<li>OOE, register file</li>
<li>And lots others.</li>
</ol>

<hr>

<p>So if the question is:</p>

<blockquote>
  <p>All other things being equal: Does a SIMD instruction consume more power than a scalar instruction.</p>
</blockquote>

<p>For this, I dare to say yes.</p>

<p>One of my graduate school projects eventually became <a href=""http://stackoverflow.com/a/8391601/922184"">this answer</a>: A side-by-side comparison of SSE2 (2-way SIMD) and AVX (4-way SIMD) did in fact show that AVX had a noticably higher power consumption and higher processor temperatures. (I don't remember the exact numbers though.)</p>

<p>This is because the code is identical between the SSE and the AVX. Only the width of the instruction was different. And the AVX version did double the work.</p>

<p>But if the question is:</p>

<blockquote>
  <p>Will vectorizing my code to use SIMD consume more power than a scalar implementation.</p>
</blockquote>

<p>There's numerous factors involved here so I'll avoid a direct answer:</p>

<p><strong>Factors that reduce power consumption:</strong></p>

<ul>
<li><p>We need to remember that the point of SIMD is to improve performance. And if you can improve performance, your app will take less time to run thus saving you power.</p></li>
<li><p>Depending on the application and the implementation, SIMD will reduce the number instructions that are needed to do a certain task. That's because you're doing per instruction.</p></li>
</ul>

<p><strong>Factors that increase power consumption:</strong></p>

<ul>
<li>As mentioned earlier, SIMD instructions do more work and can use more power than scalar equivalents.</li>
<li>Use of SIMD introduces overhead not present in scalar code (such as shuffle and permute instructions). These also need to go through the instruction execution pipeline.</li>
</ul>

<hr>

<p>Breaking it down:</p>

<ul>
<li>Fewer instructions -> less overhead for issuing and executing them -> less power</li>
<li>Faster code -> run less time -> less power</li>
<li>SIMD takes more power to execute -> more power</li>
</ul>

<p>So SIMD saves you power by making your app take less time. But while its running, it consumes more power per unit time. Who wins depends on the situation.</p>

<p>From my experience, for applications that get a worthwhile speedup from SIMD (or anything other method), the former usually wins and the power consumption goes down.</p>

<p>That's because run-time tends to be the dominant factor in power consumption for modern PCs (laptops, desktops, servers). The reason being that most of the power consumption is not in the CPU, but rather in everything else: motherboard, ram, hard drives, monitors, idle video cards, etc... most of which have a relatively fixed power draw.</p>

<p>For my computer, just keeping it on (idle) already draws more than half of what it can draw under an all-core SIMD load such as prime95 or Linpack. So if I can make an app 2x faster by means of SIMD/parallelization, I've almost certainly saved power.</p>
"
"<p>There's a comment in the <a href=""http://www.zlib.net/"">zlib compression library</a> (which is used in the Chromium project among many others) which implies that a do-while loop in C generates ""better"" code on most compilers. Here is the snippet of code where it appears.</p>

<pre><code>do {
} while (*(ushf*)(scan+=2) == *(ushf*)(match+=2) &amp;&amp;
         *(ushf*)(scan+=2) == *(ushf*)(match+=2) &amp;&amp;
         *(ushf*)(scan+=2) == *(ushf*)(match+=2) &amp;&amp;
         *(ushf*)(scan+=2) == *(ushf*)(match+=2) &amp;&amp;
         scan &lt; strend);
/* The funny ""do {}"" generates better code on most compilers */
</code></pre>

<p><a href=""https://code.google.com/p/chromium/codesearch#chromium/src/third_party/zlib/deflate.c&amp;l=1225"">https://code.google.com/p/chromium/codesearch#chromium/src/third_party/zlib/deflate.c&amp;l=1225</a></p>

<p>Is there any evidence that most (or any) compilers would generate better (e.g. more efficient) code?</p>

<p><strong>Update:</strong> <a href=""http://en.wikipedia.org/wiki/Mark_Adler"">Mark Adler</a>, one of the original authors, <a href=""http://stackoverflow.com/questions/20172402/do-compilers-produce-better-code-for-do-while-loops-versus-other-types-of-loops?noredirect=1#comment30090750_20172402"">gave a bit of context</a> in the comments.</p>
","922184","","<p>First of all:</p>

<p>A <code>do-while</code> loop is not the same as a <code>while</code>-loop or a <code>for</code>-loop.</p>

<ul>
<li><code>while</code> and <code>for</code> loops may not run the loop body at all.</li>
<li>A <code>do-while</code> loop always runs the loop body at least once - it skips the initial condition check.</li>
</ul>

<p>So that's the logical difference. That said, not everyone strictly adheres to this. It is quite common for <code>while</code> or <code>for</code> loops to be used even when it is guaranteed that it will always loop at least once. (Especially in languages with <a href=""http://en.wikipedia.org/wiki/Foreach_loop"">foreach</a> loops.)</p>

<p>So to avoid comparing apples and oranges, I'll proceed assuming that the loop will always run at least once. Furthermore, I won't mention <code>for</code> loops again since they are essentially <code>while</code> loops with a bit of syntax sugar for a loop counter.</p>

<p>So I'll be answering the question:</p>

<p><em>If a <code>while</code> loop is guaranteed to loop at least once, is there any performance gain from using a <code>do-while</code> loop instead.</em></p>

<hr>

<p>A <code>do-while</code> skips the first condition check. So there is one less branch and one less condition to evaluate.</p>

<p>If the condition is expensive to check, and you know you're guaranteed to loop at least once, then a <code>do-while</code> loop could be faster.</p>

<p>And while this is considered a micro-optimization at best, it is one that the compiler can't always do: Specifically when the compiler is unable to prove that the loop will always enter at least once.</p>

<hr>

<p>In other words, a while-loop:</p>

<pre><code>while (condition){
    body
}
</code></pre>

<p>Is effectively the same as this:</p>

<pre><code>if (condition){
    do{
        body
    }while (condition);
}
</code></pre>

<p>If you know that you will always loop at least once, that if-statement is extraneous.</p>

<hr>

<p>Likewise at the assembly level, this is roughly how the different loops compile to:</p>

<p><strong>do-while loop:</strong></p>

<pre><code>start:
    body
    test
    conditional jump to start
</code></pre>

<p><strong>while-loop:</strong></p>

<pre><code>    test
    conditional jump to end
start:
    body
    test
    conditional jump to start
end:
</code></pre>

<p>Note that the condition has been duplicated. An alternate approach is:</p>

<pre><code>    unconditional jump to end
start:
    body
end:
    test
    conditional jump to start
</code></pre>

<p>... which trades away the duplicate code for an additional jump.</p>

<p>Either way, it's still worse than a normal <code>do-while</code> loop.</p>

<p>That said, compilers can do what they want. And if they can prove that the loop always enters once, then it has done the work for you.</p>

<hr>

<p>But things are bit weird for the particular example in the question because it has an empty loop body. Since there is no body, there's no logical difference between <code>while</code> and <code>do-while</code>.</p>

<p>FWIW, I tested this in Visual Studio 2012:</p>

<ul>
<li><p>With the empty body, it does actually generate the same code for <code>while</code> and <code>do-while</code>. So that part is likely a remnant of the old days when compilers weren't as great.</p></li>
<li><p>But with a non-empty body, VS2012 manages to avoid duplication of the condition code, but still generates an extra conditional jump.</p></li>
</ul>

<p>So it's ironic that while the example in the question highlights why a <code>do-while</code> loop could be faster in the general case, the example itself doesn't seem to give any benefit on a modern compiler.</p>

<p>Considering how old the comment was, we can only guess at why it would matter. It's very possible that the compilers at the time weren't capable of recognizing that the body was empty. (Or if they did, they didn't use the information.)</p>
"
"<p>I am accessing a shared library (shared array data structure)from program1 and find the access time to read all elements of that array. I got around 17000 ticks while only Program1 executed alone.</p>

<p>Now when I execute program2 (having empty while loop to hold it from termination) in another tab first , then run program1 and measure the access time to read all elements of that array.
To my surprise now I am getting 8000ticks as compared to previous scenario where only Program1 executing.</p>

<p>It looks like while ONLY program1 is executing it takes more time to read the array as compared to while there are 2 Programs ,program1 is doing same task as previous and program2 keeps CPU busy by while loop. Expected is higher access time with presence of program1, whereas real outcome is opposite .</p>

<p>Why this happening? </p>

<p>Here is shared library</p>

<pre><code>#include &lt;stdio.h&gt; 
static const int DATA[1024]={1 ,2 ,3,.....1024];
inline void foo(void)
{
    int j, k=0,count=0;

    for(j=0;j&lt;1024;j++)
      {
        k=DATA[j];
      }

    k+=0;    
}
</code></pre>

<p><strong>Program1</strong></p>

<pre><code>   int main(void)
    {    
    foo();

    start=timer();
    foo();
    end=timer();
    printf(""Time1=%llu\n"",end-start);    

    start=timer();
    foo();
    end=timer();
    printf(""Time2=%llu\n"",end-start);    


    start=timer();
    foo();
    end=timer();
    printf(""Time3=%llu\n"",end-start); 
    sleep(1);

    start=timer();
    foo();
    end=timer();
    printf(""after sleep(1)\n"");
    printf(""Time4=%llu\n"",end-start);    

    start=timer();
    foo();
    end=timer();
    printf(""Time5=%llu\n"",end-start);    

    sleep(2); 
    start=timer();
    foo();
    end=timer();
    printf(""after sleep(2)\n"");
    printf(""Time6=%llu\n"",end-start);    

    return 0;
    }
</code></pre>

<p><strong>program2</strong></p>

<pre><code>   int main(void)
    {
    while(1)
        {}        
    return 0;
    }
</code></pre>

<p><strong>CASE1 (ONLY Program1 running)</strong></p>

<p><strong>output</strong></p>

<pre><code>Time1=17918
Time2=17672  
Time3=17816  

after sleep(1)
**Time4= 20716 ** // Is it due to wake up from sleep mode ?
Time5=17722

after sleep(2)
**Time6=20910** // Is it due to wake up from sleep mode ?
</code></pre>

<p><strong>CASE1 (Program2 runs first, then Program1 starts running)</strong></p>

<p><strong>output</strong></p>

<pre><code>Time1 =7483  
Time2=7205
Time3=7399

after sleep(1)
**Time4= 8734 ** // Is it due to wake up from sleep mode ?
Time5=7326

after sleep(2)
**Time6=9070** // Is it due to wake up from sleep mode ?
</code></pre>

<p>As per my understanding while CPU is used by program1 alone time required to read array must be less as compared to while CPU is used by both Program1 and program2.</p>

<p>Where I am making mistakes ? I have i7 machine , only one core , hyperthreading is disabled, ASLR disabled.</p>

<p><strong>EDIT 1:</strong></p>

<p>As per suggestion of Mysticial, my CPU goes into power saving mode while ONLY program1 is there , so CPU goes into power saving mode and then to wake it up from Power saving mode it takes larger access time. So his suggestion was to access the DATA array multiple times.</p>

<p>Here is my modified Shared library . Program1 and Program2 are unaltered. </p>

<pre><code>#include &lt;stdio.h&gt; 
static const int DATA[1024]={1 ,2 ,3,.....1024];
inline void foo(void)
{
    int j, k=0,count=0;
  while(count++&lt;10000)
  {  
    for(j=0;j&lt;1024;j++)
      {
        k=DATA[j];
      }
   }  
    k+=0;    
}
</code></pre>

<p><strong>Now the output is as below</strong></p>

<p><strong>CASE1 (ONLY Program1 running)</strong></p>

<p><strong>output</strong></p>

<pre><code>Time1=75186246
Time2=77570299 
Time3=80548529 

after sleep(1)
**Time4= 92608363 ** // Is it due to wake up from sleep mode ?
Time5=75616487

after sleep(2)
**Time6=97021338** // Is it due to wake up from sleep mode ?
</code></pre>

<p><strong>CASE1 (Program2 runs first, then Program1 starts running)</strong></p>

<p><strong>output</strong></p>

<pre><code>Time1 =139337099 
Time2=155801957
Time3=146586856

after sleep(1)
**Time4= 130558062 ** // Why lower access time after sleep mode ?
Time5=145250551 // Time5 is expected lower than Time4 as other run . Why lower here ?

after sleep(2)
**Time6=130940183** // Again Why lower access time after sleep mode ?
</code></pre>

<p><strong>Here are my new questions with respect to modified shared library</strong> </p>

<ol>
<li><p>When there is no program2, then after sleep access time (t4/t6) is <strong>higher</strong>  as compared to previous access time (t3/t5, before going to sleep). Can I say, it is due to waking up CPU from sleep as explained by Mysticial ?</p></li>
<li><p>Now, with program2 running in another tab, after sleep access time (t4/t6) is <strong>lower</strong>  as compared to previous access time (t3/t5, before going to sleep). Reason for my q(1) and q(2) are contradictory . What is the reason behind getting lower access time after waking up from sleep ( t4 &lt; t3)? Although I am getting higher access time after sleep without multiple access to DATA array ( original shared library).</p></li>
<li><p>Why <code>t2&lt;t1 and t3&lt;t2</code> not holding true always as shared library is loaded already into memory as well as cache . Is it due to PAGE SWAPPING ? </p></li>
</ol>

<p>I am using gcc under linux. Any help to understand this will be highly appreciated. Thanks in advance.</p>
","922184","","<p>Here's my speculative answer which seems to have been confirmed in the comments:</p>

<p>In the original benchmark, you run only one iteration of each. So the benchmark doesn't run long enough to ""average out"" all the randomness.</p>

<p>When you run program1 by itself, it needs to wake up the CPU from its power-saving state. This takes time and is likely causing the run-time to be longer.</p>

<p>When you run both programs together (starting with program2 first), program2 kicks the CPU out of power-saving state ahead of time. So this warm up penalty is not realized when you run program1.</p>

<hr>

<p>Once you loop the benchmark to take longer, this warm up penalty becomes insignificant and you finally see the expected steady-state performance of the code. (program1 by itself is faster)</p>
"
"<p>I keep seeing this constant pop up in various graphics header files</p>

<pre><code>0.0039215689
</code></pre>

<p>It seems to have something to do with color maybe?</p>

<p>Here is the first <a href=""http://ozmav.googlecode.com/svn-history/r178/trunk/badrdp/rdp.c"">hit on Google</a>:</p>

<pre><code>void RDP_G_SETFOGCOLOR(void)
{
    Gfx.FogColor.R = _SHIFTR(w1, 24, 8) * 0.0039215689f;
    Gfx.FogColor.G = _SHIFTR(w1, 16, 8) * 0.0039215689f;
    Gfx.FogColor.B = _SHIFTR(w1, 8, 8) * 0.0039215689f;
    Gfx.FogColor.A = _SHIFTR(w1, 0, 8) * 0.0039215689f;
}

void RDP_G_SETBLENDCOLOR(void)
{
    Gfx.BlendColor.R = _SHIFTR(w1, 24, 8) * 0.0039215689f;
    Gfx.BlendColor.G = _SHIFTR(w1, 16, 8) * 0.0039215689f;
    Gfx.BlendColor.B = _SHIFTR(w1, 8, 8) * 0.0039215689f;
    Gfx.BlendColor.A = _SHIFTR(w1, 0, 8) * 0.0039215689f;

    if(OpenGL.Ext_FragmentProgram &amp;&amp; (System.Options &amp; BRDP_COMBINER)) {
        glProgramEnvParameter4fARB(GL_FRAGMENT_PROGRAM_ARB, 2, Gfx.BlendColor.R, Gfx.BlendColor.G, Gfx.BlendColor.B, Gfx.BlendColor.A);
    }
}

//...more like this
</code></pre>

<p>What does this number represent? Why does no one seem to declare it as a const?</p>

<p>I couldn't find anything on Google that explained it.</p>
","922184","","<p><code>0.0039215689</code> is approximately equal to <code>1/255</code>.</p>

<p>Seeing that this is OpenGL, performance is probably important. So it's probably safe to guess that this was done for performance reasons.</p>

<p>Multiplying by the reciprocal is faster than repeatedly dividing by 255.</p>

<hr>

<p><strong>Side Note:</strong></p>

<p>If you're wondering why such a micro-optimization isn't left to the compiler, it's because it is an unsafe floating-point optimization. In other words:</p>

<pre><code>x / 255  !=  x * (1. / 255)
</code></pre>

<p>due to floating-point round-off errors.</p>

<p>So while modern compilers may be smart enough to do this optimization, they are not allowed to do it unless you explicitly tell them to via a compiler flag.</p>

<p><strong>Related:</strong> <a href=""http://stackoverflow.com/q/6430448/922184"">Why doesn&#39;t GCC optimize a*a*a*a*a*a to (a*a*a)*(a*a*a)?</a></p>
"
"<p>I was reading <a href=""http://msdn.microsoft.com/en-us/library/26232t5c.aspx"" rel=""nofollow"">this on MSDN</a>, and it says</p>

<blockquote>
  <p>You should not access the __m128i fields directly. You can, however, see these types in the debugger. A variable of type __m128i maps to the XMM[0-7] registers.</p>
</blockquote>

<p>However, it doesn't explain why. Why is it? For example, is the following ""bad"":</p>

<pre><code>void func(unsigned short x, unsigned short y)
{
    __m128i a;
    a.m128i_i64[0] = x;

    __m128i b;
    b.m128i_i64[0] = y;

    // Now do something with a and b ...
}
</code></pre>

<p>Instead of doing the assignments like in the example above, should one use some sort of <code>load</code> function?</p>
","922184","","<p>The field <code>m128i_i64</code> and family are Microsoft compiler specific extensions. They don't exist in most other compilers.</p>

<p>Nevertheless, they are useful for testing purposes.</p>

<hr>

<p>The real reason for avoiding their use is performance. The hardware cannot efficiently access individual elements of a SIMD vector.</p>

<ul>
<li>There are no instructions that let you directly access individual elements. (SSE4.1 does, but it requires a compile-time constant index.)</li>
<li>Going through memory may incur a very large penalty due to failure of <a href=""http://en.wikipedia.org/wiki/Memory_disambiguation#Store_to_load_forwarding"">store forwarding</a>.</li>
</ul>

<p>AVX and AVX2 doesn't extend the SSE4.1 instructions to allow accessing elements in a 256-bit vector. And as far as I can tell, AVX512 will not have it for 512-bit vectors.</p>

<p>Likewise, the set intrinsics (such as <code>_mm256_set_pd()</code>) suffer the same issue. They are implemented either as a series of data shuffling operations. Or by going through memory and taking on the store forwarding stalls.</p>

<hr>

<p>Which begs the question: <em>Is there an efficient way to populate a SIMD vector from scalar components? (or separate a SIMD vector into scalar components)</em></p>

<p>Short Answer: Not really. When you use SIMD, you're expected to do a lot of the work in the vectorized form. So the initialization overhead should not matter.</p>
"
"<p>I was doing some small programs in java. I know that if I write <strong><code>while(true);</code> the program will freeze in this loop</strong>. If the code is like that:</p>

<h2><strong>Test 1:</strong></h2>

<pre><code>public class While {
    public static void main(String[] args) {
        System.out.println(""start"");
        while (true);
        System.out.println(""end"");
    }
}
</code></pre>

<p><strong><em>The compiler throws me the error:</em></strong></p>

<pre><code>Exception in thread ""main"" java.lang.Error: Unresolved compilation problem: 
    Unreachable code
    at While.main(While.java:6)
</code></pre>

<p>I didn't know that this error exists. But I got why it is thrown. Of course, <strong>line 6 was unreachable</strong>, causing a compilation problem. Then I tested this:</p>

<h2><strong>Test 2:</strong></h2>

<pre><code>public class While {
    public static void main(String[] args) {
        System.out.println(""start"");
        a();
        b();
    }
    static void a() {
        while(true);
    }
    static void b() {
        System.out.println(""end"");
    }
}
</code></pre>

<p>For some reason <strong>the program ran normally</strong> (The console printed ""start"" and then froze). The compiler couldn't check inside of <strong><code>void a()</code></strong> and see that it isn't reachable. To be sure I tried:</p>

<h2><strong>Test 3:</strong></h2>

<pre><code>public class While {
    public static void main(String[] args) {
        System.out.println(""start"");
        a();
        System.out.println(""end"");
    }
    static void a() {
        while(true);
    }
}
</code></pre>

<p><strong>Same result as Test 2.</strong></p>

<p>After some research I found this <strong><a href=""http://stackoverflow.com/questions/20922371/unreachable-code-while-loop"">question</a></strong>. <em>So, if the code inside the parentheses is a variable the compiler wouldn't throw the exception</em>. That makes sense, but I don't think that the same applies to <strong><code>voids</code></strong>.</p>

<p><strong>Q:</strong> So, why does the compiler just throw me the error at Test 1, if <strong><code>void b()</code></strong> (Test 2) and <strong><code>System.out.println(""end"");</code></strong> (Test 3) isn't reachable?</p>

<p><strong>EDIT:</strong> I tried Test 1 in C++:</p>

<pre><code>#include &lt;iostream&gt;

using namespace std;

int main()
{
    cout &lt;&lt; ""start"" &lt;&lt; endl;
    while(true);
    cout &lt;&lt; ""end"" &lt;&lt; endl;
    return 0;
}
</code></pre>

<p><strong>The compiler didn't throw any errors</strong>, then I got the same result as Test 2 and as Test 3. So I suppose this is a java thing?</p>
","922184","","<p>In general, it is not possible to determine with absolute certainly whether or not something is reachable.</p>

<p>Why? It is the equivalent to the <a href=""http://en.wikipedia.org/wiki/Halting_problem"">Halting Problem</a>.</p>

<p>The halting problem asks:</p>

<blockquote>
  <p>Given a description of an arbitrary computer program, decide whether the program finishes running or continues to run forever.</p>
</blockquote>

<p>This problem has been proven to be unsolvable.</p>

<hr>

<p>Whether or not X piece of code is reachable is the same as saying whether the code before it will halt.</p>

<p>Because it is an unsolvable problem, the compiler (in Java or any other language) doesn't try very hard to solve it. If it happens to determine that it really is unreachable, then you get the warning. If not, it may or may not be reachable.</p>

<p>In Java, unreachable code is a compiler error. So in order to maintain compatibility, the language spec defines exactly ""how hard"" the compiler should try. (Which according to the other answers, is ""don't go inside another function"".)</p>

<p>In other languages (such as C++), the compiler may go further subject to optimizations. (Unreachable code may be detected after inlining the function and discovering that it never returns.)</p>
"
"<p>How ""sticky"" is the branch predictor logic? If code is being removed from the instruction caches, do the statistics stay with it?</p>

<p>Put another way, if the code is complex or not processing things in batch, is branch prediction still going to help?</p>

<p>Let's assume commodity Intel server hardware newer than 2011.</p>
","922184","","<p>The exact workings of branch predictors will vary between processors. But nearly all non-trivial branch predictors need a history of the branches in the program to function.</p>

<p>This history is recorded in the <strong>branch history buffer</strong>.</p>

<p>These come in multiple flavors. The two most commonly studied are:</p>

<ul>
<li><strong>Local History</strong> - which tracks the history of each individual branch.</li>
<li><strong>Global History</strong> - which tracks the combined history of all the branches.</li>
</ul>

<p>Modern processors will have multiple buffers for different purposes. In all cases, the buffers have a limited size. So when they run out of room, <em>something</em> will need to be evicted.</p>

<p>Neither Intel nor AMD gives details about their branch predictors. But it is believed that current processors from both companies can track thousands of branches along with their histories.</p>

<hr>

<p>Getting back to the point, the data that is used by the branch predictors will ""stick"" for as long as it stays in the history buffers. So the performance of the predictors is best if the code is small and well-behaved enough to not overrun the buffers.</p>

<ul>
<li>If most of the computation is spent in a small amount of code, the local history buffers will be able to track all the branches that are commonly hit.</li>
<li>If the computation is all over the place, there may be too many branches for the branch predictor to track and thus its performance will degrade.</li>
</ul>

<p>Note that the <em>instruction</em> and <em>uop</em> caches, while independent of the branch predictor, will exhibit the same effects. So it may be difficult to single out the branch predictor when attempting to construct test cases and benchmarks to study its behavior.</p>

<p>So this is yet another case in performance where having locality has advantages.</p>
"
"<p>(Note: Although this question is about ""store"", the ""load"" case has the same issues and is perfectly symmetric.)</p>

<p>The SSE intrinsics provide an <a href=""http://msdn.microsoft.com/en-us/library/7ek6y8w1(v=vs.90).aspx"" rel=""nofollow""><code>_mm_storeu_pd</code></a> function with the following signature:</p>

<pre><code>void _mm_storeu_pd (double *p, __m128d a);
</code></pre>

<p>So if I have vector of two doubles, and I want to store it to an array of two doubles, I can just use this intrinsic.</p>

<p>However, my vector is not two doubles; it is two 64-bit integers, and I want to store it to an array of two 64-bit integers. That is, I want a function with the following signature:</p>

<pre><code>void _mm_storeu_epi64 (int64_t *p, __m128i a);
</code></pre>

<p>But the intrinsics provide no such function. The closest they have is <a href=""http://msdn.microsoft.com/en-us/library/w1k1k29t(v=vs.90).aspx"" rel=""nofollow""><code>_mm_storeu_si128</code></a>:</p>

<pre><code>void _mm_storeu_si128 (__m128i *p, __m128i a);
</code></pre>

<p>The problem is that this function takes a pointer to <code>__m128i</code>, while my array is an array of <code>int64_t</code>. Writing to an object via the wrong type of pointer is a violation of <a href=""http://stackoverflow.com/questions/98650/"">strict aliasing</a> and is definitely undefined behavior. I am concerned that my compiler, now or in the future, will reorder or otherwise optimize away the store thus breaking my program in strange ways.</p>

<p>To be clear, what I want is a function I can invoke like this:</p>

<pre><code>__m128i v = _mm_set_epi64x(2,1);
int64_t ra[2];
_mm_storeu_epi64(&amp;ra[0], v); // does not exist, so I want to implement it
</code></pre>

<p>Here are six attempts to create such a function.</p>

<h2>Attempt #1</h2>

<pre><code>void _mm_storeu_epi64(int64_t *p, __m128i a) {
    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(p), a);
}
</code></pre>

<p>This appears to have the strict aliasing problem I am worried about.</p>

<h2>Attempt #2</h2>

<pre><code>void _mm_storeu_epi64(int64_t *p, __m128i a) {
    _mm_storeu_si128(static_cast&lt;__m128i *&gt;(static_cast&lt;void *&gt;(p)), a);
}
</code></pre>

<p><a href=""http://stackoverflow.com/questions/1863069/"">Possibly better in general</a>, but I do not think it makes any difference in this case.</p>

<h2>Attempt #3</h2>

<pre><code>void _mm_storeu_epi64(int64_t *p, __m128i a) {
    union TypePun {
        int64_t a[2];
        __m128i v;
     };
    TypePun *p_u = reinterpret_cast&lt;TypePun *&gt;(p);
    p_u-&gt;v = a;
}
</code></pre>

<p>This generates incorrect code on my compiler (GCC 4.9.0), which emits an aligned <code>movaps</code> instruction instead of an unaligned <code>movups</code>. (The union is aligned, so the <code>reinterpret_cast</code> tricks GCC into assuming <code>p_u</code> is aligned, too.)</p>

<h2>Attempt #4</h2>

<pre><code>void _mm_storeu_epi64(int64_t *p, __m128i a) {
    union TypePun {
        int64_t a[2];
        __m128i v;
     };
    TypePun *p_u = reinterpret_cast&lt;TypePun *&gt;(p);
    _mm_storeu_si128(&amp;p_u-&gt;v, a);
}
</code></pre>

<p>This appears to emit the code I want. The ""type-punning via union"" trick, although <a href=""http://stackoverflow.com/questions/11373203/"">technically undefined in C++</a>, is <a href=""http://stackoverflow.com/questions/346622/"">widely-supported</a>. But is this example -- where I pass a pointer to an element of a union rather than access via the union itself -- really a valid way to use the union for type-punning?</p>

<h2>Attempt #5</h2>

<pre><code>void _mm_storeu_epi64(int64_t *p, __m128i a) {
    p[0] = _mm_extract_epi64(a, 0);
    p[1] = _mm_extract_epi64(a, 1);
}
</code></pre>

<p>This works and is perfectly valid, but it emits two instructions instead of one.</p>

<h2>Attempt #6</h2>

<pre><code>void _mm_storeu_epi64(int64_t *p, __m128i a) {
    std::memcpy(p, &amp;a, sizeof(a));
}
</code></pre>

<p>This works and is perfectly valid... I think. But it emits frankly terrible code on my system. GCC spills <code>a</code> to an aligned stack slot via an aligned store, then manually moves the component words to the destination. (Actually it spills it twice, once for each component. Very strange.)</p>

<p>...</p>

<p>Is there any way to write this function that will (a) generate optimal code on a typical modern compiler and (b) have minimal risk of running afoul of strict aliasing?</p>
","922184","","<p>SSE intrinsics is one of those niche corner cases where you have to push the rules a bit.</p>

<p>Since these intrinsics are compiler extensions (somewhat standardized by Intel), they are already outside the specification of the C and C++ language standards. So it's somewhat self-defeating to try to be ""standard compliant"" while using a feature that clearly is not.</p>

<p>Despite the fact that the SSE intrinsic libraries try to act like normal 3rd party libraries, underneath, they are all specially handled by the compiler.</p>

<hr>

<p><strong>The Intent:</strong></p>

<p>The SSE intrinsics were likely designed from the beginning to allow aliasing between the vector and scalar types - since a vector really is just an aggregate of the scalar type.</p>

<p>But whoever designed the SSE intrinsics probably wasn't a language pedant.<br><sup>(That's not too surprising. Hard-core low-level performance programmers and language lawyering enthusiasts tend to be very different groups of people who don't always get along.)</sup></p>

<p>We can see evidence of this in the load/store intrinsics:</p>

<ul>
<li><code>__m128i _mm_stream_load_si128(__m128i* mem_addr)</code> - A load intrinsic that takes a non-const pointer?</li>
<li><code>void _mm_storeu_pd(double* mem_addr, __m128d a)</code> - What if I want to store to <code>__m128i*</code>?</li>
</ul>

<p>The strict aliasing problems are a direct result of these poor prototypes.</p>

<p>Starting from AVX512, the intrinsics have all been converted to <code>void*</code> to address this problem:</p>

<ul>
<li><code>__m512d _mm512_load_pd(void const* mem_addr)</code></li>
<li><code>void _mm512_store_epi64 (void* mem_addr, __m512i a)</code></li>
</ul>

<hr>

<p><strong>Compiler Specifics:</strong></p>

<ul>
<li><p>Visual Studio defines each of the SSE/AVX types as a union of the scalar types. This by itself allows strict-aliasing. Furthermore, Visual Studio doesn't do strict-aliasing so the point is moot:</p></li>
<li><p>The Intel Compiler has never failed me with all sorts of aliasing. It probably doesn't do strict-aliasing either - though I've never found any reliable source for this.</p></li>
<li><p>GCC does do strict-aliasing, but from my experience, not across function boundaries. It has never failed me to cast pointers which are passed in (on any type). GCC also declares SSE types as <code>__may_alias__</code> thereby explicitly allowing it to alias other types.</p></li>
</ul>

<hr>

<p><strong>My Recommendation:</strong></p>

<ul>
<li>For function parameters that are of the wrong pointer type, just cast it.</li>
<li>For variables declared and aliased on the stack, use a union. That union will already be aligned so you can read/write to them directly without intrinsics. (But be aware of store-forwarding issues that come with interleaving vector/scalar accesses.)</li>
<li>If you need to access a vector both as a whole and by its scalar components, consider using insert/extract intrinsics instead of aliasing.</li>
<li>When using GCC, turn on <code>-Wall</code> or <code>-Wstrict-aliasing</code>. It will tell you about strict-aliasing violations.</li>
</ul>
"
"<p>I was looking for the fastest way to <code>popcount</code> large arrays of data. I encountered a <em>very weird</em> effect: Changing the loop variable from <code>unsigned</code> to <code>uint64_t</code> made the performance drop by 50% on my PC.</p>

<h2>The Benchmark</h2>

<pre><code>#include &lt;iostream&gt;
#include &lt;chrono&gt;
#include &lt;x86intrin.h&gt;

int main(int argc, char* argv[]) {

    using namespace std;
    if (argc != 2) {
       cerr &lt;&lt; ""usage: array_size in MB"" &lt;&lt; endl;
       return -1;
    }

    uint64_t size = atol(argv[1])&lt;&lt;20;
    uint64_t* buffer = new uint64_t[size/8];
    char* charbuffer = reinterpret_cast&lt;char*&gt;(buffer);
    for (unsigned i=0; i&lt;size; ++i)
        charbuffer[i] = rand()%256;

    uint64_t count,duration;
    chrono::time_point&lt;chrono::system_clock&gt; startP,endP;
    {
        startP = chrono::system_clock::now();
        count = 0;
        for( unsigned k = 0; k &lt; 10000; k++){
            // Tight unrolled loop with unsigned
            for (unsigned i=0; i&lt;size/8; i+=4) {
                count += _mm_popcnt_u64(buffer[i]);
                count += _mm_popcnt_u64(buffer[i+1]);
                count += _mm_popcnt_u64(buffer[i+2]);
                count += _mm_popcnt_u64(buffer[i+3]);
            }
        }
        endP = chrono::system_clock::now();
        duration = chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(endP-startP).count();
        cout &lt;&lt; ""unsigned\t"" &lt;&lt; count &lt;&lt; '\t' &lt;&lt; (duration/1.0E9) &lt;&lt; "" sec \t""
             &lt;&lt; (10000.0*size)/(duration) &lt;&lt; "" GB/s"" &lt;&lt; endl;
    }
    {
        startP = chrono::system_clock::now();
        count=0;
        for( unsigned k = 0; k &lt; 10000; k++){
            // Tight unrolled loop with uint64_t
            for (uint64_t i=0;i&lt;size/8;i+=4) {
                count += _mm_popcnt_u64(buffer[i]);
                count += _mm_popcnt_u64(buffer[i+1]);
                count += _mm_popcnt_u64(buffer[i+2]);
                count += _mm_popcnt_u64(buffer[i+3]);
            }
        }
        endP = chrono::system_clock::now();
        duration = chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(endP-startP).count();
        cout &lt;&lt; ""uint64_t\t""  &lt;&lt; count &lt;&lt; '\t' &lt;&lt; (duration/1.0E9) &lt;&lt; "" sec \t""
             &lt;&lt; (10000.0*size)/(duration) &lt;&lt; "" GB/s"" &lt;&lt; endl;
    }

    free(charbuffer);
}
</code></pre>

<p>As you see, we create a buffer of random data, with the size being <code>x</code> megabytes where <code>x</code> is read from the command line. Afterwards, we iterate over the buffer and use an unrolled version of the x86 <code>popcount</code> intrinsic to perform the popcount. To get a more precise result, we do the popcount 10,000 times. We measure the times for the popcount. In the upper case, the inner loop variable is <code>unsigned</code>, in the lower case, the inner loop variable is <code>uint64_t</code>. I thought that this should make no difference, but the opposite is the case.</p>

<h2>The (absolutely crazy) results</h2>

<p>I compile it like this (g++ version: Ubuntu 4.8.2-19ubuntu1):</p>

<pre><code>g++ -O3 -march=native -std=c++11 test.cpp -o test
</code></pre>

<p>Here are the results on my <a href=""http://en.wikipedia.org/wiki/Haswell_%28microarchitecture%29"">Haswell</a> <a href=""http://en.wikipedia.org/wiki/Haswell_%28microarchitecture%29#Desktop_processors"">Core i7-4770K</a> CPU @ 3.50&nbsp;GHz, running <code>test 1</code> (so 1&nbsp;MB random data):</p>

<ul>
<li>unsigned  41959360000  0.401554 sec   <strong>26.113&nbsp;GB/s</strong></li>
<li>uint64_t  41959360000  0.759822 sec   <strong>13.8003&nbsp;GB/s</strong></li>
</ul>

<p>As you see, the throughput of the <code>uint64_t</code> version is <strong>only half</strong> the one of the <code>unsigned</code> version! The problem seems to be that different assembly gets generated, but why? First, I thought of a compiler bug, so I tried <code>clang++</code> (Ubuntu <a href=""http://en.wikipedia.org/wiki/Clang"">Clang</a> version 3.4-1ubuntu3):</p>

<pre><code>clang++ -O3 -march=native -std=c++11 teest.cpp -o test
</code></pre>

<p>Result: <code>test 1</code></p>

<ul>
<li>unsigned  41959360000  0.398293 sec   <strong>26.3267 GB/s</strong></li>
<li>uint64_t  41959360000  0.680954 sec   <strong>15.3986 GB/s</strong></li>
</ul>

<p>So, it is almost the same result and is still strange. <em>But now it gets super strange.</em> I replace the buffer size that was read from input with a constant <code>1</code>, so I change:</p>

<pre><code>uint64_t size = atol(argv[1]) &lt;&lt; 20;
</code></pre>

<p>to</p>

<pre><code>uint64_t size = 1 &lt;&lt; 20;
</code></pre>

<p>Thus, the compiler now knows the buffer size at compile time. Maybe it can add some optimizations! Here are the numbers for <code>g++</code>:</p>

<ul>
<li>unsigned  41959360000  0.509156 sec   <strong>20.5944&nbsp;GB/s</strong></li>
<li>uint64_t  41959360000  0.508673 sec   <strong>20.6139&nbsp;GB/s</strong></li>
</ul>

<p>Now, both versions are equally fast. However, the <code>unsigned</code> <strong>got even slower</strong>! It dropped from <code>26</code> to <code>20 GB/s</code>, thus replacing a non-constant by a constant value lead to a <strong>deoptimization</strong>. Seriously, I have no clue what is going on here! But now to <code>clang++</code> with the new version:</p>

<ul>
<li>unsigned  41959360000  0.677009 sec   <strong>15.4884&nbsp;GB/s</strong></li>
<li>uint64_t  41959360000  0.676909 sec   <strong>15.4906&nbsp;GB/s</strong></li>
</ul>

<p><em>Wait, what?</em> Now, both versions dropped to the <strong>slow</strong> number of 15&nbsp;GB/s. Thus, replacing a non-constant by a constant value even lead to slow code in <strong>both</strong> cases for Clang!</p>

<p>I asked a colleague with an <a href=""http://en.wikipedia.org/wiki/Ivy_Bridge_%28microarchitecture%29"">Ivy Bridge</a> CPU to compile my benchmark. He got similar results, so it does not seem to be Haswell. Because two compilers produce strange results here, it also does not seem to be a compiler bug. We do not have an AMD CPU here, so we could only test with Intel.</p>

<h2>More madness, please!</h2>

<p>Take the first example (the one with <code>atol(argv[1])</code>) and put a <code>static</code> before the variable, i.e.:</p>

<pre><code>static uint64_t size=atol(argv[1])&lt;&lt;20;
</code></pre>

<p>Here are my results in g++:</p>

<ul>
<li>unsigned  41959360000  0.396728 sec   <strong>26.4306 GB/s</strong></li>
<li>uint64_t  41959360000  0.509484 sec   <strong>20.5811 GB/s</strong></li>
</ul>

<p><em>Yay, yet another alternative</em>. We still have the fast 26&nbsp;GB/s with <code>u32</code>, but we managed to get <code>u64</code> at least from the 13&nbsp;GB/s to the 20&nbsp;GB/s version! <strong>On my collegue's PC, the <code>u64</code> version became even faster than the <code>u32</code> version, yielding the fastest result of all.</strong> Sadly, this only works for <code>g++</code>, <code>clang++</code> does not seem to care about <code>static</code>.</p>

<h2>My question</h2>

<p>Can you explain these results? Especially:</p>

<ul>
<li>How can there be such a difference between <code>u32</code> and <code>u64</code>?</li>
<li>How can replacing a non-constant by a constant buffer size trigger <em>less optimal code</em>?</li>
<li>How can the insertion of the <code>static</code> keyword make the <code>u64</code> loop faster? Even faster than the original code on my collegue's computer!</li>
</ul>

<p>I know that optimization is a tricky territory, however, I never thought that such small changes can lead to a <strong>100% difference</strong> in execution time and that small factors like a constant buffer size can again mix results totally. Of course, I always want to have the version that is able to popcount 26&nbsp;GB/s. The only reliable way I can think of is copy paste the assembly for this case and use inline assembly. This is the only way I can get rid of compilers that seem to go mad on small changes. What do you think? Is there another way to reliably get the code with most performance?</p>

<h2>The Disassembly</h2>

<p>Here is the disassembly for the various results:</p>

<p>26&nbsp;GB/s version from <strong>g++ / u32 / non-const bufsize</strong>:</p>

<pre><code>0x400af8:
lea 0x1(%rdx),%eax
popcnt (%rbx,%rax,8),%r9
lea 0x2(%rdx),%edi
popcnt (%rbx,%rcx,8),%rax
lea 0x3(%rdx),%esi
add %r9,%rax
popcnt (%rbx,%rdi,8),%rcx
add $0x4,%edx
add %rcx,%rax
popcnt (%rbx,%rsi,8),%rcx
add %rcx,%rax
mov %edx,%ecx
add %rax,%r14
cmp %rbp,%rcx
jb 0x400af8
</code></pre>

<p>13&nbsp;GB/s version from <strong>g++ / u64 / non-const bufsize</strong>:</p>

<pre><code>0x400c00:
popcnt 0x8(%rbx,%rdx,8),%rcx
popcnt (%rbx,%rdx,8),%rax
add %rcx,%rax
popcnt 0x10(%rbx,%rdx,8),%rcx
add %rcx,%rax
popcnt 0x18(%rbx,%rdx,8),%rcx
add $0x4,%rdx
add %rcx,%rax
add %rax,%r12
cmp %rbp,%rdx
jb 0x400c00
</code></pre>

<p>15&nbsp;GB/s version from <strong>clang++ / u64 / non-const bufsize</strong>:</p>

<pre><code>0x400e50:
popcnt (%r15,%rcx,8),%rdx
add %rbx,%rdx
popcnt 0x8(%r15,%rcx,8),%rsi
add %rdx,%rsi
popcnt 0x10(%r15,%rcx,8),%rdx
add %rsi,%rdx
popcnt 0x18(%r15,%rcx,8),%rbx
add %rdx,%rbx
add $0x4,%rcx
cmp %rbp,%rcx
jb 0x400e50
</code></pre>

<p>20&nbsp;GB/s version from <strong>g++ / u32&amp;u64 / const bufsize</strong>:</p>

<pre><code>0x400a68:
popcnt (%rbx,%rdx,1),%rax
popcnt 0x8(%rbx,%rdx,1),%rcx
add %rax,%rcx
popcnt 0x10(%rbx,%rdx,1),%rax
add %rax,%rcx
popcnt 0x18(%rbx,%rdx,1),%rsi
add $0x20,%rdx
add %rsi,%rcx
add %rcx,%rbp
cmp $0x100000,%rdx
jne 0x400a68
</code></pre>

<p>15&nbsp;GB/s version from <strong>clang++ / u32&amp;u64 / const bufsize</strong>:</p>

<pre><code>0x400dd0:
popcnt (%r14,%rcx,8),%rdx
add %rbx,%rdx
popcnt 0x8(%r14,%rcx,8),%rsi
add %rdx,%rsi
popcnt 0x10(%r14,%rcx,8),%rdx
add %rsi,%rdx
popcnt 0x18(%r14,%rcx,8),%rbx
add %rdx,%rbx
add $0x4,%rcx
cmp $0x20000,%rcx
jb 0x400dd0
</code></pre>

<p>Interestingly, the fastest (26&nbsp;GB/s) version is also the longest! It seems to be the only solution that uses <code>lea</code>. Some versions use <code>jb</code> to jump, others use <code>jne</code>. But apart from that, all versions seem to be comparable. I don't see where a 100% performance gap could originate from, but I am not too adept at deciphering assembly. The slowest (13&nbsp;GB/s) version looks even very short and good. Can anyone explain this?</p>

<h2>Lessons learned</h2>

<p>No matter what the answer to this question will be; I have learned that in really hot loops <em>every</em> detail can matter, <em>even details that do not seem to have any association to the hot code</em>. I have never thought about what type to use for a loop variable, but as you see such a minor change can make a <em>100%</em> difference! Even the storage type of a buffer can make a huge difference, as we saw with the insertion of the <code>static</code> keyword in front of the size variable! In the future, I will always test various alternatives on various compilers when writing really tight and hot loops that are crucial for system performance.</p>

<p>The interesting thing is also that the performance difference is still so high although I have already unrolled the loop four times. So even if you unroll, you can still get hit by major performance deviations. Quite interesting.</p>
","922184","","<p><strong>Culprit: False Data Dependency</strong> (and the compiler isn't even aware of it)</p>

<p>On Sandy/Ivy Bridge and Haswell processors, the instruction:</p>

<pre><code>popcnt src, dest
</code></pre>

<p>appears to have a false dependency on the destination register <code>dest</code>. Even though the instruction only writes to it, the instruction will wait until <code>dest</code> is ready before executing.</p>

<p>This dependency doesn't just hold up the 4 <code>popcnt</code>s from a single loop iteration. It can carry across loop iterations making it impossible for the processor to parallelize different loop iterations.</p>

<p>The <code>unsigned</code> vs. <code>uint64_t</code> and other tweaks don't directly affect the problem. But they influence the register allocator which assigns the registers to the variables.</p>

<p>In your case, the speeds are a direct result of what is stuck to the (false) dependency chain depending on what the register allocator decided to do.</p>

<ul>
<li>13 GB/s has a chain: popcnt-add-popcnt-popcnt --> next iteration</li>
<li>15 GB/s has a chain: popcnt-add-popcnt-add --> next iteration</li>
<li>20 GB/s has a chain: popcnt-popcnt --> next iteration</li>
<li>26 GB/s has a chain: popcnt-popcnt --> next iteration</li>
</ul>

<p>The difference between 20 GB/s and 26 GB/s seems to be a minor artifact of the indirect addressing. Either way, the processor starts to hit other bottlenecks once you reach this speed.</p>

<hr>

<p>To test this, I used inline assembly to bypass the compiler and get exactly the assembly I want. I also split up the <code>count</code> variable to break all other dependencies that might mess with the benchmarks.</p>

<p>Here are the results:</p>

<p><strong>Sandy Bridge Xeon @ 3.5 GHz:</strong> (full test code can be found at the bottom)</p>

<ul>
<li>GCC 4.6.3: <code>g++ popcnt.cpp -std=c++0x -O3 -save-temps -march=native</code></li>
<li>Ubuntu 12</li>
</ul>

<p>Different Registers: <strong>18.6195 GB/s</strong></p>

<pre><code>.L4:
    movq    (%rbx,%rax,8), %r8
    movq    8(%rbx,%rax,8), %r9
    movq    16(%rbx,%rax,8), %r10
    movq    24(%rbx,%rax,8), %r11
    addq    $4, %rax

    popcnt %r8, %r8
    add    %r8, %rdx
    popcnt %r9, %r9
    add    %r9, %rcx
    popcnt %r10, %r10
    add    %r10, %rdi
    popcnt %r11, %r11
    add    %r11, %rsi

    cmpq    $131072, %rax
    jne .L4
</code></pre>

<p>Same Register: <strong>8.49272 GB/s</strong></p>

<pre><code>.L9:
    movq    (%rbx,%rdx,8), %r9
    movq    8(%rbx,%rdx,8), %r10
    movq    16(%rbx,%rdx,8), %r11
    movq    24(%rbx,%rdx,8), %rbp
    addq    $4, %rdx

    # This time reuse ""rax"" for all the popcnts.
    popcnt %r9, %rax
    add    %rax, %rcx
    popcnt %r10, %rax
    add    %rax, %rsi
    popcnt %r11, %rax
    add    %rax, %r8
    popcnt %rbp, %rax
    add    %rax, %rdi

    cmpq    $131072, %rdx
    jne .L9
</code></pre>

<p>Same Register with broken chain: <strong>17.8869 GB/s</strong></p>

<pre><code>.L14:
    movq    (%rbx,%rdx,8), %r9
    movq    8(%rbx,%rdx,8), %r10
    movq    16(%rbx,%rdx,8), %r11
    movq    24(%rbx,%rdx,8), %rbp
    addq    $4, %rdx

    # Reuse ""rax"" for all the popcnts.
    xor    %rax, %rax    # Break the cross-iteration dependency by zeroing ""rax"".
    popcnt %r9, %rax
    add    %rax, %rcx
    popcnt %r10, %rax
    add    %rax, %rsi
    popcnt %r11, %rax
    add    %rax, %r8
    popcnt %rbp, %rax
    add    %rax, %rdi

    cmpq    $131072, %rdx
    jne .L14
</code></pre>

<hr>

<p><strong>So what went wrong with the compiler?</strong></p>

<p>It seems that neither GCC, nor Visual Studio are aware that <code>popcnt</code> has such a false dependency. Nevertheless, these false dependencies aren't uncommon. It's just a matter of whether the compiler is aware of it.</p>

<p><code>popcnt</code> isn't exactly the most used instruction. So it's not really a surprise that a major compiler could miss something like this. There also appears to be no documentation anywhere that mentions this problem. If Intel doesn't disclose it, then nobody outside will know until someone runs into it by chance.</p>

<p><strong>Why does the CPU have such a false dependency?</strong></p>

<p>We can only speculate, but it's likely that Intel has the same handling for a lot of two-operand instructions. Common instructions like <code>add</code>, <code>sub</code> take two operands both of which are inputs. So Intel probably shoved <code>popcnt</code> into the same category to keep the processor design simple.</p>

<p>AMD processors do not appear to have this false dependency.</p>

<hr>

<p>The full test code is below for reference:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;chrono&gt;
#include &lt;x86intrin.h&gt;

int main(int argc, char* argv[]) {

   using namespace std;
   uint64_t size=1&lt;&lt;20;

   uint64_t* buffer = new uint64_t[size/8];
   char* charbuffer=reinterpret_cast&lt;char*&gt;(buffer);
   for (unsigned i=0;i&lt;size;++i) charbuffer[i]=rand()%256;

   uint64_t count,duration;
   chrono::time_point&lt;chrono::system_clock&gt; startP,endP;
   {
      uint64_t c0 = 0;
      uint64_t c1 = 0;
      uint64_t c2 = 0;
      uint64_t c3 = 0;
      startP = chrono::system_clock::now();
      for( unsigned k = 0; k &lt; 10000; k++){
         for (uint64_t i=0;i&lt;size/8;i+=4) {
            uint64_t r0 = buffer[i + 0];
            uint64_t r1 = buffer[i + 1];
            uint64_t r2 = buffer[i + 2];
            uint64_t r3 = buffer[i + 3];
            __asm__(
                ""popcnt %4, %4  \n\t""
                ""add %4, %0     \n\t""
                ""popcnt %5, %5  \n\t""
                ""add %5, %1     \n\t""
                ""popcnt %6, %6  \n\t""
                ""add %6, %2     \n\t""
                ""popcnt %7, %7  \n\t""
                ""add %7, %3     \n\t""
                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)
                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)
            );
         }
      }
      count = c0 + c1 + c2 + c3;
      endP = chrono::system_clock::now();
      duration=chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(endP-startP).count();
      cout &lt;&lt; ""No Chain\t"" &lt;&lt; count &lt;&lt; '\t' &lt;&lt; (duration/1.0E9) &lt;&lt; "" sec \t""
            &lt;&lt; (10000.0*size)/(duration) &lt;&lt; "" GB/s"" &lt;&lt; endl;
   }
   {
      uint64_t c0 = 0;
      uint64_t c1 = 0;
      uint64_t c2 = 0;
      uint64_t c3 = 0;
      startP = chrono::system_clock::now();
      for( unsigned k = 0; k &lt; 10000; k++){
         for (uint64_t i=0;i&lt;size/8;i+=4) {
            uint64_t r0 = buffer[i + 0];
            uint64_t r1 = buffer[i + 1];
            uint64_t r2 = buffer[i + 2];
            uint64_t r3 = buffer[i + 3];
            __asm__(
                ""popcnt %4, %%rax   \n\t""
                ""add %%rax, %0      \n\t""
                ""popcnt %5, %%rax   \n\t""
                ""add %%rax, %1      \n\t""
                ""popcnt %6, %%rax   \n\t""
                ""add %%rax, %2      \n\t""
                ""popcnt %7, %%rax   \n\t""
                ""add %%rax, %3      \n\t""
                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)
                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)
                : ""rax""
            );
         }
      }
      count = c0 + c1 + c2 + c3;
      endP = chrono::system_clock::now();
      duration=chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(endP-startP).count();
      cout &lt;&lt; ""Chain 4   \t""  &lt;&lt; count &lt;&lt; '\t' &lt;&lt; (duration/1.0E9) &lt;&lt; "" sec \t""
            &lt;&lt; (10000.0*size)/(duration) &lt;&lt; "" GB/s"" &lt;&lt; endl;
   }
   {
      uint64_t c0 = 0;
      uint64_t c1 = 0;
      uint64_t c2 = 0;
      uint64_t c3 = 0;
      startP = chrono::system_clock::now();
      for( unsigned k = 0; k &lt; 10000; k++){
         for (uint64_t i=0;i&lt;size/8;i+=4) {
            uint64_t r0 = buffer[i + 0];
            uint64_t r1 = buffer[i + 1];
            uint64_t r2 = buffer[i + 2];
            uint64_t r3 = buffer[i + 3];
            __asm__(
                ""xor %%rax, %%rax   \n\t""   // &lt;--- Break the chain.
                ""popcnt %4, %%rax   \n\t""
                ""add %%rax, %0      \n\t""
                ""popcnt %5, %%rax   \n\t""
                ""add %%rax, %1      \n\t""
                ""popcnt %6, %%rax   \n\t""
                ""add %%rax, %2      \n\t""
                ""popcnt %7, %%rax   \n\t""
                ""add %%rax, %3      \n\t""
                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)
                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)
                : ""rax""
            );
         }
      }
      count = c0 + c1 + c2 + c3;
      endP = chrono::system_clock::now();
      duration=chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(endP-startP).count();
      cout &lt;&lt; ""Broken Chain\t""  &lt;&lt; count &lt;&lt; '\t' &lt;&lt; (duration/1.0E9) &lt;&lt; "" sec \t""
            &lt;&lt; (10000.0*size)/(duration) &lt;&lt; "" GB/s"" &lt;&lt; endl;
   }

   free(charbuffer);
}
</code></pre>

<hr>

<p>An equally interesting benchmark can be found here: <a href=""http://pastebin.com/kbzgL8si"">http://pastebin.com/kbzgL8si</a>
<br>
This benchmark varies the number of <code>popcnt</code>s that are in the (false) dependency chain.</p>

<pre><code>False Chain 0:  41959360000 0.57748 sec     18.1578 GB/s
False Chain 1:  41959360000 0.585398 sec    17.9122 GB/s
False Chain 2:  41959360000 0.645483 sec    16.2448 GB/s
False Chain 3:  41959360000 0.929718 sec    11.2784 GB/s
False Chain 4:  41959360000 1.23572 sec     8.48557 GB/s
</code></pre>
"